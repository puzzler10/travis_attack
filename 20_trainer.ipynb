{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp trainer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import torch, wandb, gc, numpy as np, pandas as pd,os\n",
    "from wandb.data_types import Histogram\n",
    "from tqdm.auto import tqdm\n",
    "from travis_attack.utils import timecode, show_gpu, merge_dicts, unpack_nested_lists_in_df, display_all\n",
    "from travis_attack.tests import check_no_nans_or_infs\n",
    "from travis_attack.models import save_pp_model, resume_pp_model, get_vm_probs, get_start_end_special_token_ids\n",
    "from travis_attack.charts import plot_grad_flow, plot_examples_chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import torch, numpy as np, pandas as pd, gc,sys, logging, warnings\n",
    "from torch.utils.data import DataLoader, RandomSampler\n",
    "from datasets import load_dataset, load_metric, load_from_disk, DatasetDict\n",
    "from transformers import (AutoModelForSeq2SeqLM, AutoModelForSequenceClassification, \n",
    "                          AutoTokenizer, AdamW, SchedulerType, get_scheduler)\n",
    "from torch.distributions import Categorical\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers.util import pytorch_cos_sim\n",
    "from collections import defaultdict\n",
    "from accelerate import Accelerator, notebook_launcher\n",
    "from cachetools import cached, LRUCache\n",
    "from types import MethodType\n",
    "from timeit import default_timer as timer\n",
    "from tqdm.auto import tqdm\n",
    "import itertools\n",
    "import copy \n",
    "import wandb\n",
    "from undecorated import undecorated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from travis_attack.utils import set_seed, set_session_options, prepare_logger\n",
    "from travis_attack.config import Config\n",
    "from travis_attack.models import prepare_models, get_optimizer\n",
    "from travis_attack.data import ProcessedDataset\n",
    "from accelerate import Accelerator, notebook_launcher\n",
    "from fastcore.basics import store_attr\n",
    "from IPython.core.debugger import set_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-b253756c445fb811\n",
      "Reusing dataset csv (/data/tproth/.cache/huggingface/datasets/csv/default-b253756c445fb811/0.0.0/bf68a4c4aefa545d0712b2fcbb1b327f905bbe2f6425fbc5e8c25234acb9e14a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dec6c447781a4e1d895cff353cf16b41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-c802946231f72062\n",
      "Reusing dataset csv (/data/tproth/.cache/huggingface/datasets/csv/default-c802946231f72062/0.0.0/bf68a4c4aefa545d0712b2fcbb1b327f905bbe2f6425fbc5e8c25234acb9e14a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2de91bb81a84b6fb1533837cb3f3ebf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-43a49c5188c42e69\n",
      "Reusing dataset csv (/data/tproth/.cache/huggingface/datasets/csv/default-43a49c5188c42e69/0.0.0/bf68a4c4aefa545d0712b2fcbb1b327f905bbe2f6425fbc5e8c25234acb9e14a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82cf4fed7a214c108e9f665d118a5370",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function ProcessedDataset._add_idx at 0x2b297aba43a0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68c383c9b7a345dcb6d3a42617844dad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9f9ad06f6a8442e89ddb53229fe4953",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e7daf1e3eb54466ac779713acb12b34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "457e568192c74c22b1ddab70832e06de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79460ea8379c410794d5f48e652f0729",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a16163c6b1884c06ba810cd769df4d85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7845bdfb66ce47e3ba3ecfd64f9f9649",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36ca2c25c7004751a2dd3da800105380",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "392c2a1a0b4e43b1a1c1aecce0af8806",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9774e32586f44189ee5f299b08607f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6eccc87d8ec491c96552be770cbc2b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33d6a8aa0f7c4d23a51f2bb189965d3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0bdd1043f7f4953b323b76b878292ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a679126fea5b4b85bdf441634c0354b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f413b6b900bd4ef8a11153c372645b52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1eafcb33ec104828a3e5ec9892595c92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "118d4b421f9242379df1fb231cf2be1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0732d8e6eefd47b1bc66c084907c2e1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89557924a57c48209735fb2b82c05259",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6b778ed89d84c5bb7a7c3b8c5d198e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d87789b63ca443af8423ffabf4b55581",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#hide\n",
    "accelerator = Accelerator()\n",
    "cfg = Config()\n",
    "cfg.device = accelerator.device\n",
    "set_seed(cfg.seed)\n",
    "set_session_options()\n",
    "logger = prepare_logger()\n",
    "vm_tokenizer, vm_model, pp_tokenizer, pp_model, sts_model, cfg = prepare_models(cfg)\n",
    "optimizer = get_optimizer(cfg, pp_model)\n",
    "ds = ProcessedDataset(cfg, vm_tokenizer, vm_model, pp_tokenizer, sts_model)\n",
    "vm_model,pp_model,sts_model,optimizer,ds.dld_tkn['train'] = accelerator.prepare(vm_model,pp_model,sts_model,optimizer,ds.dld_tkn['train'])\n",
    "cfg.n_train_steps = cfg.n_train_epochs * len(ds.dld_tkn['train'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This class is used to fine-tune the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "class Trainer: \n",
    "    def __init__(self, cfg, vm_tokenizer, vm_model, pp_tokenizer, pp_model, sts_model, optimizer, accelerator, ds,\n",
    "                logger): \n",
    "        store_attr()\n",
    "        self._cfg = self.cfg; del self.cfg;\n",
    "        self.accumulation_num,self.global_step = 0,0\n",
    "        # train_batch_d holds all info to write to csv, time_d has times, wandb_d has everything to log to wandb\n",
    "        # there will be overlap between them. \n",
    "        self.train_batch_d,self.train_batch_time_d,self.wandb_log_d = dict(),dict(),dict()\n",
    "        #resume_pp_model(f\"{path_checkpoints}devout-durian-172_39\")\n",
    "        self._setup_wandb_run()\n",
    "        self._setup_data_stores()\n",
    "        if self._cfg.wandb['plot_examples']: self._setup_wandb_examples_plots()\n",
    "        self.start_end_token_d = get_start_end_special_token_ids(self.pp_tokenizer)\n",
    "        ## TODO: why is num_processes set to 1?\n",
    "        #%lprun -f training_function -f  get_pp_logp -f training_step -f  reward_fn -f  loss_fn -f eval_dl  notebook_launcher(training_function, args=(pp_model, vm_model, dld_tkn, dld_raw, optimizer), num_processes=1, use_fp16=use_fp16)\n",
    "        notebook_launcher(self.training_function, args=(), \n",
    "                           num_processes=1, use_fp16=self._cfg.use_fp16)\n",
    "        \n",
    "    def _setup_wandb_run(self): \n",
    "        \"\"\"Init wandb run, set up paths, create dir for model artifacts if needed, \"\"\"\n",
    "        ## TODO: set notebook name and add in save_code \n",
    "        self.run = wandb.init(project=self._cfg.wandb['project'], entity=self._cfg.wandb['entity'], \n",
    "                              config=vars(self._cfg), mode=self._cfg.wandb['mode'],\n",
    "                              notes=self._cfg.wandb['run_notes'])\n",
    "        if self._cfg.wandb['log_grads']: \n",
    "            wandb.watch(self.pp_model, log='gradients', log_freq=self._cfg.wandb['log_grads_freq'])\n",
    "        self._cfg.run_name,self._cfg.run_id = self.run.name, self.run.id\n",
    "        self._cfg.path_run = f\"{self._cfg.path_checkpoints}{self.run.name}/\"\n",
    "        if not os.path.exists(self._cfg.path_run): os.makedirs(self._cfg.path_run, exist_ok=True)\n",
    "    \n",
    "    def _setup_data_stores(self): \n",
    "        \"\"\"Setup dict `self.data_d` to store observations. Setup column names for wandb tables. \"\"\"\n",
    "        # Raw observation data (lists of dicts, later becomes pandas df)\n",
    "        self.data_d = dict()\n",
    "        # These have to be in the keys of the output from eval_dl\n",
    "        self.table_columns = ['idx', 'orig_l',  'truelabel', 'orig_truelabel_probs', 'epoch', 'pp_l',\n",
    "                     'pp_truelabel_probs', \"pp_predclass\", \"pp_predclass_probs\"] + self._cfg.metrics\n",
    "        for split in self._cfg.splits + ['training_step']:   self.data_d[split] = [] \n",
    "    \n",
    "    def _setup_wandb_examples_plots(self): \n",
    "        \"\"\"If we plot a few examples this sets that up.\"\"\"\n",
    "        def get_examples_plot_idxs(dataset): \n",
    "            \"\"\"Get data indices for the examples plots\"\"\"\n",
    "            return np.random.choice(dataset['idx'], size=self._cfg.wandb['n_examples_plot'], replace=False).tolist()\n",
    "        self.plt_idx_d = dict()\n",
    "        for split in self._cfg.splits:  self.plt_idx_d[split] = get_examples_plot_idxs(self.ds.dsd[split])\n",
    "\n",
    "    def training_function(self): \n",
    "        self.logger.debug(show_gpu(f'GPU memory usage after loading models:'))\n",
    "        progress_bar = tqdm(range(self._cfg.n_train_steps))\n",
    "        self.pp_model.zero_grad(set_to_none=self._cfg.zero_grad_with_none) \n",
    "        for self.epoch in range(self._cfg.n_train_epochs): \n",
    "            self.logger.info(f\"Now on epoch {self.epoch} of {self._cfg.n_train_epochs}\")\n",
    "            if not self.pp_model.training: self.pp_model.train()\n",
    "            with timecode() as time_train_one_epoch:\n",
    "                for self.batch_num, (data, raw) in enumerate(zip(self.ds.dld_tkn['train'], self.ds.dld_raw['train'])): \n",
    "                    self.training_step(data, raw) \n",
    "                    self.accumulation_num += 1  ; self.global_step += 1 ;  progress_bar.update(1) \n",
    "                    self.train_batch_d,self.train_batch_time_d,self.wandb_log_d = dict(),dict(),dict()\n",
    "                    \n",
    "            wandb.log({'time/train_one_epoch_time': time_train_one_epoch.t,\n",
    "                       'time/train_one_epoch_thoroughput': len(self.ds.dsd_tkn['train']) / time_train_one_epoch.t,\n",
    "                       'epoch': self.epoch}, commit=True)\n",
    "\n",
    "            if self._cfg.wandb['log_grads'] and self.epoch % self._cfg.wandb_log_grads_freq == 0: \n",
    "                plt = plot_grad_flow(self.pp_model.named_parameters())\n",
    "                wandb.log({\"gradient flow\": wandb.Image(plt)})  # doesn't work as a non-image (i.e. plotly)\n",
    "                del plt \n",
    "            #gc.collect() \n",
    "            #torch.cuda.empty_cache()\n",
    "\n",
    "            if self._cfg.save_model_while_training and (self.epoch + 1) % self._cfg.save_model_freq == 0:  save_model(epoch)\n",
    "\n",
    "            # Evaluation loop\n",
    "            if self.epoch % self._cfg.eval_freq == 0: \n",
    "                with timecode() as time_eval_train:\n",
    "                    train_set_preds = self.eval_dl(dl_tkn=self.ds.dld_tkn['train_eval'], \n",
    "                                                   dl_raw=self.ds.dld_raw['train_eval'])\n",
    "\n",
    "                with timecode() as time_eval_valid:\n",
    "                    valid_set_preds = self.eval_dl(dl_tkn=self.ds.dld_tkn['valid'],\n",
    "                                                   dl_raw=self.ds.dld_raw['valid'])\n",
    "                with timecode() as time_add_eval_preds_to_data_d:    \n",
    "                    self.add_preds_to_data_d(train_set_preds, split='train')\n",
    "                    self.add_preds_to_data_d(valid_set_preds, split='valid')\n",
    "                self.plot_wandb_charts()\n",
    "                del train_set_preds, valid_set_preds\n",
    "                with timecode() as time_eval_gc_collect:\n",
    "                    gc.collect() \n",
    "                with timecode() as time_eval_empty_cache:\n",
    "                    torch.cuda.empty_cache()\n",
    "                wandb.log({'time/eval_train_time': time_eval_train.t, 'time/eval_valid_time': time_eval_valid.t,\n",
    "                           'time/eval_train_thoroughput': len(self.ds.dsd_tkn['train']) / time_eval_train.t,\n",
    "                           'time/eval_valid_thoroughput': len(self.ds.dsd_tkn['valid']) / time_eval_valid.t, \n",
    "                           'time/eval_add_preds_to_data_d': time_add_eval_preds_to_data_d.t,\n",
    "                           'time/eval_gc_collect': time_eval_gc_collect.t, \n",
    "                           'time/eval_empty_cache': time_eval_empty_cache.t,\n",
    "                   'epoch': self.epoch}, commit=True)\n",
    "        # Eval on test set \n",
    "        test_set_preds = self.eval_dl(dl_tkn = self.ds.dld_tkn['test'], dl_raw=self.ds.dld_raw['test'])\n",
    "        self.add_preds_to_data_d(test_set_preds, split='test')\n",
    "\n",
    "        # Data -> df and save dfs to file \n",
    "        for key in self.data_d.keys():  # splits and sometimes 'training_step' too \n",
    "            if key == \"training_step\": self.data_d[key] = self._convert_data_d_training_step_to_df()\n",
    "            self.data_d[key] = pd.DataFrame(self.data_d[key]) # dict of list of dict -> dict of dataframe\n",
    "            self.data_d[key].to_csv(f\"{self._cfg.path_run}{key}.csv\", index=False)\n",
    "        \n",
    "        # plot_wandb_charts()  # don't think I need this\n",
    "        self.add_wandb_run_summary_statistics()     \n",
    "        \n",
    "        self.run.finish()\n",
    "        \n",
    "    def training_step(self, data, raw): \n",
    "        \"\"\"Forward pass, loss function, backwards pass, parameter update (with gradient accumulation optional), \n",
    "        recording results, wandb logging. \n",
    "        \"\"\"\n",
    "        with timecode() as self.train_batch_time_d['time_generate_pp']:\n",
    "            pp_output, pp_l = self.pp_model_forward(data)\n",
    "\n",
    "        logger.debug(show_gpu(f'TRAIN, epoch {self.epoch}, batch {self.batch_num}, GPU memory usage after forward pass: '))\n",
    "\n",
    "        with self.accelerator.autocast():\n",
    "            with timecode() as self.train_batch_time_d['time_loss_fn']:\n",
    "                results_d = self.loss_fn(data, raw, pp_output, pp_l, return_components=True)\n",
    "            loss_batch = results_d['loss_batch'] / self._cfg.accumulation_steps  # Normalize our loss for gradient accumulation\n",
    "\n",
    "        with timecode() as self.train_batch_time_d['time_backwards']:\n",
    "            self.accelerator.backward(loss_batch) \n",
    "\n",
    "        logger.debug(show_gpu(f'TRAIN, epoch {self.epoch}, batch {self.batch_num}, GPU memory usage after backwards pass: '))\n",
    "        if (self.accumulation_num + 1) % self._cfg.accumulation_steps == 0: \n",
    "            with timecode() as self.train_batch_time_d['time_opt_step']:\n",
    "                self.optimizer.step()\n",
    "            self.pp_model.zero_grad(set_to_none=self._cfg.zero_grad_with_none)\n",
    "            \n",
    "        self._prepare_train_batch_d(raw, data, pp_l)\n",
    "        self.data_d['training_step'].append(self.train_batch_d)\n",
    "        \n",
    "        self._wandb_log_training_step()\n",
    "    \n",
    "    def add_preds_to_data_d(self, results_d, split):\n",
    "        \"\"\"TO DELETE\"\"\"\n",
    "        assert split in self.data_d.keys() \n",
    "        d1 = results_d\n",
    "        d1['epoch'] = [self.epoch for i in range(len(d1['pp_l']))]\n",
    "        dcols = [d1[c] for c in self.table_columns]  # filter out loss_batch\n",
    "        assert len(set([len(o) for o in dcols])) == 1  # all lists should be of the same length \n",
    "        for row in zip(*dcols):\n",
    "            d2 = {k:v for k,v in zip(self.table_columns,row)}\n",
    "            self.data_d[split].append(d2)\n",
    "    \n",
    "    def _prepare_train_batch_d(self, raw, data, pp_l): \n",
    "        # Add basics. (results are already added elsewhere)\n",
    "        self.train_batch_d = merge_dicts(self.train_batch_d, { 'idx': raw['idx'],\n",
    "            'epoch': self.epoch, 'batch_num': self.batch_num, 'global_step': self.global_step,\n",
    "            'accumulation_num': self.accumulation_num,  \"orig_l\": raw['text'], \n",
    "            \"orig_label\": data['label'].cpu().tolist(), \n",
    "            \"orig_truelabel_probs\": data['orig_truelabel_probs'].cpu().tolist(),\n",
    "            'orig_length': self.orig_length, 'orig_batch_size': self.orig_batch_size, \n",
    "            \"pp_l\": pp_l, 'pp_length': self.pp_length, 'pp_batch_size': self.pp_batch_size\n",
    "        })\n",
    "        # Add times\n",
    "        for k, v in self.train_batch_time_d.items(): self.train_batch_time_d[k] = v.t  # extract time from timecode object\n",
    "        self.train_batch_d = merge_dicts(self.train_batch_d, self.train_batch_time_d)\n",
    "    \n",
    "    def _wandb_log_training_step(self): \n",
    "        self.wandb_log_d = merge_dicts(self.wandb_log_d, {\n",
    "            'vm_scores_hist':       Histogram(self.train_batch_d['vm_score']), \n",
    "            'vm_scores_mean':       np.mean(  self.train_batch_d['vm_score']),\n",
    "            'sts_scores_hist':      Histogram(self.train_batch_d['sts_score']),\n",
    "            'sts_scores_mean':      np.mean(  self.train_batch_d['sts_score']), \n",
    "            'rewards_hist':         Histogram(self.train_batch_d['reward']),\n",
    "            'rewards_mean':         np.mean(  self.train_batch_d['reward']), \n",
    "            'pp_logp_hist':         Histogram(self.train_batch_d['pp_logp']),\n",
    "            'pp_logp_mean':         np.mean(  self.train_batch_d['pp_logp']),\n",
    "            'loss_hist'   :         Histogram(self.train_batch_d['loss'])})\n",
    "        self.wandb_log_d = merge_dicts(self.wandb_log_d, self.train_batch_d)\n",
    "        not_for_wandb_keys = ['orig_l', 'orig_label','orig_truelabel_probs', 'pp_l', 'loss', 'pp_logp', \n",
    "                              'reward', 'sts_score', 'vm_score',\n",
    "                              'pp_predclass_probs', 'label_flip', 'pp_predclass', 'pp_truelabel_probs']\n",
    "        for k in not_for_wandb_keys:  self.wandb_log_d.pop(k, None)\n",
    "        wandb.log(self.wandb_log_d, commit=True)\n",
    "        \n",
    "    def _convert_data_d_training_step_to_df(self): \n",
    "        df = pd.DataFrame(self.data_d['training_step']) \n",
    "        # check all lists have the same number of elements\n",
    "        nonscalar_cols = df.columns[[o == np.dtype('object') for o in df.head(1).dtypes]].tolist()\n",
    "        assert (df[nonscalar_cols].applymap(len) == cfg.batch_size_train).all(None)\n",
    "        # expand lists and broadcast scalars\n",
    "        scalar_cols = df.columns[[o != np.dtype('object') for o in df.head(1).dtypes]].tolist()\n",
    "        df_expanded = unpack_nested_lists_in_df(df, scalar_cols)\n",
    "        assert df_expanded.shape == (len(self.ds.dsd_raw['train']) * cfg.n_train_epochs, df.shape[1])\n",
    "        return df_expanded\n",
    "    \n",
    "    def pp_model_forward(self, data): \n",
    "        pp_output, pp_l = self.get_paraphrases(data['input_ids'], data['attention_mask'])\n",
    "        self._assert_start_and_end_tokens_are_correct(orig_ids=data['input_ids'], pp_ids=pp_output.sequences)\n",
    "        self._update_batch_size_and_length_variables( orig_ids=data['input_ids'], pp_ids=pp_output.sequences)\n",
    "        return pp_output, pp_l\n",
    "    \n",
    "    def _assert_start_and_end_tokens_are_correct(self, orig_ids, pp_ids):\n",
    "        \"\"\"Make sure input sequences (orig) and output sequences (pp) start and end with the \n",
    "        right special tokens (depends on tokenizer)\"\"\"\n",
    "        # Input\n",
    "        if self.start_end_token_d['input_start_id'] is not None: \n",
    "            assert torch.all(orig_ids[:,0] == self.start_end_token_d['input_start_id'])\n",
    "        # can probs rewrite this to make it nicer but it's fine for now\n",
    "        assert torch.all(torch.logical_or(orig_ids[:,-1] == self.start_end_token_d['input_end_id'][0], \n",
    "                                          orig_ids[:,-1] == self.start_end_token_d['input_end_id'][1]))\n",
    "\n",
    "        # Output\n",
    "        assert torch.all(pp_ids[:,0] == self.start_end_token_d['output_start_id'])\n",
    "        assert torch.all(torch.logical_or(pp_ids[:,-1] == self.start_end_token_d['output_end_id'][0], \n",
    "                                          pp_ids[:,-1] == self.start_end_token_d['output_end_id'][1]))\n",
    "        \n",
    "    def _update_batch_size_and_length_variables(self, orig_ids, pp_ids): \n",
    "        # Update variables\n",
    "        # for greedy search self.pp_length is equal to self.orig_batch_size but this won't be for beam search\n",
    "        self.orig_batch_size     = orig_ids.shape[0]\n",
    "        self.orig_length         = orig_ids.shape[1]\n",
    "        self.pp_batch_size       = pp_ids.shape[0]\n",
    "        self.pp_length           = pp_ids.shape[1] \n",
    "    \n",
    "    def get_paraphrases(self, orig_ids, attention_mask):\n",
    "        \"\"\"Wrapper for generating paraphrases (pp's).  Only greedy search supported at the moment\"\"\"\n",
    "        pp_output = self.pp_model.generate_with_grad(input_ids=orig_ids, \n",
    "                                                attention_mask=attention_mask, \n",
    "                                                 **self._cfg.pp,\n",
    "                                                 do_sample=False, \n",
    "                                                 return_dict_in_generate=True,\n",
    "                                                 output_scores=True,\n",
    "                                                 remove_invalid_values=False, \n",
    "                                                 pad_token_id = self.pp_tokenizer.pad_token_id,\n",
    "                                                 eos_token_id = self.pp_tokenizer.eos_token_id)\n",
    "        pp_l = self.pp_tokenizer.batch_decode(pp_output.sequences, skip_special_tokens=True)\n",
    "        return pp_output, pp_l\n",
    "    \n",
    "    def loss_fn(self, data, raw, pp_output, pp_l, return_components=False): \n",
    "        with timecode() as self.train_batch_time_d['time_reward_fn']:\n",
    "            d = self.reward_fn(data, raw, pp_l, return_components=return_components)\n",
    "\n",
    "        if self._cfg.normalise_rewards: \n",
    "            d['orig_reward'] = copy.deepcopy(d['reward'])\n",
    "            d['reward'] = (d['reward']-torch.mean(d['reward']))/torch.std(d['reward'])\n",
    "\n",
    "        with timecode() as self.train_batch_time_d['time_pp_logp']:\n",
    "            d['pp_logp'] = self.get_pp_logp(pp_output)\n",
    "\n",
    "        with timecode() as self.train_batch_time_d['time_loss_fn_loss_calc']:\n",
    "            d['loss'] = -d['reward'] * d['pp_logp']\n",
    "            d['loss_batch'] = torch.mean(d['loss'])\n",
    "            if return_components ==  False: return d['loss_batch'] \n",
    "\n",
    "        # remove some items from compgraph\n",
    "        with timecode() as self.train_batch_time_d['time_loss_fn_detach']:\n",
    "            d['pp_logp'] = d['pp_logp'].detach()  \n",
    "            d['loss']    = d['loss'].detach()\n",
    "\n",
    "        if self.pp_model.training:    \n",
    "            self.train_batch_d['pp_logp'] = d['pp_logp'].cpu().tolist()\n",
    "            self.train_batch_d['loss'] = d['loss'].cpu().tolist()\n",
    "            self.train_batch_d['loss_batch'] = d['loss_batch'].detach().cpu().tolist()\n",
    "        return d\n",
    "    \n",
    "    def reward_fn(self, data, raw, pp_l, return_components=False): \n",
    "        \"\"\"\"\"\"\n",
    "        # Victim model probability differences between orig and pp\n",
    "        with timecode() as self.train_batch_time_d['time_vm_scores']:\n",
    "            pp_probs = get_vm_probs(pp_l, self._cfg, self.vm_tokenizer, self.vm_model, return_predclass=False)\n",
    "            pp_predclass = torch.argmax(pp_probs, axis=1)\n",
    "            pp_truelabel_probs   = torch.gather(pp_probs, 1, data['label'][:,None]).squeeze()\n",
    "            pp_predclass_probs   = torch.gather(pp_probs, 1, pp_predclass[ :,None]).squeeze()\n",
    "            label_flip = ((pp_predclass != data['label']) * 1)\n",
    "            vm_scores = (data['orig_truelabel_probs'] - pp_truelabel_probs)\n",
    "            \n",
    "        # STS scores\n",
    "        with timecode() as self.train_batch_time_d['time_sts_scores']:\n",
    "            pp_embeddings  = self.sts_model.encode(pp_l, batch_size=len(raw), convert_to_tensor=True, device=self._cfg.device)\n",
    "            # This returns a cosine similarity matrix, of which we just want the diagonal\n",
    "            sts_scores = pytorch_cos_sim(data['orig_sts_embeddings'], pp_embeddings).diagonal()  \n",
    "\n",
    "        # Reward calculation \n",
    "        rewards = torch.tensor([-0.5 if sts < 0.5 else 0.5+v*sts for v,sts in zip(vm_scores, sts_scores)],device=self._cfg.device)\n",
    "        if self.pp_model.training:\n",
    "            self.train_batch_d['pp_truelabel_probs'] = pp_truelabel_probs.detach().cpu().tolist()\n",
    "            self.train_batch_d['pp_predclass']       = pp_predclass.detach().cpu().tolist()\n",
    "            self.train_batch_d['pp_predclass_probs'] = pp_predclass_probs.detach().cpu().tolist()\n",
    "            self.train_batch_d['label_flip']         = label_flip.detach().cpu().tolist()\n",
    "            self.train_batch_d['label_flip_fraction']= np.mean(self.train_batch_d['label_flip'])\n",
    "            self.train_batch_d['reward']            = rewards.detach().cpu().tolist()\n",
    "            self.train_batch_d['vm_score']          = vm_scores.detach().cpu().tolist()\n",
    "            self.train_batch_d['sts_score']         = sts_scores.detach().cpu().tolist()\n",
    "            \n",
    "        ## TODO: with a class we can just keep all these variables in self, refactor? then maybe you can log them \n",
    "        #  with wandb histogram?\n",
    "        if return_components: \n",
    "            return {\n",
    "                \"orig_l\": raw['text'],\n",
    "                \"pp_l\": pp_l,  \n",
    "                \"truelabel\": data['label'],\n",
    "                \"orig_truelabel_probs\": data['orig_truelabel_probs'],\n",
    "                \"pp_truelabel_probs\":  pp_truelabel_probs,\n",
    "                \"pp_predclass\": pp_predclass,\n",
    "                \"pp_predclass_probs\": pp_predclass_probs,\n",
    "                \"vm_score\": vm_scores, \n",
    "                \"sts_score\": sts_scores,\n",
    "                \"reward\": rewards,\n",
    "                \"label_flip\": label_flip\n",
    "            }\n",
    "        else:  return {\"reward\": rewards}\n",
    "        \n",
    "    def get_pp_logp(self, pp_output): \n",
    "        \"\"\"log(p(pp|orig)) basically.\n",
    "        works for greedy search, will need tweaking for other types probably\"\"\"\n",
    "        ### TODO: this looks like logp to me, not plogp. Find out if this is right and if so rename, if not, fix\n",
    "        ### We want to align tokens with token probabilities. The first token is given at the start \n",
    "        # and has no probability attached to it, so we remove it. \n",
    "        seq_without_first_tkn = pp_output.sequences[:, 1:]\n",
    "        assert seq_without_first_tkn.shape == torch.Size([self.orig_batch_size, self.pp_length - 1])\n",
    "\n",
    "        ### Convert from tuple of scores to one big tensor of scores \n",
    "        scores_stacked = torch.stack(pp_output.scores, 1)\n",
    "        ### TESTS \n",
    "        # We check shape and that there is no +inf or nan in scores. \n",
    "        # Scores can have -inf in them - see explanation in `exploring_generation`.  \n",
    "        assert scores_stacked.shape == torch.Size([self.orig_batch_size, (self.pp_length - 1), self._cfg.vocab_size])\n",
    "        assert torch.all(~torch.isnan(scores_stacked))\n",
    "        assert torch.all(~torch.isposinf(scores_stacked))\n",
    "        # Rough check that all idx before min_length are -inf for all elements in batch\n",
    "        # We do min_length - 1 because sequences are allowed to have length min_length so that idx \n",
    "        # shouldn't be set to -inf\n",
    "        # Not a 100% test but very likely to identify\n",
    "        idx_neginf = torch.nonzero(torch.isneginf(scores_stacked))\n",
    "        assert len(idx_neginf[idx_neginf[:,2] == self.pp_tokenizer.eos_token_id, :]) == \\\n",
    "                  (self._cfg.pp[\"min_length\"] -1) * self.orig_batch_size  \n",
    "        del idx_neginf\n",
    "\n",
    "        ### Take log softmax of scores and then extract those that correspond \n",
    "        # to the generated sequences    \n",
    "        scores_log_softmax = scores_stacked.log_softmax(2)\n",
    "        seq_token_log_probs = torch.gather(scores_log_softmax,2,seq_without_first_tkn[:,:,None]).squeeze(-1)\n",
    "        ### TESTS \n",
    "        # -inf is possible in scores_log_softmax and seq_token_log_probs before the attention mask is added. \n",
    "        assert torch.all(~torch.isnan(   scores_log_softmax))\n",
    "        assert torch.all(~torch.isposinf(scores_log_softmax))\n",
    "        self._check_scores_log_softmax_sums(scores_log_softmax)\n",
    "        # probs should be 1-1 with the filtered tkns: check shape to confirm\n",
    "        assert seq_token_log_probs.shape == seq_without_first_tkn.shape  \n",
    "        # Check that the last token probability corresponds to a possible end token\n",
    "        # this has to be tested before the attention mask is multiplied with it because if the \n",
    "        # padding token is 0 then this will be 0 too (and not the same as scores_log_softmax)\n",
    "        output_end_ids = self.start_end_token_d['output_end_id']\n",
    "        assert all([o in scores_log_softmax[:, -1, output_end_ids] for o in seq_token_log_probs[:,-1]])\n",
    "        del output_end_ids\n",
    "        ## THIS ONE IS LONG - a test rather than assert \n",
    "        # check_seq_token_log_prob_values_are_correct(seq_without_first_tkn, scores_log_softmax, \n",
    "        #                                             seq_token_log_probs) \n",
    "\n",
    "        ### Generate attention mask to identify padding tokens. Then apply it to the \n",
    "        # sequence probabilities so that we don't consider probability of padding tokens \n",
    "        # when getting sequence probabilities. \n",
    "        # Also replace the -inf values in seq_token_log_probs with a large negative number because if we \n",
    "        # leave them in we end up with nan's introduced after multiplying with attention_mask, \n",
    "        # since  -inf * 0 = nan \n",
    "        attention_mask = self.pp_model._prepare_attention_mask_for_generation(\n",
    "            seq_without_first_tkn, self.pp_tokenizer.pad_token_id, self.pp_tokenizer.eos_token_id\n",
    "        )\n",
    "        seq_token_log_probs = torch.nan_to_num(seq_token_log_probs, nan=None, posinf=None, neginf=-10000)\n",
    "        seq_token_log_probs = seq_token_log_probs * attention_mask\n",
    "        ### TESTS\n",
    "        assert seq_token_log_probs.shape == attention_mask.shape == seq_token_log_probs.shape\n",
    "        # check attention mask only has 0 for padding tokens and not eos tokens or anything else\n",
    "        assert all(seq_without_first_tkn[attention_mask == 0] == self.pp_tokenizer.pad_token_id)\n",
    "        check_no_nans_or_infs(seq_token_log_probs)\n",
    "        # check that we aren't picking extrememly rare tokens\n",
    "        assert torch.all(seq_token_log_probs  > -10)  \n",
    "\n",
    "        ### Get sequence probabilities by summing up token log probabilities \n",
    "        seq_log_prob = seq_token_log_probs.sum(-1)\n",
    "        ## TESTS \n",
    "        assert seq_log_prob.shape == torch.Size([self.pp_batch_size])\n",
    "        check_no_nans_or_infs(seq_log_prob)\n",
    "        \n",
    "        if self.pp_model.training:  # don't bother logging or calculate entropy, token_probs in eval mode\n",
    "            if self._cfg.wandb['log_token_entropy']:\n",
    "                with timecode() as self.train_batch_time_d['time_log_entropy']:\n",
    "                    self.wandb_log_d['ent_hist'] = self._get_entropy_hist(scores_stacked, attention_mask) \n",
    "\n",
    "            if self._cfg.wandb['log_token_probabilities']: \n",
    "                with timecode() as self.train_batch_time_d['time_log_token_probabilities']:\n",
    "                    self.wandb_log_d = merge_dicts(self.wandb_log_d, \n",
    "                        self._get_token_probability_metrics(scores_log_softmax, attention_mask, k=3))\n",
    "        return seq_log_prob\n",
    "   \n",
    "    def _check_scores_log_softmax_sums(self, scores_log_softmax):\n",
    "        sums = scores_log_softmax.exp().sum(2)\n",
    "        # check that the axes is right\n",
    "        # we want to sum over token probabilities at each generation step, so we \n",
    "        # should end up with a shape [self.orig_batch_size, self.pp_length]\n",
    "        assert sums.shape[0] == self.orig_batch_size  \n",
    "        assert sums.shape[1] == self.pp_length - 1\n",
    "        # check that they sum to 1 along the self.pp_length axis\n",
    "        assert torch.allclose(sums, torch.ones(sums.size(), device=self._cfg.device), atol = 1e-4)\n",
    "\n",
    "    def _check_seq_token_log_prob_values_are_correct(self, seq_without_first_tkn, scores_log_softmax, seq_token_log_probs): \n",
    "        \"\"\"Just enumerates and checks values\n",
    "        Quite slow for large batches so run as a test rather than an assert in every batch. \n",
    "        \"\"\"\n",
    "        l = []\n",
    "        for i_ex in range(self.orig_batch_size):\n",
    "            for i_step in range(self.pp_length - 1):\n",
    "                i_tkn = seq_without_first_tkn[i_ex][i_step].item()\n",
    "                l.append(scores_log_softmax[i_ex,i_step, i_tkn] == seq_token_log_probs[i_ex,i_step])\n",
    "        assert all(l)    \n",
    "    \n",
    "    def _get_entropy_hist(self, scores_stacked, attention_mask): \n",
    "        ent = Categorical(logits = scores_stacked).entropy().detach()\n",
    "        assert ent.shape == attention_mask.shape == torch.Size([self.pp_batch_size, self.pp_length - 1])\n",
    "        ent = ent * attention_mask  # stop values after eos token from contributing to ent score \n",
    "        # first remove structure (otherwise we have ragged arrays), then remove corresponding attention mask values\n",
    "        # we can't just filter by ent[ent != 0] because we might have zero tokens during the sequence\n",
    "        att_flat= attention_mask.flatten()\n",
    "        indices = torch.nonzero(att_flat)\n",
    "        ent_flat = ent.flatten()[indices].flatten()\n",
    "        assert ent_flat.shape[0] == (torch.sum(att_flat)*1).item()\n",
    "        # check everything we filter out is zero \n",
    "        torch.isclose(ent.flatten()[torch.nonzero(~(att_flat > 0))].sum(), torch.tensor(0.), 1e-3)\n",
    "        return Histogram(ent_flat.detach().cpu().tolist())\n",
    "#         ent_d = dict(\n",
    "#       #      ent_min             = ent_flat.quantile(0).item(),\n",
    "#             ent_lower_quartile  = ent_flat.quantile(0.25).item(), \n",
    "#             ent_median          = ent_flat.median().item(), \n",
    "#       #      ent_mean            = ent_flat.mean().item(), \n",
    "#             ent_upper_quartile  = ent_flat.quantile(0.75).item(), \n",
    "#       #      ent_max             = ent_flat.quantile(1).item(),   # skews the graph\n",
    "#             epoch=self.epoch, global_step=self.global_step\n",
    "#         )\n",
    "#         return ent_d\n",
    "        print('tmp')\n",
    "\n",
    "    def _get_token_probability_metrics(self, scores_log_softmax, attention_mask, k=3): \n",
    "        token_prob_d = dict()\n",
    "        tkn_kmaxprob, _ = torch.topk(scores_log_softmax, largest=True, k=k, dim=2)\n",
    "        tkn_kmaxprob = tkn_kmaxprob.detach()  \n",
    "        assert tkn_kmaxprob.shape == torch.Size([self.pp_batch_size, self.pp_length - 1, k])\n",
    "\n",
    "        # % of first prob over 0.9, 0.75, 0.5, 0.3, 0.1\n",
    "        top_probs = tkn_kmaxprob[:,:,0].exp()\n",
    "        top_probs = (top_probs * attention_mask).flatten()\n",
    "        top_probs = top_probs[top_probs != 0]\n",
    "        prob_threshold_l = [0.99, 0.975, 0.95, 0.90, 0.75, 0.5, 0.3, 0.1]\n",
    "        for p in prob_threshold_l: \n",
    "            token_prob_d[f\"top_token_prob_over_{str(p)}\"] = (torch.sum(top_probs > p) / top_probs.shape[0]).item()\n",
    "\n",
    "        # avg + median + lower + upper quartile of first, second, third choice probs\n",
    "        tkn_kmaxprob_mask = tkn_kmaxprob * attention_mask[:,:,None]  # broadcasting over kth dim\n",
    "        for i in range(k): \n",
    "            probs = tkn_kmaxprob_mask[:,:, i].flatten()\n",
    "            probs = probs[probs != 0]\n",
    "            token_prob_d[f\"rank_{i+1}_histogram\"] = Histogram(probs.detach().cpu().tolist())\n",
    "            token_prob_d[f\"rank_{i+1}_token_prob_mean\"] = probs.mean().item()\n",
    "            token_prob_d[f\"rank_{i+1}_token_prob_median\"] = probs.median().item()\n",
    "            token_prob_d[f\"rank_{i+1}_token_prob_0.25_quantile\"] = probs.quantile(0.25).item()\n",
    "            token_prob_d[f\"rank_{i+1}_token_prob_0.75_quantile\"] = probs.quantile(0.75).item()\n",
    "\n",
    "        # tokens over probs above 0.1, 0.01, 0.001, 0.0001, 1/vocab_size prob \n",
    "        allprobs = (scores_log_softmax.detach().exp() * attention_mask[:,:,None]).flatten()\n",
    "        allprobs = allprobs[allprobs != 0]\n",
    "        for p in [0.1, 0.01, 0.001, 0.0001, 0.00001]: \n",
    "            token_prob_d[f\"%_of_tokens_above_prob_{p}\"] =  (torch.sum(allprobs > p) / allprobs.shape[0]).item()\n",
    "        token_prob_d[f\"%_of_tokens_above_prob_1/vocab_size\"] = \\\n",
    "            (torch.sum(allprobs > (1/self._cfg.vocab_size)) / allprobs.shape[0]).item()\n",
    "        return token_prob_d\n",
    "    \n",
    "    def process_results_d_for_wandb(self,results_d): \n",
    "        ## TODO: figure out what to do with this and process_results_d1. \n",
    "        ## Also rename this. To me it looks like it changes types, shapes, but why?\n",
    "        # If you convert the summary plots to simple wandb charts, can you get rid of this?\n",
    "        \n",
    "        # Flatten batches for each key, depending on datatype (e.g. lists of lists )\n",
    "        for k,v in results_d.items(): \n",
    "            # v[0] is arbitrary - we are just checking the first item in the list to see the type\n",
    "            if type(v) == float or type(v) == int: \n",
    "                next\n",
    "            elif  torch.is_tensor(v[0]): \n",
    "                # case where we have a list of scalars - the cat function doesn't work here \n",
    "                if  v[0].size() == torch.Size([]): x = torch.stack(v)\n",
    "                else:                              x = torch.cat(v)\n",
    "                results_d[k] = x.detach().cpu().squeeze().tolist()  # convert to list (squeeze is for single scalar list)\n",
    "            elif type(v[0]) == list:  # this is True for tensors also, so it has to go after the is_tensor check\n",
    "                results_d[k] = list(itertools.chain(*v)) \n",
    "            elif type(v) == list: \n",
    "                next\n",
    "            else: \n",
    "                raise Exception(\"shouldn't get here\")\n",
    "        return results_d\n",
    "    \n",
    "    def eval_dl(self, dl_tkn, dl_raw): \n",
    "        \"\"\"Get evaluation metrics for a dataloader\"\"\"\n",
    "        # Put models in eval mode and do the forward pass \n",
    "        # Current logic: push all batches together into one big list.     \n",
    "        if self.pp_model.training: self.pp_model.eval()\n",
    "        if self.vm_model.training: self.vm_model.eval()\n",
    "        results_d = defaultdict(list)\n",
    "        with torch.no_grad(): \n",
    "            for eval_batch_num, (data, raw) in enumerate(zip(dl_tkn, dl_raw)):\n",
    "                self.logger.debug(show_gpu(f'EVAL, epoch {self.epoch}, batch {self.batch_num}, GPU memory usage after loading data: '))\n",
    "                for k, v in data.items(): \n",
    "                    if data[k].device != self._cfg.device: data[k] = data[k].to(self._cfg.device)\n",
    "\n",
    "                pp_output, pp_l = self.pp_model_forward(data)\n",
    "                d = self.loss_fn(data, raw, pp_output, pp_l, return_components=True)\n",
    "                self.logger.debug(show_gpu(f'EVAL, epoch {self.epoch}, batch {self.batch_num}, GPU memory usage after loss_fn pass: '))\n",
    "                d['idx'] = raw['idx']\n",
    "\n",
    "                for k,v in d.items(): \n",
    "                    results_d[k].append(v) \n",
    "        del eval_batch_num, data, raw, pp_output, pp_l, d\n",
    "        results_d = self.process_results_d_for_wandb(results_d)\n",
    "        results_d['epoch'] = self.epoch\n",
    "        return results_d\n",
    "        \n",
    "    def plot_wandb_charts(self): \n",
    "        ## TODO: rename to indicate it only plots summary and examples charts \n",
    "        ## Can you refactor into regular wandb charts?\n",
    "        if self._cfg.wandb['plot_examples']: \n",
    "            # Examples charts \n",
    "            for split in ['train', 'valid']:\n",
    "                df = pd.DataFrame(data_d[split]) if type(self.data_d[split]) is list else self.data_d[split]\n",
    "                df = df.query(\"idx in @plt_idx_d[@split]\").sort_values(['idx', 'epoch'])\n",
    "                for metric in self._cfg.metrics: \n",
    "                    chart = plot_examples_chart(split, table=wandb.Table(dataframe=df), metric=metric)\n",
    "                    wandb.log({f\"individual_examples/{split}_{metric}_vs_epoch_examples\": chart}, commit=False)  \n",
    "\n",
    "    def add_wandb_run_summary_statistics(self):\n",
    "        \"\"\"Compute test metrics for the run and log them to the wandb run summary pane. \"\"\"\n",
    "        ## Summary statistics of the test set \n",
    "        # From the last epoch atm because we don't have early stopping \n",
    "        test_metrics = self.data_d['test'].filter(self._cfg.metrics, axis=1).mean()\n",
    "        for metric, val in zip(test_metrics.index, test_metrics): \n",
    "            self.run.summary[f\"{metric}_avg_test\"] = val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.wandb['mode'] = 'disabled'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching training on one GPU.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6c15d828f554734b74ecc5f8bafb21e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now on epoch 0 of 4\n",
      "Now on epoch 1 of 4\n",
      "Now on epoch 2 of 4\n",
      "Now on epoch 3 of 4\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(cfg, vm_tokenizer, vm_model, pp_tokenizer, pp_model, sts_model, optimizer,\n",
    "                  accelerator, ds, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m<ipython-input-138-70eaca8a68ff>\u001b[0m(167)\u001b[0;36m_prepare_train_batch_d\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    165 \u001b[0;31m        }) \n",
      "\u001b[0m\u001b[0;32m    166 \u001b[0;31m        \u001b[0;31m# Add times\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 167 \u001b[0;31m        \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_batch_time_d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_batch_time_d\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m  \u001b[0;31m# extract time from timecode object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    168 \u001b[0;31m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_batch_d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmerge_dicts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_batch_d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_batch_time_d\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    169 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> self.train_batch_time_d.items()\n",
      "dict_items([('time_generate_pp', 0.15495290234684944), ('time_loss_fn', 0.04092802479863167), ('time_reward_fn', 0.030766382813453674), ('time_vm_scores', 0.008354078978300095), ('time_sts_scores', 0.02173374965786934), ('time_pp_logp', 0.010015975683927536), ('time_log_entropy', 0.0019385628402233124), ('time_log_token_probabilities', 0.004989545792341232), ('time_loss_fn_loss_calc', 5.6449323892593384e-05), ('time_loss_fn_detach', 7.618218660354614e-06), ('time_backwards', 0.14491534233093262), ('time_opt_step', 0.009237382560968399), ('time_add_to_training_step_table', <travis_attack.utils.timecode object at 0x2b297af62370>)])\n",
      "ipdb> self.train_batch_time_d['time_add_to_training_step_table']\n",
      "<travis_attack.utils.timecode object at 0x2b297af62370>\n",
      "ipdb> self.train_batch_time_d['time_add_to_training_step_table'].t\n",
      "0.014079835265874863\n",
      "ipdb> q\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label_flip_fraction</th>\n",
       "      <th>loss_batch</th>\n",
       "      <th>epoch</th>\n",
       "      <th>batch_num</th>\n",
       "      <th>global_step</th>\n",
       "      <th>accumulation_num</th>\n",
       "      <th>orig_length</th>\n",
       "      <th>orig_batch_size</th>\n",
       "      <th>pp_length</th>\n",
       "      <th>pp_batch_size</th>\n",
       "      <th>time_generate_pp</th>\n",
       "      <th>time_loss_fn</th>\n",
       "      <th>time_reward_fn</th>\n",
       "      <th>time_vm_scores</th>\n",
       "      <th>time_sts_scores</th>\n",
       "      <th>time_pp_logp</th>\n",
       "      <th>time_log_entropy</th>\n",
       "      <th>time_log_token_probabilities</th>\n",
       "      <th>time_loss_fn_loss_calc</th>\n",
       "      <th>time_loss_fn_detach</th>\n",
       "      <th>time_backwards</th>\n",
       "      <th>time_opt_step</th>\n",
       "      <th>time_add_to_training_step_table</th>\n",
       "      <th>pp_truelabel_probs</th>\n",
       "      <th>pp_predclass</th>\n",
       "      <th>pp_predclass_probs</th>\n",
       "      <th>label_flip</th>\n",
       "      <th>rewards</th>\n",
       "      <th>vm_scores</th>\n",
       "      <th>sts_scores</th>\n",
       "      <th>pp_logp</th>\n",
       "      <th>loss_examples</th>\n",
       "      <th>idx</th>\n",
       "      <th>orig_l</th>\n",
       "      <th>orig_label</th>\n",
       "      <th>orig_truelabel_probs</th>\n",
       "      <th>pp_l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.096411</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0.134076</td>\n",
       "      <td>0.038925</td>\n",
       "      <td>0.029686</td>\n",
       "      <td>0.007846</td>\n",
       "      <td>0.021220</td>\n",
       "      <td>0.009088</td>\n",
       "      <td>0.001739</td>\n",
       "      <td>0.004822</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.145566</td>\n",
       "      <td>0.005987</td>\n",
       "      <td>0.014535</td>\n",
       "      <td>0.828523</td>\n",
       "      <td>1</td>\n",
       "      <td>0.828523</td>\n",
       "      <td>0</td>\n",
       "      <td>0.378675</td>\n",
       "      <td>-0.122356</td>\n",
       "      <td>0.991577</td>\n",
       "      <td>-0.26651</td>\n",
       "      <td>0.100921</td>\n",
       "      <td>3</td>\n",
       "      <td>I hate this apple</td>\n",
       "      <td>1</td>\n",
       "      <td>0.706167</td>\n",
       "      <td>I like this movie.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.094854</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0.132344</td>\n",
       "      <td>0.041195</td>\n",
       "      <td>0.031636</td>\n",
       "      <td>0.009334</td>\n",
       "      <td>0.021611</td>\n",
       "      <td>0.009412</td>\n",
       "      <td>0.001835</td>\n",
       "      <td>0.004964</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.133019</td>\n",
       "      <td>0.006092</td>\n",
       "      <td>0.014549</td>\n",
       "      <td>0.914811</td>\n",
       "      <td>0</td>\n",
       "      <td>0.914811</td>\n",
       "      <td>0</td>\n",
       "      <td>0.478535</td>\n",
       "      <td>-0.0221628</td>\n",
       "      <td>0.968495</td>\n",
       "      <td>-0.315348</td>\n",
       "      <td>0.150905</td>\n",
       "      <td>0</td>\n",
       "      <td>I like this movie</td>\n",
       "      <td>0</td>\n",
       "      <td>0.892648</td>\n",
       "      <td>I do not like this movie.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.094854</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0.132344</td>\n",
       "      <td>0.041195</td>\n",
       "      <td>0.031636</td>\n",
       "      <td>0.009334</td>\n",
       "      <td>0.021611</td>\n",
       "      <td>0.009412</td>\n",
       "      <td>0.001835</td>\n",
       "      <td>0.004964</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.133019</td>\n",
       "      <td>0.006092</td>\n",
       "      <td>0.014549</td>\n",
       "      <td>0.883751</td>\n",
       "      <td>0</td>\n",
       "      <td>0.883751</td>\n",
       "      <td>0</td>\n",
       "      <td>0.454929</td>\n",
       "      <td>-0.0456876</td>\n",
       "      <td>0.986515</td>\n",
       "      <td>-0.109215</td>\n",
       "      <td>0.0496849</td>\n",
       "      <td>1</td>\n",
       "      <td>I do not like this movie</td>\n",
       "      <td>0</td>\n",
       "      <td>0.838063</td>\n",
       "      <td>I hate this apple.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.094854</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0.132344</td>\n",
       "      <td>0.041195</td>\n",
       "      <td>0.031636</td>\n",
       "      <td>0.009334</td>\n",
       "      <td>0.021611</td>\n",
       "      <td>0.009412</td>\n",
       "      <td>0.001835</td>\n",
       "      <td>0.004964</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.133019</td>\n",
       "      <td>0.006092</td>\n",
       "      <td>0.014549</td>\n",
       "      <td>0.910314</td>\n",
       "      <td>1</td>\n",
       "      <td>0.910314</td>\n",
       "      <td>0</td>\n",
       "      <td>0.436599</td>\n",
       "      <td>-0.0638236</td>\n",
       "      <td>0.993377</td>\n",
       "      <td>-0.183726</td>\n",
       "      <td>0.0802145</td>\n",
       "      <td>2</td>\n",
       "      <td>I love this apple</td>\n",
       "      <td>1</td>\n",
       "      <td>0.84649</td>\n",
       "      <td>I love this apple.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.094854</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0.132344</td>\n",
       "      <td>0.041195</td>\n",
       "      <td>0.031636</td>\n",
       "      <td>0.009334</td>\n",
       "      <td>0.021611</td>\n",
       "      <td>0.009412</td>\n",
       "      <td>0.001835</td>\n",
       "      <td>0.004964</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.133019</td>\n",
       "      <td>0.006092</td>\n",
       "      <td>0.014549</td>\n",
       "      <td>0.828523</td>\n",
       "      <td>1</td>\n",
       "      <td>0.828523</td>\n",
       "      <td>0</td>\n",
       "      <td>0.378675</td>\n",
       "      <td>-0.122356</td>\n",
       "      <td>0.991577</td>\n",
       "      <td>-0.26041</td>\n",
       "      <td>0.0986105</td>\n",
       "      <td>3</td>\n",
       "      <td>I hate this apple</td>\n",
       "      <td>1</td>\n",
       "      <td>0.706167</td>\n",
       "      <td>I like this movie.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    label_flip_fraction  loss_batch  epoch  batch_num  global_step  \\\n",
       "11                  0.0    0.096411      2          0            2   \n",
       "12                  0.0    0.094854      3          0            3   \n",
       "13                  0.0    0.094854      3          0            3   \n",
       "14                  0.0    0.094854      3          0            3   \n",
       "15                  0.0    0.094854      3          0            3   \n",
       "\n",
       "    accumulation_num  orig_length  orig_batch_size  pp_length  pp_batch_size  \\\n",
       "11                 2            8                4          9              4   \n",
       "12                 3            8                4          9              4   \n",
       "13                 3            8                4          9              4   \n",
       "14                 3            8                4          9              4   \n",
       "15                 3            8                4          9              4   \n",
       "\n",
       "    time_generate_pp  time_loss_fn  time_reward_fn  time_vm_scores  \\\n",
       "11          0.134076      0.038925        0.029686        0.007846   \n",
       "12          0.132344      0.041195        0.031636        0.009334   \n",
       "13          0.132344      0.041195        0.031636        0.009334   \n",
       "14          0.132344      0.041195        0.031636        0.009334   \n",
       "15          0.132344      0.041195        0.031636        0.009334   \n",
       "\n",
       "    time_sts_scores  time_pp_logp  time_log_entropy  \\\n",
       "11         0.021220      0.009088          0.001739   \n",
       "12         0.021611      0.009412          0.001835   \n",
       "13         0.021611      0.009412          0.001835   \n",
       "14         0.021611      0.009412          0.001835   \n",
       "15         0.021611      0.009412          0.001835   \n",
       "\n",
       "    time_log_token_probabilities  time_loss_fn_loss_calc  time_loss_fn_detach  \\\n",
       "11                      0.004822                0.000056             0.000008   \n",
       "12                      0.004964                0.000057             0.000008   \n",
       "13                      0.004964                0.000057             0.000008   \n",
       "14                      0.004964                0.000057             0.000008   \n",
       "15                      0.004964                0.000057             0.000008   \n",
       "\n",
       "    time_backwards  time_opt_step  time_add_to_training_step_table  \\\n",
       "11        0.145566       0.005987                         0.014535   \n",
       "12        0.133019       0.006092                         0.014549   \n",
       "13        0.133019       0.006092                         0.014549   \n",
       "14        0.133019       0.006092                         0.014549   \n",
       "15        0.133019       0.006092                         0.014549   \n",
       "\n",
       "   pp_truelabel_probs pp_predclass pp_predclass_probs label_flip   rewards  \\\n",
       "11           0.828523            1           0.828523          0  0.378675   \n",
       "12           0.914811            0           0.914811          0  0.478535   \n",
       "13           0.883751            0           0.883751          0  0.454929   \n",
       "14           0.910314            1           0.910314          0  0.436599   \n",
       "15           0.828523            1           0.828523          0  0.378675   \n",
       "\n",
       "    vm_scores sts_scores   pp_logp loss_examples idx  \\\n",
       "11  -0.122356   0.991577  -0.26651      0.100921   3   \n",
       "12 -0.0221628   0.968495 -0.315348      0.150905   0   \n",
       "13 -0.0456876   0.986515 -0.109215     0.0496849   1   \n",
       "14 -0.0638236   0.993377 -0.183726     0.0802145   2   \n",
       "15  -0.122356   0.991577  -0.26041     0.0986105   3   \n",
       "\n",
       "                      orig_l orig_label orig_truelabel_probs  \\\n",
       "11         I hate this apple          1             0.706167   \n",
       "12         I like this movie          0             0.892648   \n",
       "13  I do not like this movie          0             0.838063   \n",
       "14         I love this apple          1              0.84649   \n",
       "15         I hate this apple          1             0.706167   \n",
       "\n",
       "                         pp_l  \n",
       "11         I like this movie.  \n",
       "12  I do not like this movie.  \n",
       "13         I hate this apple.  \n",
       "14         I love this apple.  \n",
       "15         I like this movie.  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_all(trainer.data_d['training_step1'].tail(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
