{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp trainer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import torch, wandb, gc, numpy as np, pandas as pd,os\n",
    "from wandb.data_types import Histogram\n",
    "from tqdm.auto import tqdm\n",
    "from travis_attack.utils import timecode, show_gpu, merge_dicts, unpack_nested_lists_in_df, display_all\n",
    "from travis_attack.tests import check_no_nans_or_infs\n",
    "from travis_attack.models import save_pp_model, resume_pp_model, get_vm_probs, get_start_end_special_token_ids\n",
    "from travis_attack.charts import plot_grad_flow, plot_examples_chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import torch, numpy as np, pandas as pd, gc,sys, logging, warnings\n",
    "from torch.utils.data import DataLoader, RandomSampler\n",
    "from datasets import load_dataset, load_metric, load_from_disk, DatasetDict\n",
    "from transformers import (AutoModelForSeq2SeqLM, AutoModelForSequenceClassification, \n",
    "                          AutoTokenizer, AdamW, SchedulerType, get_scheduler)\n",
    "from torch.distributions import Categorical\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers.util import pytorch_cos_sim\n",
    "from collections import defaultdict\n",
    "from accelerate import Accelerator, notebook_launcher\n",
    "from cachetools import cached, LRUCache\n",
    "from types import MethodType\n",
    "from timeit import default_timer as timer\n",
    "from tqdm.auto import tqdm\n",
    "import itertools\n",
    "import copy \n",
    "import wandb\n",
    "from undecorated import undecorated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from travis_attack.utils import set_seed, set_session_options, prepare_logger\n",
    "from travis_attack.config import Config\n",
    "from travis_attack.models import prepare_models, get_optimizer\n",
    "from travis_attack.data import ProcessedDataset\n",
    "from accelerate import Accelerator, notebook_launcher\n",
    "from fastcore.basics import store_attr\n",
    "from IPython.core.debugger import set_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-b253756c445fb811\n",
      "Reusing dataset csv (/data/tproth/.cache/huggingface/datasets/csv/default-b253756c445fb811/0.0.0/bf68a4c4aefa545d0712b2fcbb1b327f905bbe2f6425fbc5e8c25234acb9e14a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd5b4c5268f543e9946ad7f0a3a46af7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-c802946231f72062\n",
      "Reusing dataset csv (/data/tproth/.cache/huggingface/datasets/csv/default-c802946231f72062/0.0.0/bf68a4c4aefa545d0712b2fcbb1b327f905bbe2f6425fbc5e8c25234acb9e14a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4009a265a9af4359a0a1c10e25a13030",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-43a49c5188c42e69\n",
      "Reusing dataset csv (/data/tproth/.cache/huggingface/datasets/csv/default-43a49c5188c42e69/0.0.0/bf68a4c4aefa545d0712b2fcbb1b327f905bbe2f6425fbc5e8c25234acb9e14a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b09a167583345cfbd21e29aba6d3b74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e95cefd010094778acc6240613771744",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e867b05c05d74d72a5d258f61753021e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "520fffebb74647ca851e94f546eea455",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad81fb3fc35b40638e9d8d2a460552d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "194602d65ca843089e178a9d88824c54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a7e6cfce0f4494e8bcf01a6212ccbf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f2a56cffc1f41439c5bfccbfbacab89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdadbd504f0e419cbcde149d3aadc339",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eede8ff27e9645cea2deaf0bc029f4d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf5b878de86a4b5ab123148ee6f182ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40a555b9becd45179a96968f3d7a3a27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12ace01edae74c65a54d3fe049c5e97f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec713c075a0a42cc88308967e3a40956",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9c49576b5da41d0bb0d959623281b61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1f26702289c4fe49c5c4c083cede3c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bfd6f14f2bf485899ebe6aed7bc8e75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12faf6d3e16f49ef803858aa53d2a537",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9a677bff50540579d937520d14acbad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ea8d14ac9934658a79dada11056c59e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "025d7fc5b26c4415abf378e3ed6c9932",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a14834f3772544b598fc6cd911fc09f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#hide\n",
    "accelerator = Accelerator()\n",
    "cfg = Config()\n",
    "cfg.device = accelerator.device\n",
    "set_seed(cfg.seed)\n",
    "set_session_options()\n",
    "logger = prepare_logger()\n",
    "vm_tokenizer, vm_model, pp_tokenizer, pp_model, sts_model, cfg = prepare_models(cfg)\n",
    "optimizer = get_optimizer(cfg, pp_model)\n",
    "ds = ProcessedDataset(cfg, vm_tokenizer, vm_model, pp_tokenizer, sts_model)\n",
    "vm_model,pp_model,sts_model,optimizer,ds.dld_tkn['train'] = accelerator.prepare(vm_model,pp_model,sts_model,optimizer,ds.dld_tkn['train'])\n",
    "cfg.n_train_steps = cfg.n_train_epochs * len(ds.dld_tkn['train'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This class is used to fine-tune the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "class Trainer: \n",
    "    def __init__(self, cfg, vm_tokenizer, vm_model, pp_tokenizer, pp_model, sts_model, optimizer, accelerator, ds,\n",
    "                logger): \n",
    "        store_attr()\n",
    "        self._cfg = self.cfg; del self.cfg;\n",
    "        self.accumulation_num,self.global_step,self.eval_num = 0,0,0\n",
    "        self._reset_batch_dicts()\n",
    "        #resume_pp_model(f\"{path_checkpoints}devout-durian-172_39\")\n",
    "        self._setup_wandb_run()\n",
    "        self._setup_data_stores()\n",
    "        if self._cfg.wandb['plot_examples']: self._setup_wandb_examples_plots()\n",
    "        self.start_end_token_d = get_start_end_special_token_ids(self.pp_tokenizer)\n",
    "        ## TODO: why is num_processes set to 1?\n",
    "        #%lprun -f training_function -f  get_pp_logp -f training_step -f  reward_fn -f  loss_fn -f eval_dl  notebook_launcher(training_function, args=(pp_model, vm_model, dld_tkn, dld_raw, optimizer), num_processes=1, use_fp16=use_fp16)\n",
    "        notebook_launcher(self.training_function, args=(), \n",
    "                           num_processes=1, use_fp16=self._cfg.use_fp16)\n",
    "       \n",
    "    def _reset_batch_dicts(self): \n",
    "          # train_batch_d holds all info to write to csv, time_d has times, wandb_d has everything to log to wandb\n",
    "        # there will be overlap between them. \n",
    "        self.batch_d,self.batch_time_d,self.batch_wandb_d = dict(),dict(),dict()\n",
    "    \n",
    "    def _setup_wandb_run(self): \n",
    "        \"\"\"Init wandb run, set up paths, create dir for model artifacts if needed, \"\"\"\n",
    "        ## TODO: set notebook name and add in save_code \n",
    "        self.run = wandb.init(project=self._cfg.wandb['project'], entity=self._cfg.wandb['entity'], \n",
    "                              config=vars(self._cfg), mode=self._cfg.wandb['mode'],\n",
    "                              notes=self._cfg.wandb['run_notes'])\n",
    "        if self._cfg.wandb['log_grads']: \n",
    "            wandb.watch(self.pp_model, log='gradients', log_freq=self._cfg.wandb['log_grads_freq'])\n",
    "        self._cfg.run_name,self._cfg.run_id = self.run.name, self.run.id\n",
    "        self._cfg.path_run = f\"{self._cfg.path_checkpoints}{self.run.name}/\"\n",
    "        if not os.path.exists(self._cfg.path_run): os.makedirs(self._cfg.path_run, exist_ok=True)\n",
    "    \n",
    "    def _setup_data_stores(self): \n",
    "        \"\"\"Setup dict `self.data_d` to store observations. Setup column names for wandb tables. \"\"\"\n",
    "        # Raw observation data (lists of dicts, later becomes pandas df)\n",
    "        self.data_d = dict()\n",
    "        # These have to be in the keys of the output from eval_dl\n",
    "        self.table_columns = ['idx', 'orig_l',  'truelabel', 'orig_truelabel_probs', 'epoch', 'pp_l',\n",
    "                     'pp_truelabel_probs', \"pp_predclass\", \"pp_predclass_probs\"] + self._cfg.metrics\n",
    "        for split in self._cfg.splits + ['training_step']:   self.data_d[split] = [] \n",
    "    \n",
    "    def _setup_wandb_examples_plots(self): \n",
    "        \"\"\"If we plot a few examples this sets that up.\"\"\"\n",
    "        def get_examples_plot_idxs(dataset): \n",
    "            \"\"\"Get data indices for the examples plots\"\"\"\n",
    "            return np.random.choice(dataset['idx'], size=self._cfg.wandb['n_examples_plot'], replace=False).tolist()\n",
    "        self.plt_idx_d = dict()\n",
    "        for split in self._cfg.splits:  self.plt_idx_d[split] = get_examples_plot_idxs(self.ds.dsd[split])\n",
    "\n",
    "    def training_function(self): \n",
    "        self.logger.debug(show_gpu(f'GPU memory usage after loading models:'))\n",
    "        progress_bar = tqdm(range(self._cfg.n_train_steps))\n",
    "        self.pp_model.zero_grad(set_to_none=self._cfg.zero_grad_with_none) \n",
    "        for self.epoch in range(self._cfg.n_train_epochs): \n",
    "            self.logger.info(f\"Now on epoch {self.epoch} of {self._cfg.n_train_epochs}\")\n",
    "            if not self.pp_model.training: self.pp_model.train()\n",
    "            with timecode() as time_train_one_epoch:\n",
    "                for self.batch_num, (data, raw) in enumerate(zip(self.ds.dld_tkn['train'], self.ds.dld_raw['train'])): \n",
    "                    self._reset_batch_dicts()\n",
    "                    self.training_step(data, raw) \n",
    "                    self.accumulation_num += 1  ; self.global_step += 1 ;  progress_bar.update(1) \n",
    "                    \n",
    "            wandb.log({'time/train_one_epoch_time': time_train_one_epoch.t,\n",
    "                       'time/train_one_epoch_thoroughput': len(self.ds.dsd_tkn['train']) / time_train_one_epoch.t,\n",
    "                       'epoch': self.epoch}, commit=True)\n",
    "\n",
    "            if self._cfg.wandb['log_grads'] and self.epoch % self._cfg.wandb_log_grads_freq == 0: \n",
    "                plt = plot_grad_flow(self.pp_model.named_parameters())\n",
    "                wandb.log({\"gradient flow\": wandb.Image(plt)})  # doesn't work as a non-image (i.e. plotly)\n",
    "                del plt \n",
    "            #gc.collect() \n",
    "            #torch.cuda.empty_cache()\n",
    "\n",
    "            if self._cfg.save_model_while_training and (self.epoch + 1) % self._cfg.save_model_freq == 0:  save_model(epoch)\n",
    "\n",
    "            # Evaluation loop\n",
    "            if self.epoch % self._cfg.eval_freq == 0: \n",
    "                self.eval_num += 1\n",
    "                with timecode() as time_eval_train:\n",
    "                    self.eval_dl(split='train') # or train_eval?\n",
    "                with timecode() as time_eval_valid:\n",
    "                    self.eval_dl(split='valid')\n",
    "                self.plot_wandb_charts()\n",
    "                with timecode() as time_eval_gc_collect:\n",
    "                    gc.collect() \n",
    "                with timecode() as time_eval_empty_cache:\n",
    "                    torch.cuda.empty_cache()\n",
    "                wandb.log({'time/eval_train_time': time_eval_train.t, 'time/eval_valid_time': time_eval_valid.t,\n",
    "                           'time/eval_train_thoroughput': len(self.ds.dsd_tkn['train']) / time_eval_train.t,\n",
    "                           'time/eval_valid_thoroughput': len(self.ds.dsd_tkn['valid']) / time_eval_valid.t, \n",
    "                           'time/eval_gc_collect': time_eval_gc_collect.t, \n",
    "                           'time/eval_empty_cache': time_eval_empty_cache.t,\n",
    "                   'epoch': self.epoch}, commit=True)\n",
    "        # Eval on test set \n",
    "        self.eval_dl(split='test')\n",
    "\n",
    "        # Data -> df and save dfs to file \n",
    "        for key in self.data_d.keys():  # splits and sometimes 'training_step' too \n",
    "            self.data_d[key] = self._convert_data_d_to_df(key)\n",
    "            self.data_d[key].to_csv(f\"{self._cfg.path_run}{key}.csv\", index=False)\n",
    "        \n",
    "        # plot_wandb_charts()  # don't think I need this\n",
    "        self.add_wandb_run_summary_statistics()     \n",
    "        self.run.finish()\n",
    "        \n",
    "    def training_step(self, data, raw): \n",
    "        \"\"\"Forward pass, loss function, backwards pass, parameter update (with gradient accumulation optional), \n",
    "        recording results, wandb logging. \n",
    "        \"\"\"\n",
    "        if not self.pp_model.training: self.pp_model.train()\n",
    "        if not self.vm_model.training: self.vm_model.train()\n",
    "            \n",
    "        with timecode() as self.batch_time_d['time_generate_pp']:\n",
    "            pp_output, pp_l = self.pp_model_forward(data)\n",
    "\n",
    "        logger.debug(show_gpu(f'TRAIN, epoch {self.epoch}, batch {self.batch_num}, GPU memory usage after forward pass: '))\n",
    "\n",
    "        with self.accelerator.autocast():\n",
    "            with timecode() as self.batch_time_d['time_loss_fn']:\n",
    "                loss_batch = self.loss_fn(data, raw, pp_output, pp_l)\n",
    "            loss_batch = loss_batch / self._cfg.accumulation_steps  # Normalize our loss for gradient accumulation\n",
    "\n",
    "        with timecode() as self.batch_time_d['time_backwards']:\n",
    "            self.accelerator.backward(loss_batch) \n",
    "\n",
    "        logger.debug(show_gpu(f'TRAIN, epoch {self.epoch}, batch {self.batch_num}, GPU memory usage after backwards pass: '))\n",
    "        if (self.accumulation_num + 1) % self._cfg.accumulation_steps == 0: \n",
    "            with timecode() as self.batch_time_d['time_opt_step']:\n",
    "                self.optimizer.step()\n",
    "            self.pp_model.zero_grad(set_to_none=self._cfg.zero_grad_with_none)\n",
    "            \n",
    "        self._prepare_train_batch_d(raw, data, pp_l)\n",
    "        self.data_d['training_step'].append(self.batch_d)\n",
    "        \n",
    "        self._wandb_log_training_step()\n",
    "    \n",
    "    def _add_batch_vars_to_batch_d(self, raw, data, pp_l): \n",
    "        # Add basics. (results are already added elsewhere)\n",
    "        self.batch_d = merge_dicts(self.batch_d, { 'idx': raw['idx'],\n",
    "            'epoch': self.epoch, 'batch_num': self.batch_num, 'global_step': self.global_step,\n",
    "            'accumulation_num': self.accumulation_num,  \"orig_l\": raw['text'], \n",
    "            \"orig_label\": data['label'].cpu().tolist(), \n",
    "            \"orig_truelabel_probs\": data['orig_truelabel_probs'].cpu().tolist(),\n",
    "            'orig_length': self.orig_length, 'orig_batch_size': self.orig_batch_size, \n",
    "            \"pp_l\": pp_l, 'pp_length': self.pp_length, 'pp_batch_size': self.pp_batch_size\n",
    "        })\n",
    "        \n",
    "    def _prepare_train_batch_d(self, raw, data, pp_l): \n",
    "        self._add_batch_vars_to_batch_d(raw, data, pp_l)\n",
    "        # Add times (only for training, not eval)\n",
    "        for k, v in self.batch_time_d.items(): self.batch_time_d[k] = v.t  # extract time from timecode object\n",
    "        self.batch_d = merge_dicts(self.batch_d, self.batch_time_d)\n",
    "    \n",
    "    def _wandb_log_training_step(self): \n",
    "        self.batch_wandb_d = merge_dicts(self.batch_wandb_d, {\n",
    "            'vm_scores_hist':       Histogram(self.batch_d['vm_score']), \n",
    "            'vm_scores_mean':       np.mean(  self.batch_d['vm_score']),\n",
    "            'sts_scores_hist':      Histogram(self.batch_d['sts_score']),\n",
    "            'sts_scores_mean':      np.mean(  self.batch_d['sts_score']), \n",
    "            'rewards_hist':         Histogram(self.batch_d['reward']),\n",
    "            'rewards_mean':         np.mean(  self.batch_d['reward']), \n",
    "            'pp_logp_hist':         Histogram(self.batch_d['pp_logp']),\n",
    "            'pp_logp_mean':         np.mean(  self.batch_d['pp_logp']),\n",
    "            'loss_hist'   :         Histogram(self.batch_d['loss'])})\n",
    "        self.batch_wandb_d = merge_dicts(self.batch_wandb_d, self.batch_d)\n",
    "        not_for_wandb_keys = ['orig_l', 'orig_label','orig_truelabel_probs', 'pp_l', 'loss', 'pp_logp', \n",
    "                              'reward', 'sts_score', 'vm_score',\n",
    "                              'pp_predclass_probs', 'label_flip', 'pp_predclass', 'pp_truelabel_probs']\n",
    "        for k in not_for_wandb_keys:  self.batch_wandb_d.pop(k, None)\n",
    "        wandb.log(self.batch_wandb_d, commit=True)\n",
    "        \n",
    "    def _wandb_log_eval_step(self): \n",
    "        ### TODO: implement\n",
    "        pass\n",
    "        wandb.log(self.batch_wandb_d, commit=True)\n",
    "        \n",
    "    def _convert_data_d_to_df(self, data_d_key): \n",
    "        df = pd.DataFrame(self.data_d[data_d_key])\n",
    "        # check all lists have the same number of elements\n",
    "        nonscalar_cols = df.columns[[o == np.dtype('object') for o in df.head(1).dtypes]].tolist()\n",
    "        assert (df[nonscalar_cols].applymap(len) == cfg.batch_size_train).all(None)\n",
    "        # expand lists and broadcast scalars\n",
    "        scalar_cols = df.columns[[o != np.dtype('object') for o in df.head(1).dtypes]].tolist()\n",
    "        df_expanded = unpack_nested_lists_in_df(df, scalar_cols)\n",
    "        # check shape of new dataframe is correct \n",
    "        if data_d_key == \"training_step\": \n",
    "            df_shape = (self._cfg.ds_length[\"train\"]    * cfg.n_train_epochs, df.shape[1])\n",
    "        elif data_d_key in [\"train\", \"valid\"]: \n",
    "            df_shape = (self._cfg.ds_length[data_d_key] * self.eval_num,      df.shape[1])\n",
    "        elif data_d_key == \"test\": \n",
    "            df_shape = (self._cfg.ds_length[\"test\"],                           df.shape[1])\n",
    "        assert df_expanded.shape == df_shape\n",
    "        return df_expanded\n",
    "    \n",
    "    def pp_model_forward(self, data): \n",
    "        pp_output, pp_l = self.get_paraphrases(data['input_ids'], data['attention_mask'])\n",
    "        self._assert_start_and_end_tokens_are_correct(orig_ids=data['input_ids'], pp_ids=pp_output.sequences)\n",
    "        self._update_batch_size_and_length_variables( orig_ids=data['input_ids'], pp_ids=pp_output.sequences)\n",
    "        return pp_output, pp_l\n",
    "    \n",
    "    def _assert_start_and_end_tokens_are_correct(self, orig_ids, pp_ids):\n",
    "        \"\"\"Make sure input sequences (orig) and output sequences (pp) start and end with the \n",
    "        right special tokens (depends on tokenizer)\"\"\"\n",
    "        # Input\n",
    "        if self.start_end_token_d['input_start_id'] is not None: \n",
    "            assert torch.all(orig_ids[:,0] == self.start_end_token_d['input_start_id'])\n",
    "        # can probs rewrite this to make it nicer but it's fine for now\n",
    "        assert torch.all(torch.logical_or(orig_ids[:,-1] == self.start_end_token_d['input_end_id'][0], \n",
    "                                          orig_ids[:,-1] == self.start_end_token_d['input_end_id'][1]))\n",
    "\n",
    "        # Output\n",
    "        assert torch.all(pp_ids[:,0] == self.start_end_token_d['output_start_id'])\n",
    "        assert torch.all(torch.logical_or(pp_ids[:,-1] == self.start_end_token_d['output_end_id'][0], \n",
    "                                          pp_ids[:,-1] == self.start_end_token_d['output_end_id'][1]))\n",
    "        \n",
    "    def _update_batch_size_and_length_variables(self, orig_ids, pp_ids): \n",
    "        # Update variables\n",
    "        # for greedy search self.pp_length is equal to self.orig_batch_size but this won't be for beam search\n",
    "        self.orig_batch_size     = orig_ids.shape[0]\n",
    "        self.orig_length         = orig_ids.shape[1]\n",
    "        self.pp_batch_size       = pp_ids.shape[0]\n",
    "        self.pp_length           = pp_ids.shape[1] \n",
    "    \n",
    "    def get_paraphrases(self, orig_ids, attention_mask):\n",
    "        \"\"\"Wrapper for generating paraphrases (pp's).  Only greedy search supported at the moment\"\"\"\n",
    "        pp_output = self.pp_model.generate_with_grad(input_ids=orig_ids, \n",
    "                                                attention_mask=attention_mask, \n",
    "                                                 **self._cfg.pp,\n",
    "                                                 do_sample=False, \n",
    "                                                 return_dict_in_generate=True,\n",
    "                                                 output_scores=True,\n",
    "                                                 remove_invalid_values=False, \n",
    "                                                 pad_token_id = self.pp_tokenizer.pad_token_id,\n",
    "                                                 eos_token_id = self.pp_tokenizer.eos_token_id)\n",
    "        pp_l = self.pp_tokenizer.batch_decode(pp_output.sequences, skip_special_tokens=True)\n",
    "        return pp_output, pp_l\n",
    "    \n",
    "    def loss_fn(self, data, raw, pp_output, pp_l): \n",
    "        with timecode() as self.batch_time_d['time_reward_fn']:\n",
    "            reward = self.reward_fn(data, raw, pp_l)\n",
    "\n",
    "        with timecode() as self.batch_time_d['time_pp_logp']:\n",
    "            pp_logp = self.get_pp_logp(pp_output)\n",
    "\n",
    "        with timecode() as self.batch_time_d['time_loss_fn_loss_calc']:\n",
    "            loss = -reward * pp_logp\n",
    "            loss_batch = torch.mean(loss)\n",
    "\n",
    "        self.batch_d['pp_logp']    =    pp_logp.detach().cpu().tolist()\n",
    "        self.batch_d['loss']       =       loss.detach().cpu().tolist()\n",
    "        self.batch_d['loss_batch'] = loss_batch.detach().cpu().tolist()\n",
    "        return loss_batch\n",
    "    \n",
    "    def reward_fn(self, data, raw, pp_l): \n",
    "        \"\"\"\"\"\"\n",
    "        # Victim model probability differences between orig and pp\n",
    "        with timecode() as self.batch_time_d['time_vm_scores']:\n",
    "            pp_probs = get_vm_probs(pp_l, self._cfg, self.vm_tokenizer, self.vm_model, return_predclass=False)\n",
    "            pp_predclass = torch.argmax(pp_probs, axis=1)\n",
    "            pp_truelabel_probs   = torch.gather(pp_probs, 1, data['label'][:,None]).squeeze()\n",
    "            pp_predclass_probs   = torch.gather(pp_probs, 1, pp_predclass[ :,None]).squeeze()\n",
    "            label_flip = ((pp_predclass != data['label']) * 1)\n",
    "            vm_scores = (data['orig_truelabel_probs'] - pp_truelabel_probs)\n",
    "            \n",
    "        # STS scores\n",
    "        with timecode() as self.batch_time_d['time_sts_scores']:\n",
    "            pp_embeddings  = self.sts_model.encode(pp_l, batch_size=len(raw), convert_to_tensor=True, device=self._cfg.device)\n",
    "            # This returns a cosine similarity matrix, of which we just want the diagonal\n",
    "            sts_scores = pytorch_cos_sim(data['orig_sts_embeddings'], pp_embeddings).diagonal()  \n",
    "\n",
    "        # Reward calculation \n",
    "        rewards = torch.tensor([-0.5 if sts < 0.5 else 0.5+v*sts for v,sts in zip(vm_scores, sts_scores)],device=self._cfg.device)\n",
    "\n",
    "        if self._cfg.normalise_rewards: \n",
    "            self.batch_d['reward_unscaled'] = rewards.detach().cpu().tolist()\n",
    "            rewards = (rewards - torch.mean(rewards)) / torch.std(rewards)\n",
    "        \n",
    "        self.batch_d['pp_truelabel_probs']  = pp_truelabel_probs.detach().cpu().tolist()\n",
    "        self.batch_d['pp_predclass']        = pp_predclass.detach().cpu().tolist()\n",
    "        self.batch_d['pp_predclass_probs']  = pp_predclass_probs.detach().cpu().tolist()\n",
    "        self.batch_d['label_flip']          = label_flip.detach().cpu().tolist()\n",
    "        self.batch_d['label_flip_fraction'] = np.mean(self.batch_d['label_flip'])\n",
    "        self.batch_d['reward']              = rewards.detach().cpu().tolist()\n",
    "        self.batch_d['vm_score']            = vm_scores.detach().cpu().tolist()\n",
    "        self.batch_d['sts_score']           = sts_scores.detach().cpu().tolist()\n",
    "    \n",
    "        return rewards\n",
    "         \n",
    "    def get_pp_logp(self, pp_output): \n",
    "        \"\"\"log(p(pp|orig)) basically.\n",
    "        works for greedy search, will need tweaking for other types probably\"\"\"\n",
    "        ### TODO: this looks like logp to me, not plogp. Find out if this is right and if so rename, if not, fix\n",
    "        ### We want to align tokens with token probabilities. The first token is given at the start \n",
    "        # and has no probability attached to it, so we remove it. \n",
    "        seq_without_first_tkn = pp_output.sequences[:, 1:]\n",
    "        assert seq_without_first_tkn.shape == torch.Size([self.orig_batch_size, self.pp_length - 1])\n",
    "\n",
    "        ### Convert from tuple of scores to one big tensor of scores \n",
    "        scores_stacked = torch.stack(pp_output.scores, 1)\n",
    "        ### TESTS \n",
    "        # We check shape and that there is no +inf or nan in scores. \n",
    "        # Scores can have -inf in them - see explanation in `exploring_generation`.  \n",
    "        assert scores_stacked.shape == torch.Size([self.orig_batch_size, (self.pp_length - 1), self._cfg.vocab_size])\n",
    "        assert torch.all(~torch.isnan(scores_stacked))\n",
    "        assert torch.all(~torch.isposinf(scores_stacked))\n",
    "        # Rough check that all idx before min_length are -inf for all elements in batch\n",
    "        # We do min_length - 1 because sequences are allowed to have length min_length so that idx \n",
    "        # shouldn't be set to -inf\n",
    "        # Not a 100% test but very likely to identify\n",
    "        idx_neginf = torch.nonzero(torch.isneginf(scores_stacked))\n",
    "        assert len(idx_neginf[idx_neginf[:,2] == self.pp_tokenizer.eos_token_id, :]) == \\\n",
    "                  (self._cfg.pp[\"min_length\"] -1) * self.orig_batch_size  \n",
    "        del idx_neginf\n",
    "\n",
    "        ### Take log softmax of scores and then extract those that correspond \n",
    "        # to the generated sequences    \n",
    "        scores_log_softmax = scores_stacked.log_softmax(2)\n",
    "        seq_token_log_probs = torch.gather(scores_log_softmax,2,seq_without_first_tkn[:,:,None]).squeeze(-1)\n",
    "        ### TESTS \n",
    "        # -inf is possible in scores_log_softmax and seq_token_log_probs before the attention mask is added. \n",
    "        assert torch.all(~torch.isnan(   scores_log_softmax))\n",
    "        assert torch.all(~torch.isposinf(scores_log_softmax))\n",
    "        self._check_scores_log_softmax_sums(scores_log_softmax)\n",
    "        # probs should be 1-1 with the filtered tkns: check shape to confirm\n",
    "        assert seq_token_log_probs.shape == seq_without_first_tkn.shape  \n",
    "        # Check that the last token probability corresponds to a possible end token\n",
    "        # this has to be tested before the attention mask is multiplied with it because if the \n",
    "        # padding token is 0 then this will be 0 too (and not the same as scores_log_softmax)\n",
    "        output_end_ids = self.start_end_token_d['output_end_id']\n",
    "        assert all([o in scores_log_softmax[:, -1, output_end_ids] for o in seq_token_log_probs[:,-1]])\n",
    "        del output_end_ids\n",
    "        ## THIS ONE IS LONG - a test rather than assert \n",
    "        # check_seq_token_log_prob_values_are_correct(seq_without_first_tkn, scores_log_softmax, \n",
    "        #                                             seq_token_log_probs) \n",
    "\n",
    "        ### Generate attention mask to identify padding tokens. Then apply it to the \n",
    "        # sequence probabilities so that we don't consider probability of padding tokens \n",
    "        # when getting sequence probabilities. \n",
    "        # Also replace the -inf values in seq_token_log_probs with a large negative number because if we \n",
    "        # leave them in we end up with nan's introduced after multiplying with attention_mask, \n",
    "        # since  -inf * 0 = nan \n",
    "        attention_mask = self.pp_model._prepare_attention_mask_for_generation(\n",
    "            seq_without_first_tkn, self.pp_tokenizer.pad_token_id, self.pp_tokenizer.eos_token_id\n",
    "        )\n",
    "        seq_token_log_probs = torch.nan_to_num(seq_token_log_probs, nan=None, posinf=None, neginf=-10000)\n",
    "        seq_token_log_probs = seq_token_log_probs * attention_mask\n",
    "        ### TESTS\n",
    "        assert seq_token_log_probs.shape == attention_mask.shape == seq_token_log_probs.shape\n",
    "        # check attention mask only has 0 for padding tokens and not eos tokens or anything else\n",
    "        assert all(seq_without_first_tkn[attention_mask == 0] == self.pp_tokenizer.pad_token_id)\n",
    "        check_no_nans_or_infs(seq_token_log_probs)\n",
    "        # check that we aren't picking extrememly rare tokens\n",
    "        assert torch.all(seq_token_log_probs  > -10)  \n",
    "\n",
    "        ### Get sequence probabilities by summing up token log probabilities \n",
    "        seq_log_prob = seq_token_log_probs.sum(-1)\n",
    "        ## TESTS \n",
    "        assert seq_log_prob.shape == torch.Size([self.pp_batch_size])\n",
    "        check_no_nans_or_infs(seq_log_prob)\n",
    "        \n",
    "        if self.pp_model.training:  # don't bother logging or calculate entropy, token_probs in eval mode\n",
    "            if self._cfg.wandb['log_token_entropy']:\n",
    "                with timecode() as self.batch_time_d['time_log_entropy']:\n",
    "                    self.batch_wandb_d['ent_hist'] = self._get_entropy_hist(scores_stacked, attention_mask) \n",
    "            if self._cfg.wandb['log_token_probabilities']: \n",
    "                with timecode() as self.batch_time_d['time_log_token_probabilities']:\n",
    "                    self.batch_wandb_d = merge_dicts(self.batch_wandb_d, \n",
    "                        self._get_token_probability_metrics(scores_log_softmax, attention_mask, k=3))\n",
    "        return seq_log_prob\n",
    "   \n",
    "    def _check_scores_log_softmax_sums(self, scores_log_softmax):\n",
    "        sums = scores_log_softmax.exp().sum(2)\n",
    "        # check that the axes is right\n",
    "        # we want to sum over token probabilities at each generation step, so we \n",
    "        # should end up with a shape [self.orig_batch_size, self.pp_length]\n",
    "        assert sums.shape[0] == self.orig_batch_size  \n",
    "        assert sums.shape[1] == self.pp_length - 1\n",
    "        # check that they sum to 1 along the self.pp_length axis\n",
    "        assert torch.allclose(sums, torch.ones(sums.size(), device=self._cfg.device), atol = 1e-4)\n",
    "\n",
    "    def _check_seq_token_log_prob_values_are_correct(self, seq_without_first_tkn, scores_log_softmax, seq_token_log_probs): \n",
    "        \"\"\"Just enumerates and checks values\n",
    "        Quite slow for large batches so run as a test rather than an assert in every batch. \n",
    "        \"\"\"\n",
    "        l = []\n",
    "        for i_ex in range(self.orig_batch_size):\n",
    "            for i_step in range(self.pp_length - 1):\n",
    "                i_tkn = seq_without_first_tkn[i_ex][i_step].item()\n",
    "                l.append(scores_log_softmax[i_ex,i_step, i_tkn] == seq_token_log_probs[i_ex,i_step])\n",
    "        assert all(l)    \n",
    "    \n",
    "    def _get_entropy_hist(self, scores_stacked, attention_mask): \n",
    "        ent = Categorical(logits = scores_stacked).entropy().detach()\n",
    "        assert ent.shape == attention_mask.shape == torch.Size([self.pp_batch_size, self.pp_length - 1])\n",
    "        ent = ent * attention_mask  # stop values after eos token from contributing to ent score \n",
    "        # first remove structure (otherwise we have ragged arrays), then remove corresponding attention mask values\n",
    "        # we can't just filter by ent[ent != 0] because we might have zero tokens during the sequence\n",
    "        att_flat= attention_mask.flatten()\n",
    "        indices = torch.nonzero(att_flat)\n",
    "        ent_flat = ent.flatten()[indices].flatten()\n",
    "        assert ent_flat.shape[0] == (torch.sum(att_flat)*1).item()\n",
    "        # check everything we filter out is zero \n",
    "        torch.isclose(ent.flatten()[torch.nonzero(~(att_flat > 0))].sum(), torch.tensor(0.), 1e-3)\n",
    "        return Histogram(ent_flat.detach().cpu().tolist())\n",
    "#         ent_d = dict(\n",
    "#       #      ent_min             = ent_flat.quantile(0).item(),\n",
    "#             ent_lower_quartile  = ent_flat.quantile(0.25).item(), \n",
    "#             ent_median          = ent_flat.median().item(), \n",
    "#       #      ent_mean            = ent_flat.mean().item(), \n",
    "#             ent_upper_quartile  = ent_flat.quantile(0.75).item(), \n",
    "#       #      ent_max             = ent_flat.quantile(1).item(),   # skews the graph\n",
    "#             epoch=self.epoch, global_step=self.global_step\n",
    "#         )\n",
    "#         return ent_d\n",
    "        print('tmp')\n",
    "\n",
    "    def _get_token_probability_metrics(self, scores_log_softmax, attention_mask, k=3): \n",
    "        token_prob_d = dict()\n",
    "        tkn_kmaxprob, _ = torch.topk(scores_log_softmax, largest=True, k=k, dim=2)\n",
    "        tkn_kmaxprob = tkn_kmaxprob.detach()  \n",
    "        assert tkn_kmaxprob.shape == torch.Size([self.pp_batch_size, self.pp_length - 1, k])\n",
    "\n",
    "        # % of first prob over 0.9, 0.75, 0.5, 0.3, 0.1\n",
    "        top_probs = tkn_kmaxprob[:,:,0].exp()\n",
    "        top_probs = (top_probs * attention_mask).flatten()\n",
    "        top_probs = top_probs[top_probs != 0]\n",
    "        prob_threshold_l = [0.99, 0.975, 0.95, 0.90, 0.75, 0.5, 0.3, 0.1]\n",
    "        for p in prob_threshold_l: \n",
    "            token_prob_d[f\"top_token_prob_over_{str(p)}\"] = (torch.sum(top_probs > p) / top_probs.shape[0]).item()\n",
    "\n",
    "        # avg + median + lower + upper quartile of first, second, third choice probs\n",
    "        tkn_kmaxprob_mask = tkn_kmaxprob * attention_mask[:,:,None]  # broadcasting over kth dim\n",
    "        for i in range(k): \n",
    "            probs = tkn_kmaxprob_mask[:,:, i].flatten()\n",
    "            probs = probs[probs != 0]\n",
    "            token_prob_d[f\"rank_{i+1}_histogram\"] = Histogram(probs.detach().cpu().tolist())\n",
    "            token_prob_d[f\"rank_{i+1}_token_prob_mean\"] = probs.mean().item()\n",
    "            token_prob_d[f\"rank_{i+1}_token_prob_median\"] = probs.median().item()\n",
    "            token_prob_d[f\"rank_{i+1}_token_prob_0.25_quantile\"] = probs.quantile(0.25).item()\n",
    "            token_prob_d[f\"rank_{i+1}_token_prob_0.75_quantile\"] = probs.quantile(0.75).item()\n",
    "\n",
    "        # tokens over probs above 0.1, 0.01, 0.001, 0.0001, 1/vocab_size prob \n",
    "        allprobs = (scores_log_softmax.detach().exp() * attention_mask[:,:,None]).flatten()\n",
    "        allprobs = allprobs[allprobs != 0]\n",
    "        for p in [0.1, 0.01, 0.001, 0.0001, 0.00001]: \n",
    "            token_prob_d[f\"%_of_tokens_above_prob_{p}\"] =  (torch.sum(allprobs > p) / allprobs.shape[0]).item()\n",
    "        token_prob_d[f\"%_of_tokens_above_prob_1/vocab_size\"] = \\\n",
    "            (torch.sum(allprobs > (1/self._cfg.vocab_size)) / allprobs.shape[0]).item()\n",
    "        return token_prob_d\n",
    "    \n",
    "    def eval_dl(self,split): \n",
    "        \"\"\"Get evaluation metrics for a dataloader\"\"\"\n",
    "        ### TODO: delete redundant stuff\n",
    "        # Put models in eval mode and do the forward pass \n",
    "        # Current logic: push all batches together into one big list.   \n",
    "        self._reset_batch_dicts()\n",
    "        if self.pp_model.training: self.pp_model.eval()\n",
    "        if self.vm_model.training: self.vm_model.eval()\n",
    "        dl_raw = self.ds.dld_raw[split]\n",
    "        dl_tkn = self.ds.dld_tkn[split]\n",
    "        with torch.no_grad(): \n",
    "            for self.batch_num, (data, raw) in enumerate(zip(dl_tkn, dl_raw)):\n",
    "                self.logger.debug(show_gpu(f'EVAL, epoch {self.epoch}, batch {self.batch_num}, GPU memory usage after loading data: '))\n",
    "                for k, v in data.items():\n",
    "                    ## TODO: do you need this line?\n",
    "                    if data[k].device != self._cfg.device: data[k] = data[k].to(self._cfg.device)\n",
    "                pp_output, pp_l = self.pp_model_forward(data)\n",
    "                _ = self.loss_fn(data, raw, pp_output, pp_l)\n",
    "                self._add_batch_vars_to_batch_d(raw, data, pp_l)\n",
    "                self.data_d[split].append(self.batch_d)\n",
    "                self.logger.debug(show_gpu(f'EVAL, epoch {self.epoch}, batch {self.batch_num}, GPU memory usage after loss_fn pass: '))\n",
    "        self._wandb_log_eval_step()  # not implemented yet\n",
    "        \n",
    "    def plot_wandb_charts(self): \n",
    "        ## TODO: rename to indicate it only plots summary and examples charts \n",
    "        ## Can you refactor into regular wandb charts?\n",
    "        if self._cfg.wandb['plot_examples']: \n",
    "            # Examples charts \n",
    "            for split in ['train', 'valid']:\n",
    "                df = pd.DataFrame(data_d[split]) if type(self.data_d[split]) is list else self.data_d[split]\n",
    "                df = df.query(\"idx in @plt_idx_d[@split]\").sort_values(['idx', 'epoch'])\n",
    "                for metric in self._cfg.metrics: \n",
    "                    chart = plot_examples_chart(split, table=wandb.Table(dataframe=df), metric=metric)\n",
    "                    wandb.log({f\"individual_examples/{split}_{metric}_vs_epoch_examples\": chart}, commit=False)  \n",
    "\n",
    "    def add_wandb_run_summary_statistics(self):\n",
    "        \"\"\"Compute test metrics for the run and log them to the wandb run summary pane. \"\"\"\n",
    "        ## Summary statistics of the test set \n",
    "        # From the last epoch atm because we don't have early stopping \n",
    "        test_metrics = self.data_d['test'].filter(self._cfg.metrics, axis=1).mean()\n",
    "        for metric, val in zip(test_metrics.index, test_metrics): \n",
    "            self.run.summary[f\"{metric}_avg_test\"] = val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.wandb['mode'] = 'disabled'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching training on one GPU.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abe916276d6a44c9a50313940b67e14c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now on epoch 0 of 4\n",
      "Now on epoch 1 of 4\n",
      "Now on epoch 2 of 4\n",
      "Now on epoch 3 of 4\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(cfg, vm_tokenizer, vm_model, pp_tokenizer, pp_model, sts_model, optimizer,\n",
    "                  accelerator, ds, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label_flip_fraction</th>\n",
       "      <th>loss_batch</th>\n",
       "      <th>epoch</th>\n",
       "      <th>batch_num</th>\n",
       "      <th>global_step</th>\n",
       "      <th>accumulation_num</th>\n",
       "      <th>orig_length</th>\n",
       "      <th>orig_batch_size</th>\n",
       "      <th>pp_length</th>\n",
       "      <th>pp_batch_size</th>\n",
       "      <th>pp_truelabel_probs</th>\n",
       "      <th>pp_predclass</th>\n",
       "      <th>pp_predclass_probs</th>\n",
       "      <th>label_flip</th>\n",
       "      <th>reward</th>\n",
       "      <th>vm_score</th>\n",
       "      <th>sts_score</th>\n",
       "      <th>pp_logp</th>\n",
       "      <th>loss</th>\n",
       "      <th>idx</th>\n",
       "      <th>orig_l</th>\n",
       "      <th>orig_label</th>\n",
       "      <th>orig_truelabel_probs</th>\n",
       "      <th>pp_l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.093983</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0.914811</td>\n",
       "      <td>0</td>\n",
       "      <td>0.914811</td>\n",
       "      <td>0</td>\n",
       "      <td>0.478535</td>\n",
       "      <td>-0.0221628</td>\n",
       "      <td>0.968495</td>\n",
       "      <td>-0.290953</td>\n",
       "      <td>0.139232</td>\n",
       "      <td>0</td>\n",
       "      <td>I like this movie</td>\n",
       "      <td>0</td>\n",
       "      <td>0.892648</td>\n",
       "      <td>I do not like this movie.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.093983</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0.883751</td>\n",
       "      <td>0</td>\n",
       "      <td>0.883751</td>\n",
       "      <td>0</td>\n",
       "      <td>0.454929</td>\n",
       "      <td>-0.0456876</td>\n",
       "      <td>0.986515</td>\n",
       "      <td>-0.155807</td>\n",
       "      <td>0.0708812</td>\n",
       "      <td>1</td>\n",
       "      <td>I do not like this movie</td>\n",
       "      <td>0</td>\n",
       "      <td>0.838063</td>\n",
       "      <td>I hate this apple.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.093983</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0.910314</td>\n",
       "      <td>1</td>\n",
       "      <td>0.910314</td>\n",
       "      <td>0</td>\n",
       "      <td>0.436599</td>\n",
       "      <td>-0.0638236</td>\n",
       "      <td>0.993377</td>\n",
       "      <td>-0.120736</td>\n",
       "      <td>0.0527134</td>\n",
       "      <td>2</td>\n",
       "      <td>I love this apple</td>\n",
       "      <td>1</td>\n",
       "      <td>0.84649</td>\n",
       "      <td>I love this apple.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.093983</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0.828523</td>\n",
       "      <td>1</td>\n",
       "      <td>0.828523</td>\n",
       "      <td>0</td>\n",
       "      <td>0.378675</td>\n",
       "      <td>-0.122356</td>\n",
       "      <td>0.991577</td>\n",
       "      <td>-0.29869</td>\n",
       "      <td>0.113106</td>\n",
       "      <td>3</td>\n",
       "      <td>I hate this apple</td>\n",
       "      <td>1</td>\n",
       "      <td>0.706167</td>\n",
       "      <td>I like this movie.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.086477</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0.914811</td>\n",
       "      <td>0</td>\n",
       "      <td>0.914811</td>\n",
       "      <td>0</td>\n",
       "      <td>0.478535</td>\n",
       "      <td>-0.0221628</td>\n",
       "      <td>0.968495</td>\n",
       "      <td>-0.267454</td>\n",
       "      <td>0.127986</td>\n",
       "      <td>0</td>\n",
       "      <td>I like this movie</td>\n",
       "      <td>0</td>\n",
       "      <td>0.892648</td>\n",
       "      <td>I do not like this movie.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.086477</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0.883751</td>\n",
       "      <td>0</td>\n",
       "      <td>0.883751</td>\n",
       "      <td>0</td>\n",
       "      <td>0.454929</td>\n",
       "      <td>-0.0456876</td>\n",
       "      <td>0.986515</td>\n",
       "      <td>-0.142381</td>\n",
       "      <td>0.064773</td>\n",
       "      <td>1</td>\n",
       "      <td>I do not like this movie</td>\n",
       "      <td>0</td>\n",
       "      <td>0.838063</td>\n",
       "      <td>I hate this apple.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.086477</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0.910314</td>\n",
       "      <td>1</td>\n",
       "      <td>0.910314</td>\n",
       "      <td>0</td>\n",
       "      <td>0.436599</td>\n",
       "      <td>-0.0638236</td>\n",
       "      <td>0.993377</td>\n",
       "      <td>-0.111618</td>\n",
       "      <td>0.0487322</td>\n",
       "      <td>2</td>\n",
       "      <td>I love this apple</td>\n",
       "      <td>1</td>\n",
       "      <td>0.84649</td>\n",
       "      <td>I love this apple.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.086477</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0.828523</td>\n",
       "      <td>1</td>\n",
       "      <td>0.828523</td>\n",
       "      <td>0</td>\n",
       "      <td>0.378675</td>\n",
       "      <td>-0.122356</td>\n",
       "      <td>0.991577</td>\n",
       "      <td>-0.275746</td>\n",
       "      <td>0.104418</td>\n",
       "      <td>3</td>\n",
       "      <td>I hate this apple</td>\n",
       "      <td>1</td>\n",
       "      <td>0.706167</td>\n",
       "      <td>I like this movie.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.079859</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0.914811</td>\n",
       "      <td>0</td>\n",
       "      <td>0.914811</td>\n",
       "      <td>0</td>\n",
       "      <td>0.478535</td>\n",
       "      <td>-0.0221628</td>\n",
       "      <td>0.968495</td>\n",
       "      <td>-0.246754</td>\n",
       "      <td>0.118081</td>\n",
       "      <td>0</td>\n",
       "      <td>I like this movie</td>\n",
       "      <td>0</td>\n",
       "      <td>0.892648</td>\n",
       "      <td>I do not like this movie.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.079859</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0.883751</td>\n",
       "      <td>0</td>\n",
       "      <td>0.883751</td>\n",
       "      <td>0</td>\n",
       "      <td>0.454929</td>\n",
       "      <td>-0.0456876</td>\n",
       "      <td>0.986515</td>\n",
       "      <td>-0.130604</td>\n",
       "      <td>0.0594156</td>\n",
       "      <td>1</td>\n",
       "      <td>I do not like this movie</td>\n",
       "      <td>0</td>\n",
       "      <td>0.838063</td>\n",
       "      <td>I hate this apple.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.079859</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0.910314</td>\n",
       "      <td>1</td>\n",
       "      <td>0.910314</td>\n",
       "      <td>0</td>\n",
       "      <td>0.436599</td>\n",
       "      <td>-0.0638236</td>\n",
       "      <td>0.993377</td>\n",
       "      <td>-0.103561</td>\n",
       "      <td>0.0452148</td>\n",
       "      <td>2</td>\n",
       "      <td>I love this apple</td>\n",
       "      <td>1</td>\n",
       "      <td>0.84649</td>\n",
       "      <td>I love this apple.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.079859</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0.828523</td>\n",
       "      <td>1</td>\n",
       "      <td>0.828523</td>\n",
       "      <td>0</td>\n",
       "      <td>0.378675</td>\n",
       "      <td>-0.122356</td>\n",
       "      <td>0.991577</td>\n",
       "      <td>-0.255433</td>\n",
       "      <td>0.0967259</td>\n",
       "      <td>3</td>\n",
       "      <td>I hate this apple</td>\n",
       "      <td>1</td>\n",
       "      <td>0.706167</td>\n",
       "      <td>I like this movie.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.073997</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0.914811</td>\n",
       "      <td>0</td>\n",
       "      <td>0.914811</td>\n",
       "      <td>0</td>\n",
       "      <td>0.478535</td>\n",
       "      <td>-0.0221628</td>\n",
       "      <td>0.968495</td>\n",
       "      <td>-0.228448</td>\n",
       "      <td>0.109321</td>\n",
       "      <td>0</td>\n",
       "      <td>I like this movie</td>\n",
       "      <td>0</td>\n",
       "      <td>0.892648</td>\n",
       "      <td>I do not like this movie.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.073997</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0.883751</td>\n",
       "      <td>0</td>\n",
       "      <td>0.883751</td>\n",
       "      <td>0</td>\n",
       "      <td>0.454929</td>\n",
       "      <td>-0.0456876</td>\n",
       "      <td>0.986515</td>\n",
       "      <td>-0.120333</td>\n",
       "      <td>0.0547431</td>\n",
       "      <td>1</td>\n",
       "      <td>I do not like this movie</td>\n",
       "      <td>0</td>\n",
       "      <td>0.838063</td>\n",
       "      <td>I hate this apple.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.073997</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0.910314</td>\n",
       "      <td>1</td>\n",
       "      <td>0.910314</td>\n",
       "      <td>0</td>\n",
       "      <td>0.436599</td>\n",
       "      <td>-0.0638236</td>\n",
       "      <td>0.993377</td>\n",
       "      <td>-0.09642</td>\n",
       "      <td>0.0420969</td>\n",
       "      <td>2</td>\n",
       "      <td>I love this apple</td>\n",
       "      <td>1</td>\n",
       "      <td>0.84649</td>\n",
       "      <td>I love this apple.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.073997</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0.828523</td>\n",
       "      <td>1</td>\n",
       "      <td>0.828523</td>\n",
       "      <td>0</td>\n",
       "      <td>0.378675</td>\n",
       "      <td>-0.122356</td>\n",
       "      <td>0.991577</td>\n",
       "      <td>-0.237212</td>\n",
       "      <td>0.0898263</td>\n",
       "      <td>3</td>\n",
       "      <td>I hate this apple</td>\n",
       "      <td>1</td>\n",
       "      <td>0.706167</td>\n",
       "      <td>I like this movie.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    label_flip_fraction  loss_batch  epoch  batch_num  global_step  \\\n",
       "0                   0.0    0.093983      0          0            1   \n",
       "1                   0.0    0.093983      0          0            1   \n",
       "2                   0.0    0.093983      0          0            1   \n",
       "3                   0.0    0.093983      0          0            1   \n",
       "4                   0.0    0.086477      1          0            2   \n",
       "5                   0.0    0.086477      1          0            2   \n",
       "6                   0.0    0.086477      1          0            2   \n",
       "7                   0.0    0.086477      1          0            2   \n",
       "8                   0.0    0.079859      2          0            3   \n",
       "9                   0.0    0.079859      2          0            3   \n",
       "10                  0.0    0.079859      2          0            3   \n",
       "11                  0.0    0.079859      2          0            3   \n",
       "12                  0.0    0.073997      3          0            4   \n",
       "13                  0.0    0.073997      3          0            4   \n",
       "14                  0.0    0.073997      3          0            4   \n",
       "15                  0.0    0.073997      3          0            4   \n",
       "\n",
       "    accumulation_num  orig_length  orig_batch_size  pp_length  pp_batch_size  \\\n",
       "0                  1            8                4          9              4   \n",
       "1                  1            8                4          9              4   \n",
       "2                  1            8                4          9              4   \n",
       "3                  1            8                4          9              4   \n",
       "4                  2            8                4          9              4   \n",
       "5                  2            8                4          9              4   \n",
       "6                  2            8                4          9              4   \n",
       "7                  2            8                4          9              4   \n",
       "8                  3            8                4          9              4   \n",
       "9                  3            8                4          9              4   \n",
       "10                 3            8                4          9              4   \n",
       "11                 3            8                4          9              4   \n",
       "12                 4            8                4          9              4   \n",
       "13                 4            8                4          9              4   \n",
       "14                 4            8                4          9              4   \n",
       "15                 4            8                4          9              4   \n",
       "\n",
       "   pp_truelabel_probs pp_predclass pp_predclass_probs label_flip    reward  \\\n",
       "0            0.914811            0           0.914811          0  0.478535   \n",
       "1            0.883751            0           0.883751          0  0.454929   \n",
       "2            0.910314            1           0.910314          0  0.436599   \n",
       "3            0.828523            1           0.828523          0  0.378675   \n",
       "4            0.914811            0           0.914811          0  0.478535   \n",
       "5            0.883751            0           0.883751          0  0.454929   \n",
       "6            0.910314            1           0.910314          0  0.436599   \n",
       "7            0.828523            1           0.828523          0  0.378675   \n",
       "8            0.914811            0           0.914811          0  0.478535   \n",
       "9            0.883751            0           0.883751          0  0.454929   \n",
       "10           0.910314            1           0.910314          0  0.436599   \n",
       "11           0.828523            1           0.828523          0  0.378675   \n",
       "12           0.914811            0           0.914811          0  0.478535   \n",
       "13           0.883751            0           0.883751          0  0.454929   \n",
       "14           0.910314            1           0.910314          0  0.436599   \n",
       "15           0.828523            1           0.828523          0  0.378675   \n",
       "\n",
       "     vm_score sts_score   pp_logp       loss idx                    orig_l  \\\n",
       "0  -0.0221628  0.968495 -0.290953   0.139232   0         I like this movie   \n",
       "1  -0.0456876  0.986515 -0.155807  0.0708812   1  I do not like this movie   \n",
       "2  -0.0638236  0.993377 -0.120736  0.0527134   2         I love this apple   \n",
       "3   -0.122356  0.991577  -0.29869   0.113106   3         I hate this apple   \n",
       "4  -0.0221628  0.968495 -0.267454   0.127986   0         I like this movie   \n",
       "5  -0.0456876  0.986515 -0.142381   0.064773   1  I do not like this movie   \n",
       "6  -0.0638236  0.993377 -0.111618  0.0487322   2         I love this apple   \n",
       "7   -0.122356  0.991577 -0.275746   0.104418   3         I hate this apple   \n",
       "8  -0.0221628  0.968495 -0.246754   0.118081   0         I like this movie   \n",
       "9  -0.0456876  0.986515 -0.130604  0.0594156   1  I do not like this movie   \n",
       "10 -0.0638236  0.993377 -0.103561  0.0452148   2         I love this apple   \n",
       "11  -0.122356  0.991577 -0.255433  0.0967259   3         I hate this apple   \n",
       "12 -0.0221628  0.968495 -0.228448   0.109321   0         I like this movie   \n",
       "13 -0.0456876  0.986515 -0.120333  0.0547431   1  I do not like this movie   \n",
       "14 -0.0638236  0.993377  -0.09642  0.0420969   2         I love this apple   \n",
       "15  -0.122356  0.991577 -0.237212  0.0898263   3         I hate this apple   \n",
       "\n",
       "   orig_label orig_truelabel_probs                       pp_l  \n",
       "0           0             0.892648  I do not like this movie.  \n",
       "1           0             0.838063         I hate this apple.  \n",
       "2           1              0.84649         I love this apple.  \n",
       "3           1             0.706167         I like this movie.  \n",
       "4           0             0.892648  I do not like this movie.  \n",
       "5           0             0.838063         I hate this apple.  \n",
       "6           1              0.84649         I love this apple.  \n",
       "7           1             0.706167         I like this movie.  \n",
       "8           0             0.892648  I do not like this movie.  \n",
       "9           0             0.838063         I hate this apple.  \n",
       "10          1              0.84649         I love this apple.  \n",
       "11          1             0.706167         I like this movie.  \n",
       "12          0             0.892648  I do not like this movie.  \n",
       "13          0             0.838063         I hate this apple.  \n",
       "14          1              0.84649         I love this apple.  \n",
       "15          1             0.706167         I like this movie.  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_all(trainer.data_d['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m<ipython-input-18-f60db6496910>\u001b[0m(206)\u001b[0;36m_convert_data_d_to_df\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    204 \u001b[0;31m        \u001b[0mdf_expanded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpack_nested_lists_in_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscalar_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    205 \u001b[0;31m        \u001b[0msplit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'train'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdata_d_key\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"training_step\"\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mdata_d_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 206 \u001b[0;31m        \u001b[0;32massert\u001b[0m \u001b[0mdf_expanded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mds_length\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_train_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    207 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0mdf_expanded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    208 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> split\n",
      "'test'\n",
      "ipdb> self._cfg.ds_length[split]\n",
      "4\n",
      "ipdb> q\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
