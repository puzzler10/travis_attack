{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np \n",
    "from travis_attack.config import Config\n",
    "from travis_attack.insights import get_training_dfs, _prepare_df_concat\n",
    "from travis_attack.utils import display_all\n",
    "from IPython.core.debugger import set_trace\n",
    "import logging \n",
    "logger = logging.getLogger(\"run\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = Config()\n",
    "#run_id = 'cdy5d5yu'\n",
    "run_name = \"pleasant-wind-125\"\n",
    "path_run = f\"{cfg.path_checkpoints}{run_name}/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at some examples "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we just look at some examples to get a feel for what is going on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_interesting_idx(df, n):\n",
    "    def get_idx_with_top_column_values(cname, n=5, ascending=False):\n",
    "        return df[['idx',cname]].\\\n",
    "            drop_duplicates().\\\n",
    "            sort_values(cname, ascending=ascending)\\\n",
    "            ['idx'][0:n].values.tolist()\n",
    "    \n",
    "    def sample_idx_with_label_flips(n=5): \n",
    "        df1 = df[['idx','label_flip']].query(\"label_flip!=0\")\n",
    "        if len(df1) == 0 : print(\"No label flips detected\"); return None\n",
    "        else: return df1.drop_duplicates()['idx'].sample(n).values.tolist()\n",
    "    \n",
    "    idx_d = dict(\n",
    "        random = df.idx.drop_duplicates().sample(n).tolist(),\n",
    "        label_flips = sample_idx_with_label_flips(n=n),\n",
    "        idx_n_unique_pp  = get_idx_with_top_column_values('idx_n_unique_pp',n=n,ascending=False),\n",
    "       # idx_n_pp_changes = get_idx_with_top_column_values('idx_n_pp_changes',n=n,ascending=False),\n",
    "        high_contradiction = get_idx_with_top_column_values('contradiction_score',n=n,ascending=False)\n",
    "    )\n",
    "    return idx_d\n",
    "\n",
    "def print_stats(df, idx_d, key, i):\n",
    "    print(\"\\n###############\\n\")\n",
    "    print(key, i, \"\\n\")\n",
    "    if idx_d[key] is None: return\n",
    "    idx = idx_d[key][i]\n",
    "    # Setup \n",
    "    df1 = df.query('idx==@idx')\n",
    "    orig = pd.unique(df1['orig_l'])[0]\n",
    "    print(\"Original:\", orig)\n",
    "    print(\"Original label\", pd.unique(df1['orig_label'])[0] )\n",
    "    pp_all = list(df1['pp_l'])\n",
    "    #print(\"All paraphrases\", pp_all)\n",
    "    pp_unique = list(pd.unique(df1['pp_l']))\n",
    "    n_pp_unique = len(pp_unique)\n",
    "\n",
    "    # showing a \"timeline\" of how the paraphrases change over the epochs\n",
    "    g_fields = [\"pp_l\",\"pp_truelabel_probs\",\"vm_score\",\"sts_score\",\"pp_letter_diff\", \"contradiction_score\", \"reward\",\"label_flip\", 'pp_logp',\n",
    "       'ref_logp', 'kl_div', 'reward_with_kl', 'loss']\n",
    "    #g_fields = [\"pp_l\",\"vm_score\"]\n",
    "    g = df1.groupby(g_fields).agg({'epoch' : lambda x: list(x)})\n",
    "    g = g.sort_values(by='epoch', key = lambda col: col.map(lambda x: np.min(x)))\n",
    "    print(\"Unique paraphrases:\", n_pp_unique)\n",
    "    print(\"How the paraphrases change:\")\n",
    "    display_all(g)\n",
    "\n",
    "    # Showing a dataframe of the few best paraphrases\n",
    "    best_pps = df1.sort_values('reward', ascending=False).iloc[0]\n",
    "    print(\"Best Paraphrase\")\n",
    "    display_all(best_pps.to_frame().T)\n",
    "        \n",
    "def print_interesting_text_stats(df, n): \n",
    "    idx_d = get_interesting_idx(df, n)\n",
    "    for key in idx_d.keys():\n",
    "        for i in range(n): \n",
    "            print_stats(df, idx_d, key,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['idx', 'epoch', 'orig_l', 'pp_l', 'orig_truelabel_probs',\n",
       "       'pp_truelabel_probs', 'pp_predclass_probs', 'orig_label',\n",
       "       'pp_predclass', 'label_flip', 'vm_score', 'sts_score', 'pp_letter_diff',\n",
       "       'pp_letter_percent', 'contradiction_score', 'reward', 'pp_logp',\n",
       "       'ref_logp', 'kl_div', 'reward_with_kl', 'loss', 'batch_num',\n",
       "       'global_step', 'acc_num', 'loss_sum', 'loss_batch',\n",
       "       'label_flip_fraction', 'orig_length', 'orig_batch_size', 'pp_length',\n",
       "       'pp_batch_size', 'time_generate_pp', 'time_loss_fn', 'time_reward_fn',\n",
       "       'time_vm_scores', 'time_sts_scores', 'time_pp_letter_diff',\n",
       "       'time_contradiction_scores', 'time_pp_logp', 'time_log_entropy',\n",
       "       'time_log_token_probabilities', 'time_ref_logprobs',\n",
       "       'time_loss_fn_loss_calc', 'time_backwards', 'time_calc_gradient_norm',\n",
       "       'time_opt_step_and_calc_param_norm', 'time_opt_step', 'idx_n_unique_pp',\n",
       "       'idx_n_pp_changes', 'epoch_of_first_label_flip', 'n_words_orig',\n",
       "       'n_sentences_orig', 'n_punctuation_orig', 'n_digits_orig',\n",
       "       'n_letters_orig', 'n_words_pp', 'n_sentences_pp', 'n_punctuation_pp',\n",
       "       'n_digits_pp', 'n_letters_pp', 'n_words_diff', 'n_sentences_diff',\n",
       "       'n_punctuation_diff', 'n_digits_diff', 'n_letters_diff', 'removals_idx',\n",
       "       'removals', 'insertions_idx', 'insertions', 'unchanged_idx',\n",
       "       'unchanged', 'n_segments_inserted', 'n_segments_removed',\n",
       "       'n_tokens_inserted', 'n_tokens_removed', 'is_truncation',\n",
       "       'any_phrase_capitalised', 'any_phrase_decapitalised',\n",
       "       'edit_distance_token_level'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_d['training_step'].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "###############\n",
      "\n",
      "random 0 \n",
      "\n",
      "Original: anyone not into high-tech splatterfests is advised to take the warning literally , and log on to something more user-friendly .\n",
      "Original label 0\n",
      "Unique paraphrases: 5\n",
      "How the paraphrases change:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pp_l</th>\n",
       "      <th>pp_truelabel_probs</th>\n",
       "      <th>vm_score</th>\n",
       "      <th>sts_score</th>\n",
       "      <th>pp_letter_diff</th>\n",
       "      <th>contradiction_score</th>\n",
       "      <th>reward</th>\n",
       "      <th>label_flip</th>\n",
       "      <th>pp_logp</th>\n",
       "      <th>ref_logp</th>\n",
       "      <th>kl_div</th>\n",
       "      <th>reward_with_kl</th>\n",
       "      <th>loss</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>The warning is meant to encourage everyone to log on to a better place.</th>\n",
       "      <th>0.32892</th>\n",
       "      <th>0.34492</th>\n",
       "      <th>0.57246</th>\n",
       "      <th>56</th>\n",
       "      <th>0.002114</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1</th>\n",
       "      <th>-20.570507</th>\n",
       "      <th>-73.204269</th>\n",
       "      <th>52.633762</th>\n",
       "      <th>0.0</th>\n",
       "      <th>-0.0</th>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Everyone is advised.</th>\n",
       "      <th>0.31579</th>\n",
       "      <th>0.35805</th>\n",
       "      <th>0.24189</th>\n",
       "      <th>107</th>\n",
       "      <th>0.170527</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1</th>\n",
       "      <th>-4.945487</th>\n",
       "      <th>-28.974981</th>\n",
       "      <th>24.029495</th>\n",
       "      <th>0.0</th>\n",
       "      <th>-0.0</th>\n",
       "      <td>[2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Also, if that.</th>\n",
       "      <th>0.55794</th>\n",
       "      <th>0.11590</th>\n",
       "      <th>0.23023</th>\n",
       "      <th>113</th>\n",
       "      <th>0.009639</th>\n",
       "      <th>0.0</th>\n",
       "      <th>0</th>\n",
       "      <th>-12.836550</th>\n",
       "      <th>-23.372009</th>\n",
       "      <th>10.535460</th>\n",
       "      <th>0.0</th>\n",
       "      <th>-0.0</th>\n",
       "      <td>[3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>It is.. A.</th>\n",
       "      <th>0.33246</th>\n",
       "      <th>0.34138</th>\n",
       "      <th>0.15107</th>\n",
       "      <th>117</th>\n",
       "      <th>0.205445</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1</th>\n",
       "      <th>-11.306890</th>\n",
       "      <th>-28.832207</th>\n",
       "      <th>17.525316</th>\n",
       "      <th>0.0</th>\n",
       "      <th>-0.0</th>\n",
       "      <td>[4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>It is..</th>\n",
       "      <th>0.34807</th>\n",
       "      <th>0.32578</th>\n",
       "      <th>0.16802</th>\n",
       "      <th>120</th>\n",
       "      <th>0.031490</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1</th>\n",
       "      <th>-1.970884</th>\n",
       "      <th>-16.545067</th>\n",
       "      <th>14.574183</th>\n",
       "      <th>0.0</th>\n",
       "      <th>-0.0</th>\n",
       "      <td>[5]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                       epoch\n",
       "pp_l                                                                    pp_truelabel_probs vm_score sts_score pp_letter_diff contradiction_score reward label_flip pp_logp    ref_logp   kl_div    reward_with_kl loss      \n",
       "The warning is meant to encourage everyone to log on to a better place. 0.32892            0.34492  0.57246   56             0.002114            0.0    1          -20.570507 -73.204269 52.633762 0.0            -0.0   [1]\n",
       "Everyone is advised.                                                    0.31579            0.35805  0.24189   107            0.170527            0.0    1          -4.945487  -28.974981 24.029495 0.0            -0.0   [2]\n",
       "Also, if that.                                                          0.55794            0.11590  0.23023   113            0.009639            0.0    0          -12.836550 -23.372009 10.535460 0.0            -0.0   [3]\n",
       "It is.. A.                                                              0.33246            0.34138  0.15107   117            0.205445            0.0    1          -11.306890 -28.832207 17.525316 0.0            -0.0   [4]\n",
       "It is..                                                                 0.34807            0.32578  0.16802   120            0.031490            0.0    1          -1.970884  -16.545067 14.574183 0.0            -0.0   [5]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Paraphrase\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>epoch</th>\n",
       "      <th>orig_l</th>\n",
       "      <th>pp_l</th>\n",
       "      <th>orig_truelabel_probs</th>\n",
       "      <th>pp_truelabel_probs</th>\n",
       "      <th>pp_predclass_probs</th>\n",
       "      <th>orig_label</th>\n",
       "      <th>pp_predclass</th>\n",
       "      <th>label_flip</th>\n",
       "      <th>vm_score</th>\n",
       "      <th>sts_score</th>\n",
       "      <th>pp_letter_diff</th>\n",
       "      <th>pp_letter_percent</th>\n",
       "      <th>contradiction_score</th>\n",
       "      <th>reward</th>\n",
       "      <th>pp_logp</th>\n",
       "      <th>ref_logp</th>\n",
       "      <th>kl_div</th>\n",
       "      <th>reward_with_kl</th>\n",
       "      <th>loss</th>\n",
       "      <th>batch_num</th>\n",
       "      <th>global_step</th>\n",
       "      <th>acc_num</th>\n",
       "      <th>loss_sum</th>\n",
       "      <th>loss_batch</th>\n",
       "      <th>label_flip_fraction</th>\n",
       "      <th>orig_length</th>\n",
       "      <th>orig_batch_size</th>\n",
       "      <th>pp_length</th>\n",
       "      <th>pp_batch_size</th>\n",
       "      <th>time_generate_pp</th>\n",
       "      <th>time_loss_fn</th>\n",
       "      <th>time_reward_fn</th>\n",
       "      <th>time_vm_scores</th>\n",
       "      <th>time_sts_scores</th>\n",
       "      <th>time_pp_letter_diff</th>\n",
       "      <th>time_contradiction_scores</th>\n",
       "      <th>time_pp_logp</th>\n",
       "      <th>time_log_entropy</th>\n",
       "      <th>time_log_token_probabilities</th>\n",
       "      <th>time_ref_logprobs</th>\n",
       "      <th>time_loss_fn_loss_calc</th>\n",
       "      <th>time_backwards</th>\n",
       "      <th>time_calc_gradient_norm</th>\n",
       "      <th>time_opt_step_and_calc_param_norm</th>\n",
       "      <th>time_opt_step</th>\n",
       "      <th>idx_n_unique_pp</th>\n",
       "      <th>idx_n_pp_changes</th>\n",
       "      <th>epoch_of_first_label_flip</th>\n",
       "      <th>n_words_orig</th>\n",
       "      <th>n_sentences_orig</th>\n",
       "      <th>n_punctuation_orig</th>\n",
       "      <th>n_digits_orig</th>\n",
       "      <th>n_letters_orig</th>\n",
       "      <th>n_words_pp</th>\n",
       "      <th>n_sentences_pp</th>\n",
       "      <th>n_punctuation_pp</th>\n",
       "      <th>n_digits_pp</th>\n",
       "      <th>n_letters_pp</th>\n",
       "      <th>n_words_diff</th>\n",
       "      <th>n_sentences_diff</th>\n",
       "      <th>n_punctuation_diff</th>\n",
       "      <th>n_digits_diff</th>\n",
       "      <th>n_letters_diff</th>\n",
       "      <th>removals_idx</th>\n",
       "      <th>removals</th>\n",
       "      <th>insertions_idx</th>\n",
       "      <th>insertions</th>\n",
       "      <th>unchanged_idx</th>\n",
       "      <th>unchanged</th>\n",
       "      <th>n_segments_inserted</th>\n",
       "      <th>n_segments_removed</th>\n",
       "      <th>n_tokens_inserted</th>\n",
       "      <th>n_tokens_removed</th>\n",
       "      <th>is_truncation</th>\n",
       "      <th>any_phrase_capitalised</th>\n",
       "      <th>any_phrase_decapitalised</th>\n",
       "      <th>edit_distance_token_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33440</th>\n",
       "      <td>7669</td>\n",
       "      <td>1</td>\n",
       "      <td>anyone not into high-tech splatterfests is advised to take the warning literally , and log on to something more user-friendly .</td>\n",
       "      <td>The warning is meant to encourage everyone to log on to a better place.</td>\n",
       "      <td>0.673842</td>\n",
       "      <td>0.32892</td>\n",
       "      <td>0.671081</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.34492</td>\n",
       "      <td>0.57246</td>\n",
       "      <td>56</td>\n",
       "      <td>0.559055</td>\n",
       "      <td>0.00211434</td>\n",
       "      <td>0</td>\n",
       "      <td>-20.5705</td>\n",
       "      <td>-73.2043</td>\n",
       "      <td>52.6338</td>\n",
       "      <td>0</td>\n",
       "      <td>-0</td>\n",
       "      <td>362</td>\n",
       "      <td>362</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>8</td>\n",
       "      <td>0.345518</td>\n",
       "      <td>0.717142</td>\n",
       "      <td>0.0525293</td>\n",
       "      <td>0.00814862</td>\n",
       "      <td>0.0273254</td>\n",
       "      <td>0.000119647</td>\n",
       "      <td>0.0161784</td>\n",
       "      <td>0.0144224</td>\n",
       "      <td>0.00360222</td>\n",
       "      <td>0.00534629</td>\n",
       "      <td>0.64977</td>\n",
       "      <td>0.000254783</td>\n",
       "      <td>0.479942</td>\n",
       "      <td>0.0548664</td>\n",
       "      <td>3.13013e-05</td>\n",
       "      <td>1.94786e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>103</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>[2, 3, 4, 5, 6, 7, 8, 10, 16, 17, 18, 19, 20, 21, 28, 29, 30, 31, 32]</td>\n",
       "      <td>[anyone not into high- tech splatterfests, advised, take the warning literally, and, something more user- friendly]</td>\n",
       "      <td>[0, 1, 11, 13, 14, 15, 25, 26, 27]</td>\n",
       "      <td>[The warning, meant, encourage everyone to, a better place]</td>\n",
       "      <td>[9, 12, 22, 23, 24, 33]</td>\n",
       "      <td>[is, to, log on to, .]</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        idx epoch  \\\n",
       "33440  7669     1   \n",
       "\n",
       "                                                                                                                                orig_l  \\\n",
       "33440  anyone not into high-tech splatterfests is advised to take the warning literally , and log on to something more user-friendly .   \n",
       "\n",
       "                                                                          pp_l  \\\n",
       "33440  The warning is meant to encourage everyone to log on to a better place.   \n",
       "\n",
       "      orig_truelabel_probs pp_truelabel_probs pp_predclass_probs orig_label  \\\n",
       "33440             0.673842            0.32892           0.671081          0   \n",
       "\n",
       "      pp_predclass label_flip vm_score sts_score pp_letter_diff  \\\n",
       "33440            1          1  0.34492   0.57246             56   \n",
       "\n",
       "      pp_letter_percent contradiction_score reward  pp_logp ref_logp   kl_div  \\\n",
       "33440          0.559055          0.00211434      0 -20.5705 -73.2043  52.6338   \n",
       "\n",
       "      reward_with_kl loss batch_num global_step acc_num loss_sum loss_batch  \\\n",
       "33440              0   -0       362         362       0        0          0   \n",
       "\n",
       "      label_flip_fraction orig_length orig_batch_size pp_length pp_batch_size  \\\n",
       "33440                0.25          32               8        21             8   \n",
       "\n",
       "      time_generate_pp time_loss_fn time_reward_fn time_vm_scores  \\\n",
       "33440         0.345518     0.717142      0.0525293     0.00814862   \n",
       "\n",
       "      time_sts_scores time_pp_letter_diff time_contradiction_scores  \\\n",
       "33440       0.0273254         0.000119647                 0.0161784   \n",
       "\n",
       "      time_pp_logp time_log_entropy time_log_token_probabilities  \\\n",
       "33440    0.0144224       0.00360222                   0.00534629   \n",
       "\n",
       "      time_ref_logprobs time_loss_fn_loss_calc time_backwards  \\\n",
       "33440           0.64977            0.000254783       0.479942   \n",
       "\n",
       "      time_calc_gradient_norm time_opt_step_and_calc_param_norm time_opt_step  \\\n",
       "33440               0.0548664                       3.13013e-05   1.94786e-06   \n",
       "\n",
       "      idx_n_unique_pp idx_n_pp_changes epoch_of_first_label_flip n_words_orig  \\\n",
       "33440               5                4                         1           19   \n",
       "\n",
       "      n_sentences_orig n_punctuation_orig n_digits_orig n_letters_orig  \\\n",
       "33440                1                  4             0            103   \n",
       "\n",
       "      n_words_pp n_sentences_pp n_punctuation_pp n_digits_pp n_letters_pp  \\\n",
       "33440         14              1                1           0           57   \n",
       "\n",
       "      n_words_diff n_sentences_diff n_punctuation_diff n_digits_diff  \\\n",
       "33440            5                0                  3             0   \n",
       "\n",
       "      n_letters_diff  \\\n",
       "33440             46   \n",
       "\n",
       "                                                                removals_idx  \\\n",
       "33440  [2, 3, 4, 5, 6, 7, 8, 10, 16, 17, 18, 19, 20, 21, 28, 29, 30, 31, 32]   \n",
       "\n",
       "                                                                                                                  removals  \\\n",
       "33440  [anyone not into high- tech splatterfests, advised, take the warning literally, and, something more user- friendly]   \n",
       "\n",
       "                           insertions_idx  \\\n",
       "33440  [0, 1, 11, 13, 14, 15, 25, 26, 27]   \n",
       "\n",
       "                                                        insertions  \\\n",
       "33440  [The warning, meant, encourage everyone to, a better place]   \n",
       "\n",
       "                 unchanged_idx               unchanged n_segments_inserted  \\\n",
       "33440  [9, 12, 22, 23, 24, 33]  [is, to, log on to, .]                   4   \n",
       "\n",
       "      n_segments_removed n_tokens_inserted n_tokens_removed is_truncation  \\\n",
       "33440                  4                 9               19         False   \n",
       "\n",
       "      any_phrase_capitalised any_phrase_decapitalised  \\\n",
       "33440                  False                    False   \n",
       "\n",
       "      edit_distance_token_level  \n",
       "33440                        19  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "###############\n",
      "\n",
      "random 1 \n",
      "\n",
      "Original: seagal ran out of movies years ago , and this is just the proof .\n",
      "Original label 0\n",
      "Unique paraphrases: 5\n",
      "How the paraphrases change:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pp_l</th>\n",
       "      <th>pp_truelabel_probs</th>\n",
       "      <th>vm_score</th>\n",
       "      <th>sts_score</th>\n",
       "      <th>pp_letter_diff</th>\n",
       "      <th>contradiction_score</th>\n",
       "      <th>reward</th>\n",
       "      <th>label_flip</th>\n",
       "      <th>pp_logp</th>\n",
       "      <th>ref_logp</th>\n",
       "      <th>kl_div</th>\n",
       "      <th>reward_with_kl</th>\n",
       "      <th>loss</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>This is the proof.</th>\n",
       "      <th>0.40565</th>\n",
       "      <th>0.24617</th>\n",
       "      <th>0.42420</th>\n",
       "      <th>47</th>\n",
       "      <th>0.000939</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1</th>\n",
       "      <th>-2.576582</th>\n",
       "      <th>-20.612467</th>\n",
       "      <th>18.035885</th>\n",
       "      <th>0.0</th>\n",
       "      <th>-0.0</th>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The proof..</th>\n",
       "      <th>0.38278</th>\n",
       "      <th>0.26904</th>\n",
       "      <th>0.41808</th>\n",
       "      <th>54</th>\n",
       "      <th>0.004152</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1</th>\n",
       "      <th>-2.634676</th>\n",
       "      <th>-25.093000</th>\n",
       "      <th>22.458324</th>\n",
       "      <th>0.0</th>\n",
       "      <th>-0.0</th>\n",
       "      <td>[2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>This is..</th>\n",
       "      <th>0.52917</th>\n",
       "      <th>0.12265</th>\n",
       "      <th>0.13309</th>\n",
       "      <th>56</th>\n",
       "      <th>0.025180</th>\n",
       "      <th>0.0</th>\n",
       "      <th>0</th>\n",
       "      <th>-1.307833</th>\n",
       "      <th>-22.430935</th>\n",
       "      <th>21.123102</th>\n",
       "      <th>0.0</th>\n",
       "      <th>-0.0</th>\n",
       "      <td>[3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>This...</th>\n",
       "      <th>0.54991</th>\n",
       "      <th>0.10191</th>\n",
       "      <th>0.11006</th>\n",
       "      <th>58</th>\n",
       "      <th>0.029038</th>\n",
       "      <th>0.0</th>\n",
       "      <th>0</th>\n",
       "      <th>-1.866032</th>\n",
       "      <th>-29.631813</th>\n",
       "      <th>27.765781</th>\n",
       "      <th>0.0</th>\n",
       "      <th>-0.0</th>\n",
       "      <td>[4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The..-</th>\n",
       "      <th>0.43626</th>\n",
       "      <th>0.21556</th>\n",
       "      <th>0.11753</th>\n",
       "      <th>59</th>\n",
       "      <th>0.051997</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1</th>\n",
       "      <th>-6.823732</th>\n",
       "      <th>-23.249329</th>\n",
       "      <th>16.425596</th>\n",
       "      <th>0.0</th>\n",
       "      <th>-0.0</th>\n",
       "      <td>[5]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                 epoch\n",
       "pp_l               pp_truelabel_probs vm_score sts_score pp_letter_diff contradiction_score reward label_flip pp_logp   ref_logp   kl_div    reward_with_kl loss      \n",
       "This is the proof. 0.40565            0.24617  0.42420   47             0.000939            0.0    1          -2.576582 -20.612467 18.035885 0.0            -0.0   [1]\n",
       "The proof..        0.38278            0.26904  0.41808   54             0.004152            0.0    1          -2.634676 -25.093000 22.458324 0.0            -0.0   [2]\n",
       "This is..          0.52917            0.12265  0.13309   56             0.025180            0.0    0          -1.307833 -22.430935 21.123102 0.0            -0.0   [3]\n",
       "This...            0.54991            0.10191  0.11006   58             0.029038            0.0    0          -1.866032 -29.631813 27.765781 0.0            -0.0   [4]\n",
       "The..-             0.43626            0.21556  0.11753   59             0.051997            0.0    1          -6.823732 -23.249329 16.425596 0.0            -0.0   [5]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Paraphrase\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>epoch</th>\n",
       "      <th>orig_l</th>\n",
       "      <th>pp_l</th>\n",
       "      <th>orig_truelabel_probs</th>\n",
       "      <th>pp_truelabel_probs</th>\n",
       "      <th>pp_predclass_probs</th>\n",
       "      <th>orig_label</th>\n",
       "      <th>pp_predclass</th>\n",
       "      <th>label_flip</th>\n",
       "      <th>vm_score</th>\n",
       "      <th>sts_score</th>\n",
       "      <th>pp_letter_diff</th>\n",
       "      <th>pp_letter_percent</th>\n",
       "      <th>contradiction_score</th>\n",
       "      <th>reward</th>\n",
       "      <th>pp_logp</th>\n",
       "      <th>ref_logp</th>\n",
       "      <th>kl_div</th>\n",
       "      <th>reward_with_kl</th>\n",
       "      <th>loss</th>\n",
       "      <th>batch_num</th>\n",
       "      <th>global_step</th>\n",
       "      <th>acc_num</th>\n",
       "      <th>loss_sum</th>\n",
       "      <th>loss_batch</th>\n",
       "      <th>label_flip_fraction</th>\n",
       "      <th>orig_length</th>\n",
       "      <th>orig_batch_size</th>\n",
       "      <th>pp_length</th>\n",
       "      <th>pp_batch_size</th>\n",
       "      <th>time_generate_pp</th>\n",
       "      <th>time_loss_fn</th>\n",
       "      <th>time_reward_fn</th>\n",
       "      <th>time_vm_scores</th>\n",
       "      <th>time_sts_scores</th>\n",
       "      <th>time_pp_letter_diff</th>\n",
       "      <th>time_contradiction_scores</th>\n",
       "      <th>time_pp_logp</th>\n",
       "      <th>time_log_entropy</th>\n",
       "      <th>time_log_token_probabilities</th>\n",
       "      <th>time_ref_logprobs</th>\n",
       "      <th>time_loss_fn_loss_calc</th>\n",
       "      <th>time_backwards</th>\n",
       "      <th>time_calc_gradient_norm</th>\n",
       "      <th>time_opt_step_and_calc_param_norm</th>\n",
       "      <th>time_opt_step</th>\n",
       "      <th>idx_n_unique_pp</th>\n",
       "      <th>idx_n_pp_changes</th>\n",
       "      <th>epoch_of_first_label_flip</th>\n",
       "      <th>n_words_orig</th>\n",
       "      <th>n_sentences_orig</th>\n",
       "      <th>n_punctuation_orig</th>\n",
       "      <th>n_digits_orig</th>\n",
       "      <th>n_letters_orig</th>\n",
       "      <th>n_words_pp</th>\n",
       "      <th>n_sentences_pp</th>\n",
       "      <th>n_punctuation_pp</th>\n",
       "      <th>n_digits_pp</th>\n",
       "      <th>n_letters_pp</th>\n",
       "      <th>n_words_diff</th>\n",
       "      <th>n_sentences_diff</th>\n",
       "      <th>n_punctuation_diff</th>\n",
       "      <th>n_digits_diff</th>\n",
       "      <th>n_letters_diff</th>\n",
       "      <th>removals_idx</th>\n",
       "      <th>removals</th>\n",
       "      <th>insertions_idx</th>\n",
       "      <th>insertions</th>\n",
       "      <th>unchanged_idx</th>\n",
       "      <th>unchanged</th>\n",
       "      <th>n_segments_inserted</th>\n",
       "      <th>n_segments_removed</th>\n",
       "      <th>n_tokens_inserted</th>\n",
       "      <th>n_tokens_removed</th>\n",
       "      <th>is_truncation</th>\n",
       "      <th>any_phrase_capitalised</th>\n",
       "      <th>any_phrase_decapitalised</th>\n",
       "      <th>edit_distance_token_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21490</th>\n",
       "      <td>4919</td>\n",
       "      <td>1</td>\n",
       "      <td>seagal ran out of movies years ago , and this is just the proof .</td>\n",
       "      <td>This is the proof.</td>\n",
       "      <td>0.651817</td>\n",
       "      <td>0.40565</td>\n",
       "      <td>0.594355</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24617</td>\n",
       "      <td>0.4242</td>\n",
       "      <td>47</td>\n",
       "      <td>0.276923</td>\n",
       "      <td>0.000939389</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.57658</td>\n",
       "      <td>-20.6125</td>\n",
       "      <td>18.0359</td>\n",
       "      <td>0</td>\n",
       "      <td>-0</td>\n",
       "      <td>702</td>\n",
       "      <td>702</td>\n",
       "      <td>0</td>\n",
       "      <td>-9.287</td>\n",
       "      <td>-0.580437</td>\n",
       "      <td>0.125</td>\n",
       "      <td>24</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>0.278298</td>\n",
       "      <td>0.591083</td>\n",
       "      <td>0.0541257</td>\n",
       "      <td>0.0071673</td>\n",
       "      <td>0.0261594</td>\n",
       "      <td>8.03568e-05</td>\n",
       "      <td>0.0197848</td>\n",
       "      <td>0.01273</td>\n",
       "      <td>0.00349506</td>\n",
       "      <td>0.00514101</td>\n",
       "      <td>0.523762</td>\n",
       "      <td>0.000266267</td>\n",
       "      <td>0.412416</td>\n",
       "      <td>0.0487945</td>\n",
       "      <td>4.39729e-05</td>\n",
       "      <td>3.09804e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 14]</td>\n",
       "      <td>[seagal ran out of movies years ago, and this, just]</td>\n",
       "      <td>[11]</td>\n",
       "      <td>[This]</td>\n",
       "      <td>[13, 15, 16, 17]</td>\n",
       "      <td>[is, the proof.]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        idx epoch  \\\n",
       "21490  4919     1   \n",
       "\n",
       "                                                                  orig_l  \\\n",
       "21490  seagal ran out of movies years ago , and this is just the proof .   \n",
       "\n",
       "                     pp_l orig_truelabel_probs pp_truelabel_probs  \\\n",
       "21490  This is the proof.             0.651817            0.40565   \n",
       "\n",
       "      pp_predclass_probs orig_label pp_predclass label_flip vm_score  \\\n",
       "21490           0.594355          0            1          1  0.24617   \n",
       "\n",
       "      sts_score pp_letter_diff pp_letter_percent contradiction_score reward  \\\n",
       "21490    0.4242             47          0.276923         0.000939389      0   \n",
       "\n",
       "       pp_logp ref_logp   kl_div reward_with_kl loss batch_num global_step  \\\n",
       "21490 -2.57658 -20.6125  18.0359              0   -0       702         702   \n",
       "\n",
       "      acc_num loss_sum loss_batch label_flip_fraction orig_length  \\\n",
       "21490       0   -9.287  -0.580437               0.125          24   \n",
       "\n",
       "      orig_batch_size pp_length pp_batch_size time_generate_pp time_loss_fn  \\\n",
       "21490               8        18             8         0.278298     0.591083   \n",
       "\n",
       "      time_reward_fn time_vm_scores time_sts_scores time_pp_letter_diff  \\\n",
       "21490      0.0541257      0.0071673       0.0261594         8.03568e-05   \n",
       "\n",
       "      time_contradiction_scores time_pp_logp time_log_entropy  \\\n",
       "21490                 0.0197848      0.01273       0.00349506   \n",
       "\n",
       "      time_log_token_probabilities time_ref_logprobs time_loss_fn_loss_calc  \\\n",
       "21490                   0.00514101          0.523762            0.000266267   \n",
       "\n",
       "      time_backwards time_calc_gradient_norm  \\\n",
       "21490       0.412416               0.0487945   \n",
       "\n",
       "      time_opt_step_and_calc_param_norm time_opt_step idx_n_unique_pp  \\\n",
       "21490                       4.39729e-05   3.09804e-06               5   \n",
       "\n",
       "      idx_n_pp_changes epoch_of_first_label_flip n_words_orig  \\\n",
       "21490                4                         1           13   \n",
       "\n",
       "      n_sentences_orig n_punctuation_orig n_digits_orig n_letters_orig  \\\n",
       "21490                1                  2             0             49   \n",
       "\n",
       "      n_words_pp n_sentences_pp n_punctuation_pp n_digits_pp n_letters_pp  \\\n",
       "21490          4              1                1           0           14   \n",
       "\n",
       "      n_words_diff n_sentences_diff n_punctuation_diff n_digits_diff  \\\n",
       "21490            9                0                  1             0   \n",
       "\n",
       "      n_letters_diff                        removals_idx  \\\n",
       "21490             35  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 14]   \n",
       "\n",
       "                                                   removals insertions_idx  \\\n",
       "21490  [seagal ran out of movies years ago, and this, just]           [11]   \n",
       "\n",
       "      insertions     unchanged_idx         unchanged n_segments_inserted  \\\n",
       "21490     [This]  [13, 15, 16, 17]  [is, the proof.]                   1   \n",
       "\n",
       "      n_segments_removed n_tokens_inserted n_tokens_removed is_truncation  \\\n",
       "21490                  2                 1               11         False   \n",
       "\n",
       "      any_phrase_capitalised any_phrase_decapitalised  \\\n",
       "21490                  False                    False   \n",
       "\n",
       "      edit_distance_token_level  \n",
       "21490                        11  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "###############\n",
      "\n",
      "random 2 \n",
      "\n",
      "Original: the smartest bonehead comedy of the summer .\n",
      "Original label 1\n",
      "Unique paraphrases: 5\n",
      "How the paraphrases change:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pp_l</th>\n",
       "      <th>pp_truelabel_probs</th>\n",
       "      <th>vm_score</th>\n",
       "      <th>sts_score</th>\n",
       "      <th>pp_letter_diff</th>\n",
       "      <th>contradiction_score</th>\n",
       "      <th>reward</th>\n",
       "      <th>label_flip</th>\n",
       "      <th>pp_logp</th>\n",
       "      <th>ref_logp</th>\n",
       "      <th>kl_div</th>\n",
       "      <th>reward_with_kl</th>\n",
       "      <th>loss</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>The smartest. well.</th>\n",
       "      <th>0.85985</th>\n",
       "      <th>0.04472</th>\n",
       "      <th>0.44944</th>\n",
       "      <th>25</th>\n",
       "      <th>0.013111</th>\n",
       "      <th>0.0</th>\n",
       "      <th>0</th>\n",
       "      <th>-6.778904</th>\n",
       "      <th>-36.438057</th>\n",
       "      <th>29.659153</th>\n",
       "      <th>0.0</th>\n",
       "      <th>-0.0</th>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The...</th>\n",
       "      <th>0.58687</th>\n",
       "      <th>0.31770</th>\n",
       "      <th>0.26614</th>\n",
       "      <th>38</th>\n",
       "      <th>0.111191</th>\n",
       "      <th>0.0</th>\n",
       "      <th>0</th>\n",
       "      <th>-1.508328</th>\n",
       "      <th>-26.960386</th>\n",
       "      <th>25.452059</th>\n",
       "      <th>0.0</th>\n",
       "      <th>-0.0</th>\n",
       "      <td>[2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the funniest..</th>\n",
       "      <th>0.79615</th>\n",
       "      <th>0.10842</th>\n",
       "      <th>0.55660</th>\n",
       "      <th>30</th>\n",
       "      <th>0.001413</th>\n",
       "      <th>0.0</th>\n",
       "      <th>0</th>\n",
       "      <th>-7.386080</th>\n",
       "      <th>-27.154137</th>\n",
       "      <th>19.768057</th>\n",
       "      <th>0.0</th>\n",
       "      <th>-0.0</th>\n",
       "      <td>[3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The... for</th>\n",
       "      <th>0.78824</th>\n",
       "      <th>0.11634</th>\n",
       "      <th>0.19470</th>\n",
       "      <th>34</th>\n",
       "      <th>0.324820</th>\n",
       "      <th>0.0</th>\n",
       "      <th>0</th>\n",
       "      <th>-13.568737</th>\n",
       "      <th>-38.561935</th>\n",
       "      <th>24.993198</th>\n",
       "      <th>0.0</th>\n",
       "      <th>-0.0</th>\n",
       "      <td>[4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A...</th>\n",
       "      <th>0.46707</th>\n",
       "      <th>0.43751</th>\n",
       "      <th>0.21345</th>\n",
       "      <th>40</th>\n",
       "      <th>0.160594</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1</th>\n",
       "      <th>-2.699717</th>\n",
       "      <th>-22.561096</th>\n",
       "      <th>19.861380</th>\n",
       "      <th>0.0</th>\n",
       "      <th>-0.0</th>\n",
       "      <td>[5]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                   epoch\n",
       "pp_l                pp_truelabel_probs vm_score sts_score pp_letter_diff contradiction_score reward label_flip pp_logp    ref_logp   kl_div    reward_with_kl loss      \n",
       "The smartest. well. 0.85985            0.04472  0.44944   25             0.013111            0.0    0          -6.778904  -36.438057 29.659153 0.0            -0.0   [1]\n",
       "The...              0.58687            0.31770  0.26614   38             0.111191            0.0    0          -1.508328  -26.960386 25.452059 0.0            -0.0   [2]\n",
       "the funniest..      0.79615            0.10842  0.55660   30             0.001413            0.0    0          -7.386080  -27.154137 19.768057 0.0            -0.0   [3]\n",
       "The... for          0.78824            0.11634  0.19470   34             0.324820            0.0    0          -13.568737 -38.561935 24.993198 0.0            -0.0   [4]\n",
       "A...                0.46707            0.43751  0.21345   40             0.160594            0.0    1          -2.699717  -22.561096 19.861380 0.0            -0.0   [5]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Paraphrase\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>epoch</th>\n",
       "      <th>orig_l</th>\n",
       "      <th>pp_l</th>\n",
       "      <th>orig_truelabel_probs</th>\n",
       "      <th>pp_truelabel_probs</th>\n",
       "      <th>pp_predclass_probs</th>\n",
       "      <th>orig_label</th>\n",
       "      <th>pp_predclass</th>\n",
       "      <th>label_flip</th>\n",
       "      <th>vm_score</th>\n",
       "      <th>sts_score</th>\n",
       "      <th>pp_letter_diff</th>\n",
       "      <th>pp_letter_percent</th>\n",
       "      <th>contradiction_score</th>\n",
       "      <th>reward</th>\n",
       "      <th>pp_logp</th>\n",
       "      <th>ref_logp</th>\n",
       "      <th>kl_div</th>\n",
       "      <th>reward_with_kl</th>\n",
       "      <th>loss</th>\n",
       "      <th>batch_num</th>\n",
       "      <th>global_step</th>\n",
       "      <th>acc_num</th>\n",
       "      <th>loss_sum</th>\n",
       "      <th>loss_batch</th>\n",
       "      <th>label_flip_fraction</th>\n",
       "      <th>orig_length</th>\n",
       "      <th>orig_batch_size</th>\n",
       "      <th>pp_length</th>\n",
       "      <th>pp_batch_size</th>\n",
       "      <th>time_generate_pp</th>\n",
       "      <th>time_loss_fn</th>\n",
       "      <th>time_reward_fn</th>\n",
       "      <th>time_vm_scores</th>\n",
       "      <th>time_sts_scores</th>\n",
       "      <th>time_pp_letter_diff</th>\n",
       "      <th>time_contradiction_scores</th>\n",
       "      <th>time_pp_logp</th>\n",
       "      <th>time_log_entropy</th>\n",
       "      <th>time_log_token_probabilities</th>\n",
       "      <th>time_ref_logprobs</th>\n",
       "      <th>time_loss_fn_loss_calc</th>\n",
       "      <th>time_backwards</th>\n",
       "      <th>time_calc_gradient_norm</th>\n",
       "      <th>time_opt_step_and_calc_param_norm</th>\n",
       "      <th>time_opt_step</th>\n",
       "      <th>idx_n_unique_pp</th>\n",
       "      <th>idx_n_pp_changes</th>\n",
       "      <th>epoch_of_first_label_flip</th>\n",
       "      <th>n_words_orig</th>\n",
       "      <th>n_sentences_orig</th>\n",
       "      <th>n_punctuation_orig</th>\n",
       "      <th>n_digits_orig</th>\n",
       "      <th>n_letters_orig</th>\n",
       "      <th>n_words_pp</th>\n",
       "      <th>n_sentences_pp</th>\n",
       "      <th>n_punctuation_pp</th>\n",
       "      <th>n_digits_pp</th>\n",
       "      <th>n_letters_pp</th>\n",
       "      <th>n_words_diff</th>\n",
       "      <th>n_sentences_diff</th>\n",
       "      <th>n_punctuation_diff</th>\n",
       "      <th>n_digits_diff</th>\n",
       "      <th>n_letters_diff</th>\n",
       "      <th>removals_idx</th>\n",
       "      <th>removals</th>\n",
       "      <th>insertions_idx</th>\n",
       "      <th>insertions</th>\n",
       "      <th>unchanged_idx</th>\n",
       "      <th>unchanged</th>\n",
       "      <th>n_segments_inserted</th>\n",
       "      <th>n_segments_removed</th>\n",
       "      <th>n_tokens_inserted</th>\n",
       "      <th>n_tokens_removed</th>\n",
       "      <th>is_truncation</th>\n",
       "      <th>any_phrase_capitalised</th>\n",
       "      <th>any_phrase_decapitalised</th>\n",
       "      <th>edit_distance_token_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2330</th>\n",
       "      <td>529</td>\n",
       "      <td>1</td>\n",
       "      <td>the smartest bonehead comedy of the summer .</td>\n",
       "      <td>The smartest. well.</td>\n",
       "      <td>0.904573</td>\n",
       "      <td>0.85985</td>\n",
       "      <td>0.859849</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.04472</td>\n",
       "      <td>0.44944</td>\n",
       "      <td>25</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.0131112</td>\n",
       "      <td>0</td>\n",
       "      <td>-6.7789</td>\n",
       "      <td>-36.4381</td>\n",
       "      <td>29.6592</td>\n",
       "      <td>0</td>\n",
       "      <td>-0</td>\n",
       "      <td>862</td>\n",
       "      <td>862</td>\n",
       "      <td>0</td>\n",
       "      <td>-22.1009</td>\n",
       "      <td>-1.38131</td>\n",
       "      <td>0.25</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>0.13973</td>\n",
       "      <td>0.303546</td>\n",
       "      <td>0.04829</td>\n",
       "      <td>0.00700388</td>\n",
       "      <td>0.0257828</td>\n",
       "      <td>8.56449e-05</td>\n",
       "      <td>0.0147641</td>\n",
       "      <td>0.00836246</td>\n",
       "      <td>0.00189006</td>\n",
       "      <td>0.00403945</td>\n",
       "      <td>0.246512</td>\n",
       "      <td>0.000231455</td>\n",
       "      <td>0.197949</td>\n",
       "      <td>0.0464889</td>\n",
       "      <td>3.00561e-05</td>\n",
       "      <td>2.57418e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>[0, 3, 4, 5, 6, 7]</td>\n",
       "      <td>[the, bonehead comedy of the summer]</td>\n",
       "      <td>[1, 9, 10]</td>\n",
       "      <td>[The, well.]</td>\n",
       "      <td>[2, 8]</td>\n",
       "      <td>[smartest, .]</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      idx epoch                                        orig_l  \\\n",
       "2330  529     1  the smartest bonehead comedy of the summer .   \n",
       "\n",
       "                     pp_l orig_truelabel_probs pp_truelabel_probs  \\\n",
       "2330  The smartest. well.             0.904573            0.85985   \n",
       "\n",
       "     pp_predclass_probs orig_label pp_predclass label_flip vm_score sts_score  \\\n",
       "2330           0.859849          1            1          0  0.04472   0.44944   \n",
       "\n",
       "     pp_letter_diff pp_letter_percent contradiction_score reward pp_logp  \\\n",
       "2330             25          0.431818           0.0131112      0 -6.7789   \n",
       "\n",
       "     ref_logp   kl_div reward_with_kl loss batch_num global_step acc_num  \\\n",
       "2330 -36.4381  29.6592              0   -0       862         862       0   \n",
       "\n",
       "     loss_sum loss_batch label_flip_fraction orig_length orig_batch_size  \\\n",
       "2330 -22.1009   -1.38131                0.25          16               8   \n",
       "\n",
       "     pp_length pp_batch_size time_generate_pp time_loss_fn time_reward_fn  \\\n",
       "2330         9             8          0.13973     0.303546        0.04829   \n",
       "\n",
       "     time_vm_scores time_sts_scores time_pp_letter_diff  \\\n",
       "2330     0.00700388       0.0257828         8.56449e-05   \n",
       "\n",
       "     time_contradiction_scores time_pp_logp time_log_entropy  \\\n",
       "2330                 0.0147641   0.00836246       0.00189006   \n",
       "\n",
       "     time_log_token_probabilities time_ref_logprobs time_loss_fn_loss_calc  \\\n",
       "2330                   0.00403945          0.246512            0.000231455   \n",
       "\n",
       "     time_backwards time_calc_gradient_norm time_opt_step_and_calc_param_norm  \\\n",
       "2330       0.197949               0.0464889                       3.00561e-05   \n",
       "\n",
       "     time_opt_step idx_n_unique_pp idx_n_pp_changes epoch_of_first_label_flip  \\\n",
       "2330   2.57418e-06               5                4                         5   \n",
       "\n",
       "     n_words_orig n_sentences_orig n_punctuation_orig n_digits_orig  \\\n",
       "2330            7                1                  1             0   \n",
       "\n",
       "     n_letters_orig n_words_pp n_sentences_pp n_punctuation_pp n_digits_pp  \\\n",
       "2330             36          3              1                2           0   \n",
       "\n",
       "     n_letters_pp n_words_diff n_sentences_diff n_punctuation_diff  \\\n",
       "2330           15            4                0                 -1   \n",
       "\n",
       "     n_digits_diff n_letters_diff        removals_idx  \\\n",
       "2330             0             21  [0, 3, 4, 5, 6, 7]   \n",
       "\n",
       "                                  removals insertions_idx    insertions  \\\n",
       "2330  [the, bonehead comedy of the summer]     [1, 9, 10]  [The, well.]   \n",
       "\n",
       "     unchanged_idx      unchanged n_segments_inserted n_segments_removed  \\\n",
       "2330        [2, 8]  [smartest, .]                   2                  2   \n",
       "\n",
       "     n_tokens_inserted n_tokens_removed is_truncation any_phrase_capitalised  \\\n",
       "2330                 3                6         False                   True   \n",
       "\n",
       "     any_phrase_decapitalised edit_distance_token_level  \n",
       "2330                    False                         6  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "###############\n",
      "\n",
      "random 3 \n",
      "\n",
      "Original: it has the ability to offend and put off everyone , but it holds you with its outrageousness .\n",
      "Original label 1\n",
      "Unique paraphrases: 3\n",
      "How the paraphrases change:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pp_l</th>\n",
       "      <th>pp_truelabel_probs</th>\n",
       "      <th>vm_score</th>\n",
       "      <th>sts_score</th>\n",
       "      <th>pp_letter_diff</th>\n",
       "      <th>contradiction_score</th>\n",
       "      <th>reward</th>\n",
       "      <th>label_flip</th>\n",
       "      <th>pp_logp</th>\n",
       "      <th>ref_logp</th>\n",
       "      <th>kl_div</th>\n",
       "      <th>reward_with_kl</th>\n",
       "      <th>loss</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>It is so offensive that it makes you think.</th>\n",
       "      <th>0.12038</th>\n",
       "      <th>0.82663</th>\n",
       "      <th>0.66179</th>\n",
       "      <th>51</th>\n",
       "      <th>0.006449</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1</th>\n",
       "      <th>-13.894878</th>\n",
       "      <th>-44.556812</th>\n",
       "      <th>30.661934</th>\n",
       "      <th>0.0</th>\n",
       "      <th>-0.0</th>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>It...</th>\n",
       "      <th>0.52170</th>\n",
       "      <th>0.42532</th>\n",
       "      <th>0.41245</th>\n",
       "      <th>89</th>\n",
       "      <th>0.037801</th>\n",
       "      <th>0.0</th>\n",
       "      <th>0</th>\n",
       "      <th>-1.471241</th>\n",
       "      <th>-26.458559</th>\n",
       "      <th>24.987318</th>\n",
       "      <th>0.0</th>\n",
       "      <th>-0.0</th>\n",
       "      <td>[2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Its...</th>\n",
       "      <th>0.56726</th>\n",
       "      <th>0.37976</th>\n",
       "      <th>0.39020</th>\n",
       "      <th>88</th>\n",
       "      <th>0.051869</th>\n",
       "      <th>0.0</th>\n",
       "      <th>0</th>\n",
       "      <th>-5.460187</th>\n",
       "      <th>-27.396584</th>\n",
       "      <th>21.936396</th>\n",
       "      <th>0.0</th>\n",
       "      <th>-0.0</th>\n",
       "      <td>[3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">It...</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">0.52170</th>\n",
       "      <th>0.42531</th>\n",
       "      <th>0.41245</th>\n",
       "      <th>89</th>\n",
       "      <th>0.037801</th>\n",
       "      <th>0.0</th>\n",
       "      <th>0</th>\n",
       "      <th>-0.437742</th>\n",
       "      <th>-24.311935</th>\n",
       "      <th>23.874193</th>\n",
       "      <th>0.0</th>\n",
       "      <th>-0.0</th>\n",
       "      <td>[4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.42532</th>\n",
       "      <th>0.41245</th>\n",
       "      <th>89</th>\n",
       "      <th>0.037801</th>\n",
       "      <th>0.0</th>\n",
       "      <th>0</th>\n",
       "      <th>-4.675045</th>\n",
       "      <th>-23.699757</th>\n",
       "      <th>19.024712</th>\n",
       "      <th>0.0</th>\n",
       "      <th>-0.0</th>\n",
       "      <td>[5]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                           epoch\n",
       "pp_l                                        pp_truelabel_probs vm_score sts_score pp_letter_diff contradiction_score reward label_flip pp_logp    ref_logp   kl_div    reward_with_kl loss      \n",
       "It is so offensive that it makes you think. 0.12038            0.82663  0.66179   51             0.006449            0.0    1          -13.894878 -44.556812 30.661934 0.0            -0.0   [1]\n",
       "It...                                       0.52170            0.42532  0.41245   89             0.037801            0.0    0          -1.471241  -26.458559 24.987318 0.0            -0.0   [2]\n",
       "Its...                                      0.56726            0.37976  0.39020   88             0.051869            0.0    0          -5.460187  -27.396584 21.936396 0.0            -0.0   [3]\n",
       "It...                                       0.52170            0.42531  0.41245   89             0.037801            0.0    0          -0.437742  -24.311935 23.874193 0.0            -0.0   [4]\n",
       "                                                               0.42532  0.41245   89             0.037801            0.0    0          -4.675045  -23.699757 19.024712 0.0            -0.0   [5]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Paraphrase\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>epoch</th>\n",
       "      <th>orig_l</th>\n",
       "      <th>pp_l</th>\n",
       "      <th>orig_truelabel_probs</th>\n",
       "      <th>pp_truelabel_probs</th>\n",
       "      <th>pp_predclass_probs</th>\n",
       "      <th>orig_label</th>\n",
       "      <th>pp_predclass</th>\n",
       "      <th>label_flip</th>\n",
       "      <th>vm_score</th>\n",
       "      <th>sts_score</th>\n",
       "      <th>pp_letter_diff</th>\n",
       "      <th>pp_letter_percent</th>\n",
       "      <th>contradiction_score</th>\n",
       "      <th>reward</th>\n",
       "      <th>pp_logp</th>\n",
       "      <th>ref_logp</th>\n",
       "      <th>kl_div</th>\n",
       "      <th>reward_with_kl</th>\n",
       "      <th>loss</th>\n",
       "      <th>batch_num</th>\n",
       "      <th>global_step</th>\n",
       "      <th>acc_num</th>\n",
       "      <th>loss_sum</th>\n",
       "      <th>loss_batch</th>\n",
       "      <th>label_flip_fraction</th>\n",
       "      <th>orig_length</th>\n",
       "      <th>orig_batch_size</th>\n",
       "      <th>pp_length</th>\n",
       "      <th>pp_batch_size</th>\n",
       "      <th>time_generate_pp</th>\n",
       "      <th>time_loss_fn</th>\n",
       "      <th>time_reward_fn</th>\n",
       "      <th>time_vm_scores</th>\n",
       "      <th>time_sts_scores</th>\n",
       "      <th>time_pp_letter_diff</th>\n",
       "      <th>time_contradiction_scores</th>\n",
       "      <th>time_pp_logp</th>\n",
       "      <th>time_log_entropy</th>\n",
       "      <th>time_log_token_probabilities</th>\n",
       "      <th>time_ref_logprobs</th>\n",
       "      <th>time_loss_fn_loss_calc</th>\n",
       "      <th>time_backwards</th>\n",
       "      <th>time_calc_gradient_norm</th>\n",
       "      <th>time_opt_step_and_calc_param_norm</th>\n",
       "      <th>time_opt_step</th>\n",
       "      <th>idx_n_unique_pp</th>\n",
       "      <th>idx_n_pp_changes</th>\n",
       "      <th>epoch_of_first_label_flip</th>\n",
       "      <th>n_words_orig</th>\n",
       "      <th>n_sentences_orig</th>\n",
       "      <th>n_punctuation_orig</th>\n",
       "      <th>n_digits_orig</th>\n",
       "      <th>n_letters_orig</th>\n",
       "      <th>n_words_pp</th>\n",
       "      <th>n_sentences_pp</th>\n",
       "      <th>n_punctuation_pp</th>\n",
       "      <th>n_digits_pp</th>\n",
       "      <th>n_letters_pp</th>\n",
       "      <th>n_words_diff</th>\n",
       "      <th>n_sentences_diff</th>\n",
       "      <th>n_punctuation_diff</th>\n",
       "      <th>n_digits_diff</th>\n",
       "      <th>n_letters_diff</th>\n",
       "      <th>removals_idx</th>\n",
       "      <th>removals</th>\n",
       "      <th>insertions_idx</th>\n",
       "      <th>insertions</th>\n",
       "      <th>unchanged_idx</th>\n",
       "      <th>unchanged</th>\n",
       "      <th>n_segments_inserted</th>\n",
       "      <th>n_segments_removed</th>\n",
       "      <th>n_tokens_inserted</th>\n",
       "      <th>n_tokens_removed</th>\n",
       "      <th>is_truncation</th>\n",
       "      <th>any_phrase_capitalised</th>\n",
       "      <th>any_phrase_decapitalised</th>\n",
       "      <th>edit_distance_token_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5935</th>\n",
       "      <td>1342</td>\n",
       "      <td>1</td>\n",
       "      <td>it has the ability to offend and put off everyone , but it holds you with its outrageousness .</td>\n",
       "      <td>It is so offensive that it makes you think.</td>\n",
       "      <td>0.947016</td>\n",
       "      <td>0.12038</td>\n",
       "      <td>0.879617</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.82663</td>\n",
       "      <td>0.66179</td>\n",
       "      <td>51</td>\n",
       "      <td>0.457447</td>\n",
       "      <td>0.00644865</td>\n",
       "      <td>0</td>\n",
       "      <td>-13.8949</td>\n",
       "      <td>-44.5568</td>\n",
       "      <td>30.6619</td>\n",
       "      <td>0</td>\n",
       "      <td>-0</td>\n",
       "      <td>582</td>\n",
       "      <td>582</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>24</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>0.223621</td>\n",
       "      <td>0.479371</td>\n",
       "      <td>0.05127</td>\n",
       "      <td>0.00709177</td>\n",
       "      <td>0.0267596</td>\n",
       "      <td>7.80192e-05</td>\n",
       "      <td>0.0166185</td>\n",
       "      <td>0.0106742</td>\n",
       "      <td>0.00259675</td>\n",
       "      <td>0.00484745</td>\n",
       "      <td>0.417048</td>\n",
       "      <td>0.000226625</td>\n",
       "      <td>0.31791</td>\n",
       "      <td>0.0496199</td>\n",
       "      <td>3.00743e-05</td>\n",
       "      <td>2.41585e-06</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>74</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>[7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 22, 23, 24]</td>\n",
       "      <td>[has the ability to offend and put off everyone, but it holds, with its outrageousness]</td>\n",
       "      <td>[0, 1, 2, 3, 4, 6, 21]</td>\n",
       "      <td>[It is so offensive that, makes, think]</td>\n",
       "      <td>[5, 20, 25]</td>\n",
       "      <td>[it, you, .]</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       idx epoch  \\\n",
       "5935  1342     1   \n",
       "\n",
       "                                                                                              orig_l  \\\n",
       "5935  it has the ability to offend and put off everyone , but it holds you with its outrageousness .   \n",
       "\n",
       "                                             pp_l orig_truelabel_probs  \\\n",
       "5935  It is so offensive that it makes you think.             0.947016   \n",
       "\n",
       "     pp_truelabel_probs pp_predclass_probs orig_label pp_predclass label_flip  \\\n",
       "5935            0.12038           0.879617          1            0          1   \n",
       "\n",
       "     vm_score sts_score pp_letter_diff pp_letter_percent contradiction_score  \\\n",
       "5935  0.82663   0.66179             51          0.457447          0.00644865   \n",
       "\n",
       "     reward  pp_logp ref_logp   kl_div reward_with_kl loss batch_num  \\\n",
       "5935      0 -13.8949 -44.5568  30.6619              0   -0       582   \n",
       "\n",
       "     global_step acc_num loss_sum loss_batch label_flip_fraction orig_length  \\\n",
       "5935         582       0        0          0                0.25          24   \n",
       "\n",
       "     orig_batch_size pp_length pp_batch_size time_generate_pp time_loss_fn  \\\n",
       "5935               8        14             8         0.223621     0.479371   \n",
       "\n",
       "     time_reward_fn time_vm_scores time_sts_scores time_pp_letter_diff  \\\n",
       "5935        0.05127     0.00709177       0.0267596         7.80192e-05   \n",
       "\n",
       "     time_contradiction_scores time_pp_logp time_log_entropy  \\\n",
       "5935                 0.0166185    0.0106742       0.00259675   \n",
       "\n",
       "     time_log_token_probabilities time_ref_logprobs time_loss_fn_loss_calc  \\\n",
       "5935                   0.00484745          0.417048            0.000226625   \n",
       "\n",
       "     time_backwards time_calc_gradient_norm time_opt_step_and_calc_param_norm  \\\n",
       "5935        0.31791               0.0496199                       3.00743e-05   \n",
       "\n",
       "     time_opt_step idx_n_unique_pp idx_n_pp_changes epoch_of_first_label_flip  \\\n",
       "5935   2.41585e-06               3                3                         1   \n",
       "\n",
       "     n_words_orig n_sentences_orig n_punctuation_orig n_digits_orig  \\\n",
       "5935           17                1                  2             0   \n",
       "\n",
       "     n_letters_orig n_words_pp n_sentences_pp n_punctuation_pp n_digits_pp  \\\n",
       "5935             74          9              1                1           0   \n",
       "\n",
       "     n_letters_pp n_words_diff n_sentences_diff n_punctuation_diff  \\\n",
       "5935           34            8                0                  1   \n",
       "\n",
       "     n_digits_diff n_letters_diff  \\\n",
       "5935             0             40   \n",
       "\n",
       "                                                       removals_idx  \\\n",
       "5935  [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 22, 23, 24]   \n",
       "\n",
       "                                                                                     removals  \\\n",
       "5935  [has the ability to offend and put off everyone, but it holds, with its outrageousness]   \n",
       "\n",
       "              insertions_idx                               insertions  \\\n",
       "5935  [0, 1, 2, 3, 4, 6, 21]  [It is so offensive that, makes, think]   \n",
       "\n",
       "     unchanged_idx     unchanged n_segments_inserted n_segments_removed  \\\n",
       "5935   [5, 20, 25]  [it, you, .]                   3                  2   \n",
       "\n",
       "     n_tokens_inserted n_tokens_removed is_truncation any_phrase_capitalised  \\\n",
       "5935                 7               16         False                  False   \n",
       "\n",
       "     any_phrase_decapitalised edit_distance_token_level  \n",
       "5935                    False                        16  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "###############\n",
      "\n",
      "random 4 \n",
      "\n",
      "Original: a valueless kiddie paean to pro basketball underwritten by the nba .\n",
      "Original label 0\n",
      "Unique paraphrases: 5\n",
      "How the paraphrases change:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pp_l</th>\n",
       "      <th>pp_truelabel_probs</th>\n",
       "      <th>vm_score</th>\n",
       "      <th>sts_score</th>\n",
       "      <th>pp_letter_diff</th>\n",
       "      <th>contradiction_score</th>\n",
       "      <th>reward</th>\n",
       "      <th>label_flip</th>\n",
       "      <th>pp_logp</th>\n",
       "      <th>ref_logp</th>\n",
       "      <th>kl_div</th>\n",
       "      <th>reward_with_kl</th>\n",
       "      <th>loss</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>The nba is.</th>\n",
       "      <th>0.65499</th>\n",
       "      <th>0.27533</th>\n",
       "      <th>0.30940</th>\n",
       "      <th>57</th>\n",
       "      <th>0.019489</th>\n",
       "      <th>0.0</th>\n",
       "      <th>0</th>\n",
       "      <th>-2.681497</th>\n",
       "      <th>-11.678024</th>\n",
       "      <th>8.996527</th>\n",
       "      <th>0.0</th>\n",
       "      <th>-0.0</th>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The. and..</th>\n",
       "      <th>0.43461</th>\n",
       "      <th>0.49571</th>\n",
       "      <th>0.18062</th>\n",
       "      <th>58</th>\n",
       "      <th>0.153481</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1</th>\n",
       "      <th>-11.211037</th>\n",
       "      <th>-33.349525</th>\n",
       "      <th>22.138489</th>\n",
       "      <th>0.0</th>\n",
       "      <th>-0.0</th>\n",
       "      <td>[2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A...</th>\n",
       "      <th>0.53293</th>\n",
       "      <th>0.39738</th>\n",
       "      <th>0.28200</th>\n",
       "      <th>64</th>\n",
       "      <th>0.385708</th>\n",
       "      <th>0.0</th>\n",
       "      <th>0</th>\n",
       "      <th>-0.733000</th>\n",
       "      <th>-27.730814</th>\n",
       "      <th>26.997814</th>\n",
       "      <th>0.0</th>\n",
       "      <th>-0.0</th>\n",
       "      <td>[3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A.99..</th>\n",
       "      <th>0.47926</th>\n",
       "      <th>0.45106</th>\n",
       "      <th>0.27286</th>\n",
       "      <th>62</th>\n",
       "      <th>0.680192</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1</th>\n",
       "      <th>-7.659225</th>\n",
       "      <th>-37.261974</th>\n",
       "      <th>29.602749</th>\n",
       "      <th>0.0</th>\n",
       "      <th>-0.0</th>\n",
       "      <td>[4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A..2..3.</th>\n",
       "      <th>0.66136</th>\n",
       "      <th>0.26896</th>\n",
       "      <th>0.25385</th>\n",
       "      <th>60</th>\n",
       "      <th>0.632533</th>\n",
       "      <th>0.0</th>\n",
       "      <th>0</th>\n",
       "      <th>-18.150717</th>\n",
       "      <th>-54.316368</th>\n",
       "      <th>36.165649</th>\n",
       "      <th>0.0</th>\n",
       "      <th>-0.0</th>\n",
       "      <td>[5]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                           epoch\n",
       "pp_l        pp_truelabel_probs vm_score sts_score pp_letter_diff contradiction_score reward label_flip pp_logp    ref_logp   kl_div    reward_with_kl loss      \n",
       "The nba is. 0.65499            0.27533  0.30940   57             0.019489            0.0    0          -2.681497  -11.678024 8.996527  0.0            -0.0   [1]\n",
       "The. and..  0.43461            0.49571  0.18062   58             0.153481            0.0    1          -11.211037 -33.349525 22.138489 0.0            -0.0   [2]\n",
       "A...        0.53293            0.39738  0.28200   64             0.385708            0.0    0          -0.733000  -27.730814 26.997814 0.0            -0.0   [3]\n",
       "A.99..      0.47926            0.45106  0.27286   62             0.680192            0.0    1          -7.659225  -37.261974 29.602749 0.0            -0.0   [4]\n",
       "A..2..3.    0.66136            0.26896  0.25385   60             0.632533            0.0    0          -18.150717 -54.316368 36.165649 0.0            -0.0   [5]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Paraphrase\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>epoch</th>\n",
       "      <th>orig_l</th>\n",
       "      <th>pp_l</th>\n",
       "      <th>orig_truelabel_probs</th>\n",
       "      <th>pp_truelabel_probs</th>\n",
       "      <th>pp_predclass_probs</th>\n",
       "      <th>orig_label</th>\n",
       "      <th>pp_predclass</th>\n",
       "      <th>label_flip</th>\n",
       "      <th>vm_score</th>\n",
       "      <th>sts_score</th>\n",
       "      <th>pp_letter_diff</th>\n",
       "      <th>pp_letter_percent</th>\n",
       "      <th>contradiction_score</th>\n",
       "      <th>reward</th>\n",
       "      <th>pp_logp</th>\n",
       "      <th>ref_logp</th>\n",
       "      <th>kl_div</th>\n",
       "      <th>reward_with_kl</th>\n",
       "      <th>loss</th>\n",
       "      <th>batch_num</th>\n",
       "      <th>global_step</th>\n",
       "      <th>acc_num</th>\n",
       "      <th>loss_sum</th>\n",
       "      <th>loss_batch</th>\n",
       "      <th>label_flip_fraction</th>\n",
       "      <th>orig_length</th>\n",
       "      <th>orig_batch_size</th>\n",
       "      <th>pp_length</th>\n",
       "      <th>pp_batch_size</th>\n",
       "      <th>time_generate_pp</th>\n",
       "      <th>time_loss_fn</th>\n",
       "      <th>time_reward_fn</th>\n",
       "      <th>time_vm_scores</th>\n",
       "      <th>time_sts_scores</th>\n",
       "      <th>time_pp_letter_diff</th>\n",
       "      <th>time_contradiction_scores</th>\n",
       "      <th>time_pp_logp</th>\n",
       "      <th>time_log_entropy</th>\n",
       "      <th>time_log_token_probabilities</th>\n",
       "      <th>time_ref_logprobs</th>\n",
       "      <th>time_loss_fn_loss_calc</th>\n",
       "      <th>time_backwards</th>\n",
       "      <th>time_calc_gradient_norm</th>\n",
       "      <th>time_opt_step_and_calc_param_norm</th>\n",
       "      <th>time_opt_step</th>\n",
       "      <th>idx_n_unique_pp</th>\n",
       "      <th>idx_n_pp_changes</th>\n",
       "      <th>epoch_of_first_label_flip</th>\n",
       "      <th>n_words_orig</th>\n",
       "      <th>n_sentences_orig</th>\n",
       "      <th>n_punctuation_orig</th>\n",
       "      <th>n_digits_orig</th>\n",
       "      <th>n_letters_orig</th>\n",
       "      <th>n_words_pp</th>\n",
       "      <th>n_sentences_pp</th>\n",
       "      <th>n_punctuation_pp</th>\n",
       "      <th>n_digits_pp</th>\n",
       "      <th>n_letters_pp</th>\n",
       "      <th>n_words_diff</th>\n",
       "      <th>n_sentences_diff</th>\n",
       "      <th>n_punctuation_diff</th>\n",
       "      <th>n_digits_diff</th>\n",
       "      <th>n_letters_diff</th>\n",
       "      <th>removals_idx</th>\n",
       "      <th>removals</th>\n",
       "      <th>insertions_idx</th>\n",
       "      <th>insertions</th>\n",
       "      <th>unchanged_idx</th>\n",
       "      <th>unchanged</th>\n",
       "      <th>n_segments_inserted</th>\n",
       "      <th>n_segments_removed</th>\n",
       "      <th>n_tokens_inserted</th>\n",
       "      <th>n_tokens_removed</th>\n",
       "      <th>is_truncation</th>\n",
       "      <th>any_phrase_capitalised</th>\n",
       "      <th>any_phrase_decapitalised</th>\n",
       "      <th>edit_distance_token_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25600</th>\n",
       "      <td>5865</td>\n",
       "      <td>1</td>\n",
       "      <td>a valueless kiddie paean to pro basketball underwritten by the nba .</td>\n",
       "      <td>The nba is.</td>\n",
       "      <td>0.930316</td>\n",
       "      <td>0.65499</td>\n",
       "      <td>0.654987</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.27533</td>\n",
       "      <td>0.3094</td>\n",
       "      <td>57</td>\n",
       "      <td>0.161765</td>\n",
       "      <td>0.0194892</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.6815</td>\n",
       "      <td>-11.678</td>\n",
       "      <td>8.99653</td>\n",
       "      <td>0</td>\n",
       "      <td>-0</td>\n",
       "      <td>759</td>\n",
       "      <td>759</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>0.206515</td>\n",
       "      <td>0.422887</td>\n",
       "      <td>0.0494658</td>\n",
       "      <td>0.00704545</td>\n",
       "      <td>0.0261724</td>\n",
       "      <td>7.93179e-05</td>\n",
       "      <td>0.0155245</td>\n",
       "      <td>0.0101787</td>\n",
       "      <td>0.00243717</td>\n",
       "      <td>0.00456362</td>\n",
       "      <td>0.362816</td>\n",
       "      <td>0.000256948</td>\n",
       "      <td>0.28969</td>\n",
       "      <td>0.046372</td>\n",
       "      <td>0.169981</td>\n",
       "      <td>0.104578</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]</td>\n",
       "      <td>[a valueless kiddie paean to pro basketball underwritten by the]</td>\n",
       "      <td>[0, 12]</td>\n",
       "      <td>[The, is]</td>\n",
       "      <td>[11, 13]</td>\n",
       "      <td>[nba, .]</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        idx epoch  \\\n",
       "25600  5865     1   \n",
       "\n",
       "                                                                     orig_l  \\\n",
       "25600  a valueless kiddie paean to pro basketball underwritten by the nba .   \n",
       "\n",
       "              pp_l orig_truelabel_probs pp_truelabel_probs pp_predclass_probs  \\\n",
       "25600  The nba is.             0.930316            0.65499           0.654987   \n",
       "\n",
       "      orig_label pp_predclass label_flip vm_score sts_score pp_letter_diff  \\\n",
       "25600          0            0          0  0.27533    0.3094             57   \n",
       "\n",
       "      pp_letter_percent contradiction_score reward pp_logp ref_logp   kl_div  \\\n",
       "25600          0.161765           0.0194892      0 -2.6815  -11.678  8.99653   \n",
       "\n",
       "      reward_with_kl loss batch_num global_step acc_num loss_sum loss_batch  \\\n",
       "25600              0   -0       759         759       1        0          0   \n",
       "\n",
       "      label_flip_fraction orig_length orig_batch_size pp_length pp_batch_size  \\\n",
       "25600                   0          16               8        13             8   \n",
       "\n",
       "      time_generate_pp time_loss_fn time_reward_fn time_vm_scores  \\\n",
       "25600         0.206515     0.422887      0.0494658     0.00704545   \n",
       "\n",
       "      time_sts_scores time_pp_letter_diff time_contradiction_scores  \\\n",
       "25600       0.0261724         7.93179e-05                 0.0155245   \n",
       "\n",
       "      time_pp_logp time_log_entropy time_log_token_probabilities  \\\n",
       "25600    0.0101787       0.00243717                   0.00456362   \n",
       "\n",
       "      time_ref_logprobs time_loss_fn_loss_calc time_backwards  \\\n",
       "25600          0.362816            0.000256948        0.28969   \n",
       "\n",
       "      time_calc_gradient_norm time_opt_step_and_calc_param_norm time_opt_step  \\\n",
       "25600                0.046372                          0.169981      0.104578   \n",
       "\n",
       "      idx_n_unique_pp idx_n_pp_changes epoch_of_first_label_flip n_words_orig  \\\n",
       "25600               5                4                         2           11   \n",
       "\n",
       "      n_sentences_orig n_punctuation_orig n_digits_orig n_letters_orig  \\\n",
       "25600                1                  1             0             56   \n",
       "\n",
       "      n_words_pp n_sentences_pp n_punctuation_pp n_digits_pp n_letters_pp  \\\n",
       "25600          3              1                1           0            8   \n",
       "\n",
       "      n_words_diff n_sentences_diff n_punctuation_diff n_digits_diff  \\\n",
       "25600            8                0                  0             0   \n",
       "\n",
       "      n_letters_diff                     removals_idx  \\\n",
       "25600             48  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]   \n",
       "\n",
       "                                                               removals  \\\n",
       "25600  [a valueless kiddie paean to pro basketball underwritten by the]   \n",
       "\n",
       "      insertions_idx insertions unchanged_idx unchanged n_segments_inserted  \\\n",
       "25600        [0, 12]  [The, is]      [11, 13]  [nba, .]                   2   \n",
       "\n",
       "      n_segments_removed n_tokens_inserted n_tokens_removed is_truncation  \\\n",
       "25600                  1                 2               10         False   \n",
       "\n",
       "      any_phrase_capitalised any_phrase_decapitalised  \\\n",
       "25600                  False                    False   \n",
       "\n",
       "      edit_distance_token_level  \n",
       "25600                        11  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "###############\n",
      "\n",
      "label_flips 0 \n",
      "\n",
      "Original: suffers from all the excesses of the genre .\n",
      "Original label 0\n",
      "Unique paraphrases: 5\n",
      "How the paraphrases change:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pp_l</th>\n",
       "      <th>pp_truelabel_probs</th>\n",
       "      <th>vm_score</th>\n",
       "      <th>sts_score</th>\n",
       "      <th>pp_letter_diff</th>\n",
       "      <th>contradiction_score</th>\n",
       "      <th>reward</th>\n",
       "      <th>label_flip</th>\n",
       "      <th>pp_logp</th>\n",
       "      <th>ref_logp</th>\n",
       "      <th>kl_div</th>\n",
       "      <th>reward_with_kl</th>\n",
       "      <th>loss</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>The genre like.</th>\n",
       "      <th>0.64105</th>\n",
       "      <th>0.27027</th>\n",
       "      <th>0.48912</th>\n",
       "      <th>29</th>\n",
       "      <th>0.129590</th>\n",
       "      <th>0.0</th>\n",
       "      <th>0</th>\n",
       "      <th>-12.845843</th>\n",
       "      <th>-23.260250</th>\n",
       "      <th>10.414407</th>\n",
       "      <th>0.0</th>\n",
       "      <th>-0.0</th>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>They.. like.</th>\n",
       "      <th>0.63041</th>\n",
       "      <th>0.28091</th>\n",
       "      <th>0.05606</th>\n",
       "      <th>32</th>\n",
       "      <th>0.570021</th>\n",
       "      <th>0.0</th>\n",
       "      <th>0</th>\n",
       "      <th>-10.718462</th>\n",
       "      <th>-43.937099</th>\n",
       "      <th>33.218636</th>\n",
       "      <th>0.0</th>\n",
       "      <th>-0.0</th>\n",
       "      <td>[2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>There.. in.,</th>\n",
       "      <th>0.44425</th>\n",
       "      <th>0.46707</th>\n",
       "      <th>0.03178</th>\n",
       "      <th>32</th>\n",
       "      <th>0.357087</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1</th>\n",
       "      <th>-16.812248</th>\n",
       "      <th>-37.430733</th>\n",
       "      <th>20.618484</th>\n",
       "      <th>0.0</th>\n",
       "      <th>-0.0</th>\n",
       "      <td>[3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I.. and</th>\n",
       "      <th>0.50934</th>\n",
       "      <th>0.40197</th>\n",
       "      <th>0.04364</th>\n",
       "      <th>37</th>\n",
       "      <th>0.197655</th>\n",
       "      <th>0.0</th>\n",
       "      <th>0</th>\n",
       "      <th>-6.347129</th>\n",
       "      <th>-35.930527</th>\n",
       "      <th>29.583397</th>\n",
       "      <th>0.0</th>\n",
       "      <th>-0.0</th>\n",
       "      <td>[4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it...</th>\n",
       "      <th>0.47830</th>\n",
       "      <th>0.43302</th>\n",
       "      <th>0.14874</th>\n",
       "      <th>39</th>\n",
       "      <th>0.136834</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1</th>\n",
       "      <th>-6.823681</th>\n",
       "      <th>-33.559235</th>\n",
       "      <th>26.735554</th>\n",
       "      <th>0.0</th>\n",
       "      <th>-0.0</th>\n",
       "      <td>[5]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                               epoch\n",
       "pp_l            pp_truelabel_probs vm_score sts_score pp_letter_diff contradiction_score reward label_flip pp_logp    ref_logp   kl_div    reward_with_kl loss      \n",
       "The genre like. 0.64105            0.27027  0.48912   29             0.129590            0.0    0          -12.845843 -23.260250 10.414407 0.0            -0.0   [1]\n",
       "They.. like.    0.63041            0.28091  0.05606   32             0.570021            0.0    0          -10.718462 -43.937099 33.218636 0.0            -0.0   [2]\n",
       "There.. in.,    0.44425            0.46707  0.03178   32             0.357087            0.0    1          -16.812248 -37.430733 20.618484 0.0            -0.0   [3]\n",
       "I.. and         0.50934            0.40197  0.04364   37             0.197655            0.0    0          -6.347129  -35.930527 29.583397 0.0            -0.0   [4]\n",
       "it...           0.47830            0.43302  0.14874   39             0.136834            0.0    1          -6.823681  -33.559235 26.735554 0.0            -0.0   [5]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Paraphrase\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>epoch</th>\n",
       "      <th>orig_l</th>\n",
       "      <th>pp_l</th>\n",
       "      <th>orig_truelabel_probs</th>\n",
       "      <th>pp_truelabel_probs</th>\n",
       "      <th>pp_predclass_probs</th>\n",
       "      <th>orig_label</th>\n",
       "      <th>pp_predclass</th>\n",
       "      <th>label_flip</th>\n",
       "      <th>vm_score</th>\n",
       "      <th>sts_score</th>\n",
       "      <th>pp_letter_diff</th>\n",
       "      <th>pp_letter_percent</th>\n",
       "      <th>contradiction_score</th>\n",
       "      <th>reward</th>\n",
       "      <th>pp_logp</th>\n",
       "      <th>ref_logp</th>\n",
       "      <th>kl_div</th>\n",
       "      <th>reward_with_kl</th>\n",
       "      <th>loss</th>\n",
       "      <th>batch_num</th>\n",
       "      <th>global_step</th>\n",
       "      <th>acc_num</th>\n",
       "      <th>loss_sum</th>\n",
       "      <th>loss_batch</th>\n",
       "      <th>label_flip_fraction</th>\n",
       "      <th>orig_length</th>\n",
       "      <th>orig_batch_size</th>\n",
       "      <th>pp_length</th>\n",
       "      <th>pp_batch_size</th>\n",
       "      <th>time_generate_pp</th>\n",
       "      <th>time_loss_fn</th>\n",
       "      <th>time_reward_fn</th>\n",
       "      <th>time_vm_scores</th>\n",
       "      <th>time_sts_scores</th>\n",
       "      <th>time_pp_letter_diff</th>\n",
       "      <th>time_contradiction_scores</th>\n",
       "      <th>time_pp_logp</th>\n",
       "      <th>time_log_entropy</th>\n",
       "      <th>time_log_token_probabilities</th>\n",
       "      <th>time_ref_logprobs</th>\n",
       "      <th>time_loss_fn_loss_calc</th>\n",
       "      <th>time_backwards</th>\n",
       "      <th>time_calc_gradient_norm</th>\n",
       "      <th>time_opt_step_and_calc_param_norm</th>\n",
       "      <th>time_opt_step</th>\n",
       "      <th>idx_n_unique_pp</th>\n",
       "      <th>idx_n_pp_changes</th>\n",
       "      <th>epoch_of_first_label_flip</th>\n",
       "      <th>n_words_orig</th>\n",
       "      <th>n_sentences_orig</th>\n",
       "      <th>n_punctuation_orig</th>\n",
       "      <th>n_digits_orig</th>\n",
       "      <th>n_letters_orig</th>\n",
       "      <th>n_words_pp</th>\n",
       "      <th>n_sentences_pp</th>\n",
       "      <th>n_punctuation_pp</th>\n",
       "      <th>n_digits_pp</th>\n",
       "      <th>n_letters_pp</th>\n",
       "      <th>n_words_diff</th>\n",
       "      <th>n_sentences_diff</th>\n",
       "      <th>n_punctuation_diff</th>\n",
       "      <th>n_digits_diff</th>\n",
       "      <th>n_letters_diff</th>\n",
       "      <th>removals_idx</th>\n",
       "      <th>removals</th>\n",
       "      <th>insertions_idx</th>\n",
       "      <th>insertions</th>\n",
       "      <th>unchanged_idx</th>\n",
       "      <th>unchanged</th>\n",
       "      <th>n_segments_inserted</th>\n",
       "      <th>n_segments_removed</th>\n",
       "      <th>n_tokens_inserted</th>\n",
       "      <th>n_tokens_removed</th>\n",
       "      <th>is_truncation</th>\n",
       "      <th>any_phrase_capitalised</th>\n",
       "      <th>any_phrase_decapitalised</th>\n",
       "      <th>edit_distance_token_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24835</th>\n",
       "      <td>5685</td>\n",
       "      <td>1</td>\n",
       "      <td>suffers from all the excesses of the genre .</td>\n",
       "      <td>The genre like.</td>\n",
       "      <td>0.911318</td>\n",
       "      <td>0.64105</td>\n",
       "      <td>0.641051</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.48912</td>\n",
       "      <td>29</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.12959</td>\n",
       "      <td>0</td>\n",
       "      <td>-12.8458</td>\n",
       "      <td>-23.2603</td>\n",
       "      <td>10.4144</td>\n",
       "      <td>0</td>\n",
       "      <td>-0</td>\n",
       "      <td>873</td>\n",
       "      <td>873</td>\n",
       "      <td>1</td>\n",
       "      <td>-32.8312</td>\n",
       "      <td>-2.05195</td>\n",
       "      <td>0.125</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0.131279</td>\n",
       "      <td>0.280986</td>\n",
       "      <td>0.0497883</td>\n",
       "      <td>0.00731743</td>\n",
       "      <td>0.0261302</td>\n",
       "      <td>9.75118e-05</td>\n",
       "      <td>0.0154954</td>\n",
       "      <td>0.00835448</td>\n",
       "      <td>0.00185084</td>\n",
       "      <td>0.00408988</td>\n",
       "      <td>0.222472</td>\n",
       "      <td>0.000223201</td>\n",
       "      <td>0.176176</td>\n",
       "      <td>0.0454367</td>\n",
       "      <td>0.169019</td>\n",
       "      <td>0.104445</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7]</td>\n",
       "      <td>[suffers from all the excesses of the]</td>\n",
       "      <td>[0, 9]</td>\n",
       "      <td>[The, like]</td>\n",
       "      <td>[8, 10]</td>\n",
       "      <td>[genre, .]</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        idx epoch                                        orig_l  \\\n",
       "24835  5685     1  suffers from all the excesses of the genre .   \n",
       "\n",
       "                  pp_l orig_truelabel_probs pp_truelabel_probs  \\\n",
       "24835  The genre like.             0.911318            0.64105   \n",
       "\n",
       "      pp_predclass_probs orig_label pp_predclass label_flip vm_score  \\\n",
       "24835           0.641051          0            0          0  0.27027   \n",
       "\n",
       "      sts_score pp_letter_diff pp_letter_percent contradiction_score reward  \\\n",
       "24835   0.48912             29          0.340909             0.12959      0   \n",
       "\n",
       "       pp_logp ref_logp   kl_div reward_with_kl loss batch_num global_step  \\\n",
       "24835 -12.8458 -23.2603  10.4144              0   -0       873         873   \n",
       "\n",
       "      acc_num loss_sum loss_batch label_flip_fraction orig_length  \\\n",
       "24835       1 -32.8312   -2.05195               0.125          16   \n",
       "\n",
       "      orig_batch_size pp_length pp_batch_size time_generate_pp time_loss_fn  \\\n",
       "24835               8         8             8         0.131279     0.280986   \n",
       "\n",
       "      time_reward_fn time_vm_scores time_sts_scores time_pp_letter_diff  \\\n",
       "24835      0.0497883     0.00731743       0.0261302         9.75118e-05   \n",
       "\n",
       "      time_contradiction_scores time_pp_logp time_log_entropy  \\\n",
       "24835                 0.0154954   0.00835448       0.00185084   \n",
       "\n",
       "      time_log_token_probabilities time_ref_logprobs time_loss_fn_loss_calc  \\\n",
       "24835                   0.00408988          0.222472            0.000223201   \n",
       "\n",
       "      time_backwards time_calc_gradient_norm  \\\n",
       "24835       0.176176               0.0454367   \n",
       "\n",
       "      time_opt_step_and_calc_param_norm time_opt_step idx_n_unique_pp  \\\n",
       "24835                          0.169019      0.104445               5   \n",
       "\n",
       "      idx_n_pp_changes epoch_of_first_label_flip n_words_orig  \\\n",
       "24835                4                         3            8   \n",
       "\n",
       "      n_sentences_orig n_punctuation_orig n_digits_orig n_letters_orig  \\\n",
       "24835                1                  1             0             35   \n",
       "\n",
       "      n_words_pp n_sentences_pp n_punctuation_pp n_digits_pp n_letters_pp  \\\n",
       "24835          3              1                1           0           12   \n",
       "\n",
       "      n_words_diff n_sentences_diff n_punctuation_diff n_digits_diff  \\\n",
       "24835            5                0                  0             0   \n",
       "\n",
       "      n_letters_diff           removals_idx  \\\n",
       "24835             23  [1, 2, 3, 4, 5, 6, 7]   \n",
       "\n",
       "                                     removals insertions_idx   insertions  \\\n",
       "24835  [suffers from all the excesses of the]         [0, 9]  [The, like]   \n",
       "\n",
       "      unchanged_idx   unchanged n_segments_inserted n_segments_removed  \\\n",
       "24835       [8, 10]  [genre, .]                   2                  1   \n",
       "\n",
       "      n_tokens_inserted n_tokens_removed is_truncation any_phrase_capitalised  \\\n",
       "24835                 2                7         False                  False   \n",
       "\n",
       "      any_phrase_decapitalised edit_distance_token_level  \n",
       "24835                    False                         8  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "###############\n",
      "\n",
      "label_flips 1 \n",
      "\n",
      "Original: a must-see for the david mamet enthusiast and for anyone who appreciates intelligent , stylish moviemaking .\n",
      "Original label 1\n",
      "Unique paraphrases: 5\n",
      "How the paraphrases change:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pp_l</th>\n",
       "      <th>pp_truelabel_probs</th>\n",
       "      <th>vm_score</th>\n",
       "      <th>sts_score</th>\n",
       "      <th>pp_letter_diff</th>\n",
       "      <th>contradiction_score</th>\n",
       "      <th>reward</th>\n",
       "      <th>label_flip</th>\n",
       "      <th>pp_logp</th>\n",
       "      <th>ref_logp</th>\n",
       "      <th>kl_div</th>\n",
       "      <th>reward_with_kl</th>\n",
       "      <th>loss</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>It's great for the David mamet.</th>\n",
       "      <th>0.93695</th>\n",
       "      <th>0.01362</th>\n",
       "      <th>0.58560</th>\n",
       "      <th>77</th>\n",
       "      <th>0.001563</th>\n",
       "      <th>0.0</th>\n",
       "      <th>0</th>\n",
       "      <th>-9.103140</th>\n",
       "      <th>-43.370731</th>\n",
       "      <th>34.267593</th>\n",
       "      <th>0.0</th>\n",
       "      <th>-0.0</th>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Anyone...</th>\n",
       "      <th>0.23004</th>\n",
       "      <th>0.72053</th>\n",
       "      <th>0.23021</th>\n",
       "      <th>99</th>\n",
       "      <th>0.062393</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1</th>\n",
       "      <th>-4.711495</th>\n",
       "      <th>-38.266251</th>\n",
       "      <th>33.554756</th>\n",
       "      <th>0.0</th>\n",
       "      <th>-0.0</th>\n",
       "      <td>[2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>For...</th>\n",
       "      <th>0.66190</th>\n",
       "      <th>0.28867</th>\n",
       "      <th>0.24199</th>\n",
       "      <th>102</th>\n",
       "      <th>0.070302</th>\n",
       "      <th>0.0</th>\n",
       "      <th>0</th>\n",
       "      <th>-2.787426</th>\n",
       "      <th>-28.787251</th>\n",
       "      <th>25.999825</th>\n",
       "      <th>0.0</th>\n",
       "      <th>-0.0</th>\n",
       "      <td>[3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>For. thing.</th>\n",
       "      <th>0.43154</th>\n",
       "      <th>0.51903</th>\n",
       "      <th>0.20322</th>\n",
       "      <th>97</th>\n",
       "      <th>0.064228</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1</th>\n",
       "      <th>-8.211937</th>\n",
       "      <th>-36.521664</th>\n",
       "      <th>28.309727</th>\n",
       "      <th>0.0</th>\n",
       "      <th>-0.0</th>\n",
       "      <td>[4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>It....</th>\n",
       "      <th>0.53404</th>\n",
       "      <th>0.41653</th>\n",
       "      <th>0.14261</th>\n",
       "      <th>102</th>\n",
       "      <th>0.046568</th>\n",
       "      <th>0.0</th>\n",
       "      <th>0</th>\n",
       "      <th>-2.590794</th>\n",
       "      <th>-42.847977</th>\n",
       "      <th>40.257183</th>\n",
       "      <th>0.0</th>\n",
       "      <th>-0.0</th>\n",
       "      <td>[5]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                              epoch\n",
       "pp_l                            pp_truelabel_probs vm_score sts_score pp_letter_diff contradiction_score reward label_flip pp_logp   ref_logp   kl_div    reward_with_kl loss      \n",
       "It's great for the David mamet. 0.93695            0.01362  0.58560   77             0.001563            0.0    0          -9.103140 -43.370731 34.267593 0.0            -0.0   [1]\n",
       "Anyone...                       0.23004            0.72053  0.23021   99             0.062393            0.0    1          -4.711495 -38.266251 33.554756 0.0            -0.0   [2]\n",
       "For...                          0.66190            0.28867  0.24199   102            0.070302            0.0    0          -2.787426 -28.787251 25.999825 0.0            -0.0   [3]\n",
       "For. thing.                     0.43154            0.51903  0.20322   97             0.064228            0.0    1          -8.211937 -36.521664 28.309727 0.0            -0.0   [4]\n",
       "It....                          0.53404            0.41653  0.14261   102            0.046568            0.0    0          -2.590794 -42.847977 40.257183 0.0            -0.0   [5]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Paraphrase\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>epoch</th>\n",
       "      <th>orig_l</th>\n",
       "      <th>pp_l</th>\n",
       "      <th>orig_truelabel_probs</th>\n",
       "      <th>pp_truelabel_probs</th>\n",
       "      <th>pp_predclass_probs</th>\n",
       "      <th>orig_label</th>\n",
       "      <th>pp_predclass</th>\n",
       "      <th>label_flip</th>\n",
       "      <th>vm_score</th>\n",
       "      <th>sts_score</th>\n",
       "      <th>pp_letter_diff</th>\n",
       "      <th>pp_letter_percent</th>\n",
       "      <th>contradiction_score</th>\n",
       "      <th>reward</th>\n",
       "      <th>pp_logp</th>\n",
       "      <th>ref_logp</th>\n",
       "      <th>kl_div</th>\n",
       "      <th>reward_with_kl</th>\n",
       "      <th>loss</th>\n",
       "      <th>batch_num</th>\n",
       "      <th>global_step</th>\n",
       "      <th>acc_num</th>\n",
       "      <th>loss_sum</th>\n",
       "      <th>loss_batch</th>\n",
       "      <th>label_flip_fraction</th>\n",
       "      <th>orig_length</th>\n",
       "      <th>orig_batch_size</th>\n",
       "      <th>pp_length</th>\n",
       "      <th>pp_batch_size</th>\n",
       "      <th>time_generate_pp</th>\n",
       "      <th>time_loss_fn</th>\n",
       "      <th>time_reward_fn</th>\n",
       "      <th>time_vm_scores</th>\n",
       "      <th>time_sts_scores</th>\n",
       "      <th>time_pp_letter_diff</th>\n",
       "      <th>time_contradiction_scores</th>\n",
       "      <th>time_pp_logp</th>\n",
       "      <th>time_log_entropy</th>\n",
       "      <th>time_log_token_probabilities</th>\n",
       "      <th>time_ref_logprobs</th>\n",
       "      <th>time_loss_fn_loss_calc</th>\n",
       "      <th>time_backwards</th>\n",
       "      <th>time_calc_gradient_norm</th>\n",
       "      <th>time_opt_step_and_calc_param_norm</th>\n",
       "      <th>time_opt_step</th>\n",
       "      <th>idx_n_unique_pp</th>\n",
       "      <th>idx_n_pp_changes</th>\n",
       "      <th>epoch_of_first_label_flip</th>\n",
       "      <th>n_words_orig</th>\n",
       "      <th>n_sentences_orig</th>\n",
       "      <th>n_punctuation_orig</th>\n",
       "      <th>n_digits_orig</th>\n",
       "      <th>n_letters_orig</th>\n",
       "      <th>n_words_pp</th>\n",
       "      <th>n_sentences_pp</th>\n",
       "      <th>n_punctuation_pp</th>\n",
       "      <th>n_digits_pp</th>\n",
       "      <th>n_letters_pp</th>\n",
       "      <th>n_words_diff</th>\n",
       "      <th>n_sentences_diff</th>\n",
       "      <th>n_punctuation_diff</th>\n",
       "      <th>n_digits_diff</th>\n",
       "      <th>n_letters_diff</th>\n",
       "      <th>removals_idx</th>\n",
       "      <th>removals</th>\n",
       "      <th>insertions_idx</th>\n",
       "      <th>insertions</th>\n",
       "      <th>unchanged_idx</th>\n",
       "      <th>unchanged</th>\n",
       "      <th>n_segments_inserted</th>\n",
       "      <th>n_segments_removed</th>\n",
       "      <th>n_tokens_inserted</th>\n",
       "      <th>n_tokens_removed</th>\n",
       "      <th>is_truncation</th>\n",
       "      <th>any_phrase_capitalised</th>\n",
       "      <th>any_phrase_decapitalised</th>\n",
       "      <th>edit_distance_token_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5015</th>\n",
       "      <td>1135</td>\n",
       "      <td>1</td>\n",
       "      <td>a must-see for the david mamet enthusiast and for anyone who appreciates intelligent , stylish moviemaking .</td>\n",
       "      <td>It's great for the David mamet.</td>\n",
       "      <td>0.950572</td>\n",
       "      <td>0.93695</td>\n",
       "      <td>0.936949</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01362</td>\n",
       "      <td>0.5856</td>\n",
       "      <td>77</td>\n",
       "      <td>0.287037</td>\n",
       "      <td>0.00156253</td>\n",
       "      <td>0</td>\n",
       "      <td>-9.10314</td>\n",
       "      <td>-43.3707</td>\n",
       "      <td>34.2676</td>\n",
       "      <td>0</td>\n",
       "      <td>-0</td>\n",
       "      <td>555</td>\n",
       "      <td>555</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>24</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>0.225263</td>\n",
       "      <td>0.45765</td>\n",
       "      <td>0.0500626</td>\n",
       "      <td>0.0072329</td>\n",
       "      <td>0.0265254</td>\n",
       "      <td>8.54079e-05</td>\n",
       "      <td>0.0155621</td>\n",
       "      <td>0.01036</td>\n",
       "      <td>0.00257704</td>\n",
       "      <td>0.00457991</td>\n",
       "      <td>0.396858</td>\n",
       "      <td>0.000217783</td>\n",
       "      <td>0.320811</td>\n",
       "      <td>0.0474666</td>\n",
       "      <td>0.168528</td>\n",
       "      <td>0.105006</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>[3, 4, 5, 6, 9, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]</td>\n",
       "      <td>[a must- see, david, enthusiast and for anyone who appreciates intelligent, stylish moviemaking]</td>\n",
       "      <td>[0, 1, 2, 11]</td>\n",
       "      <td>[It 's great, David]</td>\n",
       "      <td>[7, 8, 13, 24]</td>\n",
       "      <td>[for the, mamet, .]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       idx epoch  \\\n",
       "5015  1135     1   \n",
       "\n",
       "                                                                                                            orig_l  \\\n",
       "5015  a must-see for the david mamet enthusiast and for anyone who appreciates intelligent , stylish moviemaking .   \n",
       "\n",
       "                                 pp_l orig_truelabel_probs pp_truelabel_probs  \\\n",
       "5015  It's great for the David mamet.             0.950572            0.93695   \n",
       "\n",
       "     pp_predclass_probs orig_label pp_predclass label_flip vm_score sts_score  \\\n",
       "5015           0.936949          1            1          0  0.01362    0.5856   \n",
       "\n",
       "     pp_letter_diff pp_letter_percent contradiction_score reward  pp_logp  \\\n",
       "5015             77          0.287037          0.00156253      0 -9.10314   \n",
       "\n",
       "     ref_logp   kl_div reward_with_kl loss batch_num global_step acc_num  \\\n",
       "5015 -43.3707  34.2676              0   -0       555         555       1   \n",
       "\n",
       "     loss_sum loss_batch label_flip_fraction orig_length orig_batch_size  \\\n",
       "5015        0          0               0.125          24               8   \n",
       "\n",
       "     pp_length pp_batch_size time_generate_pp time_loss_fn time_reward_fn  \\\n",
       "5015        14             8         0.225263      0.45765      0.0500626   \n",
       "\n",
       "     time_vm_scores time_sts_scores time_pp_letter_diff  \\\n",
       "5015      0.0072329       0.0265254         8.54079e-05   \n",
       "\n",
       "     time_contradiction_scores time_pp_logp time_log_entropy  \\\n",
       "5015                 0.0155621      0.01036       0.00257704   \n",
       "\n",
       "     time_log_token_probabilities time_ref_logprobs time_loss_fn_loss_calc  \\\n",
       "5015                   0.00457991          0.396858            0.000217783   \n",
       "\n",
       "     time_backwards time_calc_gradient_norm time_opt_step_and_calc_param_norm  \\\n",
       "5015       0.320811               0.0474666                          0.168528   \n",
       "\n",
       "     time_opt_step idx_n_unique_pp idx_n_pp_changes epoch_of_first_label_flip  \\\n",
       "5015      0.105006               5                4                         2   \n",
       "\n",
       "     n_words_orig n_sentences_orig n_punctuation_orig n_digits_orig  \\\n",
       "5015           15                1                  3             0   \n",
       "\n",
       "     n_letters_orig n_words_pp n_sentences_pp n_punctuation_pp n_digits_pp  \\\n",
       "5015             89          7              1                2           0   \n",
       "\n",
       "     n_letters_pp n_words_diff n_sentences_diff n_punctuation_diff  \\\n",
       "5015           24            8                0                  1   \n",
       "\n",
       "     n_digits_diff n_letters_diff  \\\n",
       "5015             0             65   \n",
       "\n",
       "                                                 removals_idx  \\\n",
       "5015  [3, 4, 5, 6, 9, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]   \n",
       "\n",
       "                                                                                              removals  \\\n",
       "5015  [a must- see, david, enthusiast and for anyone who appreciates intelligent, stylish moviemaking]   \n",
       "\n",
       "     insertions_idx            insertions   unchanged_idx  \\\n",
       "5015  [0, 1, 2, 11]  [It 's great, David]  [7, 8, 13, 24]   \n",
       "\n",
       "                unchanged n_segments_inserted n_segments_removed  \\\n",
       "5015  [for the, mamet, .]                   2                  3   \n",
       "\n",
       "     n_tokens_inserted n_tokens_removed is_truncation any_phrase_capitalised  \\\n",
       "5015                 4               15         False                   True   \n",
       "\n",
       "     any_phrase_decapitalised edit_distance_token_level  \n",
       "5015                    False                        15  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "###############\n",
      "\n",
      "label_flips 2 \n",
      "\n",
      "Original: if i spy were funny ( enough ) or exciting ( enough ) then it would be fairly simple to forgive the financial extortion it's trying to reap from the moviegoing public .\n",
      "Original label 0\n",
      "Unique paraphrases: 5\n",
      "How the paraphrases change:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pp_l</th>\n",
       "      <th>pp_truelabel_probs</th>\n",
       "      <th>vm_score</th>\n",
       "      <th>sts_score</th>\n",
       "      <th>pp_letter_diff</th>\n",
       "      <th>contradiction_score</th>\n",
       "      <th>reward</th>\n",
       "      <th>label_flip</th>\n",
       "      <th>pp_logp</th>\n",
       "      <th>ref_logp</th>\n",
       "      <th>kl_div</th>\n",
       "      <th>reward_with_kl</th>\n",
       "      <th>loss</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>If they were funny or exciting, then it would be very simple to get rid of the financially ingssened movie.</th>\n",
       "      <th>0.73019</th>\n",
       "      <th>0.08879</th>\n",
       "      <th>0.63078</th>\n",
       "      <th>61</th>\n",
       "      <th>0.006015</th>\n",
       "      <th>0.0</th>\n",
       "      <th>0</th>\n",
       "      <th>-45.006752</th>\n",
       "      <th>-104.991013</th>\n",
       "      <th>59.984261</th>\n",
       "      <th>0.0</th>\n",
       "      <th>-0.0</th>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I can..</th>\n",
       "      <th>0.39643</th>\n",
       "      <th>0.42254</th>\n",
       "      <th>0.14407</th>\n",
       "      <th>161</th>\n",
       "      <th>0.913093</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1</th>\n",
       "      <th>-4.907734</th>\n",
       "      <th>-33.513302</th>\n",
       "      <th>28.605568</th>\n",
       "      <th>0.0</th>\n",
       "      <th>-0.0</th>\n",
       "      <td>[2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>It would..</th>\n",
       "      <th>0.64022</th>\n",
       "      <th>0.17876</th>\n",
       "      <th>0.22058</th>\n",
       "      <th>158</th>\n",
       "      <th>0.035792</th>\n",
       "      <th>0.0</th>\n",
       "      <th>0</th>\n",
       "      <th>-1.361025</th>\n",
       "      <th>-34.973305</th>\n",
       "      <th>33.612278</th>\n",
       "      <th>0.0</th>\n",
       "      <th>-0.0</th>\n",
       "      <td>[3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>It wouldn't.</th>\n",
       "      <th>0.81847</th>\n",
       "      <th>0.00050</th>\n",
       "      <th>0.11189</th>\n",
       "      <th>156</th>\n",
       "      <th>0.883700</th>\n",
       "      <th>0.0</th>\n",
       "      <th>0</th>\n",
       "      <th>-5.157005</th>\n",
       "      <th>-28.364866</th>\n",
       "      <th>23.207861</th>\n",
       "      <th>0.0</th>\n",
       "      <th>-0.0</th>\n",
       "      <td>[4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>It was..</th>\n",
       "      <th>0.53244</th>\n",
       "      <th>0.28654</th>\n",
       "      <th>0.25012</th>\n",
       "      <th>160</th>\n",
       "      <th>0.526630</th>\n",
       "      <th>0.0</th>\n",
       "      <th>0</th>\n",
       "      <th>-4.469456</th>\n",
       "      <th>-31.073715</th>\n",
       "      <th>26.604259</th>\n",
       "      <th>0.0</th>\n",
       "      <th>-0.0</th>\n",
       "      <td>[5]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                            epoch\n",
       "pp_l                                                                                                        pp_truelabel_probs vm_score sts_score pp_letter_diff contradiction_score reward label_flip pp_logp    ref_logp    kl_div    reward_with_kl loss      \n",
       "If they were funny or exciting, then it would be very simple to get rid of the financially ingssened movie. 0.73019            0.08879  0.63078   61             0.006015            0.0    0          -45.006752 -104.991013 59.984261 0.0            -0.0   [1]\n",
       "I can..                                                                                                     0.39643            0.42254  0.14407   161            0.913093            0.0    1          -4.907734  -33.513302  28.605568 0.0            -0.0   [2]\n",
       "It would..                                                                                                  0.64022            0.17876  0.22058   158            0.035792            0.0    0          -1.361025  -34.973305  33.612278 0.0            -0.0   [3]\n",
       "It wouldn't.                                                                                                0.81847            0.00050  0.11189   156            0.883700            0.0    0          -5.157005  -28.364866  23.207861 0.0            -0.0   [4]\n",
       "It was..                                                                                                    0.53244            0.28654  0.25012   160            0.526630            0.0    0          -4.469456  -31.073715  26.604259 0.0            -0.0   [5]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Paraphrase\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>epoch</th>\n",
       "      <th>orig_l</th>\n",
       "      <th>pp_l</th>\n",
       "      <th>orig_truelabel_probs</th>\n",
       "      <th>pp_truelabel_probs</th>\n",
       "      <th>pp_predclass_probs</th>\n",
       "      <th>orig_label</th>\n",
       "      <th>pp_predclass</th>\n",
       "      <th>label_flip</th>\n",
       "      <th>vm_score</th>\n",
       "      <th>sts_score</th>\n",
       "      <th>pp_letter_diff</th>\n",
       "      <th>pp_letter_percent</th>\n",
       "      <th>contradiction_score</th>\n",
       "      <th>reward</th>\n",
       "      <th>pp_logp</th>\n",
       "      <th>ref_logp</th>\n",
       "      <th>kl_div</th>\n",
       "      <th>reward_with_kl</th>\n",
       "      <th>loss</th>\n",
       "      <th>batch_num</th>\n",
       "      <th>global_step</th>\n",
       "      <th>acc_num</th>\n",
       "      <th>loss_sum</th>\n",
       "      <th>loss_batch</th>\n",
       "      <th>label_flip_fraction</th>\n",
       "      <th>orig_length</th>\n",
       "      <th>orig_batch_size</th>\n",
       "      <th>pp_length</th>\n",
       "      <th>pp_batch_size</th>\n",
       "      <th>time_generate_pp</th>\n",
       "      <th>time_loss_fn</th>\n",
       "      <th>time_reward_fn</th>\n",
       "      <th>time_vm_scores</th>\n",
       "      <th>time_sts_scores</th>\n",
       "      <th>time_pp_letter_diff</th>\n",
       "      <th>time_contradiction_scores</th>\n",
       "      <th>time_pp_logp</th>\n",
       "      <th>time_log_entropy</th>\n",
       "      <th>time_log_token_probabilities</th>\n",
       "      <th>time_ref_logprobs</th>\n",
       "      <th>time_loss_fn_loss_calc</th>\n",
       "      <th>time_backwards</th>\n",
       "      <th>time_calc_gradient_norm</th>\n",
       "      <th>time_opt_step_and_calc_param_norm</th>\n",
       "      <th>time_opt_step</th>\n",
       "      <th>idx_n_unique_pp</th>\n",
       "      <th>idx_n_pp_changes</th>\n",
       "      <th>epoch_of_first_label_flip</th>\n",
       "      <th>n_words_orig</th>\n",
       "      <th>n_sentences_orig</th>\n",
       "      <th>n_punctuation_orig</th>\n",
       "      <th>n_digits_orig</th>\n",
       "      <th>n_letters_orig</th>\n",
       "      <th>n_words_pp</th>\n",
       "      <th>n_sentences_pp</th>\n",
       "      <th>n_punctuation_pp</th>\n",
       "      <th>n_digits_pp</th>\n",
       "      <th>n_letters_pp</th>\n",
       "      <th>n_words_diff</th>\n",
       "      <th>n_sentences_diff</th>\n",
       "      <th>n_punctuation_diff</th>\n",
       "      <th>n_digits_diff</th>\n",
       "      <th>n_letters_diff</th>\n",
       "      <th>removals_idx</th>\n",
       "      <th>removals</th>\n",
       "      <th>insertions_idx</th>\n",
       "      <th>insertions</th>\n",
       "      <th>unchanged_idx</th>\n",
       "      <th>unchanged</th>\n",
       "      <th>n_segments_inserted</th>\n",
       "      <th>n_segments_removed</th>\n",
       "      <th>n_tokens_inserted</th>\n",
       "      <th>n_tokens_removed</th>\n",
       "      <th>is_truncation</th>\n",
       "      <th>any_phrase_capitalised</th>\n",
       "      <th>any_phrase_decapitalised</th>\n",
       "      <th>edit_distance_token_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30585</th>\n",
       "      <td>7009</td>\n",
       "      <td>1</td>\n",
       "      <td>if i spy were funny ( enough ) or exciting ( enough ) then it would be fairly simple to forgive the financial extortion it's trying to reap from the moviegoing public .</td>\n",
       "      <td>If they were funny or exciting, then it would be very simple to get rid of the financially ingssened movie.</td>\n",
       "      <td>0.818977</td>\n",
       "      <td>0.73019</td>\n",
       "      <td>0.730187</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.08879</td>\n",
       "      <td>0.63078</td>\n",
       "      <td>61</td>\n",
       "      <td>0.636905</td>\n",
       "      <td>0.00601536</td>\n",
       "      <td>0</td>\n",
       "      <td>-45.0068</td>\n",
       "      <td>-104.991</td>\n",
       "      <td>59.9843</td>\n",
       "      <td>0</td>\n",
       "      <td>-0</td>\n",
       "      <td>138</td>\n",
       "      <td>138</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>40</td>\n",
       "      <td>8</td>\n",
       "      <td>39</td>\n",
       "      <td>8</td>\n",
       "      <td>0.636071</td>\n",
       "      <td>1.56277</td>\n",
       "      <td>0.0613534</td>\n",
       "      <td>0.00876266</td>\n",
       "      <td>0.0314053</td>\n",
       "      <td>0.00017032</td>\n",
       "      <td>0.0178735</td>\n",
       "      <td>0.020564</td>\n",
       "      <td>0.00649516</td>\n",
       "      <td>0.00716836</td>\n",
       "      <td>1.48041</td>\n",
       "      <td>0.000248965</td>\n",
       "      <td>1.05586</td>\n",
       "      <td>0.0358786</td>\n",
       "      <td>3.45572e-05</td>\n",
       "      <td>3.26475e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>[2, 3, 4, 7, 8, 9, 13, 14, 15, 20, 24, 29, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43]</td>\n",
       "      <td>[if i spy, ( enough), ( enough), fairly, forgive, financial, extortion it 's trying to reap from the moviegoing public]</td>\n",
       "      <td>[0, 1, 12, 21, 25, 26, 27, 30, 32, 33]</td>\n",
       "      <td>[If they, ,, very, get rid of, financially, ingssened movie]</td>\n",
       "      <td>[5, 6, 10, 11, 16, 17, 18, 19, 22, 23, 28, 44]</td>\n",
       "      <td>[were funny, or exciting, then it would be, simple to, the, .]</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>22</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        idx epoch  \\\n",
       "30585  7009     1   \n",
       "\n",
       "                                                                                                                                                                         orig_l  \\\n",
       "30585  if i spy were funny ( enough ) or exciting ( enough ) then it would be fairly simple to forgive the financial extortion it's trying to reap from the moviegoing public .   \n",
       "\n",
       "                                                                                                              pp_l  \\\n",
       "30585  If they were funny or exciting, then it would be very simple to get rid of the financially ingssened movie.   \n",
       "\n",
       "      orig_truelabel_probs pp_truelabel_probs pp_predclass_probs orig_label  \\\n",
       "30585             0.818977            0.73019           0.730187          0   \n",
       "\n",
       "      pp_predclass label_flip vm_score sts_score pp_letter_diff  \\\n",
       "30585            0          0  0.08879   0.63078             61   \n",
       "\n",
       "      pp_letter_percent contradiction_score reward  pp_logp ref_logp   kl_div  \\\n",
       "30585          0.636905          0.00601536      0 -45.0068 -104.991  59.9843   \n",
       "\n",
       "      reward_with_kl loss batch_num global_step acc_num loss_sum loss_batch  \\\n",
       "30585              0   -0       138         138       0        0          0   \n",
       "\n",
       "      label_flip_fraction orig_length orig_batch_size pp_length pp_batch_size  \\\n",
       "30585               0.125          40               8        39             8   \n",
       "\n",
       "      time_generate_pp time_loss_fn time_reward_fn time_vm_scores  \\\n",
       "30585         0.636071      1.56277      0.0613534     0.00876266   \n",
       "\n",
       "      time_sts_scores time_pp_letter_diff time_contradiction_scores  \\\n",
       "30585       0.0314053          0.00017032                 0.0178735   \n",
       "\n",
       "      time_pp_logp time_log_entropy time_log_token_probabilities  \\\n",
       "30585     0.020564       0.00649516                   0.00716836   \n",
       "\n",
       "      time_ref_logprobs time_loss_fn_loss_calc time_backwards  \\\n",
       "30585           1.48041            0.000248965        1.05586   \n",
       "\n",
       "      time_calc_gradient_norm time_opt_step_and_calc_param_norm time_opt_step  \\\n",
       "30585               0.0358786                       3.45572e-05   3.26475e-06   \n",
       "\n",
       "      idx_n_unique_pp idx_n_pp_changes epoch_of_first_label_flip n_words_orig  \\\n",
       "30585               5                4                         2           29   \n",
       "\n",
       "      n_sentences_orig n_punctuation_orig n_digits_orig n_letters_orig  \\\n",
       "30585                1                  6             0            130   \n",
       "\n",
       "      n_words_pp n_sentences_pp n_punctuation_pp n_digits_pp n_letters_pp  \\\n",
       "30585         20              1                2           0           86   \n",
       "\n",
       "      n_words_diff n_sentences_diff n_punctuation_diff n_digits_diff  \\\n",
       "30585            9                0                  4             0   \n",
       "\n",
       "      n_letters_diff  \\\n",
       "30585             44   \n",
       "\n",
       "                                                                             removals_idx  \\\n",
       "30585  [2, 3, 4, 7, 8, 9, 13, 14, 15, 20, 24, 29, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43]   \n",
       "\n",
       "                                                                                                                      removals  \\\n",
       "30585  [if i spy, ( enough), ( enough), fairly, forgive, financial, extortion it 's trying to reap from the moviegoing public]   \n",
       "\n",
       "                               insertions_idx  \\\n",
       "30585  [0, 1, 12, 21, 25, 26, 27, 30, 32, 33]   \n",
       "\n",
       "                                                         insertions  \\\n",
       "30585  [If they, ,, very, get rid of, financially, ingssened movie]   \n",
       "\n",
       "                                        unchanged_idx  \\\n",
       "30585  [5, 6, 10, 11, 16, 17, 18, 19, 22, 23, 28, 44]   \n",
       "\n",
       "                                                            unchanged  \\\n",
       "30585  [were funny, or exciting, then it would be, simple to, the, .]   \n",
       "\n",
       "      n_segments_inserted n_segments_removed n_tokens_inserted  \\\n",
       "30585                   6                  7                10   \n",
       "\n",
       "      n_tokens_removed is_truncation any_phrase_capitalised  \\\n",
       "30585               22         False                  False   \n",
       "\n",
       "      any_phrase_decapitalised edit_distance_token_level  \n",
       "30585                    False                        23  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "###############\n",
      "\n",
      "label_flips 3 \n",
      "\n",
      "Original: decent but dull .\n",
      "Original label 0\n",
      "Unique paraphrases: 5\n",
      "How the paraphrases change:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pp_l</th>\n",
       "      <th>pp_truelabel_probs</th>\n",
       "      <th>vm_score</th>\n",
       "      <th>sts_score</th>\n",
       "      <th>pp_letter_diff</th>\n",
       "      <th>contradiction_score</th>\n",
       "      <th>reward</th>\n",
       "      <th>label_flip</th>\n",
       "      <th>pp_logp</th>\n",
       "      <th>ref_logp</th>\n",
       "      <th>kl_div</th>\n",
       "      <th>reward_with_kl</th>\n",
       "      <th>loss</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a..;.</th>\n",
       "      <th>0.53750</th>\n",
       "      <th>0.34648</th>\n",
       "      <th>0.21378</th>\n",
       "      <th>12</th>\n",
       "      <th>0.055505</th>\n",
       "      <th>0.0</th>\n",
       "      <th>0</th>\n",
       "      <th>-10.194430</th>\n",
       "      <th>-35.371132</th>\n",
       "      <th>25.176701</th>\n",
       "      <th>0.0</th>\n",
       "      <th>-0.0</th>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>It is..</th>\n",
       "      <th>0.34807</th>\n",
       "      <th>0.53591</th>\n",
       "      <th>0.19781</th>\n",
       "      <th>10</th>\n",
       "      <th>0.035385</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1</th>\n",
       "      <th>-3.151150</th>\n",
       "      <th>-19.381643</th>\n",
       "      <th>16.230494</th>\n",
       "      <th>0.0</th>\n",
       "      <th>-0.0</th>\n",
       "      <td>[2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>It...</th>\n",
       "      <th>0.47830</th>\n",
       "      <th>0.40568</th>\n",
       "      <th>0.21050</th>\n",
       "      <th>12</th>\n",
       "      <th>0.014025</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1</th>\n",
       "      <th>-1.246047</th>\n",
       "      <th>-24.044369</th>\n",
       "      <th>22.798321</th>\n",
       "      <th>0.0</th>\n",
       "      <th>-0.0</th>\n",
       "      <td>[3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>. all for for</th>\n",
       "      <th>0.58591</th>\n",
       "      <th>0.29807</th>\n",
       "      <th>0.29162</th>\n",
       "      <th>4</th>\n",
       "      <th>0.034694</th>\n",
       "      <th>0.0</th>\n",
       "      <th>0</th>\n",
       "      <th>-6.697148</th>\n",
       "      <th>-39.034702</th>\n",
       "      <th>32.337555</th>\n",
       "      <th>0.0</th>\n",
       "      <th>-0.0</th>\n",
       "      <td>[4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>That...</th>\n",
       "      <th>0.51063</th>\n",
       "      <th>0.37335</th>\n",
       "      <th>0.15448</th>\n",
       "      <th>10</th>\n",
       "      <th>0.011642</th>\n",
       "      <th>0.0</th>\n",
       "      <th>0</th>\n",
       "      <th>-4.109725</th>\n",
       "      <th>-20.553986</th>\n",
       "      <th>16.444260</th>\n",
       "      <th>0.0</th>\n",
       "      <th>-0.0</th>\n",
       "      <td>[5]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                             epoch\n",
       "pp_l          pp_truelabel_probs vm_score sts_score pp_letter_diff contradiction_score reward label_flip pp_logp    ref_logp   kl_div    reward_with_kl loss      \n",
       "a..;.         0.53750            0.34648  0.21378   12             0.055505            0.0    0          -10.194430 -35.371132 25.176701 0.0            -0.0   [1]\n",
       "It is..       0.34807            0.53591  0.19781   10             0.035385            0.0    1          -3.151150  -19.381643 16.230494 0.0            -0.0   [2]\n",
       "It...         0.47830            0.40568  0.21050   12             0.014025            0.0    1          -1.246047  -24.044369 22.798321 0.0            -0.0   [3]\n",
       ". all for for 0.58591            0.29807  0.29162   4              0.034694            0.0    0          -6.697148  -39.034702 32.337555 0.0            -0.0   [4]\n",
       "That...       0.51063            0.37335  0.15448   10             0.011642            0.0    0          -4.109725  -20.553986 16.444260 0.0            -0.0   [5]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Paraphrase\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>epoch</th>\n",
       "      <th>orig_l</th>\n",
       "      <th>pp_l</th>\n",
       "      <th>orig_truelabel_probs</th>\n",
       "      <th>pp_truelabel_probs</th>\n",
       "      <th>pp_predclass_probs</th>\n",
       "      <th>orig_label</th>\n",
       "      <th>pp_predclass</th>\n",
       "      <th>label_flip</th>\n",
       "      <th>vm_score</th>\n",
       "      <th>sts_score</th>\n",
       "      <th>pp_letter_diff</th>\n",
       "      <th>pp_letter_percent</th>\n",
       "      <th>contradiction_score</th>\n",
       "      <th>reward</th>\n",
       "      <th>pp_logp</th>\n",
       "      <th>ref_logp</th>\n",
       "      <th>kl_div</th>\n",
       "      <th>reward_with_kl</th>\n",
       "      <th>loss</th>\n",
       "      <th>batch_num</th>\n",
       "      <th>global_step</th>\n",
       "      <th>acc_num</th>\n",
       "      <th>loss_sum</th>\n",
       "      <th>loss_batch</th>\n",
       "      <th>label_flip_fraction</th>\n",
       "      <th>orig_length</th>\n",
       "      <th>orig_batch_size</th>\n",
       "      <th>pp_length</th>\n",
       "      <th>pp_batch_size</th>\n",
       "      <th>time_generate_pp</th>\n",
       "      <th>time_loss_fn</th>\n",
       "      <th>time_reward_fn</th>\n",
       "      <th>time_vm_scores</th>\n",
       "      <th>time_sts_scores</th>\n",
       "      <th>time_pp_letter_diff</th>\n",
       "      <th>time_contradiction_scores</th>\n",
       "      <th>time_pp_logp</th>\n",
       "      <th>time_log_entropy</th>\n",
       "      <th>time_log_token_probabilities</th>\n",
       "      <th>time_ref_logprobs</th>\n",
       "      <th>time_loss_fn_loss_calc</th>\n",
       "      <th>time_backwards</th>\n",
       "      <th>time_calc_gradient_norm</th>\n",
       "      <th>time_opt_step_and_calc_param_norm</th>\n",
       "      <th>time_opt_step</th>\n",
       "      <th>idx_n_unique_pp</th>\n",
       "      <th>idx_n_pp_changes</th>\n",
       "      <th>epoch_of_first_label_flip</th>\n",
       "      <th>n_words_orig</th>\n",
       "      <th>n_sentences_orig</th>\n",
       "      <th>n_punctuation_orig</th>\n",
       "      <th>n_digits_orig</th>\n",
       "      <th>n_letters_orig</th>\n",
       "      <th>n_words_pp</th>\n",
       "      <th>n_sentences_pp</th>\n",
       "      <th>n_punctuation_pp</th>\n",
       "      <th>n_digits_pp</th>\n",
       "      <th>n_letters_pp</th>\n",
       "      <th>n_words_diff</th>\n",
       "      <th>n_sentences_diff</th>\n",
       "      <th>n_punctuation_diff</th>\n",
       "      <th>n_digits_diff</th>\n",
       "      <th>n_letters_diff</th>\n",
       "      <th>removals_idx</th>\n",
       "      <th>removals</th>\n",
       "      <th>insertions_idx</th>\n",
       "      <th>insertions</th>\n",
       "      <th>unchanged_idx</th>\n",
       "      <th>unchanged</th>\n",
       "      <th>n_segments_inserted</th>\n",
       "      <th>n_segments_removed</th>\n",
       "      <th>n_tokens_inserted</th>\n",
       "      <th>n_tokens_removed</th>\n",
       "      <th>is_truncation</th>\n",
       "      <th>any_phrase_capitalised</th>\n",
       "      <th>any_phrase_decapitalised</th>\n",
       "      <th>edit_distance_token_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21950</th>\n",
       "      <td>5027</td>\n",
       "      <td>1</td>\n",
       "      <td>decent but dull .</td>\n",
       "      <td>a..;.</td>\n",
       "      <td>0.883979</td>\n",
       "      <td>0.5375</td>\n",
       "      <td>0.537498</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.34648</td>\n",
       "      <td>0.21378</td>\n",
       "      <td>12</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.0555051</td>\n",
       "      <td>0</td>\n",
       "      <td>-10.1944</td>\n",
       "      <td>-35.3711</td>\n",
       "      <td>25.1767</td>\n",
       "      <td>0</td>\n",
       "      <td>-0</td>\n",
       "      <td>921</td>\n",
       "      <td>921</td>\n",
       "      <td>1</td>\n",
       "      <td>-4.06879</td>\n",
       "      <td>-0.254299</td>\n",
       "      <td>0.125</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0.112832</td>\n",
       "      <td>0.262264</td>\n",
       "      <td>0.047179</td>\n",
       "      <td>0.00669604</td>\n",
       "      <td>0.0248341</td>\n",
       "      <td>8.0755e-05</td>\n",
       "      <td>0.0148438</td>\n",
       "      <td>0.00772506</td>\n",
       "      <td>0.00165581</td>\n",
       "      <td>0.0038976</td>\n",
       "      <td>0.206898</td>\n",
       "      <td>0.000281692</td>\n",
       "      <td>0.145718</td>\n",
       "      <td>0.0448271</td>\n",
       "      <td>0.169413</td>\n",
       "      <td>0.104615</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-3</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>[0, 1, 2]</td>\n",
       "      <td>[decent but dull]</td>\n",
       "      <td>[3, 4, 5]</td>\n",
       "      <td>[a ..;]</td>\n",
       "      <td>[6]</td>\n",
       "      <td>[.]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        idx epoch             orig_l   pp_l orig_truelabel_probs  \\\n",
       "21950  5027     1  decent but dull .  a..;.             0.883979   \n",
       "\n",
       "      pp_truelabel_probs pp_predclass_probs orig_label pp_predclass  \\\n",
       "21950             0.5375           0.537498          0            0   \n",
       "\n",
       "      label_flip vm_score sts_score pp_letter_diff pp_letter_percent  \\\n",
       "21950          0  0.34648   0.21378             12          0.294118   \n",
       "\n",
       "      contradiction_score reward  pp_logp ref_logp   kl_div reward_with_kl  \\\n",
       "21950           0.0555051      0 -10.1944 -35.3711  25.1767              0   \n",
       "\n",
       "      loss batch_num global_step acc_num loss_sum loss_batch  \\\n",
       "21950   -0       921         921       1 -4.06879  -0.254299   \n",
       "\n",
       "      label_flip_fraction orig_length orig_batch_size pp_length pp_batch_size  \\\n",
       "21950               0.125           8               8         7             8   \n",
       "\n",
       "      time_generate_pp time_loss_fn time_reward_fn time_vm_scores  \\\n",
       "21950         0.112832     0.262264       0.047179     0.00669604   \n",
       "\n",
       "      time_sts_scores time_pp_letter_diff time_contradiction_scores  \\\n",
       "21950       0.0248341          8.0755e-05                 0.0148438   \n",
       "\n",
       "      time_pp_logp time_log_entropy time_log_token_probabilities  \\\n",
       "21950   0.00772506       0.00165581                    0.0038976   \n",
       "\n",
       "      time_ref_logprobs time_loss_fn_loss_calc time_backwards  \\\n",
       "21950          0.206898            0.000281692       0.145718   \n",
       "\n",
       "      time_calc_gradient_norm time_opt_step_and_calc_param_norm time_opt_step  \\\n",
       "21950               0.0448271                          0.169413      0.104615   \n",
       "\n",
       "      idx_n_unique_pp idx_n_pp_changes epoch_of_first_label_flip n_words_orig  \\\n",
       "21950               5                4                         2            3   \n",
       "\n",
       "      n_sentences_orig n_punctuation_orig n_digits_orig n_letters_orig  \\\n",
       "21950                1                  1             0             13   \n",
       "\n",
       "      n_words_pp n_sentences_pp n_punctuation_pp n_digits_pp n_letters_pp  \\\n",
       "21950          1              1                4           0            1   \n",
       "\n",
       "      n_words_diff n_sentences_diff n_punctuation_diff n_digits_diff  \\\n",
       "21950            2                0                 -3             0   \n",
       "\n",
       "      n_letters_diff removals_idx           removals insertions_idx  \\\n",
       "21950             12    [0, 1, 2]  [decent but dull]      [3, 4, 5]   \n",
       "\n",
       "      insertions unchanged_idx unchanged n_segments_inserted  \\\n",
       "21950    [a ..;]           [6]       [.]                   1   \n",
       "\n",
       "      n_segments_removed n_tokens_inserted n_tokens_removed is_truncation  \\\n",
       "21950                  1                 3                3         False   \n",
       "\n",
       "      any_phrase_capitalised any_phrase_decapitalised  \\\n",
       "21950                  False                    False   \n",
       "\n",
       "      edit_distance_token_level  \n",
       "21950                         3  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "###############\n",
      "\n",
      "label_flips 4 \n",
      "\n",
      "Original: a grimly competent and stolid and earnest military courtroom drama .\n",
      "Original label 1\n",
      "Unique paraphrases: 5\n",
      "How the paraphrases change:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pp_l</th>\n",
       "      <th>pp_truelabel_probs</th>\n",
       "      <th>vm_score</th>\n",
       "      <th>sts_score</th>\n",
       "      <th>pp_letter_diff</th>\n",
       "      <th>contradiction_score</th>\n",
       "      <th>reward</th>\n",
       "      <th>label_flip</th>\n",
       "      <th>pp_logp</th>\n",
       "      <th>ref_logp</th>\n",
       "      <th>kl_div</th>\n",
       "      <th>reward_with_kl</th>\n",
       "      <th>loss</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A well produced melodrama.</th>\n",
       "      <th>0.94352</th>\n",
       "      <th>0.00704</th>\n",
       "      <th>0.46344</th>\n",
       "      <th>42</th>\n",
       "      <th>0.281784</th>\n",
       "      <th>0.0</th>\n",
       "      <th>0</th>\n",
       "      <th>-11.101753</th>\n",
       "      <th>-30.506971</th>\n",
       "      <th>19.405218</th>\n",
       "      <th>0.0</th>\n",
       "      <th>-0.0</th>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>And. There.</th>\n",
       "      <th>0.57294</th>\n",
       "      <th>0.37763</th>\n",
       "      <th>0.20417</th>\n",
       "      <th>57</th>\n",
       "      <th>0.273598</th>\n",
       "      <th>0.0</th>\n",
       "      <th>0</th>\n",
       "      <th>-9.571020</th>\n",
       "      <th>-31.323414</th>\n",
       "      <th>21.752394</th>\n",
       "      <th>0.0</th>\n",
       "      <th>-0.0</th>\n",
       "      <td>[2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>There...</th>\n",
       "      <th>0.57189</th>\n",
       "      <th>0.37868</th>\n",
       "      <th>0.14723</th>\n",
       "      <th>60</th>\n",
       "      <th>0.198334</th>\n",
       "      <th>0.0</th>\n",
       "      <th>0</th>\n",
       "      <th>-3.152729</th>\n",
       "      <th>-23.924900</th>\n",
       "      <th>20.772171</th>\n",
       "      <th>0.0</th>\n",
       "      <th>-0.0</th>\n",
       "      <td>[3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>That...</th>\n",
       "      <th>0.48937</th>\n",
       "      <th>0.46119</th>\n",
       "      <th>0.15851</th>\n",
       "      <th>61</th>\n",
       "      <th>0.168598</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1</th>\n",
       "      <th>-4.216444</th>\n",
       "      <th>-21.024010</th>\n",
       "      <th>16.807566</th>\n",
       "      <th>0.0</th>\n",
       "      <th>-0.0</th>\n",
       "      <td>[4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a...</th>\n",
       "      <th>0.46707</th>\n",
       "      <th>0.48349</th>\n",
       "      <th>0.26843</th>\n",
       "      <th>64</th>\n",
       "      <th>0.286845</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1</th>\n",
       "      <th>-3.296313</th>\n",
       "      <th>-29.940699</th>\n",
       "      <th>26.644386</th>\n",
       "      <th>0.0</th>\n",
       "      <th>-0.0</th>\n",
       "      <td>[5]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                          epoch\n",
       "pp_l                       pp_truelabel_probs vm_score sts_score pp_letter_diff contradiction_score reward label_flip pp_logp    ref_logp   kl_div    reward_with_kl loss      \n",
       "A well produced melodrama. 0.94352            0.00704  0.46344   42             0.281784            0.0    0          -11.101753 -30.506971 19.405218 0.0            -0.0   [1]\n",
       "And. There.                0.57294            0.37763  0.20417   57             0.273598            0.0    0          -9.571020  -31.323414 21.752394 0.0            -0.0   [2]\n",
       "There...                   0.57189            0.37868  0.14723   60             0.198334            0.0    0          -3.152729  -23.924900 20.772171 0.0            -0.0   [3]\n",
       "That...                    0.48937            0.46119  0.15851   61             0.168598            0.0    1          -4.216444  -21.024010 16.807566 0.0            -0.0   [4]\n",
       "a...                       0.46707            0.48349  0.26843   64             0.286845            0.0    1          -3.296313  -29.940699 26.644386 0.0            -0.0   [5]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Paraphrase\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>epoch</th>\n",
       "      <th>orig_l</th>\n",
       "      <th>pp_l</th>\n",
       "      <th>orig_truelabel_probs</th>\n",
       "      <th>pp_truelabel_probs</th>\n",
       "      <th>pp_predclass_probs</th>\n",
       "      <th>orig_label</th>\n",
       "      <th>pp_predclass</th>\n",
       "      <th>label_flip</th>\n",
       "      <th>vm_score</th>\n",
       "      <th>sts_score</th>\n",
       "      <th>pp_letter_diff</th>\n",
       "      <th>pp_letter_percent</th>\n",
       "      <th>contradiction_score</th>\n",
       "      <th>reward</th>\n",
       "      <th>pp_logp</th>\n",
       "      <th>ref_logp</th>\n",
       "      <th>kl_div</th>\n",
       "      <th>reward_with_kl</th>\n",
       "      <th>loss</th>\n",
       "      <th>batch_num</th>\n",
       "      <th>global_step</th>\n",
       "      <th>acc_num</th>\n",
       "      <th>loss_sum</th>\n",
       "      <th>loss_batch</th>\n",
       "      <th>label_flip_fraction</th>\n",
       "      <th>orig_length</th>\n",
       "      <th>orig_batch_size</th>\n",
       "      <th>pp_length</th>\n",
       "      <th>pp_batch_size</th>\n",
       "      <th>time_generate_pp</th>\n",
       "      <th>time_loss_fn</th>\n",
       "      <th>time_reward_fn</th>\n",
       "      <th>time_vm_scores</th>\n",
       "      <th>time_sts_scores</th>\n",
       "      <th>time_pp_letter_diff</th>\n",
       "      <th>time_contradiction_scores</th>\n",
       "      <th>time_pp_logp</th>\n",
       "      <th>time_log_entropy</th>\n",
       "      <th>time_log_token_probabilities</th>\n",
       "      <th>time_ref_logprobs</th>\n",
       "      <th>time_loss_fn_loss_calc</th>\n",
       "      <th>time_backwards</th>\n",
       "      <th>time_calc_gradient_norm</th>\n",
       "      <th>time_opt_step_and_calc_param_norm</th>\n",
       "      <th>time_opt_step</th>\n",
       "      <th>idx_n_unique_pp</th>\n",
       "      <th>idx_n_pp_changes</th>\n",
       "      <th>epoch_of_first_label_flip</th>\n",
       "      <th>n_words_orig</th>\n",
       "      <th>n_sentences_orig</th>\n",
       "      <th>n_punctuation_orig</th>\n",
       "      <th>n_digits_orig</th>\n",
       "      <th>n_letters_orig</th>\n",
       "      <th>n_words_pp</th>\n",
       "      <th>n_sentences_pp</th>\n",
       "      <th>n_punctuation_pp</th>\n",
       "      <th>n_digits_pp</th>\n",
       "      <th>n_letters_pp</th>\n",
       "      <th>n_words_diff</th>\n",
       "      <th>n_sentences_diff</th>\n",
       "      <th>n_punctuation_diff</th>\n",
       "      <th>n_digits_diff</th>\n",
       "      <th>n_letters_diff</th>\n",
       "      <th>removals_idx</th>\n",
       "      <th>removals</th>\n",
       "      <th>insertions_idx</th>\n",
       "      <th>insertions</th>\n",
       "      <th>unchanged_idx</th>\n",
       "      <th>unchanged</th>\n",
       "      <th>n_segments_inserted</th>\n",
       "      <th>n_segments_removed</th>\n",
       "      <th>n_tokens_inserted</th>\n",
       "      <th>n_tokens_removed</th>\n",
       "      <th>is_truncation</th>\n",
       "      <th>any_phrase_capitalised</th>\n",
       "      <th>any_phrase_decapitalised</th>\n",
       "      <th>edit_distance_token_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6450</th>\n",
       "      <td>1453</td>\n",
       "      <td>1</td>\n",
       "      <td>a grimly competent and stolid and earnest military courtroom drama .</td>\n",
       "      <td>A well produced melodrama.</td>\n",
       "      <td>0.950561</td>\n",
       "      <td>0.94352</td>\n",
       "      <td>0.943525</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00704</td>\n",
       "      <td>0.46344</td>\n",
       "      <td>42</td>\n",
       "      <td>0.382353</td>\n",
       "      <td>0.281784</td>\n",
       "      <td>0</td>\n",
       "      <td>-11.1018</td>\n",
       "      <td>-30.507</td>\n",
       "      <td>19.4052</td>\n",
       "      <td>0</td>\n",
       "      <td>-0</td>\n",
       "      <td>779</td>\n",
       "      <td>779</td>\n",
       "      <td>1</td>\n",
       "      <td>-4.58905</td>\n",
       "      <td>-0.286816</td>\n",
       "      <td>0.625</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>0.144962</td>\n",
       "      <td>0.297988</td>\n",
       "      <td>0.0480508</td>\n",
       "      <td>0.0070491</td>\n",
       "      <td>0.0252673</td>\n",
       "      <td>9.28608e-05</td>\n",
       "      <td>0.0149816</td>\n",
       "      <td>0.00827057</td>\n",
       "      <td>0.00189241</td>\n",
       "      <td>0.00399449</td>\n",
       "      <td>0.241297</td>\n",
       "      <td>0.000221244</td>\n",
       "      <td>0.194604</td>\n",
       "      <td>0.0470719</td>\n",
       "      <td>0.170267</td>\n",
       "      <td>0.104328</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>[4, 5, 6, 7, 8, 9, 10, 11, 12, 13]</td>\n",
       "      <td>[a grimly competent and stolid and earnest military courtroom drama]</td>\n",
       "      <td>[0, 1, 2, 3]</td>\n",
       "      <td>[A well produced melodrama]</td>\n",
       "      <td>[14]</td>\n",
       "      <td>[.]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       idx epoch  \\\n",
       "6450  1453     1   \n",
       "\n",
       "                                                                    orig_l  \\\n",
       "6450  a grimly competent and stolid and earnest military courtroom drama .   \n",
       "\n",
       "                            pp_l orig_truelabel_probs pp_truelabel_probs  \\\n",
       "6450  A well produced melodrama.             0.950561            0.94352   \n",
       "\n",
       "     pp_predclass_probs orig_label pp_predclass label_flip vm_score sts_score  \\\n",
       "6450           0.943525          1            1          0  0.00704   0.46344   \n",
       "\n",
       "     pp_letter_diff pp_letter_percent contradiction_score reward  pp_logp  \\\n",
       "6450             42          0.382353            0.281784      0 -11.1018   \n",
       "\n",
       "     ref_logp   kl_div reward_with_kl loss batch_num global_step acc_num  \\\n",
       "6450  -30.507  19.4052              0   -0       779         779       1   \n",
       "\n",
       "     loss_sum loss_batch label_flip_fraction orig_length orig_batch_size  \\\n",
       "6450 -4.58905  -0.286816               0.625          16               8   \n",
       "\n",
       "     pp_length pp_batch_size time_generate_pp time_loss_fn time_reward_fn  \\\n",
       "6450         9             8         0.144962     0.297988      0.0480508   \n",
       "\n",
       "     time_vm_scores time_sts_scores time_pp_letter_diff  \\\n",
       "6450      0.0070491       0.0252673         9.28608e-05   \n",
       "\n",
       "     time_contradiction_scores time_pp_logp time_log_entropy  \\\n",
       "6450                 0.0149816   0.00827057       0.00189241   \n",
       "\n",
       "     time_log_token_probabilities time_ref_logprobs time_loss_fn_loss_calc  \\\n",
       "6450                   0.00399449          0.241297            0.000221244   \n",
       "\n",
       "     time_backwards time_calc_gradient_norm time_opt_step_and_calc_param_norm  \\\n",
       "6450       0.194604               0.0470719                          0.170267   \n",
       "\n",
       "     time_opt_step idx_n_unique_pp idx_n_pp_changes epoch_of_first_label_flip  \\\n",
       "6450      0.104328               5                4                         4   \n",
       "\n",
       "     n_words_orig n_sentences_orig n_punctuation_orig n_digits_orig  \\\n",
       "6450           10                1                  1             0   \n",
       "\n",
       "     n_letters_orig n_words_pp n_sentences_pp n_punctuation_pp n_digits_pp  \\\n",
       "6450             57          4              1                1           0   \n",
       "\n",
       "     n_letters_pp n_words_diff n_sentences_diff n_punctuation_diff  \\\n",
       "6450           22            6                0                  0   \n",
       "\n",
       "     n_digits_diff n_letters_diff                        removals_idx  \\\n",
       "6450             0             35  [4, 5, 6, 7, 8, 9, 10, 11, 12, 13]   \n",
       "\n",
       "                                                                  removals  \\\n",
       "6450  [a grimly competent and stolid and earnest military courtroom drama]   \n",
       "\n",
       "     insertions_idx                   insertions unchanged_idx unchanged  \\\n",
       "6450   [0, 1, 2, 3]  [A well produced melodrama]          [14]       [.]   \n",
       "\n",
       "     n_segments_inserted n_segments_removed n_tokens_inserted  \\\n",
       "6450                   1                  1                 4   \n",
       "\n",
       "     n_tokens_removed is_truncation any_phrase_capitalised  \\\n",
       "6450               10         False                  False   \n",
       "\n",
       "     any_phrase_decapitalised edit_distance_token_level  \n",
       "6450                    False                        10  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "###############\n",
      "\n",
      "idx_n_unique_pp 0 \n",
      "\n",
      "Original: the rock is destined to be the 21st century's new \" conan \" and that he's going to make a splash even greater than arnold schwarzenegger , jean-claud van damme or steven segal .\n",
      "Original label 1\n",
      "Unique paraphrases: 5\n",
      "How the paraphrases change:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pp_l</th>\n",
       "      <th>pp_truelabel_probs</th>\n",
       "      <th>vm_score</th>\n",
       "      <th>sts_score</th>\n",
       "      <th>pp_letter_diff</th>\n",
       "      <th>contradiction_score</th>\n",
       "      <th>reward</th>\n",
       "      <th>label_flip</th>\n",
       "      <th>pp_logp</th>\n",
       "      <th>ref_logp</th>\n",
       "      <th>kl_div</th>\n",
       "      <th>reward_with_kl</th>\n",
       "      <th>loss</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a. 1964.ally</th>\n",
       "      <th>0.47732</th>\n",
       "      <th>0.37823</th>\n",
       "      <th>0.15152</th>\n",
       "      <th>165</th>\n",
       "      <th>0.326463</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1</th>\n",
       "      <th>-11.333163</th>\n",
       "      <th>-51.255611</th>\n",
       "      <th>39.922447</th>\n",
       "      <th>0.0</th>\n",
       "      <th>-0.0</th>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.))..</th>\n",
       "      <th>0.39710</th>\n",
       "      <th>0.45845</th>\n",
       "      <th>0.16296</th>\n",
       "      <th>172</th>\n",
       "      <th>0.011180</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1</th>\n",
       "      <th>-5.287820</th>\n",
       "      <th>-27.805031</th>\n",
       "      <th>22.517210</th>\n",
       "      <th>0.0</th>\n",
       "      <th>-0.0</th>\n",
       "      <td>[2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>It.,.</th>\n",
       "      <th>0.40179</th>\n",
       "      <th>0.45376</th>\n",
       "      <th>0.14368</th>\n",
       "      <th>172</th>\n",
       "      <th>0.042346</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1</th>\n",
       "      <th>-6.459289</th>\n",
       "      <th>-21.289001</th>\n",
       "      <th>14.829712</th>\n",
       "      <th>0.0</th>\n",
       "      <th>-0.0</th>\n",
       "      <td>[3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The.3..</th>\n",
       "      <th>0.39349</th>\n",
       "      <th>0.46206</th>\n",
       "      <th>0.17027</th>\n",
       "      <th>170</th>\n",
       "      <th>0.409990</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1</th>\n",
       "      <th>-8.753947</th>\n",
       "      <th>-36.361156</th>\n",
       "      <th>27.607208</th>\n",
       "      <th>0.0</th>\n",
       "      <th>-0.0</th>\n",
       "      <td>[4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I. He.</th>\n",
       "      <th>0.33670</th>\n",
       "      <th>0.51885</th>\n",
       "      <th>0.16951</th>\n",
       "      <th>171</th>\n",
       "      <th>0.056055</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1</th>\n",
       "      <th>-9.187491</th>\n",
       "      <th>-32.755455</th>\n",
       "      <th>23.567963</th>\n",
       "      <th>0.0</th>\n",
       "      <th>-0.0</th>\n",
       "      <td>[5]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                            epoch\n",
       "pp_l         pp_truelabel_probs vm_score sts_score pp_letter_diff contradiction_score reward label_flip pp_logp    ref_logp   kl_div    reward_with_kl loss      \n",
       "a. 1964.ally 0.47732            0.37823  0.15152   165            0.326463            0.0    1          -11.333163 -51.255611 39.922447 0.0            -0.0   [1]\n",
       ".))..        0.39710            0.45845  0.16296   172            0.011180            0.0    1          -5.287820  -27.805031 22.517210 0.0            -0.0   [2]\n",
       "It.,.        0.40179            0.45376  0.14368   172            0.042346            0.0    1          -6.459289  -21.289001 14.829712 0.0            -0.0   [3]\n",
       "The.3..      0.39349            0.46206  0.17027   170            0.409990            0.0    1          -8.753947  -36.361156 27.607208 0.0            -0.0   [4]\n",
       "I. He.       0.33670            0.51885  0.16951   171            0.056055            0.0    1          -9.187491  -32.755455 23.567963 0.0            -0.0   [5]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Paraphrase\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>epoch</th>\n",
       "      <th>orig_l</th>\n",
       "      <th>pp_l</th>\n",
       "      <th>orig_truelabel_probs</th>\n",
       "      <th>pp_truelabel_probs</th>\n",
       "      <th>pp_predclass_probs</th>\n",
       "      <th>orig_label</th>\n",
       "      <th>pp_predclass</th>\n",
       "      <th>label_flip</th>\n",
       "      <th>vm_score</th>\n",
       "      <th>sts_score</th>\n",
       "      <th>pp_letter_diff</th>\n",
       "      <th>pp_letter_percent</th>\n",
       "      <th>contradiction_score</th>\n",
       "      <th>reward</th>\n",
       "      <th>pp_logp</th>\n",
       "      <th>ref_logp</th>\n",
       "      <th>kl_div</th>\n",
       "      <th>reward_with_kl</th>\n",
       "      <th>loss</th>\n",
       "      <th>batch_num</th>\n",
       "      <th>global_step</th>\n",
       "      <th>acc_num</th>\n",
       "      <th>loss_sum</th>\n",
       "      <th>loss_batch</th>\n",
       "      <th>label_flip_fraction</th>\n",
       "      <th>orig_length</th>\n",
       "      <th>orig_batch_size</th>\n",
       "      <th>pp_length</th>\n",
       "      <th>pp_batch_size</th>\n",
       "      <th>time_generate_pp</th>\n",
       "      <th>time_loss_fn</th>\n",
       "      <th>time_reward_fn</th>\n",
       "      <th>time_vm_scores</th>\n",
       "      <th>time_sts_scores</th>\n",
       "      <th>time_pp_letter_diff</th>\n",
       "      <th>time_contradiction_scores</th>\n",
       "      <th>time_pp_logp</th>\n",
       "      <th>time_log_entropy</th>\n",
       "      <th>time_log_token_probabilities</th>\n",
       "      <th>time_ref_logprobs</th>\n",
       "      <th>time_loss_fn_loss_calc</th>\n",
       "      <th>time_backwards</th>\n",
       "      <th>time_calc_gradient_norm</th>\n",
       "      <th>time_opt_step_and_calc_param_norm</th>\n",
       "      <th>time_opt_step</th>\n",
       "      <th>idx_n_unique_pp</th>\n",
       "      <th>idx_n_pp_changes</th>\n",
       "      <th>epoch_of_first_label_flip</th>\n",
       "      <th>n_words_orig</th>\n",
       "      <th>n_sentences_orig</th>\n",
       "      <th>n_punctuation_orig</th>\n",
       "      <th>n_digits_orig</th>\n",
       "      <th>n_letters_orig</th>\n",
       "      <th>n_words_pp</th>\n",
       "      <th>n_sentences_pp</th>\n",
       "      <th>n_punctuation_pp</th>\n",
       "      <th>n_digits_pp</th>\n",
       "      <th>n_letters_pp</th>\n",
       "      <th>n_words_diff</th>\n",
       "      <th>n_sentences_diff</th>\n",
       "      <th>n_punctuation_diff</th>\n",
       "      <th>n_digits_diff</th>\n",
       "      <th>n_letters_diff</th>\n",
       "      <th>removals_idx</th>\n",
       "      <th>removals</th>\n",
       "      <th>insertions_idx</th>\n",
       "      <th>insertions</th>\n",
       "      <th>unchanged_idx</th>\n",
       "      <th>unchanged</th>\n",
       "      <th>n_segments_inserted</th>\n",
       "      <th>n_segments_removed</th>\n",
       "      <th>n_tokens_inserted</th>\n",
       "      <th>n_tokens_removed</th>\n",
       "      <th>is_truncation</th>\n",
       "      <th>any_phrase_capitalised</th>\n",
       "      <th>any_phrase_decapitalised</th>\n",
       "      <th>edit_distance_token_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>the rock is destined to be the 21st century's new \" conan \" and that he's going to make a splash even greater than arnold schwarzenegger , jean-claud van damme or steven segal .</td>\n",
       "      <td>a. 1964.ally</td>\n",
       "      <td>0.855556</td>\n",
       "      <td>0.47732</td>\n",
       "      <td>0.522677</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.37823</td>\n",
       "      <td>0.15152</td>\n",
       "      <td>165</td>\n",
       "      <td>0.0677966</td>\n",
       "      <td>0.326463</td>\n",
       "      <td>0</td>\n",
       "      <td>-11.3332</td>\n",
       "      <td>-51.2556</td>\n",
       "      <td>39.9224</td>\n",
       "      <td>0</td>\n",
       "      <td>-0</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>56</td>\n",
       "      <td>8</td>\n",
       "      <td>47</td>\n",
       "      <td>8</td>\n",
       "      <td>0.730642</td>\n",
       "      <td>2.208</td>\n",
       "      <td>0.0651331</td>\n",
       "      <td>0.0082351</td>\n",
       "      <td>0.0304929</td>\n",
       "      <td>8.50903e-05</td>\n",
       "      <td>0.0170405</td>\n",
       "      <td>0.0231077</td>\n",
       "      <td>0.00686075</td>\n",
       "      <td>0.00809908</td>\n",
       "      <td>2.11927</td>\n",
       "      <td>0.000288009</td>\n",
       "      <td>1.12282</td>\n",
       "      <td>0.0597984</td>\n",
       "      <td>3.38908e-05</td>\n",
       "      <td>2.45171e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>135</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>-2</td>\n",
       "      <td>130</td>\n",
       "      <td>[2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39]</td>\n",
       "      <td>[the rock is destined to be the 21st century 's new\" conan\" and that he 's going to make a splash even greater than arnold schwarzenegger, jean- claud van damme or steven segal.]</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>[a. 1964.ally]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>38</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  idx epoch  \\\n",
       "0   0     1   \n",
       "\n",
       "                                                                                                                                                                              orig_l  \\\n",
       "0  the rock is destined to be the 21st century's new \" conan \" and that he's going to make a splash even greater than arnold schwarzenegger , jean-claud van damme or steven segal .   \n",
       "\n",
       "           pp_l orig_truelabel_probs pp_truelabel_probs pp_predclass_probs  \\\n",
       "0  a. 1964.ally             0.855556            0.47732           0.522677   \n",
       "\n",
       "  orig_label pp_predclass label_flip vm_score sts_score pp_letter_diff  \\\n",
       "0          1            0          1  0.37823   0.15152            165   \n",
       "\n",
       "  pp_letter_percent contradiction_score reward  pp_logp ref_logp   kl_div  \\\n",
       "0         0.0677966            0.326463      0 -11.3332 -51.2556  39.9224   \n",
       "\n",
       "  reward_with_kl loss batch_num global_step acc_num loss_sum loss_batch  \\\n",
       "0              0   -0        14          14       0        0          0   \n",
       "\n",
       "  label_flip_fraction orig_length orig_batch_size pp_length pp_batch_size  \\\n",
       "0                 0.5          56               8        47             8   \n",
       "\n",
       "  time_generate_pp time_loss_fn time_reward_fn time_vm_scores time_sts_scores  \\\n",
       "0         0.730642        2.208      0.0651331      0.0082351       0.0304929   \n",
       "\n",
       "  time_pp_letter_diff time_contradiction_scores time_pp_logp time_log_entropy  \\\n",
       "0         8.50903e-05                 0.0170405    0.0231077       0.00686075   \n",
       "\n",
       "  time_log_token_probabilities time_ref_logprobs time_loss_fn_loss_calc  \\\n",
       "0                   0.00809908           2.11927            0.000288009   \n",
       "\n",
       "  time_backwards time_calc_gradient_norm time_opt_step_and_calc_param_norm  \\\n",
       "0        1.12282               0.0597984                       3.38908e-05   \n",
       "\n",
       "  time_opt_step idx_n_unique_pp idx_n_pp_changes epoch_of_first_label_flip  \\\n",
       "0   2.45171e-06               5                4                         1   \n",
       "\n",
       "  n_words_orig n_sentences_orig n_punctuation_orig n_digits_orig  \\\n",
       "0           32                1                  7             2   \n",
       "\n",
       "  n_letters_orig n_words_pp n_sentences_pp n_punctuation_pp n_digits_pp  \\\n",
       "0            135          2              1                2           4   \n",
       "\n",
       "  n_letters_pp n_words_diff n_sentences_diff n_punctuation_diff n_digits_diff  \\\n",
       "0            5           30                0                  5            -2   \n",
       "\n",
       "  n_letters_diff  \\\n",
       "0            130   \n",
       "\n",
       "                                                                                                                                       removals_idx  \\\n",
       "0  [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39]   \n",
       "\n",
       "                                                                                                                                                                             removals  \\\n",
       "0  [the rock is destined to be the 21st century 's new\" conan\" and that he 's going to make a splash even greater than arnold schwarzenegger, jean- claud van damme or steven segal.]   \n",
       "\n",
       "  insertions_idx      insertions unchanged_idx unchanged n_segments_inserted  \\\n",
       "0         [0, 1]  [a. 1964.ally]            []        []                   1   \n",
       "\n",
       "  n_segments_removed n_tokens_inserted n_tokens_removed is_truncation  \\\n",
       "0                  1                 2               38         False   \n",
       "\n",
       "  any_phrase_capitalised any_phrase_decapitalised edit_distance_token_level  \n",
       "0                  False                    False                        38  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "###############\n",
      "\n",
      "idx_n_unique_pp 1 \n",
      "\n",
      "Original: both the crime story and the love story are unusual . but they don't fit well together and neither is well told .\n",
      "Original label 0\n",
      "Unique paraphrases: 5\n",
      "How the paraphrases change:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pp_l</th>\n",
       "      <th>pp_truelabel_probs</th>\n",
       "      <th>vm_score</th>\n",
       "      <th>sts_score</th>\n",
       "      <th>pp_letter_diff</th>\n",
       "      <th>contradiction_score</th>\n",
       "      <th>reward</th>\n",
       "      <th>label_flip</th>\n",
       "      <th>pp_logp</th>\n",
       "      <th>ref_logp</th>\n",
       "      <th>kl_div</th>\n",
       "      <th>reward_with_kl</th>\n",
       "      <th>loss</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Neither is told in the same way.</th>\n",
       "      <th>0.79695</th>\n",
       "      <th>0.10179</th>\n",
       "      <th>0.46731</th>\n",
       "      <th>81</th>\n",
       "      <th>0.005267</th>\n",
       "      <th>0.0</th>\n",
       "      <th>0</th>\n",
       "      <th>-7.951353</th>\n",
       "      <th>-40.617188</th>\n",
       "      <th>32.665836</th>\n",
       "      <th>0.0</th>\n",
       "      <th>-0.0</th>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Both are..</th>\n",
       "      <th>0.46918</th>\n",
       "      <th>0.42956</th>\n",
       "      <th>0.31643</th>\n",
       "      <th>103</th>\n",
       "      <th>0.339550</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1</th>\n",
       "      <th>-3.053111</th>\n",
       "      <th>-26.979683</th>\n",
       "      <th>23.926573</th>\n",
       "      <th>0.0</th>\n",
       "      <th>-0.0</th>\n",
       "      <td>[2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The are..</th>\n",
       "      <th>0.50657</th>\n",
       "      <th>0.39217</th>\n",
       "      <th>0.10193</th>\n",
       "      <th>104</th>\n",
       "      <th>0.063060</th>\n",
       "      <th>0.0</th>\n",
       "      <th>0</th>\n",
       "      <th>-4.843100</th>\n",
       "      <th>-28.573240</th>\n",
       "      <th>23.730141</th>\n",
       "      <th>0.0</th>\n",
       "      <th>-0.0</th>\n",
       "      <td>[3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The...</th>\n",
       "      <th>0.41313</th>\n",
       "      <th>0.48560</th>\n",
       "      <th>0.11727</th>\n",
       "      <th>107</th>\n",
       "      <th>0.067154</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1</th>\n",
       "      <th>-1.381138</th>\n",
       "      <th>-17.473675</th>\n",
       "      <th>16.092537</th>\n",
       "      <th>0.0</th>\n",
       "      <th>-0.0</th>\n",
       "      <td>[4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>They are..</th>\n",
       "      <th>0.24830</th>\n",
       "      <th>0.65044</th>\n",
       "      <th>0.10044</th>\n",
       "      <th>103</th>\n",
       "      <th>0.051880</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1</th>\n",
       "      <th>-4.208287</th>\n",
       "      <th>-23.213818</th>\n",
       "      <th>19.005531</th>\n",
       "      <th>0.0</th>\n",
       "      <th>-0.0</th>\n",
       "      <td>[5]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                               epoch\n",
       "pp_l                             pp_truelabel_probs vm_score sts_score pp_letter_diff contradiction_score reward label_flip pp_logp   ref_logp   kl_div    reward_with_kl loss      \n",
       "Neither is told in the same way. 0.79695            0.10179  0.46731   81             0.005267            0.0    0          -7.951353 -40.617188 32.665836 0.0            -0.0   [1]\n",
       "Both are..                       0.46918            0.42956  0.31643   103            0.339550            0.0    1          -3.053111 -26.979683 23.926573 0.0            -0.0   [2]\n",
       "The are..                        0.50657            0.39217  0.10193   104            0.063060            0.0    0          -4.843100 -28.573240 23.730141 0.0            -0.0   [3]\n",
       "The...                           0.41313            0.48560  0.11727   107            0.067154            0.0    1          -1.381138 -17.473675 16.092537 0.0            -0.0   [4]\n",
       "They are..                       0.24830            0.65044  0.10044   103            0.051880            0.0    1          -4.208287 -23.213818 19.005531 0.0            -0.0   [5]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Paraphrase\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>epoch</th>\n",
       "      <th>orig_l</th>\n",
       "      <th>pp_l</th>\n",
       "      <th>orig_truelabel_probs</th>\n",
       "      <th>pp_truelabel_probs</th>\n",
       "      <th>pp_predclass_probs</th>\n",
       "      <th>orig_label</th>\n",
       "      <th>pp_predclass</th>\n",
       "      <th>label_flip</th>\n",
       "      <th>vm_score</th>\n",
       "      <th>sts_score</th>\n",
       "      <th>pp_letter_diff</th>\n",
       "      <th>pp_letter_percent</th>\n",
       "      <th>contradiction_score</th>\n",
       "      <th>reward</th>\n",
       "      <th>pp_logp</th>\n",
       "      <th>ref_logp</th>\n",
       "      <th>kl_div</th>\n",
       "      <th>reward_with_kl</th>\n",
       "      <th>loss</th>\n",
       "      <th>batch_num</th>\n",
       "      <th>global_step</th>\n",
       "      <th>acc_num</th>\n",
       "      <th>loss_sum</th>\n",
       "      <th>loss_batch</th>\n",
       "      <th>label_flip_fraction</th>\n",
       "      <th>orig_length</th>\n",
       "      <th>orig_batch_size</th>\n",
       "      <th>pp_length</th>\n",
       "      <th>pp_batch_size</th>\n",
       "      <th>time_generate_pp</th>\n",
       "      <th>time_loss_fn</th>\n",
       "      <th>time_reward_fn</th>\n",
       "      <th>time_vm_scores</th>\n",
       "      <th>time_sts_scores</th>\n",
       "      <th>time_pp_letter_diff</th>\n",
       "      <th>time_contradiction_scores</th>\n",
       "      <th>time_pp_logp</th>\n",
       "      <th>time_log_entropy</th>\n",
       "      <th>time_log_token_probabilities</th>\n",
       "      <th>time_ref_logprobs</th>\n",
       "      <th>time_loss_fn_loss_calc</th>\n",
       "      <th>time_backwards</th>\n",
       "      <th>time_calc_gradient_norm</th>\n",
       "      <th>time_opt_step_and_calc_param_norm</th>\n",
       "      <th>time_opt_step</th>\n",
       "      <th>idx_n_unique_pp</th>\n",
       "      <th>idx_n_pp_changes</th>\n",
       "      <th>epoch_of_first_label_flip</th>\n",
       "      <th>n_words_orig</th>\n",
       "      <th>n_sentences_orig</th>\n",
       "      <th>n_punctuation_orig</th>\n",
       "      <th>n_digits_orig</th>\n",
       "      <th>n_letters_orig</th>\n",
       "      <th>n_words_pp</th>\n",
       "      <th>n_sentences_pp</th>\n",
       "      <th>n_punctuation_pp</th>\n",
       "      <th>n_digits_pp</th>\n",
       "      <th>n_letters_pp</th>\n",
       "      <th>n_words_diff</th>\n",
       "      <th>n_sentences_diff</th>\n",
       "      <th>n_punctuation_diff</th>\n",
       "      <th>n_digits_diff</th>\n",
       "      <th>n_letters_diff</th>\n",
       "      <th>removals_idx</th>\n",
       "      <th>removals</th>\n",
       "      <th>insertions_idx</th>\n",
       "      <th>insertions</th>\n",
       "      <th>unchanged_idx</th>\n",
       "      <th>unchanged</th>\n",
       "      <th>n_segments_inserted</th>\n",
       "      <th>n_segments_removed</th>\n",
       "      <th>n_tokens_inserted</th>\n",
       "      <th>n_tokens_removed</th>\n",
       "      <th>is_truncation</th>\n",
       "      <th>any_phrase_capitalised</th>\n",
       "      <th>any_phrase_decapitalised</th>\n",
       "      <th>edit_distance_token_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23805</th>\n",
       "      <td>5451</td>\n",
       "      <td>1</td>\n",
       "      <td>both the crime story and the love story are unusual . but they don't fit well together and neither is well told .</td>\n",
       "      <td>Neither is told in the same way.</td>\n",
       "      <td>0.898734</td>\n",
       "      <td>0.79695</td>\n",
       "      <td>0.796945</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.10179</td>\n",
       "      <td>0.46731</td>\n",
       "      <td>81</td>\n",
       "      <td>0.283186</td>\n",
       "      <td>0.00526715</td>\n",
       "      <td>0</td>\n",
       "      <td>-7.95135</td>\n",
       "      <td>-40.6172</td>\n",
       "      <td>32.6658</td>\n",
       "      <td>0</td>\n",
       "      <td>-0</td>\n",
       "      <td>436</td>\n",
       "      <td>436</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>22</td>\n",
       "      <td>8</td>\n",
       "      <td>0.565236</td>\n",
       "      <td>0.756997</td>\n",
       "      <td>0.0528946</td>\n",
       "      <td>0.00868569</td>\n",
       "      <td>0.0274795</td>\n",
       "      <td>7.96961e-05</td>\n",
       "      <td>0.0159932</td>\n",
       "      <td>0.0137685</td>\n",
       "      <td>0.00372695</td>\n",
       "      <td>0.00569823</td>\n",
       "      <td>0.689923</td>\n",
       "      <td>0.000242757</td>\n",
       "      <td>0.505851</td>\n",
       "      <td>0.0555003</td>\n",
       "      <td>2.99844e-05</td>\n",
       "      <td>2.56533e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>[0, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]</td>\n",
       "      <td>[both, crime story and the love story are unusual, but they do n't fit well together and neither is well told.]</td>\n",
       "      <td>[1, 2, 3, 4, 6, 7]</td>\n",
       "      <td>[Neither is told in, same way]</td>\n",
       "      <td>[5, 16]</td>\n",
       "      <td>[the, .]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        idx epoch  \\\n",
       "23805  5451     1   \n",
       "\n",
       "                                                                                                                  orig_l  \\\n",
       "23805  both the crime story and the love story are unusual . but they don't fit well together and neither is well told .   \n",
       "\n",
       "                                   pp_l orig_truelabel_probs  \\\n",
       "23805  Neither is told in the same way.             0.898734   \n",
       "\n",
       "      pp_truelabel_probs pp_predclass_probs orig_label pp_predclass  \\\n",
       "23805            0.79695           0.796945          0            0   \n",
       "\n",
       "      label_flip vm_score sts_score pp_letter_diff pp_letter_percent  \\\n",
       "23805          0  0.10179   0.46731             81          0.283186   \n",
       "\n",
       "      contradiction_score reward  pp_logp ref_logp   kl_div reward_with_kl  \\\n",
       "23805          0.00526715      0 -7.95135 -40.6172  32.6658              0   \n",
       "\n",
       "      loss batch_num global_step acc_num loss_sum loss_batch  \\\n",
       "23805   -0       436         436       0        0          0   \n",
       "\n",
       "      label_flip_fraction orig_length orig_batch_size pp_length pp_batch_size  \\\n",
       "23805                0.25          32               8        22             8   \n",
       "\n",
       "      time_generate_pp time_loss_fn time_reward_fn time_vm_scores  \\\n",
       "23805         0.565236     0.756997      0.0528946     0.00868569   \n",
       "\n",
       "      time_sts_scores time_pp_letter_diff time_contradiction_scores  \\\n",
       "23805       0.0274795         7.96961e-05                 0.0159932   \n",
       "\n",
       "      time_pp_logp time_log_entropy time_log_token_probabilities  \\\n",
       "23805    0.0137685       0.00372695                   0.00569823   \n",
       "\n",
       "      time_ref_logprobs time_loss_fn_loss_calc time_backwards  \\\n",
       "23805          0.689923            0.000242757       0.505851   \n",
       "\n",
       "      time_calc_gradient_norm time_opt_step_and_calc_param_norm time_opt_step  \\\n",
       "23805               0.0555003                       2.99844e-05   2.56533e-06   \n",
       "\n",
       "      idx_n_unique_pp idx_n_pp_changes epoch_of_first_label_flip n_words_orig  \\\n",
       "23805               5                4                         2           22   \n",
       "\n",
       "      n_sentences_orig n_punctuation_orig n_digits_orig n_letters_orig  \\\n",
       "23805                1                  3             0             88   \n",
       "\n",
       "      n_words_pp n_sentences_pp n_punctuation_pp n_digits_pp n_letters_pp  \\\n",
       "23805          7              1                1           0           25   \n",
       "\n",
       "      n_words_diff n_sentences_diff n_punctuation_diff n_digits_diff  \\\n",
       "23805           15                0                  2             0   \n",
       "\n",
       "      n_letters_diff  \\\n",
       "23805             63   \n",
       "\n",
       "                                                                                removals_idx  \\\n",
       "23805  [0, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]   \n",
       "\n",
       "                                                                                                              removals  \\\n",
       "23805  [both, crime story and the love story are unusual, but they do n't fit well together and neither is well told.]   \n",
       "\n",
       "           insertions_idx                      insertions unchanged_idx  \\\n",
       "23805  [1, 2, 3, 4, 6, 7]  [Neither is told in, same way]       [5, 16]   \n",
       "\n",
       "      unchanged n_segments_inserted n_segments_removed n_tokens_inserted  \\\n",
       "23805  [the, .]                   2                  3                 6   \n",
       "\n",
       "      n_tokens_removed is_truncation any_phrase_capitalised  \\\n",
       "23805               22          True                  False   \n",
       "\n",
       "      any_phrase_decapitalised edit_distance_token_level  \n",
       "23805                    False                        22  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "###############\n",
      "\n",
      "idx_n_unique_pp 2 \n",
      "\n",
      "Original: like a can of 2-day old coke . you can taste it , but there's no fizz .\n",
      "Original label 0\n",
      "Unique paraphrases: 5\n",
      "How the paraphrases change:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pp_l</th>\n",
       "      <th>pp_truelabel_probs</th>\n",
       "      <th>vm_score</th>\n",
       "      <th>sts_score</th>\n",
       "      <th>pp_letter_diff</th>\n",
       "      <th>contradiction_score</th>\n",
       "      <th>reward</th>\n",
       "      <th>label_flip</th>\n",
       "      <th>pp_logp</th>\n",
       "      <th>ref_logp</th>\n",
       "      <th>kl_div</th>\n",
       "      <th>reward_with_kl</th>\n",
       "      <th>loss</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>You can taste it though.</th>\n",
       "      <th>0.41003</th>\n",
       "      <th>0.49345</th>\n",
       "      <th>0.57913</th>\n",
       "      <th>47</th>\n",
       "      <th>0.000670</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1</th>\n",
       "      <th>-7.764310</th>\n",
       "      <th>-32.978302</th>\n",
       "      <th>25.213991</th>\n",
       "      <th>0.0</th>\n",
       "      <th>-0.0</th>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>You can..</th>\n",
       "      <th>0.29707</th>\n",
       "      <th>0.60641</th>\n",
       "      <th>0.41962</th>\n",
       "      <th>62</th>\n",
       "      <th>0.103262</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1</th>\n",
       "      <th>-1.538959</th>\n",
       "      <th>-13.925531</th>\n",
       "      <th>12.386572</th>\n",
       "      <th>0.0</th>\n",
       "      <th>-0.0</th>\n",
       "      <td>[2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>there.. it.</th>\n",
       "      <th>0.43286</th>\n",
       "      <th>0.47062</th>\n",
       "      <th>0.25162</th>\n",
       "      <th>60</th>\n",
       "      <th>0.086131</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1</th>\n",
       "      <th>-8.879734</th>\n",
       "      <th>-30.270638</th>\n",
       "      <th>21.390903</th>\n",
       "      <th>0.0</th>\n",
       "      <th>-0.0</th>\n",
       "      <td>[3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Some. There.</th>\n",
       "      <th>0.56509</th>\n",
       "      <th>0.33839</th>\n",
       "      <th>0.19602</th>\n",
       "      <th>59</th>\n",
       "      <th>0.135073</th>\n",
       "      <th>0.0</th>\n",
       "      <th>0</th>\n",
       "      <th>-10.781796</th>\n",
       "      <th>-31.709274</th>\n",
       "      <th>20.927479</th>\n",
       "      <th>0.0</th>\n",
       "      <th>-0.0</th>\n",
       "      <td>[4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>You...</th>\n",
       "      <th>0.26897</th>\n",
       "      <th>0.63452</th>\n",
       "      <th>0.24455</th>\n",
       "      <th>65</th>\n",
       "      <th>0.161853</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1</th>\n",
       "      <th>-1.637215</th>\n",
       "      <th>-27.159557</th>\n",
       "      <th>25.522343</th>\n",
       "      <th>0.0</th>\n",
       "      <th>-0.0</th>\n",
       "      <td>[5]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                        epoch\n",
       "pp_l                     pp_truelabel_probs vm_score sts_score pp_letter_diff contradiction_score reward label_flip pp_logp    ref_logp   kl_div    reward_with_kl loss      \n",
       "You can taste it though. 0.41003            0.49345  0.57913   47             0.000670            0.0    1          -7.764310  -32.978302 25.213991 0.0            -0.0   [1]\n",
       "You can..                0.29707            0.60641  0.41962   62             0.103262            0.0    1          -1.538959  -13.925531 12.386572 0.0            -0.0   [2]\n",
       "there.. it.              0.43286            0.47062  0.25162   60             0.086131            0.0    1          -8.879734  -30.270638 21.390903 0.0            -0.0   [3]\n",
       "Some. There.             0.56509            0.33839  0.19602   59             0.135073            0.0    0          -10.781796 -31.709274 20.927479 0.0            -0.0   [4]\n",
       "You...                   0.26897            0.63452  0.24455   65             0.161853            0.0    1          -1.637215  -27.159557 25.522343 0.0            -0.0   [5]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Paraphrase\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>epoch</th>\n",
       "      <th>orig_l</th>\n",
       "      <th>pp_l</th>\n",
       "      <th>orig_truelabel_probs</th>\n",
       "      <th>pp_truelabel_probs</th>\n",
       "      <th>pp_predclass_probs</th>\n",
       "      <th>orig_label</th>\n",
       "      <th>pp_predclass</th>\n",
       "      <th>label_flip</th>\n",
       "      <th>vm_score</th>\n",
       "      <th>sts_score</th>\n",
       "      <th>pp_letter_diff</th>\n",
       "      <th>pp_letter_percent</th>\n",
       "      <th>contradiction_score</th>\n",
       "      <th>reward</th>\n",
       "      <th>pp_logp</th>\n",
       "      <th>ref_logp</th>\n",
       "      <th>kl_div</th>\n",
       "      <th>reward_with_kl</th>\n",
       "      <th>loss</th>\n",
       "      <th>batch_num</th>\n",
       "      <th>global_step</th>\n",
       "      <th>acc_num</th>\n",
       "      <th>loss_sum</th>\n",
       "      <th>loss_batch</th>\n",
       "      <th>label_flip_fraction</th>\n",
       "      <th>orig_length</th>\n",
       "      <th>orig_batch_size</th>\n",
       "      <th>pp_length</th>\n",
       "      <th>pp_batch_size</th>\n",
       "      <th>time_generate_pp</th>\n",
       "      <th>time_loss_fn</th>\n",
       "      <th>time_reward_fn</th>\n",
       "      <th>time_vm_scores</th>\n",
       "      <th>time_sts_scores</th>\n",
       "      <th>time_pp_letter_diff</th>\n",
       "      <th>time_contradiction_scores</th>\n",
       "      <th>time_pp_logp</th>\n",
       "      <th>time_log_entropy</th>\n",
       "      <th>time_log_token_probabilities</th>\n",
       "      <th>time_ref_logprobs</th>\n",
       "      <th>time_loss_fn_loss_calc</th>\n",
       "      <th>time_backwards</th>\n",
       "      <th>time_calc_gradient_norm</th>\n",
       "      <th>time_opt_step_and_calc_param_norm</th>\n",
       "      <th>time_opt_step</th>\n",
       "      <th>idx_n_unique_pp</th>\n",
       "      <th>idx_n_pp_changes</th>\n",
       "      <th>epoch_of_first_label_flip</th>\n",
       "      <th>n_words_orig</th>\n",
       "      <th>n_sentences_orig</th>\n",
       "      <th>n_punctuation_orig</th>\n",
       "      <th>n_digits_orig</th>\n",
       "      <th>n_letters_orig</th>\n",
       "      <th>n_words_pp</th>\n",
       "      <th>n_sentences_pp</th>\n",
       "      <th>n_punctuation_pp</th>\n",
       "      <th>n_digits_pp</th>\n",
       "      <th>n_letters_pp</th>\n",
       "      <th>n_words_diff</th>\n",
       "      <th>n_sentences_diff</th>\n",
       "      <th>n_punctuation_diff</th>\n",
       "      <th>n_digits_diff</th>\n",
       "      <th>n_letters_diff</th>\n",
       "      <th>removals_idx</th>\n",
       "      <th>removals</th>\n",
       "      <th>insertions_idx</th>\n",
       "      <th>insertions</th>\n",
       "      <th>unchanged_idx</th>\n",
       "      <th>unchanged</th>\n",
       "      <th>n_segments_inserted</th>\n",
       "      <th>n_segments_removed</th>\n",
       "      <th>n_tokens_inserted</th>\n",
       "      <th>n_tokens_removed</th>\n",
       "      <th>is_truncation</th>\n",
       "      <th>any_phrase_capitalised</th>\n",
       "      <th>any_phrase_decapitalised</th>\n",
       "      <th>edit_distance_token_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23795</th>\n",
       "      <td>5449</td>\n",
       "      <td>1</td>\n",
       "      <td>like a can of 2-day old coke . you can taste it , but there's no fizz .</td>\n",
       "      <td>You can taste it though.</td>\n",
       "      <td>0.903481</td>\n",
       "      <td>0.41003</td>\n",
       "      <td>0.589975</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.49345</td>\n",
       "      <td>0.57913</td>\n",
       "      <td>47</td>\n",
       "      <td>0.338028</td>\n",
       "      <td>0.000670363</td>\n",
       "      <td>0</td>\n",
       "      <td>-7.76431</td>\n",
       "      <td>-32.9783</td>\n",
       "      <td>25.214</td>\n",
       "      <td>0</td>\n",
       "      <td>-0</td>\n",
       "      <td>517</td>\n",
       "      <td>517</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.375</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>19</td>\n",
       "      <td>8</td>\n",
       "      <td>0.293421</td>\n",
       "      <td>0.646849</td>\n",
       "      <td>0.049459</td>\n",
       "      <td>0.00693217</td>\n",
       "      <td>0.0259767</td>\n",
       "      <td>8.02982e-05</td>\n",
       "      <td>0.0157728</td>\n",
       "      <td>0.0124103</td>\n",
       "      <td>0.00322279</td>\n",
       "      <td>0.00519702</td>\n",
       "      <td>0.584582</td>\n",
       "      <td>0.000240007</td>\n",
       "      <td>0.432327</td>\n",
       "      <td>0.0559118</td>\n",
       "      <td>0.169686</td>\n",
       "      <td>0.104389</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 14, 15, 16, 17, 18, 19]</td>\n",
       "      <td>[like a can of 2-day old coke. you, , but there 's no fizz]</td>\n",
       "      <td>[0, 13]</td>\n",
       "      <td>[You, though]</td>\n",
       "      <td>[10, 11, 12, 20]</td>\n",
       "      <td>[can taste it, .]</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        idx epoch  \\\n",
       "23795  5449     1   \n",
       "\n",
       "                                                                        orig_l  \\\n",
       "23795  like a can of 2-day old coke . you can taste it , but there's no fizz .   \n",
       "\n",
       "                           pp_l orig_truelabel_probs pp_truelabel_probs  \\\n",
       "23795  You can taste it though.             0.903481            0.41003   \n",
       "\n",
       "      pp_predclass_probs orig_label pp_predclass label_flip vm_score  \\\n",
       "23795           0.589975          0            1          1  0.49345   \n",
       "\n",
       "      sts_score pp_letter_diff pp_letter_percent contradiction_score reward  \\\n",
       "23795   0.57913             47          0.338028         0.000670363      0   \n",
       "\n",
       "       pp_logp ref_logp  kl_div reward_with_kl loss batch_num global_step  \\\n",
       "23795 -7.76431 -32.9783  25.214              0   -0       517         517   \n",
       "\n",
       "      acc_num loss_sum loss_batch label_flip_fraction orig_length  \\\n",
       "23795       1        0          0               0.375          32   \n",
       "\n",
       "      orig_batch_size pp_length pp_batch_size time_generate_pp time_loss_fn  \\\n",
       "23795               8        19             8         0.293421     0.646849   \n",
       "\n",
       "      time_reward_fn time_vm_scores time_sts_scores time_pp_letter_diff  \\\n",
       "23795       0.049459     0.00693217       0.0259767         8.02982e-05   \n",
       "\n",
       "      time_contradiction_scores time_pp_logp time_log_entropy  \\\n",
       "23795                 0.0157728    0.0124103       0.00322279   \n",
       "\n",
       "      time_log_token_probabilities time_ref_logprobs time_loss_fn_loss_calc  \\\n",
       "23795                   0.00519702          0.584582            0.000240007   \n",
       "\n",
       "      time_backwards time_calc_gradient_norm  \\\n",
       "23795       0.432327               0.0559118   \n",
       "\n",
       "      time_opt_step_and_calc_param_norm time_opt_step idx_n_unique_pp  \\\n",
       "23795                          0.169686      0.104389               5   \n",
       "\n",
       "      idx_n_pp_changes epoch_of_first_label_flip n_words_orig  \\\n",
       "23795                4                         1           16   \n",
       "\n",
       "      n_sentences_orig n_punctuation_orig n_digits_orig n_letters_orig  \\\n",
       "23795                1                  5             1             48   \n",
       "\n",
       "      n_words_pp n_sentences_pp n_punctuation_pp n_digits_pp n_letters_pp  \\\n",
       "23795          5              1                1           0           19   \n",
       "\n",
       "      n_words_diff n_sentences_diff n_punctuation_diff n_digits_diff  \\\n",
       "23795           11                0                  4             1   \n",
       "\n",
       "      n_letters_diff                                         removals_idx  \\\n",
       "23795             29  [1, 2, 3, 4, 5, 6, 7, 8, 9, 14, 15, 16, 17, 18, 19]   \n",
       "\n",
       "                                                          removals  \\\n",
       "23795  [like a can of 2-day old coke. you, , but there 's no fizz]   \n",
       "\n",
       "      insertions_idx     insertions     unchanged_idx          unchanged  \\\n",
       "23795        [0, 13]  [You, though]  [10, 11, 12, 20]  [can taste it, .]   \n",
       "\n",
       "      n_segments_inserted n_segments_removed n_tokens_inserted  \\\n",
       "23795                   2                  2                 2   \n",
       "\n",
       "      n_tokens_removed is_truncation any_phrase_capitalised  \\\n",
       "23795               15         False                  False   \n",
       "\n",
       "      any_phrase_decapitalised edit_distance_token_level  \n",
       "23795                    False                        15  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "###############\n",
      "\n",
      "idx_n_unique_pp 3 \n",
      "\n",
      "Original: a well-acted movie that simply doesn't gel .\n",
      "Original label 0\n",
      "Unique paraphrases: 5\n",
      "How the paraphrases change:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pp_l</th>\n",
       "      <th>pp_truelabel_probs</th>\n",
       "      <th>vm_score</th>\n",
       "      <th>sts_score</th>\n",
       "      <th>pp_letter_diff</th>\n",
       "      <th>contradiction_score</th>\n",
       "      <th>reward</th>\n",
       "      <th>label_flip</th>\n",
       "      <th>pp_logp</th>\n",
       "      <th>ref_logp</th>\n",
       "      <th>kl_div</th>\n",
       "      <th>reward_with_kl</th>\n",
       "      <th>loss</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>\"This doesn't jive\".</th>\n",
       "      <th>0.66950</th>\n",
       "      <th>0.24125</th>\n",
       "      <th>0.36236</th>\n",
       "      <th>24</th>\n",
       "      <th>0.000644</th>\n",
       "      <th>0.0</th>\n",
       "      <th>0</th>\n",
       "      <th>-18.804672</th>\n",
       "      <th>-36.929344</th>\n",
       "      <th>18.124672</th>\n",
       "      <th>0.0</th>\n",
       "      <th>-0.0</th>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Well...</th>\n",
       "      <th>0.43355</th>\n",
       "      <th>0.47720</th>\n",
       "      <th>0.15785</th>\n",
       "      <th>37</th>\n",
       "      <th>0.915782</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1</th>\n",
       "      <th>-3.814358</th>\n",
       "      <th>-29.577160</th>\n",
       "      <th>25.762802</th>\n",
       "      <th>0.0</th>\n",
       "      <th>-0.0</th>\n",
       "      <td>[2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A..!</th>\n",
       "      <th>0.44825</th>\n",
       "      <th>0.46250</th>\n",
       "      <th>0.17425</th>\n",
       "      <th>40</th>\n",
       "      <th>0.841634</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1</th>\n",
       "      <th>-3.666783</th>\n",
       "      <th>-27.247244</th>\n",
       "      <th>23.580462</th>\n",
       "      <th>0.0</th>\n",
       "      <th>-0.0</th>\n",
       "      <td>[3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A.;;</th>\n",
       "      <th>0.57770</th>\n",
       "      <th>0.33305</th>\n",
       "      <th>0.09286</th>\n",
       "      <th>40</th>\n",
       "      <th>0.773183</th>\n",
       "      <th>0.0</th>\n",
       "      <th>0</th>\n",
       "      <th>-9.092116</th>\n",
       "      <th>-24.071657</th>\n",
       "      <th>14.979541</th>\n",
       "      <th>0.0</th>\n",
       "      <th>-0.0</th>\n",
       "      <td>[4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>It...</th>\n",
       "      <th>0.47830</th>\n",
       "      <th>0.43245</th>\n",
       "      <th>0.22360</th>\n",
       "      <th>39</th>\n",
       "      <th>0.680387</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1</th>\n",
       "      <th>-2.475851</th>\n",
       "      <th>-30.842594</th>\n",
       "      <th>28.366743</th>\n",
       "      <th>0.0</th>\n",
       "      <th>-0.0</th>\n",
       "      <td>[5]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                    epoch\n",
       "pp_l                 pp_truelabel_probs vm_score sts_score pp_letter_diff contradiction_score reward label_flip pp_logp    ref_logp   kl_div    reward_with_kl loss      \n",
       "\"This doesn't jive\". 0.66950            0.24125  0.36236   24             0.000644            0.0    0          -18.804672 -36.929344 18.124672 0.0            -0.0   [1]\n",
       "Well...              0.43355            0.47720  0.15785   37             0.915782            0.0    1          -3.814358  -29.577160 25.762802 0.0            -0.0   [2]\n",
       "A..!                 0.44825            0.46250  0.17425   40             0.841634            0.0    1          -3.666783  -27.247244 23.580462 0.0            -0.0   [3]\n",
       "A.;;                 0.57770            0.33305  0.09286   40             0.773183            0.0    0          -9.092116  -24.071657 14.979541 0.0            -0.0   [4]\n",
       "It...                0.47830            0.43245  0.22360   39             0.680387            0.0    1          -2.475851  -30.842594 28.366743 0.0            -0.0   [5]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Paraphrase\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>epoch</th>\n",
       "      <th>orig_l</th>\n",
       "      <th>pp_l</th>\n",
       "      <th>orig_truelabel_probs</th>\n",
       "      <th>pp_truelabel_probs</th>\n",
       "      <th>pp_predclass_probs</th>\n",
       "      <th>orig_label</th>\n",
       "      <th>pp_predclass</th>\n",
       "      <th>label_flip</th>\n",
       "      <th>vm_score</th>\n",
       "      <th>sts_score</th>\n",
       "      <th>pp_letter_diff</th>\n",
       "      <th>pp_letter_percent</th>\n",
       "      <th>contradiction_score</th>\n",
       "      <th>reward</th>\n",
       "      <th>pp_logp</th>\n",
       "      <th>ref_logp</th>\n",
       "      <th>kl_div</th>\n",
       "      <th>reward_with_kl</th>\n",
       "      <th>loss</th>\n",
       "      <th>batch_num</th>\n",
       "      <th>global_step</th>\n",
       "      <th>acc_num</th>\n",
       "      <th>loss_sum</th>\n",
       "      <th>loss_batch</th>\n",
       "      <th>label_flip_fraction</th>\n",
       "      <th>orig_length</th>\n",
       "      <th>orig_batch_size</th>\n",
       "      <th>pp_length</th>\n",
       "      <th>pp_batch_size</th>\n",
       "      <th>time_generate_pp</th>\n",
       "      <th>time_loss_fn</th>\n",
       "      <th>time_reward_fn</th>\n",
       "      <th>time_vm_scores</th>\n",
       "      <th>time_sts_scores</th>\n",
       "      <th>time_pp_letter_diff</th>\n",
       "      <th>time_contradiction_scores</th>\n",
       "      <th>time_pp_logp</th>\n",
       "      <th>time_log_entropy</th>\n",
       "      <th>time_log_token_probabilities</th>\n",
       "      <th>time_ref_logprobs</th>\n",
       "      <th>time_loss_fn_loss_calc</th>\n",
       "      <th>time_backwards</th>\n",
       "      <th>time_calc_gradient_norm</th>\n",
       "      <th>time_opt_step_and_calc_param_norm</th>\n",
       "      <th>time_opt_step</th>\n",
       "      <th>idx_n_unique_pp</th>\n",
       "      <th>idx_n_pp_changes</th>\n",
       "      <th>epoch_of_first_label_flip</th>\n",
       "      <th>n_words_orig</th>\n",
       "      <th>n_sentences_orig</th>\n",
       "      <th>n_punctuation_orig</th>\n",
       "      <th>n_digits_orig</th>\n",
       "      <th>n_letters_orig</th>\n",
       "      <th>n_words_pp</th>\n",
       "      <th>n_sentences_pp</th>\n",
       "      <th>n_punctuation_pp</th>\n",
       "      <th>n_digits_pp</th>\n",
       "      <th>n_letters_pp</th>\n",
       "      <th>n_words_diff</th>\n",
       "      <th>n_sentences_diff</th>\n",
       "      <th>n_punctuation_diff</th>\n",
       "      <th>n_digits_diff</th>\n",
       "      <th>n_letters_diff</th>\n",
       "      <th>removals_idx</th>\n",
       "      <th>removals</th>\n",
       "      <th>insertions_idx</th>\n",
       "      <th>insertions</th>\n",
       "      <th>unchanged_idx</th>\n",
       "      <th>unchanged</th>\n",
       "      <th>n_segments_inserted</th>\n",
       "      <th>n_segments_removed</th>\n",
       "      <th>n_tokens_inserted</th>\n",
       "      <th>n_tokens_removed</th>\n",
       "      <th>is_truncation</th>\n",
       "      <th>any_phrase_capitalised</th>\n",
       "      <th>any_phrase_decapitalised</th>\n",
       "      <th>edit_distance_token_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23790</th>\n",
       "      <td>5448</td>\n",
       "      <td>1</td>\n",
       "      <td>a well-acted movie that simply doesn't gel .</td>\n",
       "      <td>\"This doesn't jive\".</td>\n",
       "      <td>0.910749</td>\n",
       "      <td>0.6695</td>\n",
       "      <td>0.669497</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.24125</td>\n",
       "      <td>0.36236</td>\n",
       "      <td>24</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.000644204</td>\n",
       "      <td>0</td>\n",
       "      <td>-18.8047</td>\n",
       "      <td>-36.9293</td>\n",
       "      <td>18.1247</td>\n",
       "      <td>0</td>\n",
       "      <td>-0</td>\n",
       "      <td>820</td>\n",
       "      <td>820</td>\n",
       "      <td>0</td>\n",
       "      <td>-26.9383</td>\n",
       "      <td>-1.68365</td>\n",
       "      <td>0.25</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>0.167556</td>\n",
       "      <td>0.353789</td>\n",
       "      <td>0.0474573</td>\n",
       "      <td>0.00676021</td>\n",
       "      <td>0.0247938</td>\n",
       "      <td>7.93519e-05</td>\n",
       "      <td>0.0150937</td>\n",
       "      <td>0.00916996</td>\n",
       "      <td>0.00216033</td>\n",
       "      <td>0.00427702</td>\n",
       "      <td>0.296785</td>\n",
       "      <td>0.000228575</td>\n",
       "      <td>0.24584</td>\n",
       "      <td>0.0456078</td>\n",
       "      <td>3.01078e-05</td>\n",
       "      <td>2.25799e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>[2, 3, 4, 5, 6, 7, 8, 11]</td>\n",
       "      <td>[a well- acted movie that simply, gel]</td>\n",
       "      <td>[0, 1, 12, 13]</td>\n",
       "      <td>[\" This, jive\"]</td>\n",
       "      <td>[9, 10, 14]</td>\n",
       "      <td>[does n't, .]</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        idx epoch                                        orig_l  \\\n",
       "23790  5448     1  a well-acted movie that simply doesn't gel .   \n",
       "\n",
       "                       pp_l orig_truelabel_probs pp_truelabel_probs  \\\n",
       "23790  \"This doesn't jive\".             0.910749             0.6695   \n",
       "\n",
       "      pp_predclass_probs orig_label pp_predclass label_flip vm_score  \\\n",
       "23790           0.669497          0            0          0  0.24125   \n",
       "\n",
       "      sts_score pp_letter_diff pp_letter_percent contradiction_score reward  \\\n",
       "23790   0.36236             24          0.454545         0.000644204      0   \n",
       "\n",
       "       pp_logp ref_logp   kl_div reward_with_kl loss batch_num global_step  \\\n",
       "23790 -18.8047 -36.9293  18.1247              0   -0       820         820   \n",
       "\n",
       "      acc_num loss_sum loss_batch label_flip_fraction orig_length  \\\n",
       "23790       0 -26.9383   -1.68365                0.25          16   \n",
       "\n",
       "      orig_batch_size pp_length pp_batch_size time_generate_pp time_loss_fn  \\\n",
       "23790               8        11             8         0.167556     0.353789   \n",
       "\n",
       "      time_reward_fn time_vm_scores time_sts_scores time_pp_letter_diff  \\\n",
       "23790      0.0474573     0.00676021       0.0247938         7.93519e-05   \n",
       "\n",
       "      time_contradiction_scores time_pp_logp time_log_entropy  \\\n",
       "23790                 0.0150937   0.00916996       0.00216033   \n",
       "\n",
       "      time_log_token_probabilities time_ref_logprobs time_loss_fn_loss_calc  \\\n",
       "23790                   0.00427702          0.296785            0.000228575   \n",
       "\n",
       "      time_backwards time_calc_gradient_norm  \\\n",
       "23790        0.24584               0.0456078   \n",
       "\n",
       "      time_opt_step_and_calc_param_norm time_opt_step idx_n_unique_pp  \\\n",
       "23790                       3.01078e-05   2.25799e-06               5   \n",
       "\n",
       "      idx_n_pp_changes epoch_of_first_label_flip n_words_orig  \\\n",
       "23790                4                         2            8   \n",
       "\n",
       "      n_sentences_orig n_punctuation_orig n_digits_orig n_letters_orig  \\\n",
       "23790                1                  3             0             34   \n",
       "\n",
       "      n_words_pp n_sentences_pp n_punctuation_pp n_digits_pp n_letters_pp  \\\n",
       "23790          4              1                4           0           14   \n",
       "\n",
       "      n_words_diff n_sentences_diff n_punctuation_diff n_digits_diff  \\\n",
       "23790            4                0                 -1             0   \n",
       "\n",
       "      n_letters_diff               removals_idx  \\\n",
       "23790             20  [2, 3, 4, 5, 6, 7, 8, 11]   \n",
       "\n",
       "                                     removals  insertions_idx  \\\n",
       "23790  [a well- acted movie that simply, gel]  [0, 1, 12, 13]   \n",
       "\n",
       "            insertions unchanged_idx      unchanged n_segments_inserted  \\\n",
       "23790  [\" This, jive\"]   [9, 10, 14]  [does n't, .]                   2   \n",
       "\n",
       "      n_segments_removed n_tokens_inserted n_tokens_removed is_truncation  \\\n",
       "23790                  2                 4                8         False   \n",
       "\n",
       "      any_phrase_capitalised any_phrase_decapitalised  \\\n",
       "23790                  False                    False   \n",
       "\n",
       "      edit_distance_token_level  \n",
       "23790                         9  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "###############\n",
      "\n",
      "idx_n_unique_pp 4 \n",
      "\n",
      "Original: at a time when we've learned the hard way just how complex international terrorism is , collateral damage paints an absurdly simplistic picture .\n",
      "Original label 0\n",
      "Unique paraphrases: 5\n",
      "How the paraphrases change:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pp_l</th>\n",
       "      <th>pp_truelabel_probs</th>\n",
       "      <th>vm_score</th>\n",
       "      <th>sts_score</th>\n",
       "      <th>pp_letter_diff</th>\n",
       "      <th>contradiction_score</th>\n",
       "      <th>reward</th>\n",
       "      <th>label_flip</th>\n",
       "      <th>pp_logp</th>\n",
       "      <th>ref_logp</th>\n",
       "      <th>kl_div</th>\n",
       "      <th>reward_with_kl</th>\n",
       "      <th>loss</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>The hard way is just how complex international terrorism is.</th>\n",
       "      <th>0.82378</th>\n",
       "      <th>-0.09055</th>\n",
       "      <th>0.74580</th>\n",
       "      <th>85</th>\n",
       "      <th>0.003083</th>\n",
       "      <th>0.0</th>\n",
       "      <th>0</th>\n",
       "      <th>-5.445161</th>\n",
       "      <th>-70.559006</th>\n",
       "      <th>65.113846</th>\n",
       "      <th>0.0</th>\n",
       "      <th>-0.0</th>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>At least in that.</th>\n",
       "      <th>0.40833</th>\n",
       "      <th>0.32490</th>\n",
       "      <th>0.25553</th>\n",
       "      <th>128</th>\n",
       "      <th>0.137088</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1</th>\n",
       "      <th>-8.032297</th>\n",
       "      <th>-36.564869</th>\n",
       "      <th>28.532572</th>\n",
       "      <th>0.0</th>\n",
       "      <th>-0.0</th>\n",
       "      <td>[2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>An is..</th>\n",
       "      <th>0.61837</th>\n",
       "      <th>0.11486</th>\n",
       "      <th>0.10058</th>\n",
       "      <th>138</th>\n",
       "      <th>0.518335</th>\n",
       "      <th>0.0</th>\n",
       "      <th>0</th>\n",
       "      <th>-5.902942</th>\n",
       "      <th>-21.763609</th>\n",
       "      <th>15.860666</th>\n",
       "      <th>0.0</th>\n",
       "      <th>-0.0</th>\n",
       "      <td>[3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>We've.</th>\n",
       "      <th>0.50482</th>\n",
       "      <th>0.22841</th>\n",
       "      <th>0.18324</th>\n",
       "      <th>139</th>\n",
       "      <th>0.152127</th>\n",
       "      <th>0.0</th>\n",
       "      <th>0</th>\n",
       "      <th>-5.834177</th>\n",
       "      <th>-16.815992</th>\n",
       "      <th>10.981815</th>\n",
       "      <th>0.0</th>\n",
       "      <th>-0.0</th>\n",
       "      <td>[4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The.. it.</th>\n",
       "      <th>0.49859</th>\n",
       "      <th>0.23463</th>\n",
       "      <th>0.12801</th>\n",
       "      <th>136</th>\n",
       "      <th>0.729655</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1</th>\n",
       "      <th>-8.961340</th>\n",
       "      <th>-31.685368</th>\n",
       "      <th>22.724028</th>\n",
       "      <th>0.0</th>\n",
       "      <th>-0.0</th>\n",
       "      <td>[5]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                           epoch\n",
       "pp_l                                                         pp_truelabel_probs vm_score sts_score pp_letter_diff contradiction_score reward label_flip pp_logp   ref_logp   kl_div    reward_with_kl loss      \n",
       "The hard way is just how complex international terrorism is. 0.82378            -0.09055 0.74580   85             0.003083            0.0    0          -5.445161 -70.559006 65.113846 0.0            -0.0   [1]\n",
       "At least in that.                                            0.40833             0.32490 0.25553   128            0.137088            0.0    1          -8.032297 -36.564869 28.532572 0.0            -0.0   [2]\n",
       "An is..                                                      0.61837             0.11486 0.10058   138            0.518335            0.0    0          -5.902942 -21.763609 15.860666 0.0            -0.0   [3]\n",
       "We've.                                                       0.50482             0.22841 0.18324   139            0.152127            0.0    0          -5.834177 -16.815992 10.981815 0.0            -0.0   [4]\n",
       "The.. it.                                                    0.49859             0.23463 0.12801   136            0.729655            0.0    1          -8.961340 -31.685368 22.724028 0.0            -0.0   [5]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Paraphrase\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>epoch</th>\n",
       "      <th>orig_l</th>\n",
       "      <th>pp_l</th>\n",
       "      <th>orig_truelabel_probs</th>\n",
       "      <th>pp_truelabel_probs</th>\n",
       "      <th>pp_predclass_probs</th>\n",
       "      <th>orig_label</th>\n",
       "      <th>pp_predclass</th>\n",
       "      <th>label_flip</th>\n",
       "      <th>vm_score</th>\n",
       "      <th>sts_score</th>\n",
       "      <th>pp_letter_diff</th>\n",
       "      <th>pp_letter_percent</th>\n",
       "      <th>contradiction_score</th>\n",
       "      <th>reward</th>\n",
       "      <th>pp_logp</th>\n",
       "      <th>ref_logp</th>\n",
       "      <th>kl_div</th>\n",
       "      <th>reward_with_kl</th>\n",
       "      <th>loss</th>\n",
       "      <th>batch_num</th>\n",
       "      <th>global_step</th>\n",
       "      <th>acc_num</th>\n",
       "      <th>loss_sum</th>\n",
       "      <th>loss_batch</th>\n",
       "      <th>label_flip_fraction</th>\n",
       "      <th>orig_length</th>\n",
       "      <th>orig_batch_size</th>\n",
       "      <th>pp_length</th>\n",
       "      <th>pp_batch_size</th>\n",
       "      <th>time_generate_pp</th>\n",
       "      <th>time_loss_fn</th>\n",
       "      <th>time_reward_fn</th>\n",
       "      <th>time_vm_scores</th>\n",
       "      <th>time_sts_scores</th>\n",
       "      <th>time_pp_letter_diff</th>\n",
       "      <th>time_contradiction_scores</th>\n",
       "      <th>time_pp_logp</th>\n",
       "      <th>time_log_entropy</th>\n",
       "      <th>time_log_token_probabilities</th>\n",
       "      <th>time_ref_logprobs</th>\n",
       "      <th>time_loss_fn_loss_calc</th>\n",
       "      <th>time_backwards</th>\n",
       "      <th>time_calc_gradient_norm</th>\n",
       "      <th>time_opt_step_and_calc_param_norm</th>\n",
       "      <th>time_opt_step</th>\n",
       "      <th>idx_n_unique_pp</th>\n",
       "      <th>idx_n_pp_changes</th>\n",
       "      <th>epoch_of_first_label_flip</th>\n",
       "      <th>n_words_orig</th>\n",
       "      <th>n_sentences_orig</th>\n",
       "      <th>n_punctuation_orig</th>\n",
       "      <th>n_digits_orig</th>\n",
       "      <th>n_letters_orig</th>\n",
       "      <th>n_words_pp</th>\n",
       "      <th>n_sentences_pp</th>\n",
       "      <th>n_punctuation_pp</th>\n",
       "      <th>n_digits_pp</th>\n",
       "      <th>n_letters_pp</th>\n",
       "      <th>n_words_diff</th>\n",
       "      <th>n_sentences_diff</th>\n",
       "      <th>n_punctuation_diff</th>\n",
       "      <th>n_digits_diff</th>\n",
       "      <th>n_letters_diff</th>\n",
       "      <th>removals_idx</th>\n",
       "      <th>removals</th>\n",
       "      <th>insertions_idx</th>\n",
       "      <th>insertions</th>\n",
       "      <th>unchanged_idx</th>\n",
       "      <th>unchanged</th>\n",
       "      <th>n_segments_inserted</th>\n",
       "      <th>n_segments_removed</th>\n",
       "      <th>n_tokens_inserted</th>\n",
       "      <th>n_tokens_removed</th>\n",
       "      <th>is_truncation</th>\n",
       "      <th>any_phrase_capitalised</th>\n",
       "      <th>any_phrase_decapitalised</th>\n",
       "      <th>edit_distance_token_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23780</th>\n",
       "      <td>5446</td>\n",
       "      <td>1</td>\n",
       "      <td>at a time when we've learned the hard way just how complex international terrorism is , collateral damage paints an absurdly simplistic picture .</td>\n",
       "      <td>The hard way is just how complex international terrorism is.</td>\n",
       "      <td>0.733228</td>\n",
       "      <td>0.82378</td>\n",
       "      <td>0.823777</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.09055</td>\n",
       "      <td>0.7458</td>\n",
       "      <td>85</td>\n",
       "      <td>0.413793</td>\n",
       "      <td>0.00308329</td>\n",
       "      <td>0</td>\n",
       "      <td>-5.44516</td>\n",
       "      <td>-70.559</td>\n",
       "      <td>65.1138</td>\n",
       "      <td>0</td>\n",
       "      <td>-0</td>\n",
       "      <td>399</td>\n",
       "      <td>399</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>0.311529</td>\n",
       "      <td>0.694823</td>\n",
       "      <td>0.0504628</td>\n",
       "      <td>0.00742058</td>\n",
       "      <td>0.0263752</td>\n",
       "      <td>8.67383e-05</td>\n",
       "      <td>0.0157414</td>\n",
       "      <td>0.0128652</td>\n",
       "      <td>0.0034883</td>\n",
       "      <td>0.00544851</td>\n",
       "      <td>0.631113</td>\n",
       "      <td>0.0002285</td>\n",
       "      <td>0.45505</td>\n",
       "      <td>0.0569872</td>\n",
       "      <td>0.170046</td>\n",
       "      <td>0.104557</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>119</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 18, 19, 20, 21, 22, 23, 24, 25]</td>\n",
       "      <td>[at a time when we 've learned the, , collateral damage paints an absurdly simplistic picture]</td>\n",
       "      <td>[0, 11]</td>\n",
       "      <td>[The, is]</td>\n",
       "      <td>[9, 10, 12, 13, 14, 15, 16, 17, 26]</td>\n",
       "      <td>[hard way, just how complex international terrorism is, .]</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        idx epoch  \\\n",
       "23780  5446     1   \n",
       "\n",
       "                                                                                                                                                  orig_l  \\\n",
       "23780  at a time when we've learned the hard way just how complex international terrorism is , collateral damage paints an absurdly simplistic picture .   \n",
       "\n",
       "                                                               pp_l  \\\n",
       "23780  The hard way is just how complex international terrorism is.   \n",
       "\n",
       "      orig_truelabel_probs pp_truelabel_probs pp_predclass_probs orig_label  \\\n",
       "23780             0.733228            0.82378           0.823777          0   \n",
       "\n",
       "      pp_predclass label_flip vm_score sts_score pp_letter_diff  \\\n",
       "23780            0          0 -0.09055    0.7458             85   \n",
       "\n",
       "      pp_letter_percent contradiction_score reward  pp_logp ref_logp   kl_div  \\\n",
       "23780          0.413793          0.00308329      0 -5.44516  -70.559  65.1138   \n",
       "\n",
       "      reward_with_kl loss batch_num global_step acc_num loss_sum loss_batch  \\\n",
       "23780              0   -0       399         399       1        0          0   \n",
       "\n",
       "      label_flip_fraction orig_length orig_batch_size pp_length pp_batch_size  \\\n",
       "23780               0.125          32               8        20             8   \n",
       "\n",
       "      time_generate_pp time_loss_fn time_reward_fn time_vm_scores  \\\n",
       "23780         0.311529     0.694823      0.0504628     0.00742058   \n",
       "\n",
       "      time_sts_scores time_pp_letter_diff time_contradiction_scores  \\\n",
       "23780       0.0263752         8.67383e-05                 0.0157414   \n",
       "\n",
       "      time_pp_logp time_log_entropy time_log_token_probabilities  \\\n",
       "23780    0.0128652        0.0034883                   0.00544851   \n",
       "\n",
       "      time_ref_logprobs time_loss_fn_loss_calc time_backwards  \\\n",
       "23780          0.631113              0.0002285        0.45505   \n",
       "\n",
       "      time_calc_gradient_norm time_opt_step_and_calc_param_norm time_opt_step  \\\n",
       "23780               0.0569872                          0.170046      0.104557   \n",
       "\n",
       "      idx_n_unique_pp idx_n_pp_changes epoch_of_first_label_flip n_words_orig  \\\n",
       "23780               5                4                         2           23   \n",
       "\n",
       "      n_sentences_orig n_punctuation_orig n_digits_orig n_letters_orig  \\\n",
       "23780                1                  3             0            119   \n",
       "\n",
       "      n_words_pp n_sentences_pp n_punctuation_pp n_digits_pp n_letters_pp  \\\n",
       "23780         10              1                1           0           50   \n",
       "\n",
       "      n_words_diff n_sentences_diff n_punctuation_diff n_digits_diff  \\\n",
       "23780           13                0                  2             0   \n",
       "\n",
       "      n_letters_diff  \\\n",
       "23780             69   \n",
       "\n",
       "                                                   removals_idx  \\\n",
       "23780  [1, 2, 3, 4, 5, 6, 7, 8, 18, 19, 20, 21, 22, 23, 24, 25]   \n",
       "\n",
       "                                                                                             removals  \\\n",
       "23780  [at a time when we 've learned the, , collateral damage paints an absurdly simplistic picture]   \n",
       "\n",
       "      insertions_idx insertions                        unchanged_idx  \\\n",
       "23780        [0, 11]  [The, is]  [9, 10, 12, 13, 14, 15, 16, 17, 26]   \n",
       "\n",
       "                                                        unchanged  \\\n",
       "23780  [hard way, just how complex international terrorism is, .]   \n",
       "\n",
       "      n_segments_inserted n_segments_removed n_tokens_inserted  \\\n",
       "23780                   2                  2                 2   \n",
       "\n",
       "      n_tokens_removed is_truncation any_phrase_capitalised  \\\n",
       "23780               16         False                  False   \n",
       "\n",
       "      any_phrase_decapitalised edit_distance_token_level  \n",
       "23780                    False                        17  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "###############\n",
      "\n",
      "high_contradiction 0 \n",
      "\n",
      "Original: one of the greatest films i've ever seen .\n",
      "Original label 1\n",
      "Unique paraphrases: 5\n",
      "How the paraphrases change:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pp_l</th>\n",
       "      <th>pp_truelabel_probs</th>\n",
       "      <th>vm_score</th>\n",
       "      <th>sts_score</th>\n",
       "      <th>pp_letter_diff</th>\n",
       "      <th>contradiction_score</th>\n",
       "      <th>reward</th>\n",
       "      <th>label_flip</th>\n",
       "      <th>pp_logp</th>\n",
       "      <th>ref_logp</th>\n",
       "      <th>kl_div</th>\n",
       "      <th>reward_with_kl</th>\n",
       "      <th>loss</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>The film is awful.</th>\n",
       "      <th>0.08051</th>\n",
       "      <th>0.85161</th>\n",
       "      <th>0.38028</th>\n",
       "      <th>24</th>\n",
       "      <th>0.999642</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1</th>\n",
       "      <th>-10.057673</th>\n",
       "      <th>-27.383030</th>\n",
       "      <th>17.325357</th>\n",
       "      <th>0.0</th>\n",
       "      <th>-0.0</th>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>One..!</th>\n",
       "      <th>0.44422</th>\n",
       "      <th>0.48790</th>\n",
       "      <th>0.16162</th>\n",
       "      <th>36</th>\n",
       "      <th>0.498136</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1</th>\n",
       "      <th>-4.654774</th>\n",
       "      <th>-28.740562</th>\n",
       "      <th>24.085789</th>\n",
       "      <th>0.0</th>\n",
       "      <th>-0.0</th>\n",
       "      <td>[2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I have..</th>\n",
       "      <th>0.55150</th>\n",
       "      <th>0.38062</th>\n",
       "      <th>0.09901</th>\n",
       "      <th>34</th>\n",
       "      <th>0.027450</th>\n",
       "      <th>0.0</th>\n",
       "      <th>0</th>\n",
       "      <th>-1.861452</th>\n",
       "      <th>-20.056181</th>\n",
       "      <th>18.194729</th>\n",
       "      <th>0.0</th>\n",
       "      <th>-0.0</th>\n",
       "      <td>[3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it's.</th>\n",
       "      <th>0.39474</th>\n",
       "      <th>0.53738</th>\n",
       "      <th>0.18799</th>\n",
       "      <th>37</th>\n",
       "      <th>0.024327</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1</th>\n",
       "      <th>-6.256389</th>\n",
       "      <th>-23.312683</th>\n",
       "      <th>17.056293</th>\n",
       "      <th>0.0</th>\n",
       "      <th>-0.0</th>\n",
       "      <td>[4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I...</th>\n",
       "      <th>0.33060</th>\n",
       "      <th>0.60151</th>\n",
       "      <th>0.11148</th>\n",
       "      <th>38</th>\n",
       "      <th>0.122625</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1</th>\n",
       "      <th>-0.741391</th>\n",
       "      <th>-25.086140</th>\n",
       "      <th>24.344749</th>\n",
       "      <th>0.0</th>\n",
       "      <th>-0.0</th>\n",
       "      <td>[5]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                  epoch\n",
       "pp_l               pp_truelabel_probs vm_score sts_score pp_letter_diff contradiction_score reward label_flip pp_logp    ref_logp   kl_div    reward_with_kl loss      \n",
       "The film is awful. 0.08051            0.85161  0.38028   24             0.999642            0.0    1          -10.057673 -27.383030 17.325357 0.0            -0.0   [1]\n",
       "One..!             0.44422            0.48790  0.16162   36             0.498136            0.0    1          -4.654774  -28.740562 24.085789 0.0            -0.0   [2]\n",
       "I have..           0.55150            0.38062  0.09901   34             0.027450            0.0    0          -1.861452  -20.056181 18.194729 0.0            -0.0   [3]\n",
       "it's.              0.39474            0.53738  0.18799   37             0.024327            0.0    1          -6.256389  -23.312683 17.056293 0.0            -0.0   [4]\n",
       "I...               0.33060            0.60151  0.11148   38             0.122625            0.0    1          -0.741391  -25.086140 24.344749 0.0            -0.0   [5]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Paraphrase\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>epoch</th>\n",
       "      <th>orig_l</th>\n",
       "      <th>pp_l</th>\n",
       "      <th>orig_truelabel_probs</th>\n",
       "      <th>pp_truelabel_probs</th>\n",
       "      <th>pp_predclass_probs</th>\n",
       "      <th>orig_label</th>\n",
       "      <th>pp_predclass</th>\n",
       "      <th>label_flip</th>\n",
       "      <th>vm_score</th>\n",
       "      <th>sts_score</th>\n",
       "      <th>pp_letter_diff</th>\n",
       "      <th>pp_letter_percent</th>\n",
       "      <th>contradiction_score</th>\n",
       "      <th>reward</th>\n",
       "      <th>pp_logp</th>\n",
       "      <th>ref_logp</th>\n",
       "      <th>kl_div</th>\n",
       "      <th>reward_with_kl</th>\n",
       "      <th>loss</th>\n",
       "      <th>batch_num</th>\n",
       "      <th>global_step</th>\n",
       "      <th>acc_num</th>\n",
       "      <th>loss_sum</th>\n",
       "      <th>loss_batch</th>\n",
       "      <th>label_flip_fraction</th>\n",
       "      <th>orig_length</th>\n",
       "      <th>orig_batch_size</th>\n",
       "      <th>pp_length</th>\n",
       "      <th>pp_batch_size</th>\n",
       "      <th>time_generate_pp</th>\n",
       "      <th>time_loss_fn</th>\n",
       "      <th>time_reward_fn</th>\n",
       "      <th>time_vm_scores</th>\n",
       "      <th>time_sts_scores</th>\n",
       "      <th>time_pp_letter_diff</th>\n",
       "      <th>time_contradiction_scores</th>\n",
       "      <th>time_pp_logp</th>\n",
       "      <th>time_log_entropy</th>\n",
       "      <th>time_log_token_probabilities</th>\n",
       "      <th>time_ref_logprobs</th>\n",
       "      <th>time_loss_fn_loss_calc</th>\n",
       "      <th>time_backwards</th>\n",
       "      <th>time_calc_gradient_norm</th>\n",
       "      <th>time_opt_step_and_calc_param_norm</th>\n",
       "      <th>time_opt_step</th>\n",
       "      <th>idx_n_unique_pp</th>\n",
       "      <th>idx_n_pp_changes</th>\n",
       "      <th>epoch_of_first_label_flip</th>\n",
       "      <th>n_words_orig</th>\n",
       "      <th>n_sentences_orig</th>\n",
       "      <th>n_punctuation_orig</th>\n",
       "      <th>n_digits_orig</th>\n",
       "      <th>n_letters_orig</th>\n",
       "      <th>n_words_pp</th>\n",
       "      <th>n_sentences_pp</th>\n",
       "      <th>n_punctuation_pp</th>\n",
       "      <th>n_digits_pp</th>\n",
       "      <th>n_letters_pp</th>\n",
       "      <th>n_words_diff</th>\n",
       "      <th>n_sentences_diff</th>\n",
       "      <th>n_punctuation_diff</th>\n",
       "      <th>n_digits_diff</th>\n",
       "      <th>n_letters_diff</th>\n",
       "      <th>removals_idx</th>\n",
       "      <th>removals</th>\n",
       "      <th>insertions_idx</th>\n",
       "      <th>insertions</th>\n",
       "      <th>unchanged_idx</th>\n",
       "      <th>unchanged</th>\n",
       "      <th>n_segments_inserted</th>\n",
       "      <th>n_segments_removed</th>\n",
       "      <th>n_tokens_inserted</th>\n",
       "      <th>n_tokens_removed</th>\n",
       "      <th>is_truncation</th>\n",
       "      <th>any_phrase_capitalised</th>\n",
       "      <th>any_phrase_decapitalised</th>\n",
       "      <th>edit_distance_token_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13475</th>\n",
       "      <td>3086</td>\n",
       "      <td>1</td>\n",
       "      <td>one of the greatest films i've ever seen .</td>\n",
       "      <td>The film is awful.</td>\n",
       "      <td>0.932119</td>\n",
       "      <td>0.08051</td>\n",
       "      <td>0.919489</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.85161</td>\n",
       "      <td>0.38028</td>\n",
       "      <td>24</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.999642</td>\n",
       "      <td>0</td>\n",
       "      <td>-10.0577</td>\n",
       "      <td>-27.383</td>\n",
       "      <td>17.3254</td>\n",
       "      <td>0</td>\n",
       "      <td>-0</td>\n",
       "      <td>832</td>\n",
       "      <td>832</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>60</td>\n",
       "      <td>8</td>\n",
       "      <td>0.948455</td>\n",
       "      <td>2.12989</td>\n",
       "      <td>0.0528397</td>\n",
       "      <td>0.00703873</td>\n",
       "      <td>0.0261085</td>\n",
       "      <td>8.13114e-05</td>\n",
       "      <td>0.0149936</td>\n",
       "      <td>0.0287996</td>\n",
       "      <td>0.00838578</td>\n",
       "      <td>0.0089133</td>\n",
       "      <td>2.04783</td>\n",
       "      <td>0.000227676</td>\n",
       "      <td>1.40866</td>\n",
       "      <td>0.0458958</td>\n",
       "      <td>3.73633e-05</td>\n",
       "      <td>2.28127e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>[1, 2, 3, 4, 5, 10, 11, 12, 13]</td>\n",
       "      <td>[one of the greatest films, i 've ever seen]</td>\n",
       "      <td>[0, 7, 8, 9]</td>\n",
       "      <td>[The, film is awful]</td>\n",
       "      <td>[14]</td>\n",
       "      <td>[.]</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        idx epoch                                      orig_l  \\\n",
       "13475  3086     1  one of the greatest films i've ever seen .   \n",
       "\n",
       "                     pp_l orig_truelabel_probs pp_truelabel_probs  \\\n",
       "13475  The film is awful.             0.932119            0.08051   \n",
       "\n",
       "      pp_predclass_probs orig_label pp_predclass label_flip vm_score  \\\n",
       "13475           0.919489          1            0          1  0.85161   \n",
       "\n",
       "      sts_score pp_letter_diff pp_letter_percent contradiction_score reward  \\\n",
       "13475   0.38028             24          0.428571            0.999642      0   \n",
       "\n",
       "       pp_logp ref_logp   kl_div reward_with_kl loss batch_num global_step  \\\n",
       "13475 -10.0577  -27.383  17.3254              0   -0       832         832   \n",
       "\n",
       "      acc_num loss_sum loss_batch label_flip_fraction orig_length  \\\n",
       "13475       0        0          0               0.125          16   \n",
       "\n",
       "      orig_batch_size pp_length pp_batch_size time_generate_pp time_loss_fn  \\\n",
       "13475               8        60             8         0.948455      2.12989   \n",
       "\n",
       "      time_reward_fn time_vm_scores time_sts_scores time_pp_letter_diff  \\\n",
       "13475      0.0528397     0.00703873       0.0261085         8.13114e-05   \n",
       "\n",
       "      time_contradiction_scores time_pp_logp time_log_entropy  \\\n",
       "13475                 0.0149936    0.0287996       0.00838578   \n",
       "\n",
       "      time_log_token_probabilities time_ref_logprobs time_loss_fn_loss_calc  \\\n",
       "13475                    0.0089133           2.04783            0.000227676   \n",
       "\n",
       "      time_backwards time_calc_gradient_norm  \\\n",
       "13475        1.40866               0.0458958   \n",
       "\n",
       "      time_opt_step_and_calc_param_norm time_opt_step idx_n_unique_pp  \\\n",
       "13475                       3.73633e-05   2.28127e-06               5   \n",
       "\n",
       "      idx_n_pp_changes epoch_of_first_label_flip n_words_orig  \\\n",
       "13475                4                         1            9   \n",
       "\n",
       "      n_sentences_orig n_punctuation_orig n_digits_orig n_letters_orig  \\\n",
       "13475                1                  2             0             32   \n",
       "\n",
       "      n_words_pp n_sentences_pp n_punctuation_pp n_digits_pp n_letters_pp  \\\n",
       "13475          4              1                1           0           14   \n",
       "\n",
       "      n_words_diff n_sentences_diff n_punctuation_diff n_digits_diff  \\\n",
       "13475            5                0                  1             0   \n",
       "\n",
       "      n_letters_diff                     removals_idx  \\\n",
       "13475             18  [1, 2, 3, 4, 5, 10, 11, 12, 13]   \n",
       "\n",
       "                                           removals insertions_idx  \\\n",
       "13475  [one of the greatest films, i 've ever seen]   [0, 7, 8, 9]   \n",
       "\n",
       "                 insertions unchanged_idx unchanged n_segments_inserted  \\\n",
       "13475  [The, film is awful]          [14]       [.]                   2   \n",
       "\n",
       "      n_segments_removed n_tokens_inserted n_tokens_removed is_truncation  \\\n",
       "13475                  2                 4                9         False   \n",
       "\n",
       "      any_phrase_capitalised any_phrase_decapitalised  \\\n",
       "13475                  False                    False   \n",
       "\n",
       "      edit_distance_token_level  \n",
       "13475                         9  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "###############\n",
      "\n",
      "high_contradiction 1 \n",
      "\n",
      "Original: hugely entertaining from start to finish , featuring a fall from grace that still leaves shockwaves , it will gratify anyone who has ever suspected hollywood of being overrun by corrupt and hedonistic weasels .\n",
      "Original label 1\n",
      "Unique paraphrases: 5\n",
      "How the paraphrases change:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pp_l</th>\n",
       "      <th>pp_truelabel_probs</th>\n",
       "      <th>vm_score</th>\n",
       "      <th>sts_score</th>\n",
       "      <th>pp_letter_diff</th>\n",
       "      <th>contradiction_score</th>\n",
       "      <th>reward</th>\n",
       "      <th>label_flip</th>\n",
       "      <th>pp_logp</th>\n",
       "      <th>ref_logp</th>\n",
       "      <th>kl_div</th>\n",
       "      <th>reward_with_kl</th>\n",
       "      <th>loss</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>It should satisfy anybody that has ever believed that Hollywood is overrun by corrupted and deviant populations.</th>\n",
       "      <th>0.44217</th>\n",
       "      <th>0.51110</th>\n",
       "      <th>0.72459</th>\n",
       "      <th>98</th>\n",
       "      <th>0.000276</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1</th>\n",
       "      <th>-40.516647</th>\n",
       "      <th>-113.033897</th>\n",
       "      <th>72.517250</th>\n",
       "      <th>0.0</th>\n",
       "      <th>-0.0</th>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>It will give.</th>\n",
       "      <th>0.80531</th>\n",
       "      <th>0.14796</th>\n",
       "      <th>0.16696</th>\n",
       "      <th>197</th>\n",
       "      <th>0.044451</th>\n",
       "      <th>0.0</th>\n",
       "      <th>0</th>\n",
       "      <th>-6.769799</th>\n",
       "      <th>-34.981071</th>\n",
       "      <th>28.211273</th>\n",
       "      <th>0.0</th>\n",
       "      <th>-0.0</th>\n",
       "      <td>[2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it will make anyone happy.</th>\n",
       "      <th>0.88321</th>\n",
       "      <th>0.07006</th>\n",
       "      <th>0.28453</th>\n",
       "      <th>184</th>\n",
       "      <th>0.001153</th>\n",
       "      <th>0.0</th>\n",
       "      <th>0</th>\n",
       "      <th>-6.453514</th>\n",
       "      <th>-45.610367</th>\n",
       "      <th>39.156853</th>\n",
       "      <th>0.0</th>\n",
       "      <th>-0.0</th>\n",
       "      <td>[3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Its boring. I.</th>\n",
       "      <th>0.06747</th>\n",
       "      <th>0.88580</th>\n",
       "      <th>0.04745</th>\n",
       "      <th>196</th>\n",
       "      <th>0.999617</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1</th>\n",
       "      <th>-14.089851</th>\n",
       "      <th>-42.551170</th>\n",
       "      <th>28.461319</th>\n",
       "      <th>0.0</th>\n",
       "      <th>-0.0</th>\n",
       "      <td>[4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>It will..</th>\n",
       "      <th>0.74581</th>\n",
       "      <th>0.20746</th>\n",
       "      <th>0.19410</th>\n",
       "      <th>201</th>\n",
       "      <th>0.003546</th>\n",
       "      <th>0.0</th>\n",
       "      <th>0</th>\n",
       "      <th>-1.074885</th>\n",
       "      <th>-18.977867</th>\n",
       "      <th>17.902981</th>\n",
       "      <th>0.0</th>\n",
       "      <th>-0.0</th>\n",
       "      <td>[5]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                 epoch\n",
       "pp_l                                                                                                             pp_truelabel_probs vm_score sts_score pp_letter_diff contradiction_score reward label_flip pp_logp    ref_logp    kl_div    reward_with_kl loss      \n",
       "It should satisfy anybody that has ever believed that Hollywood is overrun by corrupted and deviant populations. 0.44217            0.51110  0.72459   98             0.000276            0.0    1          -40.516647 -113.033897 72.517250 0.0            -0.0   [1]\n",
       "It will give.                                                                                                    0.80531            0.14796  0.16696   197            0.044451            0.0    0          -6.769799  -34.981071  28.211273 0.0            -0.0   [2]\n",
       "it will make anyone happy.                                                                                       0.88321            0.07006  0.28453   184            0.001153            0.0    0          -6.453514  -45.610367  39.156853 0.0            -0.0   [3]\n",
       "Its boring. I.                                                                                                   0.06747            0.88580  0.04745   196            0.999617            0.0    1          -14.089851 -42.551170  28.461319 0.0            -0.0   [4]\n",
       "It will..                                                                                                        0.74581            0.20746  0.19410   201            0.003546            0.0    0          -1.074885  -18.977867  17.902981 0.0            -0.0   [5]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Paraphrase\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>epoch</th>\n",
       "      <th>orig_l</th>\n",
       "      <th>pp_l</th>\n",
       "      <th>orig_truelabel_probs</th>\n",
       "      <th>pp_truelabel_probs</th>\n",
       "      <th>pp_predclass_probs</th>\n",
       "      <th>orig_label</th>\n",
       "      <th>pp_predclass</th>\n",
       "      <th>label_flip</th>\n",
       "      <th>vm_score</th>\n",
       "      <th>sts_score</th>\n",
       "      <th>pp_letter_diff</th>\n",
       "      <th>pp_letter_percent</th>\n",
       "      <th>contradiction_score</th>\n",
       "      <th>reward</th>\n",
       "      <th>pp_logp</th>\n",
       "      <th>ref_logp</th>\n",
       "      <th>kl_div</th>\n",
       "      <th>reward_with_kl</th>\n",
       "      <th>loss</th>\n",
       "      <th>batch_num</th>\n",
       "      <th>global_step</th>\n",
       "      <th>acc_num</th>\n",
       "      <th>loss_sum</th>\n",
       "      <th>loss_batch</th>\n",
       "      <th>label_flip_fraction</th>\n",
       "      <th>orig_length</th>\n",
       "      <th>orig_batch_size</th>\n",
       "      <th>pp_length</th>\n",
       "      <th>pp_batch_size</th>\n",
       "      <th>time_generate_pp</th>\n",
       "      <th>time_loss_fn</th>\n",
       "      <th>time_reward_fn</th>\n",
       "      <th>time_vm_scores</th>\n",
       "      <th>time_sts_scores</th>\n",
       "      <th>time_pp_letter_diff</th>\n",
       "      <th>time_contradiction_scores</th>\n",
       "      <th>time_pp_logp</th>\n",
       "      <th>time_log_entropy</th>\n",
       "      <th>time_log_token_probabilities</th>\n",
       "      <th>time_ref_logprobs</th>\n",
       "      <th>time_loss_fn_loss_calc</th>\n",
       "      <th>time_backwards</th>\n",
       "      <th>time_calc_gradient_norm</th>\n",
       "      <th>time_opt_step_and_calc_param_norm</th>\n",
       "      <th>time_opt_step</th>\n",
       "      <th>idx_n_unique_pp</th>\n",
       "      <th>idx_n_pp_changes</th>\n",
       "      <th>epoch_of_first_label_flip</th>\n",
       "      <th>n_words_orig</th>\n",
       "      <th>n_sentences_orig</th>\n",
       "      <th>n_punctuation_orig</th>\n",
       "      <th>n_digits_orig</th>\n",
       "      <th>n_letters_orig</th>\n",
       "      <th>n_words_pp</th>\n",
       "      <th>n_sentences_pp</th>\n",
       "      <th>n_punctuation_pp</th>\n",
       "      <th>n_digits_pp</th>\n",
       "      <th>n_letters_pp</th>\n",
       "      <th>n_words_diff</th>\n",
       "      <th>n_sentences_diff</th>\n",
       "      <th>n_punctuation_diff</th>\n",
       "      <th>n_digits_diff</th>\n",
       "      <th>n_letters_diff</th>\n",
       "      <th>removals_idx</th>\n",
       "      <th>removals</th>\n",
       "      <th>insertions_idx</th>\n",
       "      <th>insertions</th>\n",
       "      <th>unchanged_idx</th>\n",
       "      <th>unchanged</th>\n",
       "      <th>n_segments_inserted</th>\n",
       "      <th>n_segments_removed</th>\n",
       "      <th>n_tokens_inserted</th>\n",
       "      <th>n_tokens_removed</th>\n",
       "      <th>is_truncation</th>\n",
       "      <th>any_phrase_capitalised</th>\n",
       "      <th>any_phrase_decapitalised</th>\n",
       "      <th>edit_distance_token_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15420</th>\n",
       "      <td>3547</td>\n",
       "      <td>1</td>\n",
       "      <td>hugely entertaining from start to finish , featuring a fall from grace that still leaves shockwaves , it will gratify anyone who has ever suspected hollywood of being overrun by corrupt and hedonistic weasels .</td>\n",
       "      <td>It should satisfy anybody that has ever believed that Hollywood is overrun by corrupted and deviant populations.</td>\n",
       "      <td>0.953267</td>\n",
       "      <td>0.44217</td>\n",
       "      <td>0.55783</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5111</td>\n",
       "      <td>0.72459</td>\n",
       "      <td>98</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.000276361</td>\n",
       "      <td>0</td>\n",
       "      <td>-40.5166</td>\n",
       "      <td>-113.034</td>\n",
       "      <td>72.5173</td>\n",
       "      <td>0</td>\n",
       "      <td>-0</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>48</td>\n",
       "      <td>8</td>\n",
       "      <td>37</td>\n",
       "      <td>8</td>\n",
       "      <td>0.601631</td>\n",
       "      <td>1.52922</td>\n",
       "      <td>0.0557779</td>\n",
       "      <td>0.00752785</td>\n",
       "      <td>0.0270139</td>\n",
       "      <td>7.54199e-05</td>\n",
       "      <td>0.0168661</td>\n",
       "      <td>0.0191377</td>\n",
       "      <td>0.00552928</td>\n",
       "      <td>0.00716831</td>\n",
       "      <td>1.4539</td>\n",
       "      <td>0.000243111</td>\n",
       "      <td>0.945828</td>\n",
       "      <td>0.0459254</td>\n",
       "      <td>2.88901e-05</td>\n",
       "      <td>2.08803e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>173</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "      <td>[4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 28, 31, 36, 37, 40, 44, 45]</td>\n",
       "      <td>[hugely entertaining from start to finish, featuring a fall from grace, still leaves shockwaves, it will gratify anyone who, suspected, hollywood, of being, corrupt, hedonistic weasels]</td>\n",
       "      <td>[0, 1, 2, 3, 29, 30, 33, 35, 41, 46, 47]</td>\n",
       "      <td>[It should satisfy anybody, believed that, Hollywood, is, corrupted, deviant populations]</td>\n",
       "      <td>[16, 26, 27, 38, 39, 43, 48]</td>\n",
       "      <td>[that, has ever, overrun by, and, .]</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>28</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        idx epoch  \\\n",
       "15420  3547     1   \n",
       "\n",
       "                                                                                                                                                                                                                   orig_l  \\\n",
       "15420  hugely entertaining from start to finish , featuring a fall from grace that still leaves shockwaves , it will gratify anyone who has ever suspected hollywood of being overrun by corrupt and hedonistic weasels .   \n",
       "\n",
       "                                                                                                                   pp_l  \\\n",
       "15420  It should satisfy anybody that has ever believed that Hollywood is overrun by corrupted and deviant populations.   \n",
       "\n",
       "      orig_truelabel_probs pp_truelabel_probs pp_predclass_probs orig_label  \\\n",
       "15420             0.953267            0.44217            0.55783          1   \n",
       "\n",
       "      pp_predclass label_flip vm_score sts_score pp_letter_diff  \\\n",
       "15420            0          1   0.5111   0.72459             98   \n",
       "\n",
       "      pp_letter_percent contradiction_score reward  pp_logp ref_logp   kl_div  \\\n",
       "15420          0.533333         0.000276361      0 -40.5166 -113.034  72.5173   \n",
       "\n",
       "      reward_with_kl loss batch_num global_step acc_num loss_sum loss_batch  \\\n",
       "15420              0   -0       100         100       0        0          0   \n",
       "\n",
       "      label_flip_fraction orig_length orig_batch_size pp_length pp_batch_size  \\\n",
       "15420                 0.5          48               8        37             8   \n",
       "\n",
       "      time_generate_pp time_loss_fn time_reward_fn time_vm_scores  \\\n",
       "15420         0.601631      1.52922      0.0557779     0.00752785   \n",
       "\n",
       "      time_sts_scores time_pp_letter_diff time_contradiction_scores  \\\n",
       "15420       0.0270139         7.54199e-05                 0.0168661   \n",
       "\n",
       "      time_pp_logp time_log_entropy time_log_token_probabilities  \\\n",
       "15420    0.0191377       0.00552928                   0.00716831   \n",
       "\n",
       "      time_ref_logprobs time_loss_fn_loss_calc time_backwards  \\\n",
       "15420            1.4539            0.000243111       0.945828   \n",
       "\n",
       "      time_calc_gradient_norm time_opt_step_and_calc_param_norm time_opt_step  \\\n",
       "15420               0.0459254                       2.88901e-05   2.08803e-06   \n",
       "\n",
       "      idx_n_unique_pp idx_n_pp_changes epoch_of_first_label_flip n_words_orig  \\\n",
       "15420               5                4                         1           32   \n",
       "\n",
       "      n_sentences_orig n_punctuation_orig n_digits_orig n_letters_orig  \\\n",
       "15420                1                  3             0            173   \n",
       "\n",
       "      n_words_pp n_sentences_pp n_punctuation_pp n_digits_pp n_letters_pp  \\\n",
       "15420         17              1                1           0           95   \n",
       "\n",
       "      n_words_diff n_sentences_diff n_punctuation_diff n_digits_diff  \\\n",
       "15420           15                0                  2             0   \n",
       "\n",
       "      n_letters_diff  \\\n",
       "15420             78   \n",
       "\n",
       "                                                                                                     removals_idx  \\\n",
       "15420  [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 28, 31, 36, 37, 40, 44, 45]   \n",
       "\n",
       "                                                                                                                                                                                        removals  \\\n",
       "15420  [hugely entertaining from start to finish, featuring a fall from grace, still leaves shockwaves, it will gratify anyone who, suspected, hollywood, of being, corrupt, hedonistic weasels]   \n",
       "\n",
       "                                 insertions_idx  \\\n",
       "15420  [0, 1, 2, 3, 29, 30, 33, 35, 41, 46, 47]   \n",
       "\n",
       "                                                                                      insertions  \\\n",
       "15420  [It should satisfy anybody, believed that, Hollywood, is, corrupted, deviant populations]   \n",
       "\n",
       "                      unchanged_idx                             unchanged  \\\n",
       "15420  [16, 26, 27, 38, 39, 43, 48]  [that, has ever, overrun by, and, .]   \n",
       "\n",
       "      n_segments_inserted n_segments_removed n_tokens_inserted  \\\n",
       "15420                   6                  7                11   \n",
       "\n",
       "      n_tokens_removed is_truncation any_phrase_capitalised  \\\n",
       "15420               28         False                   True   \n",
       "\n",
       "      any_phrase_decapitalised edit_distance_token_level  \n",
       "15420                    False                        28  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "###############\n",
      "\n",
      "high_contradiction 2 \n",
      "\n",
      "Original: awkward but sincere and , ultimately , it wins you over .\n",
      "Original label 1\n",
      "Unique paraphrases: 5\n",
      "How the paraphrases change:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pp_l</th>\n",
       "      <th>pp_truelabel_probs</th>\n",
       "      <th>vm_score</th>\n",
       "      <th>sts_score</th>\n",
       "      <th>pp_letter_diff</th>\n",
       "      <th>contradiction_score</th>\n",
       "      <th>reward</th>\n",
       "      <th>label_flip</th>\n",
       "      <th>pp_logp</th>\n",
       "      <th>ref_logp</th>\n",
       "      <th>kl_div</th>\n",
       "      <th>reward_with_kl</th>\n",
       "      <th>loss</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ultimately, it doesn't win!</th>\n",
       "      <th>0.09596</th>\n",
       "      <th>0.79562</th>\n",
       "      <th>0.36761</th>\n",
       "      <th>30</th>\n",
       "      <th>0.999594</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1</th>\n",
       "      <th>-13.697066</th>\n",
       "      <th>-33.533211</th>\n",
       "      <th>19.836143</th>\n",
       "      <th>0.0</th>\n",
       "      <th>-0.0</th>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>It.dhgate.</th>\n",
       "      <th>0.28216</th>\n",
       "      <th>0.60942</th>\n",
       "      <th>0.16849</th>\n",
       "      <th>47</th>\n",
       "      <th>0.245489</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1</th>\n",
       "      <th>-5.876832</th>\n",
       "      <th>-44.511898</th>\n",
       "      <th>38.635067</th>\n",
       "      <th>0.0</th>\n",
       "      <th>-0.0</th>\n",
       "      <td>[2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>It..,</th>\n",
       "      <th>0.46013</th>\n",
       "      <th>0.43145</th>\n",
       "      <th>0.32865</th>\n",
       "      <th>52</th>\n",
       "      <th>0.064430</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1</th>\n",
       "      <th>-5.388003</th>\n",
       "      <th>-28.507832</th>\n",
       "      <th>23.119827</th>\n",
       "      <th>0.0</th>\n",
       "      <th>-0.0</th>\n",
       "      <td>[3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>It.-.</th>\n",
       "      <th>0.51351</th>\n",
       "      <th>0.37806</th>\n",
       "      <th>0.35501</th>\n",
       "      <th>52</th>\n",
       "      <th>0.033905</th>\n",
       "      <th>0.0</th>\n",
       "      <th>0</th>\n",
       "      <th>-5.502182</th>\n",
       "      <th>-30.054920</th>\n",
       "      <th>24.552738</th>\n",
       "      <th>0.0</th>\n",
       "      <th>-0.0</th>\n",
       "      <td>[4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>That. in.</th>\n",
       "      <th>0.52892</th>\n",
       "      <th>0.36265</th>\n",
       "      <th>0.25333</th>\n",
       "      <th>48</th>\n",
       "      <th>0.030155</th>\n",
       "      <th>0.0</th>\n",
       "      <th>0</th>\n",
       "      <th>-11.048236</th>\n",
       "      <th>-35.595688</th>\n",
       "      <th>24.547451</th>\n",
       "      <th>0.0</th>\n",
       "      <th>-0.0</th>\n",
       "      <td>[5]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                           epoch\n",
       "pp_l                        pp_truelabel_probs vm_score sts_score pp_letter_diff contradiction_score reward label_flip pp_logp    ref_logp   kl_div    reward_with_kl loss      \n",
       "Ultimately, it doesn't win! 0.09596            0.79562  0.36761   30             0.999594            0.0    1          -13.697066 -33.533211 19.836143 0.0            -0.0   [1]\n",
       "It.dhgate.                  0.28216            0.60942  0.16849   47             0.245489            0.0    1          -5.876832  -44.511898 38.635067 0.0            -0.0   [2]\n",
       "It..,                       0.46013            0.43145  0.32865   52             0.064430            0.0    1          -5.388003  -28.507832 23.119827 0.0            -0.0   [3]\n",
       "It.-.                       0.51351            0.37806  0.35501   52             0.033905            0.0    0          -5.502182  -30.054920 24.552738 0.0            -0.0   [4]\n",
       "That. in.                   0.52892            0.36265  0.25333   48             0.030155            0.0    0          -11.048236 -35.595688 24.547451 0.0            -0.0   [5]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Paraphrase\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>epoch</th>\n",
       "      <th>orig_l</th>\n",
       "      <th>pp_l</th>\n",
       "      <th>orig_truelabel_probs</th>\n",
       "      <th>pp_truelabel_probs</th>\n",
       "      <th>pp_predclass_probs</th>\n",
       "      <th>orig_label</th>\n",
       "      <th>pp_predclass</th>\n",
       "      <th>label_flip</th>\n",
       "      <th>vm_score</th>\n",
       "      <th>sts_score</th>\n",
       "      <th>pp_letter_diff</th>\n",
       "      <th>pp_letter_percent</th>\n",
       "      <th>contradiction_score</th>\n",
       "      <th>reward</th>\n",
       "      <th>pp_logp</th>\n",
       "      <th>ref_logp</th>\n",
       "      <th>kl_div</th>\n",
       "      <th>reward_with_kl</th>\n",
       "      <th>loss</th>\n",
       "      <th>batch_num</th>\n",
       "      <th>global_step</th>\n",
       "      <th>acc_num</th>\n",
       "      <th>loss_sum</th>\n",
       "      <th>loss_batch</th>\n",
       "      <th>label_flip_fraction</th>\n",
       "      <th>orig_length</th>\n",
       "      <th>orig_batch_size</th>\n",
       "      <th>pp_length</th>\n",
       "      <th>pp_batch_size</th>\n",
       "      <th>time_generate_pp</th>\n",
       "      <th>time_loss_fn</th>\n",
       "      <th>time_reward_fn</th>\n",
       "      <th>time_vm_scores</th>\n",
       "      <th>time_sts_scores</th>\n",
       "      <th>time_pp_letter_diff</th>\n",
       "      <th>time_contradiction_scores</th>\n",
       "      <th>time_pp_logp</th>\n",
       "      <th>time_log_entropy</th>\n",
       "      <th>time_log_token_probabilities</th>\n",
       "      <th>time_ref_logprobs</th>\n",
       "      <th>time_loss_fn_loss_calc</th>\n",
       "      <th>time_backwards</th>\n",
       "      <th>time_calc_gradient_norm</th>\n",
       "      <th>time_opt_step_and_calc_param_norm</th>\n",
       "      <th>time_opt_step</th>\n",
       "      <th>idx_n_unique_pp</th>\n",
       "      <th>idx_n_pp_changes</th>\n",
       "      <th>epoch_of_first_label_flip</th>\n",
       "      <th>n_words_orig</th>\n",
       "      <th>n_sentences_orig</th>\n",
       "      <th>n_punctuation_orig</th>\n",
       "      <th>n_digits_orig</th>\n",
       "      <th>n_letters_orig</th>\n",
       "      <th>n_words_pp</th>\n",
       "      <th>n_sentences_pp</th>\n",
       "      <th>n_punctuation_pp</th>\n",
       "      <th>n_digits_pp</th>\n",
       "      <th>n_letters_pp</th>\n",
       "      <th>n_words_diff</th>\n",
       "      <th>n_sentences_diff</th>\n",
       "      <th>n_punctuation_diff</th>\n",
       "      <th>n_digits_diff</th>\n",
       "      <th>n_letters_diff</th>\n",
       "      <th>removals_idx</th>\n",
       "      <th>removals</th>\n",
       "      <th>insertions_idx</th>\n",
       "      <th>insertions</th>\n",
       "      <th>unchanged_idx</th>\n",
       "      <th>unchanged</th>\n",
       "      <th>n_segments_inserted</th>\n",
       "      <th>n_segments_removed</th>\n",
       "      <th>n_tokens_inserted</th>\n",
       "      <th>n_tokens_removed</th>\n",
       "      <th>is_truncation</th>\n",
       "      <th>any_phrase_capitalised</th>\n",
       "      <th>any_phrase_decapitalised</th>\n",
       "      <th>edit_distance_token_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2875</th>\n",
       "      <td>651</td>\n",
       "      <td>1</td>\n",
       "      <td>awkward but sincere and , ultimately , it wins you over .</td>\n",
       "      <td>Ultimately, it doesn't win!</td>\n",
       "      <td>0.891576</td>\n",
       "      <td>0.09596</td>\n",
       "      <td>0.904044</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.79562</td>\n",
       "      <td>0.36761</td>\n",
       "      <td>30</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.999594</td>\n",
       "      <td>0</td>\n",
       "      <td>-13.6971</td>\n",
       "      <td>-33.5332</td>\n",
       "      <td>19.8361</td>\n",
       "      <td>0</td>\n",
       "      <td>-0</td>\n",
       "      <td>775</td>\n",
       "      <td>775</td>\n",
       "      <td>1</td>\n",
       "      <td>-17.1486</td>\n",
       "      <td>-1.07179</td>\n",
       "      <td>0.25</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>0.17877</td>\n",
       "      <td>0.36329</td>\n",
       "      <td>0.0541039</td>\n",
       "      <td>0.00707165</td>\n",
       "      <td>0.0306351</td>\n",
       "      <td>8.63178e-05</td>\n",
       "      <td>0.0155486</td>\n",
       "      <td>0.00943681</td>\n",
       "      <td>0.0022339</td>\n",
       "      <td>0.00445215</td>\n",
       "      <td>0.299372</td>\n",
       "      <td>0.000229013</td>\n",
       "      <td>0.242282</td>\n",
       "      <td>0.0465136</td>\n",
       "      <td>0.170198</td>\n",
       "      <td>0.104649</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 13, 17, 18, 19]</td>\n",
       "      <td>[awkward but sincere and, ultimately, wins, you over.]</td>\n",
       "      <td>[7, 11, 12, 15, 16]</td>\n",
       "      <td>[Ultimately, does n't, win!]</td>\n",
       "      <td>[9, 10]</td>\n",
       "      <td>[, it]</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      idx epoch                                                     orig_l  \\\n",
       "2875  651     1  awkward but sincere and , ultimately , it wins you over .   \n",
       "\n",
       "                             pp_l orig_truelabel_probs pp_truelabel_probs  \\\n",
       "2875  Ultimately, it doesn't win!             0.891576            0.09596   \n",
       "\n",
       "     pp_predclass_probs orig_label pp_predclass label_flip vm_score sts_score  \\\n",
       "2875           0.904044          1            0          1  0.79562   0.36761   \n",
       "\n",
       "     pp_letter_diff pp_letter_percent contradiction_score reward  pp_logp  \\\n",
       "2875             30          0.473684            0.999594      0 -13.6971   \n",
       "\n",
       "     ref_logp   kl_div reward_with_kl loss batch_num global_step acc_num  \\\n",
       "2875 -33.5332  19.8361              0   -0       775         775       1   \n",
       "\n",
       "     loss_sum loss_batch label_flip_fraction orig_length orig_batch_size  \\\n",
       "2875 -17.1486   -1.07179                0.25          16               8   \n",
       "\n",
       "     pp_length pp_batch_size time_generate_pp time_loss_fn time_reward_fn  \\\n",
       "2875        11             8          0.17877      0.36329      0.0541039   \n",
       "\n",
       "     time_vm_scores time_sts_scores time_pp_letter_diff  \\\n",
       "2875     0.00707165       0.0306351         8.63178e-05   \n",
       "\n",
       "     time_contradiction_scores time_pp_logp time_log_entropy  \\\n",
       "2875                 0.0155486   0.00943681        0.0022339   \n",
       "\n",
       "     time_log_token_probabilities time_ref_logprobs time_loss_fn_loss_calc  \\\n",
       "2875                   0.00445215          0.299372            0.000229013   \n",
       "\n",
       "     time_backwards time_calc_gradient_norm time_opt_step_and_calc_param_norm  \\\n",
       "2875       0.242282               0.0465136                          0.170198   \n",
       "\n",
       "     time_opt_step idx_n_unique_pp idx_n_pp_changes epoch_of_first_label_flip  \\\n",
       "2875      0.104649               5                4                         1   \n",
       "\n",
       "     n_words_orig n_sentences_orig n_punctuation_orig n_digits_orig  \\\n",
       "2875            9                1                  3             0   \n",
       "\n",
       "     n_letters_orig n_words_pp n_sentences_pp n_punctuation_pp n_digits_pp  \\\n",
       "2875             43          5              1                3           0   \n",
       "\n",
       "     n_letters_pp n_words_diff n_sentences_diff n_punctuation_diff  \\\n",
       "2875           21            4                0                  0   \n",
       "\n",
       "     n_digits_diff n_letters_diff                        removals_idx  \\\n",
       "2875             0             22  [0, 1, 2, 3, 4, 5, 13, 17, 18, 19]   \n",
       "\n",
       "                                                    removals  \\\n",
       "2875  [awkward but sincere and, ultimately, wins, you over.]   \n",
       "\n",
       "           insertions_idx                    insertions unchanged_idx  \\\n",
       "2875  [7, 11, 12, 15, 16]  [Ultimately, does n't, win!]       [9, 10]   \n",
       "\n",
       "     unchanged n_segments_inserted n_segments_removed n_tokens_inserted  \\\n",
       "2875    [, it]                   3                  3                 5   \n",
       "\n",
       "     n_tokens_removed is_truncation any_phrase_capitalised  \\\n",
       "2875               10          True                  False   \n",
       "\n",
       "     any_phrase_decapitalised edit_distance_token_level  \n",
       "2875                    False                        10  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "###############\n",
      "\n",
      "high_contradiction 3 \n",
      "\n",
      "Original: i hate the feeling of having been slimed in the name of high art .\n",
      "Original label 0\n",
      "Unique paraphrases: 5\n",
      "How the paraphrases change:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pp_l</th>\n",
       "      <th>pp_truelabel_probs</th>\n",
       "      <th>vm_score</th>\n",
       "      <th>sts_score</th>\n",
       "      <th>pp_letter_diff</th>\n",
       "      <th>contradiction_score</th>\n",
       "      <th>reward</th>\n",
       "      <th>label_flip</th>\n",
       "      <th>pp_logp</th>\n",
       "      <th>ref_logp</th>\n",
       "      <th>kl_div</th>\n",
       "      <th>reward_with_kl</th>\n",
       "      <th>loss</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>I didn' being slim</th>\n",
       "      <th>0.75067</th>\n",
       "      <th>0.11440</th>\n",
       "      <th>0.48204</th>\n",
       "      <th>48</th>\n",
       "      <th>0.963414</th>\n",
       "      <th>0.0</th>\n",
       "      <th>0</th>\n",
       "      <th>-8.749724</th>\n",
       "      <th>-39.481506</th>\n",
       "      <th>30.731781</th>\n",
       "      <th>0.0</th>\n",
       "      <th>-0.0</th>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I love..</th>\n",
       "      <th>0.17029</th>\n",
       "      <th>0.69478</th>\n",
       "      <th>0.13496</th>\n",
       "      <th>58</th>\n",
       "      <th>0.999592</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1</th>\n",
       "      <th>-6.341783</th>\n",
       "      <th>-25.769392</th>\n",
       "      <th>19.427608</th>\n",
       "      <th>0.0</th>\n",
       "      <th>-0.0</th>\n",
       "      <td>[2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I detest. bernstein.</th>\n",
       "      <th>0.73464</th>\n",
       "      <th>0.13043</th>\n",
       "      <th>0.34910</th>\n",
       "      <th>46</th>\n",
       "      <th>0.037325</th>\n",
       "      <th>0.0</th>\n",
       "      <th>0</th>\n",
       "      <th>-15.989642</th>\n",
       "      <th>-48.796467</th>\n",
       "      <th>32.806824</th>\n",
       "      <th>0.0</th>\n",
       "      <th>-0.0</th>\n",
       "      <td>[3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I do not.</th>\n",
       "      <th>0.82060</th>\n",
       "      <th>0.04447</th>\n",
       "      <th>0.11808</th>\n",
       "      <th>57</th>\n",
       "      <th>0.984228</th>\n",
       "      <th>0.0</th>\n",
       "      <th>0</th>\n",
       "      <th>-3.417122</th>\n",
       "      <th>-18.746132</th>\n",
       "      <th>15.329010</th>\n",
       "      <th>0.0</th>\n",
       "      <th>-0.0</th>\n",
       "      <td>[4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I feel..</th>\n",
       "      <th>0.48320</th>\n",
       "      <th>0.38187</th>\n",
       "      <th>0.25592</th>\n",
       "      <th>58</th>\n",
       "      <th>0.111997</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1</th>\n",
       "      <th>-5.264175</th>\n",
       "      <th>-27.981052</th>\n",
       "      <th>22.716877</th>\n",
       "      <th>0.0</th>\n",
       "      <th>-0.0</th>\n",
       "      <td>[5]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                    epoch\n",
       "pp_l                 pp_truelabel_probs vm_score sts_score pp_letter_diff contradiction_score reward label_flip pp_logp    ref_logp   kl_div    reward_with_kl loss      \n",
       "I didn' being slim   0.75067            0.11440  0.48204   48             0.963414            0.0    0          -8.749724  -39.481506 30.731781 0.0            -0.0   [1]\n",
       "I love..             0.17029            0.69478  0.13496   58             0.999592            0.0    1          -6.341783  -25.769392 19.427608 0.0            -0.0   [2]\n",
       "I detest. bernstein. 0.73464            0.13043  0.34910   46             0.037325            0.0    0          -15.989642 -48.796467 32.806824 0.0            -0.0   [3]\n",
       "I do not.            0.82060            0.04447  0.11808   57             0.984228            0.0    0          -3.417122  -18.746132 15.329010 0.0            -0.0   [4]\n",
       "I feel..             0.48320            0.38187  0.25592   58             0.111997            0.0    1          -5.264175  -27.981052 22.716877 0.0            -0.0   [5]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Paraphrase\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>epoch</th>\n",
       "      <th>orig_l</th>\n",
       "      <th>pp_l</th>\n",
       "      <th>orig_truelabel_probs</th>\n",
       "      <th>pp_truelabel_probs</th>\n",
       "      <th>pp_predclass_probs</th>\n",
       "      <th>orig_label</th>\n",
       "      <th>pp_predclass</th>\n",
       "      <th>label_flip</th>\n",
       "      <th>vm_score</th>\n",
       "      <th>sts_score</th>\n",
       "      <th>pp_letter_diff</th>\n",
       "      <th>pp_letter_percent</th>\n",
       "      <th>contradiction_score</th>\n",
       "      <th>reward</th>\n",
       "      <th>pp_logp</th>\n",
       "      <th>ref_logp</th>\n",
       "      <th>kl_div</th>\n",
       "      <th>reward_with_kl</th>\n",
       "      <th>loss</th>\n",
       "      <th>batch_num</th>\n",
       "      <th>global_step</th>\n",
       "      <th>acc_num</th>\n",
       "      <th>loss_sum</th>\n",
       "      <th>loss_batch</th>\n",
       "      <th>label_flip_fraction</th>\n",
       "      <th>orig_length</th>\n",
       "      <th>orig_batch_size</th>\n",
       "      <th>pp_length</th>\n",
       "      <th>pp_batch_size</th>\n",
       "      <th>time_generate_pp</th>\n",
       "      <th>time_loss_fn</th>\n",
       "      <th>time_reward_fn</th>\n",
       "      <th>time_vm_scores</th>\n",
       "      <th>time_sts_scores</th>\n",
       "      <th>time_pp_letter_diff</th>\n",
       "      <th>time_contradiction_scores</th>\n",
       "      <th>time_pp_logp</th>\n",
       "      <th>time_log_entropy</th>\n",
       "      <th>time_log_token_probabilities</th>\n",
       "      <th>time_ref_logprobs</th>\n",
       "      <th>time_loss_fn_loss_calc</th>\n",
       "      <th>time_backwards</th>\n",
       "      <th>time_calc_gradient_norm</th>\n",
       "      <th>time_opt_step_and_calc_param_norm</th>\n",
       "      <th>time_opt_step</th>\n",
       "      <th>idx_n_unique_pp</th>\n",
       "      <th>idx_n_pp_changes</th>\n",
       "      <th>epoch_of_first_label_flip</th>\n",
       "      <th>n_words_orig</th>\n",
       "      <th>n_sentences_orig</th>\n",
       "      <th>n_punctuation_orig</th>\n",
       "      <th>n_digits_orig</th>\n",
       "      <th>n_letters_orig</th>\n",
       "      <th>n_words_pp</th>\n",
       "      <th>n_sentences_pp</th>\n",
       "      <th>n_punctuation_pp</th>\n",
       "      <th>n_digits_pp</th>\n",
       "      <th>n_letters_pp</th>\n",
       "      <th>n_words_diff</th>\n",
       "      <th>n_sentences_diff</th>\n",
       "      <th>n_punctuation_diff</th>\n",
       "      <th>n_digits_diff</th>\n",
       "      <th>n_letters_diff</th>\n",
       "      <th>removals_idx</th>\n",
       "      <th>removals</th>\n",
       "      <th>insertions_idx</th>\n",
       "      <th>insertions</th>\n",
       "      <th>unchanged_idx</th>\n",
       "      <th>unchanged</th>\n",
       "      <th>n_segments_inserted</th>\n",
       "      <th>n_segments_removed</th>\n",
       "      <th>n_tokens_inserted</th>\n",
       "      <th>n_tokens_removed</th>\n",
       "      <th>is_truncation</th>\n",
       "      <th>any_phrase_capitalised</th>\n",
       "      <th>any_phrase_decapitalised</th>\n",
       "      <th>edit_distance_token_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32295</th>\n",
       "      <td>7404</td>\n",
       "      <td>1</td>\n",
       "      <td>i hate the feeling of having been slimed in the name of high art .</td>\n",
       "      <td>I didn' being slim</td>\n",
       "      <td>0.865071</td>\n",
       "      <td>0.75067</td>\n",
       "      <td>0.750669</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1144</td>\n",
       "      <td>0.48204</td>\n",
       "      <td>48</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.963414</td>\n",
       "      <td>0</td>\n",
       "      <td>-8.74972</td>\n",
       "      <td>-39.4815</td>\n",
       "      <td>30.7318</td>\n",
       "      <td>0</td>\n",
       "      <td>-0</td>\n",
       "      <td>716</td>\n",
       "      <td>716</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.58405</td>\n",
       "      <td>-0.286503</td>\n",
       "      <td>0.125</td>\n",
       "      <td>24</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>0.207462</td>\n",
       "      <td>0.432661</td>\n",
       "      <td>0.0491012</td>\n",
       "      <td>0.00726504</td>\n",
       "      <td>0.0254721</td>\n",
       "      <td>8.4104e-05</td>\n",
       "      <td>0.0155804</td>\n",
       "      <td>0.0118924</td>\n",
       "      <td>0.00245932</td>\n",
       "      <td>0.00640699</td>\n",
       "      <td>0.371267</td>\n",
       "      <td>0.00023691</td>\n",
       "      <td>0.296563</td>\n",
       "      <td>0.0475441</td>\n",
       "      <td>3.18349e-05</td>\n",
       "      <td>2.25939e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>[4, 5, 6, 7, 8, 9, 10, 11, 14, 15, 16, 17, 18, 19, 20]</td>\n",
       "      <td>[i hate the feeling of having been slimed, in the name of high art.]</td>\n",
       "      <td>[0, 1, 2, 3, 13]</td>\n",
       "      <td>[I didn' being, slim]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        idx epoch  \\\n",
       "32295  7404     1   \n",
       "\n",
       "                                                                   orig_l  \\\n",
       "32295  i hate the feeling of having been slimed in the name of high art .   \n",
       "\n",
       "                     pp_l orig_truelabel_probs pp_truelabel_probs  \\\n",
       "32295  I didn' being slim             0.865071            0.75067   \n",
       "\n",
       "      pp_predclass_probs orig_label pp_predclass label_flip vm_score  \\\n",
       "32295           0.750669          0            0          0   0.1144   \n",
       "\n",
       "      sts_score pp_letter_diff pp_letter_percent contradiction_score reward  \\\n",
       "32295   0.48204             48          0.272727            0.963414      0   \n",
       "\n",
       "       pp_logp ref_logp   kl_div reward_with_kl loss batch_num global_step  \\\n",
       "32295 -8.74972 -39.4815  30.7318              0   -0       716         716   \n",
       "\n",
       "      acc_num loss_sum loss_batch label_flip_fraction orig_length  \\\n",
       "32295       0 -4.58405  -0.286503               0.125          24   \n",
       "\n",
       "      orig_batch_size pp_length pp_batch_size time_generate_pp time_loss_fn  \\\n",
       "32295               8        13             8         0.207462     0.432661   \n",
       "\n",
       "      time_reward_fn time_vm_scores time_sts_scores time_pp_letter_diff  \\\n",
       "32295      0.0491012     0.00726504       0.0254721          8.4104e-05   \n",
       "\n",
       "      time_contradiction_scores time_pp_logp time_log_entropy  \\\n",
       "32295                 0.0155804    0.0118924       0.00245932   \n",
       "\n",
       "      time_log_token_probabilities time_ref_logprobs time_loss_fn_loss_calc  \\\n",
       "32295                   0.00640699          0.371267             0.00023691   \n",
       "\n",
       "      time_backwards time_calc_gradient_norm  \\\n",
       "32295       0.296563               0.0475441   \n",
       "\n",
       "      time_opt_step_and_calc_param_norm time_opt_step idx_n_unique_pp  \\\n",
       "32295                       3.18349e-05   2.25939e-06               5   \n",
       "\n",
       "      idx_n_pp_changes epoch_of_first_label_flip n_words_orig  \\\n",
       "32295                4                         2           14   \n",
       "\n",
       "      n_sentences_orig n_punctuation_orig n_digits_orig n_letters_orig  \\\n",
       "32295                1                  1             0             51   \n",
       "\n",
       "      n_words_pp n_sentences_pp n_punctuation_pp n_digits_pp n_letters_pp  \\\n",
       "32295          4              1                1           0           14   \n",
       "\n",
       "      n_words_diff n_sentences_diff n_punctuation_diff n_digits_diff  \\\n",
       "32295           10                0                  0             0   \n",
       "\n",
       "      n_letters_diff                                            removals_idx  \\\n",
       "32295             37  [4, 5, 6, 7, 8, 9, 10, 11, 14, 15, 16, 17, 18, 19, 20]   \n",
       "\n",
       "                                                                   removals  \\\n",
       "32295  [i hate the feeling of having been slimed, in the name of high art.]   \n",
       "\n",
       "         insertions_idx             insertions unchanged_idx unchanged  \\\n",
       "32295  [0, 1, 2, 3, 13]  [I didn' being, slim]            []        []   \n",
       "\n",
       "      n_segments_inserted n_segments_removed n_tokens_inserted  \\\n",
       "32295                   2                  2                 5   \n",
       "\n",
       "      n_tokens_removed is_truncation any_phrase_capitalised  \\\n",
       "32295               15         False                  False   \n",
       "\n",
       "      any_phrase_decapitalised edit_distance_token_level  \n",
       "32295                    False                        15  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "###############\n",
      "\n",
      "high_contradiction 4 \n",
      "\n",
      "Original: beneath clouds is a succinct low-budget film whose compelling characters and intelligent script are exactly what was missing from rabbit-proof fence .\n",
      "Original label 1\n",
      "Unique paraphrases: 5\n",
      "How the paraphrases change:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pp_l</th>\n",
       "      <th>pp_truelabel_probs</th>\n",
       "      <th>vm_score</th>\n",
       "      <th>sts_score</th>\n",
       "      <th>pp_letter_diff</th>\n",
       "      <th>contradiction_score</th>\n",
       "      <th>reward</th>\n",
       "      <th>label_flip</th>\n",
       "      <th>pp_logp</th>\n",
       "      <th>ref_logp</th>\n",
       "      <th>kl_div</th>\n",
       "      <th>reward_with_kl</th>\n",
       "      <th>loss</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>The film's briefness and lack of depth make it very well suited for small screening halls.</th>\n",
       "      <th>0.13357</th>\n",
       "      <th>0.78590</th>\n",
       "      <th>0.59095</th>\n",
       "      <th>60</th>\n",
       "      <th>0.029497</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1</th>\n",
       "      <th>-41.578568</th>\n",
       "      <th>-97.544090</th>\n",
       "      <th>55.965523</th>\n",
       "      <th>0.0</th>\n",
       "      <th>-0.0</th>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the was..</th>\n",
       "      <th>0.35307</th>\n",
       "      <th>0.56640</th>\n",
       "      <th>0.18755</th>\n",
       "      <th>141</th>\n",
       "      <th>0.594505</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1</th>\n",
       "      <th>-7.506480</th>\n",
       "      <th>-30.012928</th>\n",
       "      <th>22.506447</th>\n",
       "      <th>0.0</th>\n",
       "      <th>-0.0</th>\n",
       "      <td>[2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>It's a dull and boring.</th>\n",
       "      <th>0.06185</th>\n",
       "      <th>0.85762</th>\n",
       "      <th>0.18666</th>\n",
       "      <th>127</th>\n",
       "      <th>0.999587</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1</th>\n",
       "      <th>-13.716248</th>\n",
       "      <th>-35.283470</th>\n",
       "      <th>21.567223</th>\n",
       "      <th>0.0</th>\n",
       "      <th>-0.0</th>\n",
       "      <td>[3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>., at one, also,!</th>\n",
       "      <th>0.54277</th>\n",
       "      <th>0.37670</th>\n",
       "      <th>0.16717</th>\n",
       "      <th>133</th>\n",
       "      <th>0.046067</th>\n",
       "      <th>0.0</th>\n",
       "      <th>0</th>\n",
       "      <th>-19.467342</th>\n",
       "      <th>-44.574295</th>\n",
       "      <th>25.106953</th>\n",
       "      <th>0.0</th>\n",
       "      <th>-0.0</th>\n",
       "      <td>[4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The.. A.</th>\n",
       "      <th>0.59156</th>\n",
       "      <th>0.32791</th>\n",
       "      <th>0.18827</th>\n",
       "      <th>142</th>\n",
       "      <th>0.836482</th>\n",
       "      <th>0.0</th>\n",
       "      <th>0</th>\n",
       "      <th>-5.484054</th>\n",
       "      <th>-24.918808</th>\n",
       "      <th>19.434753</th>\n",
       "      <th>0.0</th>\n",
       "      <th>-0.0</th>\n",
       "      <td>[5]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                          epoch\n",
       "pp_l                                                                                       pp_truelabel_probs vm_score sts_score pp_letter_diff contradiction_score reward label_flip pp_logp    ref_logp   kl_div    reward_with_kl loss      \n",
       "The film's briefness and lack of depth make it very well suited for small screening halls. 0.13357            0.78590  0.59095   60             0.029497            0.0    1          -41.578568 -97.544090 55.965523 0.0            -0.0   [1]\n",
       "the was..                                                                                  0.35307            0.56640  0.18755   141            0.594505            0.0    1          -7.506480  -30.012928 22.506447 0.0            -0.0   [2]\n",
       "It's a dull and boring.                                                                    0.06185            0.85762  0.18666   127            0.999587            0.0    1          -13.716248 -35.283470 21.567223 0.0            -0.0   [3]\n",
       "., at one, also,!                                                                          0.54277            0.37670  0.16717   133            0.046067            0.0    0          -19.467342 -44.574295 25.106953 0.0            -0.0   [4]\n",
       "The.. A.                                                                                   0.59156            0.32791  0.18827   142            0.836482            0.0    0          -5.484054  -24.918808 19.434753 0.0            -0.0   [5]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Paraphrase\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>epoch</th>\n",
       "      <th>orig_l</th>\n",
       "      <th>pp_l</th>\n",
       "      <th>orig_truelabel_probs</th>\n",
       "      <th>pp_truelabel_probs</th>\n",
       "      <th>pp_predclass_probs</th>\n",
       "      <th>orig_label</th>\n",
       "      <th>pp_predclass</th>\n",
       "      <th>label_flip</th>\n",
       "      <th>vm_score</th>\n",
       "      <th>sts_score</th>\n",
       "      <th>pp_letter_diff</th>\n",
       "      <th>pp_letter_percent</th>\n",
       "      <th>contradiction_score</th>\n",
       "      <th>reward</th>\n",
       "      <th>pp_logp</th>\n",
       "      <th>ref_logp</th>\n",
       "      <th>kl_div</th>\n",
       "      <th>reward_with_kl</th>\n",
       "      <th>loss</th>\n",
       "      <th>batch_num</th>\n",
       "      <th>global_step</th>\n",
       "      <th>acc_num</th>\n",
       "      <th>loss_sum</th>\n",
       "      <th>loss_batch</th>\n",
       "      <th>label_flip_fraction</th>\n",
       "      <th>orig_length</th>\n",
       "      <th>orig_batch_size</th>\n",
       "      <th>pp_length</th>\n",
       "      <th>pp_batch_size</th>\n",
       "      <th>time_generate_pp</th>\n",
       "      <th>time_loss_fn</th>\n",
       "      <th>time_reward_fn</th>\n",
       "      <th>time_vm_scores</th>\n",
       "      <th>time_sts_scores</th>\n",
       "      <th>time_pp_letter_diff</th>\n",
       "      <th>time_contradiction_scores</th>\n",
       "      <th>time_pp_logp</th>\n",
       "      <th>time_log_entropy</th>\n",
       "      <th>time_log_token_probabilities</th>\n",
       "      <th>time_ref_logprobs</th>\n",
       "      <th>time_loss_fn_loss_calc</th>\n",
       "      <th>time_backwards</th>\n",
       "      <th>time_calc_gradient_norm</th>\n",
       "      <th>time_opt_step_and_calc_param_norm</th>\n",
       "      <th>time_opt_step</th>\n",
       "      <th>idx_n_unique_pp</th>\n",
       "      <th>idx_n_pp_changes</th>\n",
       "      <th>epoch_of_first_label_flip</th>\n",
       "      <th>n_words_orig</th>\n",
       "      <th>n_sentences_orig</th>\n",
       "      <th>n_punctuation_orig</th>\n",
       "      <th>n_digits_orig</th>\n",
       "      <th>n_letters_orig</th>\n",
       "      <th>n_words_pp</th>\n",
       "      <th>n_sentences_pp</th>\n",
       "      <th>n_punctuation_pp</th>\n",
       "      <th>n_digits_pp</th>\n",
       "      <th>n_letters_pp</th>\n",
       "      <th>n_words_diff</th>\n",
       "      <th>n_sentences_diff</th>\n",
       "      <th>n_punctuation_diff</th>\n",
       "      <th>n_digits_diff</th>\n",
       "      <th>n_letters_diff</th>\n",
       "      <th>removals_idx</th>\n",
       "      <th>removals</th>\n",
       "      <th>insertions_idx</th>\n",
       "      <th>insertions</th>\n",
       "      <th>unchanged_idx</th>\n",
       "      <th>unchanged</th>\n",
       "      <th>n_segments_inserted</th>\n",
       "      <th>n_segments_removed</th>\n",
       "      <th>n_tokens_inserted</th>\n",
       "      <th>n_tokens_removed</th>\n",
       "      <th>is_truncation</th>\n",
       "      <th>any_phrase_capitalised</th>\n",
       "      <th>any_phrase_decapitalised</th>\n",
       "      <th>edit_distance_token_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5775</th>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "      <td>beneath clouds is a succinct low-budget film whose compelling characters and intelligent script are exactly what was missing from rabbit-proof fence .</td>\n",
       "      <td>The film's briefness and lack of depth make it very well suited for small screening halls.</td>\n",
       "      <td>0.919471</td>\n",
       "      <td>0.13357</td>\n",
       "      <td>0.866428</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7859</td>\n",
       "      <td>0.59095</td>\n",
       "      <td>60</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0294972</td>\n",
       "      <td>0</td>\n",
       "      <td>-41.5786</td>\n",
       "      <td>-97.5441</td>\n",
       "      <td>55.9655</td>\n",
       "      <td>0</td>\n",
       "      <td>-0</td>\n",
       "      <td>438</td>\n",
       "      <td>438</td>\n",
       "      <td>0</td>\n",
       "      <td>-45.9049</td>\n",
       "      <td>-2.86906</td>\n",
       "      <td>0.5</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>25</td>\n",
       "      <td>8</td>\n",
       "      <td>0.378253</td>\n",
       "      <td>0.852264</td>\n",
       "      <td>0.0509828</td>\n",
       "      <td>0.00753365</td>\n",
       "      <td>0.0267984</td>\n",
       "      <td>8.12029e-05</td>\n",
       "      <td>0.0158493</td>\n",
       "      <td>0.0145136</td>\n",
       "      <td>0.00398528</td>\n",
       "      <td>0.0056928</td>\n",
       "      <td>0.78633</td>\n",
       "      <td>0.000254625</td>\n",
       "      <td>0.579283</td>\n",
       "      <td>0.0517453</td>\n",
       "      <td>3.12449e-05</td>\n",
       "      <td>2.10106e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>126</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27]</td>\n",
       "      <td>[beneath clouds is a succinct low- budget, whose compelling characters, intelligent script are exactly what was missing from rabbit- proof fence]</td>\n",
       "      <td>[0, 10, 11, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39]</td>\n",
       "      <td>[The, 's briefness, lack of depth make it very well suited for small screening halls]</td>\n",
       "      <td>[9, 15, 40]</td>\n",
       "      <td>[film, and, .]</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>23</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       idx epoch  \\\n",
       "5775  1306     1   \n",
       "\n",
       "                                                                                                                                                      orig_l  \\\n",
       "5775  beneath clouds is a succinct low-budget film whose compelling characters and intelligent script are exactly what was missing from rabbit-proof fence .   \n",
       "\n",
       "                                                                                            pp_l  \\\n",
       "5775  The film's briefness and lack of depth make it very well suited for small screening halls.   \n",
       "\n",
       "     orig_truelabel_probs pp_truelabel_probs pp_predclass_probs orig_label  \\\n",
       "5775             0.919471            0.13357           0.866428          1   \n",
       "\n",
       "     pp_predclass label_flip vm_score sts_score pp_letter_diff  \\\n",
       "5775            0          1   0.7859   0.59095             60   \n",
       "\n",
       "     pp_letter_percent contradiction_score reward  pp_logp ref_logp   kl_div  \\\n",
       "5775               0.6           0.0294972      0 -41.5786 -97.5441  55.9655   \n",
       "\n",
       "     reward_with_kl loss batch_num global_step acc_num loss_sum loss_batch  \\\n",
       "5775              0   -0       438         438       0 -45.9049   -2.86906   \n",
       "\n",
       "     label_flip_fraction orig_length orig_batch_size pp_length pp_batch_size  \\\n",
       "5775                 0.5          32               8        25             8   \n",
       "\n",
       "     time_generate_pp time_loss_fn time_reward_fn time_vm_scores  \\\n",
       "5775         0.378253     0.852264      0.0509828     0.00753365   \n",
       "\n",
       "     time_sts_scores time_pp_letter_diff time_contradiction_scores  \\\n",
       "5775       0.0267984         8.12029e-05                 0.0158493   \n",
       "\n",
       "     time_pp_logp time_log_entropy time_log_token_probabilities  \\\n",
       "5775    0.0145136       0.00398528                    0.0056928   \n",
       "\n",
       "     time_ref_logprobs time_loss_fn_loss_calc time_backwards  \\\n",
       "5775           0.78633            0.000254625       0.579283   \n",
       "\n",
       "     time_calc_gradient_norm time_opt_step_and_calc_param_norm time_opt_step  \\\n",
       "5775               0.0517453                       3.12449e-05   2.10106e-06   \n",
       "\n",
       "     idx_n_unique_pp idx_n_pp_changes epoch_of_first_label_flip n_words_orig  \\\n",
       "5775               5                4                         1           21   \n",
       "\n",
       "     n_sentences_orig n_punctuation_orig n_digits_orig n_letters_orig  \\\n",
       "5775                1                  3             0            126   \n",
       "\n",
       "     n_words_pp n_sentences_pp n_punctuation_pp n_digits_pp n_letters_pp  \\\n",
       "5775         17              1                2           0           73   \n",
       "\n",
       "     n_words_diff n_sentences_diff n_punctuation_diff n_digits_diff  \\\n",
       "5775            4                0                  1             0   \n",
       "\n",
       "     n_letters_diff  \\\n",
       "5775             53   \n",
       "\n",
       "                                                                              removals_idx  \\\n",
       "5775  [1, 2, 3, 4, 5, 6, 7, 8, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27]   \n",
       "\n",
       "                                                                                                                                               removals  \\\n",
       "5775  [beneath clouds is a succinct low- budget, whose compelling characters, intelligent script are exactly what was missing from rabbit- proof fence]   \n",
       "\n",
       "                                                   insertions_idx  \\\n",
       "5775  [0, 10, 11, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39]   \n",
       "\n",
       "                                                                                 insertions  \\\n",
       "5775  [The, 's briefness, lack of depth make it very well suited for small screening halls]   \n",
       "\n",
       "     unchanged_idx       unchanged n_segments_inserted n_segments_removed  \\\n",
       "5775   [9, 15, 40]  [film, and, .]                   3                  3   \n",
       "\n",
       "     n_tokens_inserted n_tokens_removed is_truncation any_phrase_capitalised  \\\n",
       "5775                15               23         False                  False   \n",
       "\n",
       "     any_phrase_decapitalised edit_distance_token_level  \n",
       "5775                    False                        23  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "split = 'training_step'\n",
    "df_d = get_training_dfs(path_run, postprocessed=True)\n",
    "idx_d = get_interesting_idx(df_d[split], n=5)\n",
    "print_interesting_text_stats(df_d[split], n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at common removals and insertions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_common_removals_and_insertions(df_concat): \n",
    "    idx = df_concat[['data_split','orig_l', 'pp_l']].drop_duplicates().index\n",
    "    df_unique_pp = df_concat[['data_split','orig_l', 'pp_l','insertions', 'removals']].iloc[idx]\n",
    "    def flatten_list(l): return [item for sublist in l for item in sublist] \n",
    "    removals_flat   =  flatten_list(df_unique_pp['removals'].values)\n",
    "    insertions_flat =  flatten_list(df_unique_pp['insertions'].values)\n",
    "    return pd.value_counts(removals_flat), pd.value_counts(insertions_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat = _prepare_df_concat(df_d)\n",
    "removals, insertions = get_common_removals_and_insertions(df_concat)\n",
    "\n",
    "print(\"\\n#### REMOVALS ####\\n\")\n",
    "print(removals.head(30))\n",
    "print(\"\\n#### INSERTIONS ####\\n\")\n",
    "print(insertions.head(30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you can look at a specific phrase and examples of where it appears. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def investigate_phrase(phrase, cname, n ): \n",
    "    mask = [phrase in strs for strs in df_concat[cname]]\n",
    "    display_all(df_concat[mask].sample(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "investigate_phrase('despite', 'removals', 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
