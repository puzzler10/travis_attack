{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np \n",
    "from travis_attack.config import Config\n",
    "from travis_attack.insights import get_training_dfs, _prepare_df_concat\n",
    "from travis_attack.utils import display_all\n",
    "from IPython.core.debugger import set_trace\n",
    "import logging \n",
    "logger = logging.getLogger(\"run\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = Config()\n",
    "run_name = \"civilized-womprat-133\"\n",
    "path_run = f\"{cfg.path_checkpoints}{run_name}/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at some examples "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we just look at some examples to get a feel for what is going on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_interesting_idx(df, n):\n",
    "    def get_idx_with_top_column_values(cname, n=5, ascending=False):\n",
    "        return df[['idx',cname]].\\\n",
    "            drop_duplicates().\\\n",
    "            sort_values(cname, ascending=ascending)\\\n",
    "            ['idx'][0:n].values.tolist()\n",
    "    \n",
    "    def sample_idx_with_label_flips(n=5): \n",
    "        df1 = df[['idx','label_flip']].query(\"label_flip!=0\")\n",
    "        if len(df1) == 0 : print(\"No label flips detected\"); return None\n",
    "        else: return df1.drop_duplicates()['idx'].sample(n).values.tolist()\n",
    "    \n",
    "    idx_d = dict(\n",
    "        random = df.idx.drop_duplicates().sample(n).tolist(),\n",
    "        label_flips = sample_idx_with_label_flips(n=n),\n",
    "        idx_n_unique_pp  = get_idx_with_top_column_values('idx_n_unique_pp',n=n,ascending=False),\n",
    "       # idx_n_pp_changes = get_idx_with_top_column_values('idx_n_pp_changes',n=n,ascending=False),\n",
    "        high_contradiction = get_idx_with_top_column_values('contradiction_score',n=n,ascending=False)\n",
    "    )\n",
    "    return idx_d\n",
    "\n",
    "def print_stats(df, idx_d, key, i):\n",
    "    print(\"\\n###############\\n\")\n",
    "    print(key, i, \"\\n\")\n",
    "    if idx_d[key] is None: return\n",
    "    idx = idx_d[key][i]\n",
    "    # Setup \n",
    "    df1 = df.query('idx==@idx')\n",
    "    orig = pd.unique(df1['orig_l'])[0]\n",
    "    print(\"Original:\", orig)\n",
    "    print(\"Original label\", pd.unique(df1['orig_label'])[0] )\n",
    "    pp_all = list(df1['pp_l'])\n",
    "    #print(\"All paraphrases\", pp_all)\n",
    "    pp_unique = list(pd.unique(df1['pp_l']))\n",
    "    n_pp_unique = len(pp_unique)\n",
    "\n",
    "    # showing a \"timeline\" of how the paraphrases change over the epochs\n",
    "    g_fields = [\"pp_l\",\"pp_truelabel_probs\",\"vm_score\",\"sts_score\",\"pp_letter_diff\", \"contradiction_score\", \"reward\",\"label_flip\", 'pp_logp',\n",
    "       'ref_logp', 'kl_div', 'reward_penalty', 'loss']\n",
    "    #g_fields = [\"pp_l\",\"vm_score\"]\n",
    "    g = df1.groupby(g_fields).agg({'epoch' : lambda x: list(x)})\n",
    "    g = g.sort_values(by='epoch', key = lambda col: col.map(lambda x: np.min(x)))\n",
    "    print(\"Unique paraphrases:\", n_pp_unique)\n",
    "    print(\"How the paraphrases change:\")\n",
    "    display_all(g)\n",
    "\n",
    "    # Showing a dataframe of the few best paraphrases\n",
    "    best_pps = df1.sort_values('reward', ascending=False).iloc[0]\n",
    "    print(\"Best Paraphrase\")\n",
    "    display_all(best_pps.to_frame().T)\n",
    "        \n",
    "def print_interesting_text_stats(df, n): \n",
    "    idx_d = get_interesting_idx(df, n)\n",
    "    for key in idx_d.keys():\n",
    "        for i in range(n): \n",
    "            print_stats(df, idx_d, key,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "###############\n",
      "\n",
      "random 0 \n",
      "\n",
      "Original: a well-made thriller with a certain level of intelligence and non-reactionary morality .\n",
      "Original label 1\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'reward_penalty'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-6229384a4b91>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdf_d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_training_dfs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_run\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocessed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0midx_d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_interesting_idx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_d\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint_interesting_text_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_d\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-97494f9aa637>\u001b[0m in \u001b[0;36mprint_interesting_text_stats\u001b[0;34m(df, n)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0midx_d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0mprint_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx_d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-97494f9aa637>\u001b[0m in \u001b[0;36mprint_stats\u001b[0;34m(df, idx_d, key, i)\u001b[0m\n\u001b[1;32m     39\u001b[0m        'ref_logp', 'kl_div', 'reward_penalty', 'loss']\n\u001b[1;32m     40\u001b[0m     \u001b[0;31m#g_fields = [\"pp_l\",\"vm_score\"]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_fields\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'epoch'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'epoch'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unique paraphrases:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_pp_unique\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Programs/miniconda/envs/nlp_env/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mgroupby\u001b[0;34m(self, by, axis, level, as_index, sort, group_keys, squeeze, observed, dropna)\u001b[0m\n\u001b[1;32m   6502\u001b[0m         \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6504\u001b[0;31m         return DataFrameGroupBy(\n\u001b[0m\u001b[1;32m   6505\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6506\u001b[0m             \u001b[0mkeys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Programs/miniconda/envs/nlp_env/lib/python3.8/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, squeeze, observed, mutated, dropna)\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrouper\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_grouper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m             grouper, exclusions, obj = get_grouper(\n\u001b[0m\u001b[1;32m    526\u001b[0m                 \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m                 \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Programs/miniconda/envs/nlp_env/lib/python3.8/site-packages/pandas/core/groupby/grouper.py\u001b[0m in \u001b[0;36mget_grouper\u001b[0;34m(obj, key, axis, level, sort, observed, mutated, validate, dropna)\u001b[0m\n\u001b[1;32m    775\u001b[0m                 \u001b[0min_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGrouper\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mgpr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;31m# Add key to exclusions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'reward_penalty'"
     ]
    }
   ],
   "source": [
    "split = 'training_step'\n",
    "df_d = get_training_dfs(path_run, postprocessed=True)\n",
    "idx_d = get_interesting_idx(df_d[split], n=5)\n",
    "print_interesting_text_stats(df_d[split], n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at common removals and insertions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_common_removals_and_insertions(df_concat): \n",
    "    idx = df_concat[['data_split','orig_l', 'pp_l']].drop_duplicates().index\n",
    "    df_unique_pp = df_concat[['data_split','orig_l', 'pp_l','insertions', 'removals']].iloc[idx]\n",
    "    def flatten_list(l): return [item for sublist in l for item in sublist] \n",
    "    removals_flat   =  flatten_list(df_unique_pp['removals'].values)\n",
    "    insertions_flat =  flatten_list(df_unique_pp['insertions'].values)\n",
    "    return pd.value_counts(removals_flat), pd.value_counts(insertions_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#### REMOVALS ####\n",
      "\n",
      "not                   7\n",
      "this                  5\n",
      "love                  3\n",
      "film                  2\n",
      "movie                 2\n",
      "apple                 2\n",
      "like                  1\n",
      "hate                  1\n",
      "I do not like this    1\n",
      "this apple            1\n",
      "do                    1\n",
      "I do not like         1\n",
      "I love                1\n",
      "dtype: int64\n",
      "\n",
      "#### INSERTIONS ####\n",
      "\n",
      ".                                    21\n",
      "n't                                   7\n",
      "like                                  2\n",
      "that                                  2\n",
      "film.                                 2\n",
      "- I like it                           1\n",
      "thyme                                 1\n",
      "really                                1\n",
      "Not so much                           1\n",
      "'.                                    1\n",
      ":                                     1\n",
      "''.                                   1\n",
      "love                                  1\n",
      "ie                                    1\n",
      "cherry.                               1\n",
      "enjoy                                 1\n",
      "carrar.                               1\n",
      "savor                                 1\n",
      "the                                   1\n",
      "pie!                                  1\n",
      "!                                     1\n",
      "Love                                  1\n",
      "This                                  1\n",
      "movie.                                1\n",
      "in particular.                        1\n",
      "- the apple is really lovely.         1\n",
      "does n't suit me.                     1\n",
      "- very sweet and incredibly soft.     1\n",
      "movie                                 1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_concat = _prepare_df_concat(df_d)\n",
    "removals, insertions = get_common_removals_and_insertions(df_concat)\n",
    "\n",
    "print(\"\\n#### REMOVALS ####\\n\")\n",
    "print(removals.head(30))\n",
    "print(\"\\n#### INSERTIONS ####\\n\")\n",
    "print(insertions.head(30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you can look at a specific phrase and examples of where it appears. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def investigate_phrase(phrase, cname, n ): \n",
    "    mask = [phrase in strs for strs in df_concat[cname]]\n",
    "    display_all(df_concat[mask].sample(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "a must be greater than 0 unless no samples are taken",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-b1e23f110994>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minvestigate_phrase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'despite'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'removals'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-bcb8ea567d24>\u001b[0m in \u001b[0;36minvestigate_phrase\u001b[0;34m(phrase, cname, n)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minvestigate_phrase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphrase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mphrase\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstrs\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mstrs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf_concat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mdisplay_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_concat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Programs/miniconda/envs/nlp_env/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, n, frac, replace, weights, random_state, axis)\u001b[0m\n\u001b[1;32m   4982\u001b[0m             )\n\u001b[1;32m   4983\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4984\u001b[0;31m         \u001b[0mlocs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4985\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4986\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: a must be greater than 0 unless no samples are taken"
     ]
    }
   ],
   "source": [
    "investigate_phrase('despite', 'removals', 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
