{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- tackle classification as the victim system for now\n",
    "- use PEGASUS for paraphrase or, better, a comparable BART/PyTorch model as the Ex -> Ex' generator\n",
    "- fine tune it with a REINFORCE approach that uses a combination of various rewards such as:\n",
    "  - quality of Ex'\n",
    "  - loss (y,f(Ex'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup, load models + datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch \n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import load_dataset, load_metric\n",
    "import datasets, transformers\n",
    "from transformers import pipeline, AutoModelForSeq2SeqLM, AutoModelForSequenceClassification, AutoTokenizer\n",
    "from pprint import pprint\n",
    "import numpy as np, pandas as pd\n",
    "import scipy\n",
    "from utils import *   # local script \n",
    "import pyarrow\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from IPython.core.debugger import set_trace\n",
    "from GPUtil import showUtilization\n",
    "import seaborn as sns\n",
    "from itertools import repeat\n",
    "from collections import defaultdict\n",
    "from IPython.display import Markdown\n",
    "\n",
    "path_cache = './cache/'\n",
    "path_results = \"./results/\"\n",
    "\n",
    "seed = 420\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \n",
    "devicenum = torch.cuda.current_device() if device.type == 'cuda' else -1\n",
    "n_wkrs = 4 * torch.cuda.device_count()\n",
    "batch_size = 64\n",
    "pd.set_option(\"display.max_colwidth\", 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paraphrase model (para)\n",
    "para_name = \"tuner007/pegasus_paraphrase\"\n",
    "para_tokenizer = AutoTokenizer.from_pretrained(para_name)\n",
    "para_model = AutoModelForSeq2SeqLM.from_pretrained(para_name).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Victim Model (VM)\n",
    "vm_name = \"textattack/distilbert-base-uncased-rotten-tomatoes\"\n",
    "vm_tokenizer = AutoTokenizer.from_pretrained(vm_name)\n",
    "vm_model = AutoModelForSequenceClassification.from_pretrained(vm_name).to(device)\n",
    "vm_idx2lbl = vm_model.config.id2label\n",
    "vm_lbl2idx = vm_model.config.label2id\n",
    "vm_num_labels = vm_model.num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset rotten_tomatoes_movie_review (/data/tproth/.cache/huggingface/datasets/rotten_tomatoes_movie_review/default/1.0.0/9c411f7ecd9f3045389de0d9ce984061a1056507703d2e3183b1ac1a90816e4d)\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"rotten_tomatoes\")\n",
    "train,valid,test = dataset['train'],dataset['validation'],dataset['test']\n",
    "\n",
    "label_cname = 'label'\n",
    "## For snli\n",
    "# remove_minus1_labels = lambda x: x[label_cname] != -1\n",
    "# train = train.filter(remove_minus1_labels)\n",
    "# valid = valid.filter(remove_minus1_labels)\n",
    "# test = test.filter(remove_minus1_labels)\n",
    "\n",
    "# make sure that all datasets have the same number of labels as what the victim model predicts\n",
    "assert train.features[label_cname].num_classes == vm_num_labels\n",
    "assert valid.features[label_cname].num_classes == vm_num_labels\n",
    "assert test.features[ label_cname].num_classes == vm_num_labels\n",
    "\n",
    "train_dl = DataLoader(train, batch_size=batch_size, shuffle=True, num_workers=n_wkrs)\n",
    "valid_dl = DataLoader(valid, batch_size=batch_size, shuffle=True, num_workers=n_wkrs)\n",
    "test_dl = DataLoader( test,  batch_size=batch_size, shuffle=True, num_workers=n_wkrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Which set? Start with training set. \n",
    "* get paraphrases of each example x with label y\n",
    "    * how many? Start with 3\n",
    "    * with what diversity? Just go with default settings for now\n",
    "    * just pick the top three: we can pick better ones later\n",
    "* make a new dataset of the paraphrases p1,p2,p3 for each example x\n",
    "    * assumption is that they all have the same ground truth label y\n",
    "* put each paraphrase through victim model (vm) to get predictions f(p1), f(p2), f(p3)\n",
    "* make a function that calculates loss \n",
    "    * you will have to \"shape\" the reward from this function, which means you will have to try out a number of different things \n",
    "    * for now, try $ |f(p1) - y|^2 + |f(p2) - y|^2 + |f(p3) - y|^2 $ where $f(p1)$ is model confidence for class y. \n",
    "        * this is tricky because the reward isn't calculated over one datapoint any longer but rather a few of them. in addition you have two datasets: the original and the paraphrase. \n",
    "        * maybe the best is to compute the paraphrases inside the reward function. or compute them before but just store them, and then reference it in the reward function. \n",
    "    * later you can add various terms, e.g. BERTScore, or a term for fluency, or the semantic similarity component. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**\n",
    "* if speed improvement needed - work out how to batch the gen_dataset_paraphrases_simple fn (DONE)\n",
    "* merge functions togehter \n",
    "* fix caching\n",
    "* might have to bring generating paraphrases into the training loop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Precompute paraphrases for the training set and store them\n",
    "def get_paraphrases(input_text,num_return_sequences,num_beams, num_beam_groups=1,diversity_penalty=0):\n",
    "    batch = para_tokenizer(input_text,truncation=True,padding='longest', return_tensors=\"pt\").to(device)\n",
    "    translated = para_model.generate(**batch,num_beams=num_beams, num_return_sequences=num_return_sequences, \n",
    "                                   temperature=1.5, num_beam_groups=num_beam_groups, diversity_penalty=diversity_penalty)\n",
    "    tgt_text = para_tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
    "    return tgt_text\n",
    "\n",
    "# def gen_dataset_paraphrases(x, cname_input, cname_output, n_seed_seqs=32): \n",
    "#     \"\"\" x: one row of a dataset. \n",
    "#     cname_input: column to generate paraphrases for \n",
    "#     cname_output: column name to give output of paraphrases \n",
    "#     n_seed_seqs: rough indicator of how many paraphrases to return. \n",
    "#             For now, keep at 4,8,16,32,64 etc\"\"\"\n",
    "#     # TODO: figure out how to batch this. \n",
    "#     if n_seed_seqs % 4 != 0: raise ValueError(\"keep n_seed_seqs divisible by 4 for now\")\n",
    "#     n = n_seed_seqs/2\n",
    "#     #low diversity (ld) paraphrases \n",
    "#     ld_l = get_paraphrases(x[cname_input],num_return_sequences=int(n),\n",
    "#                             num_beams=int(n))\n",
    "#     #high diversity (hd) paraphrases. We can use num_beam_groups and diversity_penalty as hyperparameters. \n",
    "#     hd_l =  get_paraphrases(x[cname_input],num_return_sequences=int(n),\n",
    "#                             num_beams=int(n), num_beam_groups=int(n),diversity_penalty=50002.5)\n",
    "#     l = ld_l + hd_l \n",
    "#     x[cname_output] = l #TODO: change to list(set(l))             \n",
    "#     return x \n",
    "\n",
    "\n",
    "def create_paraphrase_dataset(batch, cname_input, cname_output, n_seed_seqs=32): \n",
    "    \"\"\"Create `n_seed_seq` paraphrases for each example in the batch. Then repeat the other fields \n",
    "        so that the resulting datase has the same length as the number of paraphrases. Key assumption is \n",
    "        that the same number of paraphrases is created for each example.\n",
    "    batch: a dict of examples used by the `map` function from the dataset\n",
    "    cname_input: What column to create paraphrases of \n",
    "    cname_output: What to call the column of paraphrases\n",
    "    n_seed_seqs: Number of paraphrases to generate. \"\"\"\n",
    "    \n",
    "    # Generate paraphrases. \n",
    "    # This can be later extended to add diversity or so on. \n",
    "    para_l = get_paraphrases(batch[cname_input], n_seed_seqs, n_seed_seqs)\n",
    "    \n",
    "    # To return paraphrases as a list of lists for batch input (not done here but might need later)\n",
    "    #     split_into_sublists = lambda l,n: [l[i:i + n] for i in range(0, len(l), n)]\n",
    "    #     para_l = split_into_sublists(para_l, n_seed_seqs)\n",
    "    batch[cname_output] = para_l \n",
    "    \n",
    "    # Repeat each entry in all other columns `n_seed_seq` times so they are the same length\n",
    "    # as the paraphrase column\n",
    "    return_d = defaultdict(list) \n",
    "    repeat_each_item_n_times = lambda l,n: [o for o in l for i in range(n)]\n",
    "    for k in batch.keys(): \n",
    "        if   k == cname_output: return_d[k] = batch[cname_output]\n",
    "        else:                   return_d[k] = repeat_each_item_n_times(batch[k], n_seed_seqs)\n",
    "    return return_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "985bcfde904d406d90d185b05de22e1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=134.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_pphrases_ds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-3658c12ffcce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m             cname_input=cname_input, cname_output=cname_output),\n\u001b[1;32m     17\u001b[0m         batched=True, batch_size=64) \n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mtrain_pphrases_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_to_disk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train_pphrases_ds' is not defined"
     ]
    }
   ],
   "source": [
    "# Generate paraphrase dataset\n",
    "n_seed_seqs = 3\n",
    "cname_input = 'text' # which text column to paraphrase\n",
    "cname_output= cname_input + '_pphrases'\n",
    "date = '20210802'\n",
    "fname = path_cache + '_rt_train'+ date + '_' + str(n_seed_seqs)\n",
    "if os.path.exists(fname):  \n",
    "    train_pphrases = datasets.load_from_disk(fname)\n",
    "else:\n",
    "    train_pphrases = train.shard(1, 0, contiguous=True)\n",
    "    # Have to call with batched=True\n",
    "    # Need to set a batch size otherwise will run out of memory on the GPU card. \n",
    "    # 64 seems to work well \n",
    "    train_pphrases = train_pphrases.map(\n",
    "        lambda x: create_paraphrase_dataset(x, n_seed_seqs=n_seed_seqs,\n",
    "            cname_input=cname_input, cname_output=cname_output),\n",
    "        batched=True, batch_size=64) \n",
    "    train_pphrases_ds.save_to_disk(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': [1, 1, 1, 1, 1, 1, 1],\n",
       " 'text': ['the rock is destined to be the 21st century\\'s new \" conan \" and that he\\'s going to make a splash even greater than arnold schwarzenegger , jean-claud van damme or steven segal .',\n",
       "  'the rock is destined to be the 21st century\\'s new \" conan \" and that he\\'s going to make a splash even greater than arnold schwarzenegger , jean-claud van damme or steven segal .',\n",
       "  'the gorgeously elaborate continuation of \" the lord of the rings \" trilogy is so huge that a column of words cannot adequately describe co-writer/director peter jackson\\'s expanded vision of j . r . r . tolkien\\'s middle-earth .',\n",
       "  'the gorgeously elaborate continuation of \" the lord of the rings \" trilogy is so huge that a column of words cannot adequately describe co-writer/director peter jackson\\'s expanded vision of j . r . r . tolkien\\'s middle-earth .',\n",
       "  'the gorgeously elaborate continuation of \" the lord of the rings \" trilogy is so huge that a column of words cannot adequately describe co-writer/director peter jackson\\'s expanded vision of j . r . r . tolkien\\'s middle-earth .',\n",
       "  'effective but too-tepid biopic',\n",
       "  'effective but too-tepid biopic'],\n",
       " 'text_pphrases': [\"The rock is going to be the 21st century's new conan, and he's going to make a bigger splash than arnold schwarzenegger, jean-claud van damme or steven segal.\",\n",
       "  \"The rock is going to be the 21st century's new conan, and he's going to make a bigger splash than arnold schwarzenegger, jean-claud van damme, or steven segal.\",\n",
       "  \"Peter Jackson's expanded vision of middle-earth is so huge that a column of words cannot adequately describe it.\",\n",
       "  \"Peter Jackson's expanded vision of middle-earth is so large that a column of words cannot adequately describe it.\",\n",
       "  \"Peter Jackson's expanded vision of middle-earth in the Lord of the Rings trilogy is so huge that a column of words cannot adequately describe it.\",\n",
       "  'The film was effective but too-tepid.',\n",
       "  'The film is effective but too-tepid.']}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pphrases[1:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pphrases = train.shard(200, 0, contiguous=True)\n",
    "train_pphrases = train_pphrases.map(     \n",
    "        lambda x: create_paraphrase_dataset(x, n_seed_seqs=n_seed_seqs,\n",
    "            cname_input=cname_input, cname_output=cname_output),\n",
    "        batched=True, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch={'label': [1, 1, 1, 1], \n",
    "       'text': ['the rock is destined to be the 21st century\\'s new \" conan \" and that he\\'s going to make a splash even greater than arnold schwarzenegger , jean-claud van damme or steven segal .', 'the gorgeously elaborate continuation of \" the lord of the rings \" trilogy is so huge that a column of words cannot adequately describe co-writer/director peter jackson\\'s expanded vision of j . r . r . tolkien\\'s middle-earth .', 'effective but too-tepid biopic', 'if you sometimes like to go to the movies to have fun , wasabi is a good place to start .'], \n",
    "       'text_pphrases': [\"The rock is going to be the new conan, and he's going to make a bigger splash than arnold schwarzenegger, jean-claud van damme or steven segal.\", \"The rock is going to be the new conan, and he's going to make a bigger splash than arnold schwarzenegger or jean-claud van damme.\", \"A column of words can't adequately describe the expanded vision of peter jackson's trilogy.\", \"A column of words can't adequately describe the expanded vision of Peter Jackson's trilogy.\", 'The film was effective but too-tepid.', 'The film is effective but too-tepid.', 'If you like to go to the movies to have fun, you should start at wasabi.', 'If you like to go to the movies to have fun, you can start at wasabi.']\n",
    "      }\n",
    "n_seed_seqs = 2\n",
    "cname_input='text',\n",
    "cname_output='text_pphrases'\n",
    "\n",
    "# Only works if the same number of paraphrases is generated for each phrase. \n",
    "# Else try something like \n",
    "# for o in zip(*batch.values()):\n",
    "#     d = dict(zip(batch.keys(), o))\n",
    "#     get_paraphrases(batch[cname_input],num_return_sequences=n_seed_seqs,num_beams=n_seed_seqs)\n",
    "#     for k,v in d.items(): \n",
    "#       return_d[k] += v if k == 'text' else [v for o in range(n_paraphrases)]\n",
    "# return return_d\n",
    "return_d = defaultdict(list) \n",
    "repeat_each_item_n_times = lambda l,n: [o for o in l for i in range(n)]\n",
    "for k in batch.keys(): \n",
    "    if   k == cname_output: return_d[k] = batch[cname_output]\n",
    "    else:                   return_d[k] = repeat_each_item_n_times(batch[k], n_seed_seqs)\n",
    "return return_d\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x={\"a\":4, \"b\":[1,2]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=n_seed_seqs\n",
    "lambda l,n: [l[i:i + n] for i in range(0, len(l), n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeat_each_item_n_times(batch['text'], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
