{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction \n",
    "Here we are trying to adjust parameters of a paraphrase model to generate adversarial examples. \n",
    "\n",
    "### Policy gradients \n",
    "The key parameter update equation is $\\theta_{t+1} = \\theta_t + \\alpha \\nabla_\\theta J(\\theta)$, where $\\alpha$ is a step size parameter, the parameter vector $\\theta$ is for a model (here a paraphrase model), and $J$ is a loss function. The time step $t$ depends on the problem specification and we will get to it later. \n",
    "\n",
    "Now in my review I have defined the loss function $J(\\theta) = E_\\pi[r(\\tau)]$. Here: \n",
    "* $\\pi$ is the policy, a probability distribution for the next action in a given state; essentially $p(a_t|s_t)$\n",
    "* $\\tau$ is a trajectory, a specific sequence $s_0, a_0, r_1, s_1, a_1, \\ldots$ of the agent in the game. This starts at time $t=0$ and finishes at time $t=T$. \n",
    "* $r(\\tau)$ is the sum of rewards for a trajectory $\\tau$, or in other words, the total reward for the trajectory. \n",
    "\n",
    "For this loss function higher values are better (which might make it a reward function) and so we might have to invert it at some point. \n",
    "\n",
    "To update parameters we must find the gradient $\\nabla_\\theta J(\\theta)$, which measures how $J(\\theta)$ changes when we adjust the parameters of the paraphrase model. The gradient is simplified through some maths to get the policy gradient theorem $$ \\nabla_\\theta J(\\theta) =  \\nabla_\\theta E_\\pi [r(\\tau)]  = E_\\pi \\left[r(\\tau) \\sum_{t=1}^T \\nabla_\\theta \\log \\pi (a_t|s_t)  \\right] $$ \n",
    "\n",
    "To calculate this you need to calculate the expectation term, which in turn means evaluating every possible trajectory $\\tau$ and its expected return. Generally this is not possible and instead we turn to estimators.  \n",
    "\n",
    "One of these is REINFORCE. It gives us  $$ \\nabla_\\theta J(\\theta) \\approx \\sum_{s=1}^S \\sum_{t=1}^T G_t \\nabla \\log \\pi(a_t|s_t)$$ where \n",
    "* $G_t$ is the discounted return and is given by $G_t = r_t + \\beta r_{t-1} + \\beta^2 r_{t-2} + \\dots$. It's a rough estimate of $r(\\tau)$. Rewards obtained later in the episode are weighted much higher than rewards obtained earlier. I guess it assumes that the parameters update every timestep. \n",
    "* $S$ is some number of samples.\n",
    "\n",
    "The implementation of REINFORCE and similar estimators depends on how we formulate the problem. Below we present some possible formulations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation One: Document-level  \n",
    "This is the first implementation we will try. \n",
    "\n",
    "Here we generate a list of paraphrases at each time point. The idea is that there is one paraphrase amongst them that is a good adversarial example. We try to tune the model to produce the best one. \n",
    "\n",
    "This interpretation sees forming the complete paraphrase as one time step. So it isn't token-level but document-level. \n",
    "\n",
    "* Starting state: $s0 = x$, the original example  \n",
    "* Actions: each action is \"choosing\" a paraphrase (or of choosing $n$ paraphrases). The set of all possible paraphrases and their probabilities is the policy. So $\\pi(a|s) = p(x'| x;\\theta)$ where $x'$ is the paraphrase (or list of paraphrases). \n",
    "    * To approximate this probability, what we can do is generate a large list of paraphrases, and for each, the probabilities of generating each token in turn for that paraphrase. This gives a rough \"probability\" of how likely that sequence was. This number is kind of like a weight for how good that paraphrase is, according to the model.  We can then turn the weights into probabilities to get a \"probability\" of the paraphrase. This is dependent on the number of paraphrases generated, so generating a large list is likely to be better for this task. \n",
    "* Reward: The paraphrase moves through the reward function $R(x, x')$) to get the reward $r$. \n",
    "* Time steps: We only have one time step in the game ($T=1$ and $G_t=r$)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few variations to this scenario that we can do. For each of these we will formulate the policy and the reward function $R$. Below, $x'$ means paraphrase, $f(x)_y$ means the model confidence of x for the class of the true label $y$, $SS(a,b)$ is the result of a semantic similarity model run over $a$ and $b$, and $\\lambda$ is a hyperparameter.  \n",
    "\n",
    "\n",
    "#### One-paraphrase \n",
    "Here we only generate one paraphrase. This scenario also has a few options. First we generate a list of paraphrases with the probabilities of selecting one. Then we either sample probabilistically from the list or pick the most probable option. \n",
    "\n",
    "In this case the policy $p(x'|x,\\theta)$ is the chance of obtaining a specific paraphrase. For the sampling option this is equal to its sample probability. For the top option this is just the probability of selecting that option. \n",
    "\n",
    "The reward function might look like $R(x,x') = f(x)_y - f(x')_y + \\lambda SS(x, x')$. We could also make the $SS$ factor a step-function above some threshold. \n",
    "\n",
    "The REINFORCE equation $$ \\nabla_\\theta J(\\theta) \\approx \\sum_{s=1}^S \\sum_{t=1}^T G_t \\nabla \\log \\pi(a_t|s_t)$$ becomes $$ \\nabla_\\theta J(\\theta) \\approx \\sum_{s=1}^S  R(x,x'_s) \\nabla \\log p(x'_s|x,\\theta)$$ We repeat the process $S$ times where $S$ is ideally as large as possible. We can start with something simple (e.g. $S=10$ or $S=100$) and go from there.  \n",
    "\n",
    "The gradient term $\\nabla \\log p(x'_s|x,\\theta)$ can hopefully be found with autodiff. \n",
    "\n",
    "#### Set of paraphrases\n",
    "In this scenario the paraphrase model is evaluated on performance over a set of paraphrases, which we call $X'$ here. The policy becomes $p(X'|x, \\theta)$, the probability of obtaining that list. We can get this probability by multipling together the \"probability\" of each individual paraphrase, multiplying also by nCr (for r paraphrases out of n total) to account for the lack of order in the list. \n",
    "\n",
    "We can make a number of sub-scenarios here. \n",
    "\n",
    "For the **top-paraphrase in set** condition the paraphrase generator is only measured on the best reward for a paraphrase in its set. The idea is the generator will learn to produce a diverse set of examples, any of which could plausibly be a good adversarial example. Here we only look at best performing paraphrase $x'_m$, which we can find by $x'_m = \\max_i [f(x)_y - f(x'_i)_y]$, then return $R(x,x'_m) = [f(x)_y - f(x'_m)_y] + \\lambda SS(x,x'_m)$ \n",
    "\n",
    "For the **average-paraphrase in set** condition the paraphrase generator is measured on the average reward of the paraphrases in its set. This encourages the generator to consider performance of all examples more-or-less equally. The reward function could be something like $\\frac{1}{k} \\sum_{i=1}^k \\left[ f(x)_y - f(x'_i)_y + \\lambda SS(x, x'_i) \\right]$ \n",
    "\n",
    "A combination of these scenarios is the **top-k/top-p\\% paraphrases in set**. Here we only use the top-$k$ paraphrases, or more generally, the top $p$ percentage of paraphrases. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation 2: Token-level\n",
    "This interpretation is at token-level; it sees choosing the next word as the next time step. \n",
    "\n",
    "* Starting state: $s0 = x$, the initial state. But you also have a \"blank slate\" for the paraphrase. So maybe it's a tuple (x, pp) where pp is a paraphrase with no words. Here x is used as the reference for the paraphrase generator.  \n",
    "* Actions: Choose the next word of p. I guess this starts with the \\<START\\> token (or something similar). Then you have the policy $\\pi(a|s)$ which is the same as $p(w_{next}|pp, x; \\theta)$ where $\\theta$ is the paraphrase model parameters, $pp$ is the so-far constructed sentence, and $w_{next}$ is the next token (I say token because I don't know if this model is on the subword or word basis). \n",
    "* Time steps: every token is generated one-by-one and each of these is allocated a time step. This means probably that you also update the parameters after each token generated too. \n",
    "* Reward. The reward is allocated every token. There are many reward functions (see papers on token-level loss functions). Some also incorporate document-level rewards too. \n",
    "* Next state. $s_1$ is again the tuple $(x, pp)$ but now $pp$ has the first word in it. \n",
    "\n",
    "On *teacher forcing*. This is when you have a ground-truth paraphrase and you can use it when generating tokens. This is useful because if the model makes a mistake it doesn't continue down that track but is adjusted back. This stops big divergences (but also might limit the diversity of generated paraphrases). This is used when training a paraphrase model. You have a set of reference paraphrases that are human provided. Here though we only have the original sentence and no references. We could generate adversarial examples and use that to do teacher forcing. Generating them using textattack recipes might work. This is only really used on the token-level rewards. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating the paraphrase model parameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a choice here. We can either directly update the parameters of the paraphrase model. Or we can fix the parameters and add a new dense layer to the end of the model. We could then train this dense layer to convert paraphrases to adversarial paraphrases. \n",
    "\n",
    "Before trying this out, I am worried that we will destroy the capabilities of the paraphrase generator a bit. We might get semantically invalid or ungrammatical or gibberish text. If so we could try and mitigate it a bit by shaping our reward function to maintain grammatical components. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plan is to try the following order: \n",
    "\n",
    "1. One-paraphrase (most probable option). I'll start with this one because it is probably the most simple case. Within this category: \n",
    "    1a. tune existing parameters only (see if the text is recognisable) \n",
    "    1b. add dense layer onto end and try again \n",
    "2. One-paraphrase (sampled). This seems like a logical extension on the first one. \n",
    "3. Paraphrase-set options. (Decide after finishing 1, 2) \n",
    "4. Token-level tuning. (Decide after 1,2,3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer Freezing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am uncertain on if to do this or not. \n",
    "\n",
    "* This [paper](https://arxiv.org/abs/1911.03090) indicates that you can get pretty good results by freezing all layers except the last few \n",
    "* Conversely I saw in the transformers documentation that transformers train better if you don't do layer freezing \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup, load models + datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, gc\n",
    "import torch \n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import load_dataset, load_metric\n",
    "import datasets, transformers\n",
    "from transformers import pipeline, AutoModelForSeq2SeqLM, AutoModelForSequenceClassification, AutoTokenizer\n",
    "from pprint import pprint\n",
    "import numpy as np, pandas as pd\n",
    "import scipy\n",
    "from utils import *   # local script \n",
    "import pyarrow\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from IPython.core.debugger import set_trace\n",
    "from GPUtil import showUtilization\n",
    "import seaborn as sns\n",
    "from itertools import repeat\n",
    "from collections import defaultdict\n",
    "from IPython.display import Markdown\n",
    "\n",
    "path_cache = './cache/'\n",
    "path_results = \"./results/\"\n",
    "\n",
    "seed = 420\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \n",
    "devicenum = torch.cuda.current_device() if device.type == 'cuda' else -1\n",
    "n_wkrs = 4 * torch.cuda.device_count()\n",
    "batch_size = 64\n",
    "pd.set_option(\"display.max_colwidth\", 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paraphrase (pp) model \n",
    "pp_name = \"tuner007/pegasus_paraphrase\"\n",
    "pp_tokenizer = AutoTokenizer.from_pretrained(pp_name)\n",
    "# takes about 3GB memory space up on the GPU\n",
    "pp_model = AutoModelForSeq2SeqLM.from_pretrained(pp_name).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from types import MethodType\n",
    "from undecorated import undecorated\n",
    "generate1 = undecorated(pp_model.generate)\n",
    "pp_model.generate1 = MethodType(generate1, pp_model)\n",
    "pp_model.generate3 = MethodType(pp_model.generate.__closure__[0].cell_contents,pp_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# from transformers.models.pegasus import PegasusForConditionalGeneration\n",
    "from typing import Any, Callable, Dict, Iterable, List, Mapping, Optional, Union\n",
    "from transformers.generation_beam_search import BeamScorer, BeamSearchScorer\n",
    "import torchsnooper\n",
    "\n",
    "def generate2(\n",
    "    self,\n",
    "    input_ids: Optional[torch.LongTensor] = None,\n",
    "    max_length: Optional[int] = None,\n",
    "    min_length: Optional[int] = None,\n",
    "    do_sample: Optional[bool] = None,\n",
    "    early_stopping: Optional[bool] = None,\n",
    "    num_beams: Optional[int] = None,\n",
    "    temperature: Optional[float] = None,\n",
    "    top_k: Optional[int] = None,\n",
    "    top_p: Optional[float] = None,\n",
    "    repetition_penalty: Optional[float] = None,\n",
    "    bad_words_ids: Optional[Iterable[int]] = None,\n",
    "    bos_token_id: Optional[int] = None,\n",
    "    pad_token_id: Optional[int] = None,\n",
    "    eos_token_id: Optional[int] = None,\n",
    "    length_penalty: Optional[float] = None,\n",
    "    no_repeat_ngram_size: Optional[int] = None,\n",
    "    encoder_no_repeat_ngram_size: Optional[int] = None,\n",
    "    num_return_sequences: Optional[int] = None,\n",
    "    max_time: Optional[float] = None,\n",
    "    decoder_start_token_id: Optional[int] = None,\n",
    "    use_cache: Optional[bool] = None,\n",
    "    num_beam_groups: Optional[int] = None,\n",
    "    diversity_penalty: Optional[float] = None,\n",
    "    prefix_allowed_tokens_fn: Optional[Callable[[int, torch.Tensor], List[int]]] = None,\n",
    "    output_attentions: Optional[bool] = None,\n",
    "    output_hidden_states: Optional[bool] = None,\n",
    "    output_scores: Optional[bool] = None,\n",
    "    return_dict_in_generate: Optional[bool] = None,\n",
    "    forced_bos_token_id: Optional[int] = None,\n",
    "    forced_eos_token_id: Optional[int] = None,\n",
    "    remove_invalid_values: Optional[bool] = None,\n",
    "    **model_kwargs):\n",
    "    # set init values\n",
    "    num_beams = num_beams if num_beams is not None else self.config.num_beams\n",
    "    num_beam_groups = num_beam_groups if num_beam_groups is not None else self.config.num_beam_groups\n",
    "    max_length = max_length if max_length is not None else self.config.max_length\n",
    "    do_sample = do_sample if do_sample is not None else self.config.do_sample\n",
    "    num_return_sequences = (\n",
    "        num_return_sequences if num_return_sequences is not None else self.config.num_return_sequences\n",
    "    )\n",
    "\n",
    "    pad_token_id = pad_token_id if pad_token_id is not None else self.config.pad_token_id\n",
    "    bos_token_id = bos_token_id if bos_token_id is not None else self.config.bos_token_id\n",
    "    eos_token_id = eos_token_id if eos_token_id is not None else self.config.eos_token_id\n",
    "\n",
    "    output_scores = output_scores if output_scores is not None else self.config.output_scores\n",
    "    output_attentions = output_attentions if output_attentions is not None else self.config.output_attentions\n",
    "    output_hidden_states = (\n",
    "        output_hidden_states if output_hidden_states is not None else self.config.output_hidden_states\n",
    "    )\n",
    "    return_dict_in_generate = (\n",
    "        return_dict_in_generate if return_dict_in_generate is not None else self.config.return_dict_in_generate\n",
    "    )\n",
    "\n",
    "    model_kwargs[\"output_attentions\"] = output_attentions\n",
    "    model_kwargs[\"output_hidden_states\"] = output_hidden_states\n",
    "\n",
    "    if input_ids is None:\n",
    "        # init `input_ids` with bos_token_id\n",
    "        input_ids = self._prepare_input_ids_for_generation(bos_token_id, model_kwargs.get(\"encoder_outputs\"))\n",
    "\n",
    "    if model_kwargs.get(\"attention_mask\", None) is None:\n",
    "        # init `attention_mask` depending on `pad_token_id`\n",
    "        model_kwargs[\"attention_mask\"] = self._prepare_attention_mask_for_generation(\n",
    "            input_ids, pad_token_id, eos_token_id\n",
    "        )\n",
    "\n",
    "    # special case if pad_token_id is not defined\n",
    "    if pad_token_id is None and eos_token_id is not None:\n",
    "        logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
    "        pad_token_id = eos_token_id\n",
    "\n",
    "    # Storing encoder_input_ids for logits_processor that could use them\n",
    "    encoder_input_ids = input_ids if self.config.is_encoder_decoder else None\n",
    "\n",
    "    if self.config.is_encoder_decoder:\n",
    "        # add encoder_outputs to model_kwargs\n",
    "        model_kwargs = self._prepare_encoder_decoder_kwargs_for_generation(input_ids, model_kwargs)\n",
    "\n",
    "        # set input_ids as decoder_input_ids\n",
    "        if \"decoder_input_ids\" in model_kwargs:\n",
    "            input_ids = model_kwargs.pop(\"decoder_input_ids\")\n",
    "        else:\n",
    "            input_ids = self._prepare_decoder_input_ids_for_generation(\n",
    "                input_ids, decoder_start_token_id=decoder_start_token_id, bos_token_id=bos_token_id\n",
    "            )\n",
    "\n",
    "#         if \"encoder_outputs\" not in model_kwargs or not isinstance(model_kwargs[\"encoder_outputs\"], ModelOutput):\n",
    "#             raise ValueError(\"Make sure that `model_kwargs` include `encoder_outputs` of type `ModelOutput`.\")\n",
    "    if input_ids.shape[-1] >= max_length:\n",
    "        input_ids_string = \"decoder_input_ids\" if self.config.is_encoder_decoder else \"input_ids\"\n",
    "        logger.warning(\n",
    "            f\"Input length of {input_ids_string} is {input_ids.shape[-1]}, but ``max_length`` is set to {max_length}.\"\n",
    "            \"This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\"\n",
    "        )\n",
    "\n",
    "    # determine generation mode\n",
    "    is_greedy_gen_mode = (num_beams == 1) and (num_beam_groups == 1) and do_sample is False\n",
    "    is_sample_gen_mode = (num_beams == 1) and (num_beam_groups == 1) and do_sample is True\n",
    "    is_beam_gen_mode = (num_beams > 1) and (num_beam_groups == 1) and do_sample is False\n",
    "    is_beam_sample_gen_mode = (num_beams > 1) and (num_beam_groups == 1) and do_sample is True\n",
    "    is_group_beam_gen_mode = (num_beams > 1) and (num_beam_groups > 1)\n",
    "    if num_beam_groups > num_beams:\n",
    "        raise ValueError(\"`num_beam_groups` has to be smaller or equal to `num_beams`\")\n",
    "    if is_group_beam_gen_mode and do_sample is True:\n",
    "        raise ValueError(\n",
    "            \"Diverse beam search cannot be used in sampling mode. Make sure that `do_sample` is set to `False`.\"\n",
    "        )\n",
    "\n",
    "    # set model_kwargs\n",
    "    model_kwargs[\"use_cache\"] = use_cache\n",
    "\n",
    "    # get distribution pre_processing samplers\n",
    "    logits_processor = self._get_logits_processor(\n",
    "        repetition_penalty=repetition_penalty,\n",
    "        no_repeat_ngram_size=no_repeat_ngram_size,\n",
    "        encoder_no_repeat_ngram_size=encoder_no_repeat_ngram_size,\n",
    "        encoder_input_ids=encoder_input_ids,\n",
    "        bad_words_ids=bad_words_ids,\n",
    "        min_length=min_length,\n",
    "        max_length=max_length,\n",
    "        eos_token_id=eos_token_id,\n",
    "        forced_bos_token_id=forced_bos_token_id,\n",
    "        forced_eos_token_id=forced_eos_token_id,\n",
    "        prefix_allowed_tokens_fn=prefix_allowed_tokens_fn,\n",
    "        num_beams=num_beams,\n",
    "        num_beam_groups=num_beam_groups,\n",
    "        diversity_penalty=diversity_penalty,\n",
    "        remove_invalid_values=remove_invalid_values,\n",
    "    )\n",
    "\n",
    "    stopping_criteria = self._get_stopping_criteria(\n",
    "        max_length=max_length,\n",
    "        max_time=max_time,\n",
    "    )\n",
    "\n",
    "    if is_greedy_gen_mode:\n",
    "        if num_return_sequences > 1:\n",
    "            raise ValueError(\n",
    "                f\"num_return_sequences has to be 1, but is {num_return_sequences} when doing greedy search.\"\n",
    "            )\n",
    "\n",
    "        # greedy search\n",
    "        return self.greedy_search(\n",
    "            input_ids,\n",
    "            logits_processor=logits_processor,\n",
    "            stopping_criteria=stopping_criteria,\n",
    "            max_length=max_length,\n",
    "            pad_token_id=pad_token_id,\n",
    "            eos_token_id=eos_token_id,\n",
    "            output_scores=output_scores,\n",
    "            return_dict_in_generate=return_dict_in_generate,\n",
    "            **model_kwargs,\n",
    "        )\n",
    "\n",
    "    elif is_sample_gen_mode:\n",
    "        # get probability distribution warper\n",
    "        logits_warper = self._get_logits_warper(\n",
    "            top_k=top_k, top_p=top_p, temperature=temperature, num_beams=num_beams\n",
    "        )\n",
    "\n",
    "        # expand input_ids with `num_return_sequences` additional sequences per batch\n",
    "        input_ids, model_kwargs = self._expand_inputs_for_generation(\n",
    "            input_ids,\n",
    "            expand_size=num_return_sequences,\n",
    "            is_encoder_decoder=self.config.is_encoder_decoder,\n",
    "            **model_kwargs,\n",
    "        )\n",
    "\n",
    "        # sample\n",
    "        return self.sample(\n",
    "            input_ids,\n",
    "            logits_processor=logits_processor,\n",
    "            logits_warper=logits_warper,\n",
    "            stopping_criteria=stopping_criteria,\n",
    "            max_length=max_length,\n",
    "            pad_token_id=pad_token_id,\n",
    "            eos_token_id=eos_token_id,\n",
    "            output_scores=output_scores,\n",
    "            return_dict_in_generate=return_dict_in_generate,\n",
    "            **model_kwargs,\n",
    "        )\n",
    "\n",
    "    elif is_beam_gen_mode:\n",
    "        batch_size = input_ids.shape[0]\n",
    "\n",
    "        length_penalty = length_penalty if length_penalty is not None else self.config.length_penalty\n",
    "        early_stopping = early_stopping if early_stopping is not None else self.config.early_stopping\n",
    "\n",
    "        if num_return_sequences > num_beams:\n",
    "            raise ValueError(\"`num_return_sequences` has to be smaller or equal to `num_beams`.\")\n",
    "\n",
    "        beam_scorer = BeamSearchScorer(\n",
    "            batch_size=batch_size,\n",
    "            max_length=max_length,\n",
    "            num_beams=num_beams,\n",
    "            device=self.device,\n",
    "            length_penalty=length_penalty,\n",
    "            do_early_stopping=early_stopping,\n",
    "            num_beam_hyps_to_keep=num_return_sequences,\n",
    "        )\n",
    "        # interleave with `num_beams`\n",
    "        input_ids, model_kwargs = self._expand_inputs_for_generation(\n",
    "            input_ids, expand_size=num_beams, is_encoder_decoder=self.config.is_encoder_decoder, **model_kwargs\n",
    "        )\n",
    "        with torchsnooper.snoop(depth=4, max_variable_length=200, normalize=True):\n",
    "            return self.beam_search(\n",
    "                input_ids,\n",
    "                beam_scorer,\n",
    "                logits_processor=logits_processor,\n",
    "                stopping_criteria=stopping_criteria,\n",
    "                max_length=max_length,\n",
    "                pad_token_id=pad_token_id,\n",
    "                eos_token_id=eos_token_id,\n",
    "                output_scores=output_scores,\n",
    "                return_dict_in_generate=return_dict_in_generate,\n",
    "                **model_kwargs,\n",
    "            )\n",
    "\n",
    "    elif is_beam_sample_gen_mode:\n",
    "        logits_warper = self._get_logits_warper(\n",
    "            top_k=top_k, top_p=top_p, temperature=temperature, num_beams=num_beams\n",
    "        )\n",
    "\n",
    "        batch_size = input_ids.shape[0] * num_return_sequences\n",
    "\n",
    "        length_penalty = length_penalty if length_penalty is not None else self.config.length_penalty\n",
    "        beam_scorer = BeamSearchScorer(\n",
    "            batch_size=batch_size,\n",
    "            max_length=max_length,\n",
    "            num_beams=num_beams,\n",
    "            device=self.device,\n",
    "            length_penalty=length_penalty,\n",
    "            do_early_stopping=early_stopping,\n",
    "        )\n",
    "\n",
    "        # interleave with `num_beams * num_return_sequences`\n",
    "        input_ids, model_kwargs = self._expand_inputs_for_generation(\n",
    "            input_ids,\n",
    "            expand_size=num_beams * num_return_sequences,\n",
    "            is_encoder_decoder=self.config.is_encoder_decoder,\n",
    "            **model_kwargs,\n",
    "        )\n",
    "\n",
    "        return self.beam_sample(\n",
    "            input_ids,\n",
    "            beam_scorer,\n",
    "            logits_processor=logits_processor,\n",
    "            logits_warper=logits_warper,\n",
    "            stopping_criteria=stopping_criteria,\n",
    "            max_length=max_length,\n",
    "            pad_token_id=pad_token_id,\n",
    "            eos_token_id=eos_token_id,\n",
    "            output_scores=output_scores,\n",
    "            return_dict_in_generate=return_dict_in_generate,\n",
    "            **model_kwargs,\n",
    "        )\n",
    "\n",
    "    elif is_group_beam_gen_mode:\n",
    "        batch_size = input_ids.shape[0]\n",
    "\n",
    "        length_penalty = length_penalty if length_penalty is not None else self.config.length_penalty\n",
    "        early_stopping = early_stopping if early_stopping is not None else self.config.early_stopping\n",
    "\n",
    "        if num_return_sequences > num_beams:\n",
    "            raise ValueError(\"`num_return_sequences` has to be smaller or equal to `num_beams`.\")\n",
    "\n",
    "        if num_beams % num_beam_groups != 0:\n",
    "            raise ValueError(\"`num_beams` should be divisible by `num_beam_groups` for group beam search.\")\n",
    "\n",
    "        diverse_beam_scorer = BeamSearchScorer(\n",
    "            batch_size=batch_size,\n",
    "            max_length=max_length,\n",
    "            num_beams=num_beams,\n",
    "            device=self.device,\n",
    "            length_penalty=length_penalty,\n",
    "            do_early_stopping=early_stopping,\n",
    "            num_beam_hyps_to_keep=num_return_sequences,\n",
    "            num_beam_groups=num_beam_groups,\n",
    "        )\n",
    "        # interleave with `num_beams`\n",
    "        input_ids, model_kwargs = self._expand_inputs_for_generation(\n",
    "            input_ids, expand_size=num_beams, is_encoder_decoder=self.config.is_encoder_decoder, **model_kwargs\n",
    "        )\n",
    "        return self.group_beam_search(\n",
    "            input_ids,\n",
    "            diverse_beam_scorer,\n",
    "            logits_processor=logits_processor,\n",
    "            stopping_criteria=stopping_criteria,\n",
    "            max_length=max_length,\n",
    "            pad_token_id=pad_token_id,\n",
    "            eos_token_id=eos_token_id,\n",
    "            output_scores=output_scores,\n",
    "            return_dict_in_generate=return_dict_in_generate,\n",
    "            **model_kwargs,\n",
    "        )\n",
    "pp_model.generate2 = MethodType(generate2, pp_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Victim Model (VM)\n",
    "vm_name = \"textattack/distilbert-base-uncased-rotten-tomatoes\"\n",
    "vm_tokenizer = AutoTokenizer.from_pretrained(vm_name)\n",
    "vm_model = AutoModelForSequenceClassification.from_pretrained(vm_name).to(device)\n",
    "vm_idx2lbl = vm_model.config.id2label\n",
    "vm_lbl2idx = vm_model.config.label2id\n",
    "vm_num_labels = vm_model.num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset rotten_tomatoes_movie_review (/data/tproth/.cache/huggingface/datasets/rotten_tomatoes_movie_review/default/1.0.0/9c411f7ecd9f3045389de0d9ce984061a1056507703d2e3183b1ac1a90816e4d)\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"rotten_tomatoes\")\n",
    "train,valid,test = dataset['train'],dataset['validation'],dataset['test']\n",
    "label_cname = 'label'\n",
    "## For snli\n",
    "# remove_minus1_labels = lambda x: x[label_cname] != -1\n",
    "# train = train.filter(remove_minus1_labels)\n",
    "# valid = valid.filter(remove_minus1_labels)\n",
    "# test = test.filter(remove_minus1_labels)\n",
    "\n",
    "# make sure that all datasets have the same number of labels as what the victim model predicts\n",
    "assert train.features[label_cname].num_classes == vm_num_labels\n",
    "assert valid.features[label_cname].num_classes == vm_num_labels\n",
    "assert test.features[ label_cname].num_classes == vm_num_labels\n",
    "\n",
    "train_dl = DataLoader(train, batch_size=batch_size, shuffle=True, num_workers=n_wkrs)\n",
    "valid_dl = DataLoader(valid, batch_size=batch_size, shuffle=True, num_workers=n_wkrs)\n",
    "test_dl = DataLoader( test,  batch_size=batch_size, shuffle=True, num_workers=n_wkrs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Setup**\n",
    "* use training dataset\n",
    "* sentiment analysis\n",
    "\n",
    "\n",
    "**Training loop** \n",
    "* get batch (e.g. 16 examples) which we call batch_orig\n",
    "* get paraphrases for each example in batch to make new batch (batch_pp)\n",
    "    * more efficient if we have bigger batches\n",
    "    * start with k=2 paraphrases for now (so the code can handle the multi-paraphrase case) but we will try with 1 and with a few as well. \n",
    "    * will have to later play around with diversity parameters (or maybe they can also be learned with rl too)\n",
    "* get reward \n",
    "    * the *reward function* $R$ takes in k rows of batch_pp, which corresponds to one example of batch_orig\n",
    "    * here are the formulas. \n",
    "    * for k=1: $R = f(x)_y - f(x')_y + \\lambda SS(x, x')$\n",
    "    * for k>1 (e.g. 3): some thought needed. ideas: \n",
    "        * only look at best performing paraphrase $x'_m$. find it by $x'_m = \\max_i [f(x)_y - f(x'_i)_y]$, then return $R [f(x)_y - f(x'_m)_y] + \\lambda SS(x,x')$ \n",
    "        * take average of each: $\\frac{1}{k} \\sum_{i=1}^k \\left[ f(x)_y - f(x'_i)_y + \\lambda SS(x, x'_i) \\right]$\n",
    "* update parameters of $f_{x'}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tasks \n",
    "* ~~clean up text above~~\n",
    "    * ~~Second edit that makes clear the scenario that is being implemented.~~\n",
    "* ~~clean up a bunch of commented code~~\n",
    "* ~~write out some scenarios~~ \n",
    "    * ~~best-paraphrase reward from set~~\n",
    "    * ~~avg-paraphrase reward from set~~\n",
    "    * ~~one paraphrase reward~~ \n",
    "* ~~write out order of scenarios~~\n",
    "* ~~add to git~~\n",
    "* ~~merge `get_paraphrases` and `get_paraphrases_and_probs`~~\n",
    "* ~~Adjust `create_paraphrase_dataset` to be able to deal with probabilities.~~\n",
    "* ~~Make terminology `para` and `pp` consistent~~\n",
    "* ~~Adjust `get_vm_scores` to deal with probabilities~~\n",
    "* write out pseudocode for how the training loop works\n",
    "    * ~~stochastic gradient descent version~~\n",
    "    * batched version\n",
    "    * version with Adam / other gradient descent technique\n",
    "\n",
    "* work out the simplest way you can start\n",
    "* ~~run through Trainer tutorial at: https://colab.research.google.com/github/huggingface/notebooks/blob/master/transformers_doc/pytorch/training.ipynb~~\n",
    "* ~~look into accumulated gradients~~\n",
    "* ~~look into mixed precision~~\n",
    "* ~~look into callbacks~~\n",
    "* ~~look into ZeRO~~\n",
    "* ~~look into curriculum learning~~\n",
    "\n",
    "* ~~look at the generate return function to check size (can you find token-level scores somewhere?)~~\n",
    "* implement non-batched version\n",
    "* write batched version pseudocode\n",
    "* write version where it is extended with Adam \n",
    "* write `reward_fn_onepp`\n",
    "\n",
    "\n",
    "First scenario: one paraphrase (top-one from probabilities) tuning parameters \n",
    "* implement reinforce \n",
    "* checkpoint: reward for one set of paraphrases \n",
    "\n",
    "* write out idea for tweaking hyperparameters of paraphrase model with this approach too\n",
    "\n",
    "**Possible future tasks**\n",
    "* try using pytorch AMP\n",
    "* how do GPU's work\n",
    "* gradient checkpointing \n",
    "* distributed training\n",
    "* hooks\n",
    "* pinned memory\n",
    "* freezing layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# def get_paraphrases(input_text, num_return_sequences, num_beams, return_probs=True, \n",
    "#                      num_beam_groups=1, diversity_penalty=0, temperature=1.5):\n",
    "#     \"\"\"Wrapper for generating paraphrases (pp's). Most keywords are passed on to pp_model.generate function, \n",
    "#     so see docs for that function. Set return_probs=True to return a tuple of (pp's, probs), \n",
    "#     else we return just a list of pp's. \"\"\"\n",
    "#     set_trace()\n",
    "#     batch = pp_tokenizer(input_text, truncation=True, padding='longest', return_tensors=\"pt\").to(device)\n",
    "    \n",
    "#     translated = pp_model.generate2(**batch, num_beams=num_beams, \n",
    "#         num_return_sequences=num_return_sequences, temperature=temperature, \n",
    "#         num_beam_groups=num_beam_groups, diversity_penalty=diversity_penalty,\n",
    "#         return_dict_in_generate=True, output_scores=True\n",
    "#     )\n",
    "#     # Sequence scores won't add to 1 across the generated paraphrases, so here we normalise them. \n",
    "#     # We also need to take exp for them to work. \n",
    "#     seq_probs = torch.exp(translated.sequences_scores) / sum(torch.exp(translated.sequences_scores))\n",
    "#     tgt_text = pp_tokenizer.batch_decode(translated.sequences, skip_special_tokens=True)\n",
    "#     if return_probs:   return tgt_text, seq_probs\n",
    "#     else:              return tgt_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated: [\"Today is a beautiful day, and I'm so happy to be here. I'm so happy to\"]\n"
     ]
    }
   ],
   "source": [
    "# from transformers import (\n",
    "# AutoTokenizer,\n",
    "# AutoModelForCausalLM,\n",
    "# LogitsProcessorList,\n",
    "# MinLengthLogitsProcessor,\n",
    "# )\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "# model = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n",
    "\n",
    "# # set pad_token_id to eos_token_id because GPT2 does not have a EOS token\n",
    "# model.config.pad_token_id = model.config.eos_token_id\n",
    "\n",
    "# input_prompt = \"Today is a beautiful day, and\"\n",
    "# input_ids = tokenizer(input_prompt, return_tensors=\"pt\").input_ids\n",
    "\n",
    "# # instantiate logits processors\n",
    "# logits_processor = LogitsProcessorList([\n",
    "#     MinLengthLogitsProcessor(15, eos_token_id=model.config.eos_token_id),\n",
    "# ])\n",
    "\n",
    "# outputs = model.greedy_search(input_ids, logits_processor=logits_processor)\n",
    "\n",
    "# print(\"Generated:\", tokenizer.batch_decode(outputs, skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# translated = pp_model.generate2(**batch, num_beams=num_beams, \n",
    "#     num_return_sequences=num_return_sequences, temperature=temperature, \n",
    "#     num_beam_groups=num_beam_groups, diversity_penalty=diversity_penalty,\n",
    "#     return_dict_in_generate=True, output_scores=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# translated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Source path:... <ipython-input-80-178233e04878>\n",
      "New var:....... self = PegasusForConditionalGeneration(  (model): PegasusModel(    (shared): Embedding(96103, 1024, paddi...mentwise_affine=True)    )  )  (lm_head): Linear(in_features=1024, out_features=96103, bias=False))\n",
      "New var:....... input_ids = tensor<(2, 1), int64, cuda:0>\n",
      "New var:....... max_length = 60\n",
      "New var:....... min_length = None\n",
      "New var:....... do_sample = False\n",
      "New var:....... early_stopping = False\n",
      "New var:....... num_beams = 2\n",
      "New var:....... temperature = 1.5\n",
      "New var:....... top_k = None\n",
      "New var:....... top_p = None\n",
      "New var:....... repetition_penalty = None\n",
      "New var:....... bad_words_ids = None\n",
      "New var:....... bos_token_id = 0\n",
      "New var:....... pad_token_id = 0\n",
      "New var:....... eos_token_id = 1\n",
      "New var:....... length_penalty = 1\n",
      "New var:....... no_repeat_ngram_size = None\n",
      "New var:....... encoder_no_repeat_ngram_size = None\n",
      "New var:....... num_return_sequences = 1\n",
      "New var:....... max_time = None\n",
      "New var:....... decoder_start_token_id = None\n",
      "New var:....... use_cache = None\n",
      "New var:....... num_beam_groups = 1\n",
      "New var:....... diversity_penalty = 0\n",
      "New var:....... prefix_allowed_tokens_fn = None\n",
      "New var:....... output_attentions = False\n",
      "New var:....... output_hidden_states = False\n",
      "New var:....... output_scores = True\n",
      "New var:....... return_dict_in_generate = True\n",
      "New var:....... forced_bos_token_id = None\n",
      "New var:....... forced_eos_token_id = None\n",
      "New var:....... remove_invalid_values = None\n",
      "New var:....... model_kwargs = {'output_attentions': False, 'output_hidden_states': False, 'use_cache': None, 'attention_mask': t...64, cuda:0>, 'encoder_outputs': {'last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0, grad>}}\n",
      "New var:....... encoder_input_ids = tensor<(1, 6), int64, cuda:0>\n",
      "New var:....... is_greedy_gen_mode = False\n",
      "New var:....... is_sample_gen_mode = False\n",
      "New var:....... is_beam_gen_mode = True\n",
      "New var:....... is_beam_sample_gen_mode = False\n",
      "New var:....... is_group_beam_gen_mode = False\n",
      "New var:....... logits_processor = [<transformers.generation_logits_process.MinLengthLogitsProcessor object>, <transformers.generation_logits_process.ForcedEOSTokenLogitsProcessor object>]\n",
      "New var:....... stopping_criteria = [<transformers.generation_stopping_criteria.MaxLengthCriteria object>]\n",
      "New var:....... batch_size = 1\n",
      "New var:....... beam_scorer = <transformers.generation_beam_search.BeamSearchScorer object>\n",
      "                line       214             return self.beam_search(\n",
      "                line       215                 input_ids,\n",
      "                line       216                 beam_scorer,\n",
      "                line       214             return self.beam_search(\n",
      "                line       217                 logits_processor=logits_processor,\n",
      "                line       218                 stopping_criteria=stopping_criteria,\n",
      "                line       219                 max_length=max_length,\n",
      "                line       220                 pad_token_id=pad_token_id,\n",
      "                line       221                 eos_token_id=eos_token_id,\n",
      "                line       222                 output_scores=output_scores,\n",
      "                line       223                 return_dict_in_generate=return_dict_in_generate,\n",
      "                line       214             return self.beam_search(\n",
      "                line       224                 **model_kwargs,\n",
      "                line       214             return self.beam_search(\n",
      "Source path:... generation_utils.py\n",
      "Starting var:.. self = PegasusForConditionalGeneration(  (model): PegasusModel(    (shared): Embedding(96103, 1024, paddi...mentwise_affine=True)    )  )  (lm_head): Linear(in_features=1024, out_features=96103, bias=False))\n",
      "Starting var:.. input_ids = tensor<(2, 1), int64, cuda:0>\n",
      "Starting var:.. beam_scorer = <transformers.generation_beam_search.BeamSearchScorer object>\n",
      "Starting var:.. logits_processor = [<transformers.generation_logits_process.MinLengthLogitsProcessor object>, <transformers.generation_logits_process.ForcedEOSTokenLogitsProcessor object>]\n",
      "Starting var:.. stopping_criteria = [<transformers.generation_stopping_criteria.MaxLengthCriteria object>]\n",
      "Starting var:.. max_length = 60\n",
      "Starting var:.. pad_token_id = 0\n",
      "Starting var:.. eos_token_id = 1\n",
      "Starting var:.. output_attentions = False\n",
      "Starting var:.. output_hidden_states = False\n",
      "Starting var:.. output_scores = True\n",
      "Starting var:.. return_dict_in_generate = True\n",
      "Starting var:.. model_kwargs = {'use_cache': None, 'attention_mask': tensor<(2, 6), int64, cuda:0>, 'encoder_outputs': {'last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0, grad>}}\n",
      "                call      1577     def beam_search(\n",
      "                line      1688         logits_processor = logits_processor if logits_processor is not None else LogitsProcessorList()\n",
      "                line      1689         stopping_criteria = stopping_criteria if stopping_criteria is not None else StoppingCriteriaList()\n",
      "                line      1690         max_length = max_length if max_length is not None else self.config.max_length\n",
      "                line      1691         validate_stopping_criteria(stopping_criteria, max_length)\n",
      "    Source path:... generation_stopping_criteria.py\n",
      "    Starting var:.. stopping_criteria = [<transformers.generation_stopping_criteria.MaxLengthCriteria object>]\n",
      "    Starting var:.. max_length = 60\n",
      "                    call        87 def validate_stopping_criteria(stopping_criteria: StoppingCriteriaList, max_length: int):\n",
      "                    line        88     found = False\n",
      "    New var:....... found = False\n",
      "                    line        89     for stopping_criterium in stopping_criteria:\n",
      "    New var:....... stopping_criterium = <transformers.generation_stopping_criteria.MaxLengthCriteria object>\n",
      "                    line        90         if isinstance(stopping_criterium, MaxLengthCriteria):\n",
      "                    line        91             found = True\n",
      "    Modified var:.. found = True\n",
      "                    line        92             if stopping_criterium.max_length != max_length:\n",
      "                    line        89     for stopping_criterium in stopping_criteria:\n",
      "                    line        96     if not found:\n",
      "                    return      96     if not found:\n",
      "    Return value:.. None\n",
      "Source path:... generation_utils.py\n",
      "                line      1692         pad_token_id = pad_token_id if pad_token_id is not None else self.config.pad_token_id\n",
      "                line      1693         eos_token_id = eos_token_id if eos_token_id is not None else self.config.eos_token_id\n",
      "                line      1694         output_scores = output_scores if output_scores is not None else self.config.output_scores\n",
      "                line      1695         output_attentions = output_attentions if output_attentions is not None else self.config.output_attentions\n",
      "                line      1697             output_hidden_states if output_hidden_states is not None else self.config.output_hidden_states\n",
      "                line      1696         output_hidden_states = (\n",
      "                line      1700             return_dict_in_generate if return_dict_in_generate is not None else self.config.return_dict_in_generate\n",
      "                line      1699         return_dict_in_generate = (\n",
      "                line      1704         scores = () if (return_dict_in_generate and output_scores) else None\n",
      "New var:....... scores = ()\n",
      "                line      1705         decoder_attentions = () if (return_dict_in_generate and output_attentions) else None\n",
      "New var:....... decoder_attentions = None\n",
      "                line      1706         cross_attentions = () if (return_dict_in_generate and output_attentions) else None\n",
      "New var:....... cross_attentions = None\n",
      "                line      1707         decoder_hidden_states = () if (return_dict_in_generate and output_hidden_states) else None\n",
      "New var:....... decoder_hidden_states = None\n",
      "                line      1710         if return_dict_in_generate and self.config.is_encoder_decoder:\n",
      "                line      1711             encoder_attentions = model_kwargs[\"encoder_outputs\"].get(\"attentions\") if output_attentions else None\n",
      "New var:....... encoder_attentions = None\n",
      "                line      1713                 model_kwargs[\"encoder_outputs\"].get(\"hidden_states\") if output_hidden_states else None\n",
      "                line      1712             encoder_hidden_states = (\n",
      "New var:....... encoder_hidden_states = None\n",
      "                line      1716         batch_size = len(beam_scorer._beam_hyps)\n",
      "New var:....... batch_size = 1\n",
      "                line      1717         num_beams = beam_scorer.num_beams\n",
      "New var:....... num_beams = 2\n",
      "                line      1719         batch_beam_size, cur_len = input_ids.shape\n",
      "New var:....... batch_beam_size = 2\n",
      "New var:....... cur_len = 1\n",
      "                line      1722             num_beams * batch_size == batch_beam_size\n",
      "                line      1721         assert (\n",
      "                line      1725         beam_scores = torch.zeros((batch_size, num_beams), dtype=torch.float, device=input_ids.device)\n",
      "New var:....... beam_scores = tensor<(1, 2), float32, cuda:0>\n",
      "                line      1726         beam_scores[:, 1:] = -1e9\n",
      "                line      1727         beam_scores = beam_scores.view((batch_size * num_beams,))\n",
      "Modified var:.. beam_scores = tensor<(2,), float32, cuda:0>\n",
      "                line      1729         while cur_len < max_length:\n",
      "                line      1730             model_inputs = self.prepare_inputs_for_generation(input_ids, **model_kwargs)\n",
      "    Source path:... modeling_pegasus.py\n",
      "    Starting var:.. self = PegasusForConditionalGeneration(  (model): PegasusModel(    (shared): Embedding(96103, 1024, paddi...mentwise_affine=True)    )  )  (lm_head): Linear(in_features=1024, out_features=96103, bias=False))\n",
      "    Starting var:.. decoder_input_ids = tensor<(2, 1), int64, cuda:0>\n",
      "    Starting var:.. past = None\n",
      "    Starting var:.. attention_mask = tensor<(2, 6), int64, cuda:0>\n",
      "    Starting var:.. head_mask = None\n",
      "    Starting var:.. use_cache = None\n",
      "    Starting var:.. encoder_outputs = {'last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0, grad>}\n",
      "    Starting var:.. kwargs = {}\n",
      "                    call      1305     def prepare_inputs_for_generation(\n",
      "                    line      1316         if past is not None:\n",
      "                    line      1320             \"input_ids\": None,  # encoder_outputs is defined. input_ids not needed\n",
      "                    line      1321             \"encoder_outputs\": encoder_outputs,\n",
      "                    line      1322             \"past_key_values\": past,\n",
      "                    line      1323             \"decoder_input_ids\": decoder_input_ids,\n",
      "                    line      1324             \"attention_mask\": attention_mask,\n",
      "                    line      1325             \"head_mask\": head_mask,\n",
      "                    line      1326             \"use_cache\": use_cache,  # change this to avoid caching (presumably for debugging)\n",
      "                    line      1319         return {\n",
      "                    return    1319         return {\n",
      "    Return value:.. {'input_ids': None, 'encoder_outputs': {'last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0,...64, cuda:0>, 'attention_mask': tensor<(2, 6), int64, cuda:0>, 'head_mask': None, 'use_cache': None}\n",
      "Source path:... generation_utils.py\n",
      "New var:....... model_inputs = {'input_ids': None, 'encoder_outputs': {'last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0,...64, cuda:0>, 'attention_mask': tensor<(2, 6), int64, cuda:0>, 'head_mask': None, 'use_cache': None}\n",
      "                line      1732             outputs = self(\n",
      "                line      1733                 **model_inputs,\n",
      "                line      1734                 return_dict=True,\n",
      "                line      1735                 output_attentions=output_attentions,\n",
      "                line      1736                 output_hidden_states=output_hidden_states,\n",
      "                line      1732             outputs = self(\n",
      "    Source path:... module.py\n",
      "    Starting var:.. self = PegasusForConditionalGeneration(  (model): PegasusModel(    (shared): Embedding(96103, 1024, paddi...mentwise_affine=True)    )  )  (lm_head): Linear(in_features=1024, out_features=96103, bias=False))\n",
      "    Starting var:.. input = ()\n",
      "    Starting var:.. kwargs = {'input_ids': None, 'encoder_outputs': {'last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0,... 'use_cache': None, 'return_dict': True, 'output_attentions': False, 'output_hidden_states': False}\n",
      "                    call       715     def _call_impl(self, *input, **kwargs):\n",
      "                    line       716         for hook in itertools.chain(\n",
      "                    line       717                 _global_forward_pre_hooks.values(),\n",
      "                    line       718                 self._forward_pre_hooks.values()):\n",
      "                    line       716         for hook in itertools.chain(\n",
      "                    line       724         if torch._C._get_tracing_state():\n",
      "                    line       727             result = self.forward(*input, **kwargs)\n",
      "        Source path:... modeling_pegasus.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        Starting var:.. self = PegasusForConditionalGeneration(  (model): PegasusModel(    (shared): Embedding(96103, 1024, paddi...mentwise_affine=True)    )  )  (lm_head): Linear(in_features=1024, out_features=96103, bias=False))\n",
      "        Starting var:.. input_ids = None\n",
      "        Starting var:.. attention_mask = tensor<(2, 6), int64, cuda:0>\n",
      "        Starting var:.. decoder_input_ids = tensor<(2, 1), int64, cuda:0>\n",
      "        Starting var:.. decoder_attention_mask = None\n",
      "        Starting var:.. head_mask = None\n",
      "        Starting var:.. decoder_head_mask = None\n",
      "        Starting var:.. encoder_outputs = {'last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0, grad>}\n",
      "        Starting var:.. past_key_values = None\n",
      "        Starting var:.. inputs_embeds = None\n",
      "        Starting var:.. decoder_inputs_embeds = None\n",
      "        Starting var:.. labels = None\n",
      "        Starting var:.. use_cache = None\n",
      "        Starting var:.. output_attentions = False\n",
      "        Starting var:.. output_hidden_states = False\n",
      "        Starting var:.. return_dict = True\n",
      "                        call      1231     def forward(\n",
      "                        line      1258         return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
      "                        line      1260         if labels is not None:\n",
      "                        line      1266         outputs = self.model(\n",
      "                        line      1267             input_ids,\n",
      "                        line      1268             attention_mask=attention_mask,\n",
      "                        line      1269             decoder_input_ids=decoder_input_ids,\n",
      "                        line      1270             encoder_outputs=encoder_outputs,\n",
      "                        line      1271             decoder_attention_mask=decoder_attention_mask,\n",
      "                        line      1272             head_mask=head_mask,\n",
      "                        line      1273             decoder_head_mask=decoder_head_mask,\n",
      "                        line      1274             past_key_values=past_key_values,\n",
      "                        line      1275             inputs_embeds=inputs_embeds,\n",
      "                        line      1276             decoder_inputs_embeds=decoder_inputs_embeds,\n",
      "                        line      1277             use_cache=use_cache,\n",
      "                        line      1278             output_attentions=output_attentions,\n",
      "                        line      1279             output_hidden_states=output_hidden_states,\n",
      "                        line      1280             return_dict=return_dict,\n",
      "                        line      1266         outputs = self.model(\n",
      "        New var:....... outputs = {'last_hidden_state': tensor<(2, 1, 1024), float32, cuda:0, grad>, 'past_key_values': ((tensor<(2,...float32, cuda:0, grad>)), 'encoder_last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0, grad>}\n",
      "                        line      1282         lm_logits = self.lm_head(outputs[0]) + self.final_logits_bias\n",
      "        New var:....... lm_logits = tensor<(2, 1, 96103), float32, cuda:0, grad>\n",
      "                        line      1284         masked_lm_loss = None\n",
      "        New var:....... masked_lm_loss = None\n",
      "                        line      1285         if labels is not None:\n",
      "                        line      1289         if not return_dict:\n",
      "                        line      1293         return Seq2SeqLMOutput(\n",
      "                        line      1294             loss=masked_lm_loss,\n",
      "                        line      1295             logits=lm_logits,\n",
      "                        line      1296             past_key_values=outputs.past_key_values,\n",
      "                        line      1297             decoder_hidden_states=outputs.decoder_hidden_states,\n",
      "                        line      1298             decoder_attentions=outputs.decoder_attentions,\n",
      "                        line      1299             cross_attentions=outputs.cross_attentions,\n",
      "                        line      1300             encoder_last_hidden_state=outputs.encoder_last_hidden_state,\n",
      "                        line      1301             encoder_hidden_states=outputs.encoder_hidden_states,\n",
      "                        line      1302             encoder_attentions=outputs.encoder_attentions,\n",
      "                        line      1293         return Seq2SeqLMOutput(\n",
      "                        return    1293         return Seq2SeqLMOutput(\n",
      "        Return value:.. {'logits': tensor<(2, 1, 96103), float32, cuda:0, grad>, 'past_key_values': ((tensor<(2, 16, 1, 64...float32, cuda:0, grad>)), 'encoder_last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0, grad>}\n",
      "    Source path:... module.py\n",
      "    New var:....... result = {'logits': tensor<(2, 1, 96103), float32, cuda:0, grad>, 'past_key_values': ((tensor<(2, 16, 1, 64...float32, cuda:0, grad>)), 'encoder_last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0, grad>}\n",
      "                    line       728         for hook in itertools.chain(\n",
      "                    line       729                 _global_forward_hooks.values(),\n",
      "                    line       730                 self._forward_hooks.values()):\n",
      "                    line       728         for hook in itertools.chain(\n",
      "                    line       734         if (len(self._backward_hooks) > 0) or (len(_global_backward_hooks) > 0):\n",
      "                    line       749         return result\n",
      "                    return     749         return result\n",
      "    Return value:.. {'logits': tensor<(2, 1, 96103), float32, cuda:0, grad>, 'past_key_values': ((tensor<(2, 16, 1, 64...float32, cuda:0, grad>)), 'encoder_last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0, grad>}\n",
      "Source path:... generation_utils.py\n",
      "New var:....... outputs = {'logits': tensor<(2, 1, 96103), float32, cuda:0, grad>, 'past_key_values': ((tensor<(2, 16, 1, 64...float32, cuda:0, grad>)), 'encoder_last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0, grad>}\n",
      "                line      1738             next_token_logits = outputs.logits[:, -1, :]\n",
      "New var:....... next_token_logits = tensor<(2, 96103), float32, cuda:0, grad>\n",
      "                line      1742             next_token_logits = self.adjust_logits_during_generation(\n",
      "                line      1743                 next_token_logits, cur_len=cur_len, max_length=max_length\n",
      "                line      1742             next_token_logits = self.adjust_logits_during_generation(\n",
      "    Starting var:.. self = PegasusForConditionalGeneration(  (model): PegasusModel(    (shared): Embedding(96103, 1024, paddi...mentwise_affine=True)    )  )  (lm_head): Linear(in_features=1024, out_features=96103, bias=False))\n",
      "    Starting var:.. logits = tensor<(2, 96103), float32, cuda:0, grad>\n",
      "    Starting var:.. kwargs = {'cur_len': 1, 'max_length': 60}\n",
      "                    call       373     def adjust_logits_during_generation(self, logits: torch.FloatTensor, **kwargs) -> torch.FloatTensor:\n",
      "                    line       378         return logits\n",
      "                    return     378         return logits\n",
      "    Return value:.. tensor<(2, 96103), float32, cuda:0, grad>\n",
      "                line      1746             next_token_scores = F.log_softmax(next_token_logits, dim=-1)  # (batch_size * num_beams, vocab_size)\n",
      "    Source path:... functional.py\n",
      "    Starting var:.. input = tensor<(2, 96103), float32, cuda:0, grad>\n",
      "    Starting var:.. dim = -1\n",
      "    Starting var:.. _stacklevel = 3\n",
      "    Starting var:.. dtype = None\n",
      "                    call      1581 def log_softmax(input, dim=None, _stacklevel=3, dtype=None):\n",
      "                    line      1598     if not torch.jit.is_scripting():\n",
      "        Source path:... _jit_internal.py\n",
      "                        call       750 def is_scripting():\n",
      "                        line       769     return False\n",
      "                        return     769     return False\n",
      "        Return value:.. False\n",
      "    Source path:... functional.py\n",
      "                    line      1599         if type(input) is not Tensor and has_torch_function((input,)):\n",
      "                    line      1602     if dim is None:\n",
      "                    line      1604     if dtype is None:\n",
      "                    line      1605         ret = input.log_softmax(dim)\n",
      "    New var:....... ret = tensor<(2, 96103), float32, cuda:0, grad>\n",
      "                    line      1608     return ret\n",
      "                    return    1608     return ret\n",
      "    Return value:.. tensor<(2, 96103), float32, cuda:0, grad>\n",
      "Source path:... generation_utils.py\n",
      "New var:....... next_token_scores = tensor<(2, 96103), float32, cuda:0, grad>\n",
      "                line      1748             next_token_scores = logits_processor(input_ids, next_token_scores)\n",
      "    Source path:... generation_logits_process.py\n",
      "    Starting var:.. self = [<transformers.generation_logits_process.MinLengthLogitsProcessor object>, <transformers.generation_logits_process.ForcedEOSTokenLogitsProcessor object>]\n",
      "    Starting var:.. input_ids = tensor<(2, 1), int64, cuda:0>\n",
      "    Starting var:.. scores = tensor<(2, 96103), float32, cuda:0, grad>\n",
      "    Starting var:.. kwargs = {}\n",
      "                    call        84     def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor, **kwargs) -> torch.FloatTensor:\n",
      "                    line        85         for processor in self:\n",
      "    New var:....... processor = <transformers.generation_logits_process.MinLengthLogitsProcessor object>\n",
      "                    line        86             function_args = inspect.signature(processor.__call__).parameters\n",
      "        Source path:... inspect.py\n",
      "        Starting var:.. obj = <bound method MinLengthLogitsProcessor.__call__ of <transformers.generation_logits_process.MinLengthLogitsProcessor object>>\n",
      "        Starting var:.. follow_wrapped = True\n",
      "                        call      3091 def signature(obj, *, follow_wrapped=True):\n",
      "                        line      3093     return Signature.from_callable(obj, follow_wrapped=follow_wrapped)\n",
      "                        return    3093     return Signature.from_callable(obj, follow_wrapped=follow_wrapped)\n",
      "        Return value:.. <Signature (input_ids: torch.LongTensor, scores: torch.FloatTensor) -> torch.FloatTensor>\n",
      "        Starting var:.. self = <Signature (input_ids: torch.LongTensor, scores: torch.FloatTensor) -> torch.FloatTensor>\n",
      "                        call      2846     def parameters(self):\n",
      "                        line      2847         return self._parameters\n",
      "                        return    2847         return self._parameters\n",
      "        Return value:.. mappingproxy(OrderedDict([('input_ids', <Parameter \"input_ids: torch.LongTensor\">), ('scores', <Parameter \"scores: torch.FloatTensor\">)]))\n",
      "    Source path:... generation_logits_process.py\n",
      "    New var:....... function_args = mappingproxy(OrderedDict([('input_ids', <Parameter \"input_ids: torch.LongTensor\">), ('scores', <Parameter \"scores: torch.FloatTensor\">)]))\n",
      "                    line        87             if len(function_args) > 2:\n",
      "                    line        93                 scores = processor(input_ids, scores)\n",
      "        Starting var:.. self = <transformers.generation_logits_process.MinLengthLogitsProcessor object>\n",
      "        Starting var:.. input_ids = tensor<(2, 1), int64, cuda:0>\n",
      "        Starting var:.. scores = tensor<(2, 96103), float32, cuda:0, grad>\n",
      "                        call       118     def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor) -> torch.FloatTensor:\n",
      "                        line       119         cur_len = input_ids.shape[-1]\n",
      "        New var:....... cur_len = 1\n",
      "                        line       120         if cur_len < self.min_length:\n",
      "                        line       122         return scores\n",
      "                        return     122         return scores\n",
      "        Return value:.. tensor<(2, 96103), float32, cuda:0, grad>\n",
      "                    line        85         for processor in self:\n",
      "    Modified var:.. processor = <transformers.generation_logits_process.ForcedEOSTokenLogitsProcessor object>\n",
      "                    line        86             function_args = inspect.signature(processor.__call__).parameters\n",
      "        Source path:... inspect.py\n",
      "        Starting var:.. obj = <bound method ForcedEOSTokenLogitsProcessor.__call__ of <transformers.generation_logits_process.ForcedEOSTokenLogitsProcessor object>>\n",
      "        Starting var:.. follow_wrapped = True\n",
      "                        call      3091 def signature(obj, *, follow_wrapped=True):\n",
      "                        line      3093     return Signature.from_callable(obj, follow_wrapped=follow_wrapped)\n",
      "                        return    3093     return Signature.from_callable(obj, follow_wrapped=follow_wrapped)\n",
      "        Return value:.. <Signature (input_ids: torch.LongTensor, scores: torch.FloatTensor) -> torch.FloatTensor>\n",
      "        Starting var:.. self = <Signature (input_ids: torch.LongTensor, scores: torch.FloatTensor) -> torch.FloatTensor>\n",
      "                        call      2846     def parameters(self):\n",
      "                        line      2847         return self._parameters\n",
      "                        return    2847         return self._parameters\n",
      "        Return value:.. mappingproxy(OrderedDict([('input_ids', <Parameter \"input_ids: torch.LongTensor\">), ('scores', <Parameter \"scores: torch.FloatTensor\">)]))\n",
      "    Source path:... generation_logits_process.py\n",
      "                    line        87             if len(function_args) > 2:\n",
      "                    line        93                 scores = processor(input_ids, scores)\n",
      "        Starting var:.. self = <transformers.generation_logits_process.ForcedEOSTokenLogitsProcessor object>\n",
      "        Starting var:.. input_ids = tensor<(2, 1), int64, cuda:0>\n",
      "        Starting var:.. scores = tensor<(2, 96103), float32, cuda:0, grad>\n",
      "                        call       571     def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor) -> torch.FloatTensor:\n",
      "                        line       572         cur_len = input_ids.shape[-1]\n",
      "        New var:....... cur_len = 1\n",
      "                        line       573         if cur_len == self.max_length - 1:\n",
      "                        line       577         return scores\n",
      "                        return     577         return scores\n",
      "        Return value:.. tensor<(2, 96103), float32, cuda:0, grad>\n",
      "                    line        85         for processor in self:\n",
      "                    line        94         return scores\n",
      "                    return      94         return scores\n",
      "    Return value:.. tensor<(2, 96103), float32, cuda:0, grad>\n",
      "Source path:... generation_utils.py\n",
      "                line      1749             next_token_scores = next_token_scores + beam_scores[:, None].expand_as(next_token_scores)\n",
      "                line      1752             if return_dict_in_generate:\n",
      "                line      1753                 if output_scores:\n",
      "                line      1754                     scores += (next_token_scores,)\n",
      "Modified var:.. scores = (tensor<(2, 96103), float32, cuda:0, grad>,)\n",
      "                line      1755                 if output_attentions:\n",
      "                line      1762                 if output_hidden_states:\n",
      "                line      1770             vocab_size = next_token_scores.shape[-1]\n",
      "New var:....... vocab_size = 96103\n",
      "                line      1771             next_token_scores = next_token_scores.view(batch_size, num_beams * vocab_size)\n",
      "Modified var:.. next_token_scores = tensor<(1, 192206), float32, cuda:0, grad>\n",
      "                line      1773             next_token_scores, next_tokens = torch.topk(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                line      1774                 next_token_scores, 2 * num_beams, dim=1, largest=True, sorted=True\n",
      "                line      1773             next_token_scores, next_tokens = torch.topk(\n",
      "Modified var:.. next_token_scores = tensor<(1, 4), float32, cuda:0, grad>\n",
      "New var:....... next_tokens = tensor<(1, 4), int64, cuda:0>\n",
      "                line      1777             next_indices = next_tokens // vocab_size\n",
      "    Source path:... tensor.py\n",
      "    Starting var:.. args = (tensor<(1, 4), int64, cuda:0>, 96103)\n",
      "    Starting var:.. kwargs = {}\n",
      "    Starting var:.. f = <function Tensor.__floordiv__>\n",
      "    Starting var:.. wrapped = <function Tensor.__floordiv__>\n",
      "                    call        22     def wrapped(*args, **kwargs):\n",
      "                    line        23         from torch.overrides import has_torch_function, handle_torch_function\n",
      "    New var:....... has_torch_function = <function has_torch_function>\n",
      "    New var:....... handle_torch_function = <function handle_torch_function>\n",
      "                    line        24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "                        call        24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "                        line        24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "        New var:....... t = tensor<(1, 4), int64, cuda:0>\n",
      "                        return      24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "        Return value:.. True\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. t = tensor<(1, 4), int64, cuda:0>\n",
      "                        call        24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "                        line        24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "        Modified var:.. t = 96103\n",
      "                        return      24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "        Return value:.. False\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. t = 96103\n",
      "                        call        24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "                        exception   24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "        Exception:..... GeneratorExit\n",
      "                        return      24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "        Return value:.. None\n",
      "        Source path:... overrides.py\n",
      "        Starting var:.. relevant_args = (tensor<(1, 4), int64, cuda:0>, 96103)\n",
      "                        call      1070 def has_torch_function(relevant_args: Iterable[Any]) -> bool:\n",
      "                        line      1083     return _is_torch_function_enabled() and any(\n",
      "                        line      1087         for a in relevant_args\n",
      "                        line      1083     return _is_torch_function_enabled() and any(\n",
      "                        return    1083     return _is_torch_function_enabled() and any(\n",
      "        Return value:.. False\n",
      "    Source path:... tensor.py\n",
      "                    line        26         try:\n",
      "                    line        27             return f(*args, **kwargs)\n",
      "        Starting var:.. self = tensor<(1, 4), int64, cuda:0>\n",
      "        Starting var:.. other = 96103\n",
      "                        call       550     def __floordiv__(self, other):\n",
      "                        line       551         return torch.floor_divide(self, other)\n",
      "                        return     551         return torch.floor_divide(self, other)\n",
      "        Return value:.. tensor<(1, 4), int64, cuda:0>\n",
      "                    return      27             return f(*args, **kwargs)\n",
      "    Return value:.. tensor<(1, 4), int64, cuda:0>\n",
      "Source path:... generation_utils.py\n",
      "New var:....... next_indices = tensor<(1, 4), int64, cuda:0>\n",
      "                line      1778             next_tokens = next_tokens % vocab_size\n",
      "                line      1781             beam_outputs = beam_scorer.process(\n",
      "                line      1782                 input_ids,\n",
      "                line      1783                 next_token_scores,\n",
      "                line      1784                 next_tokens,\n",
      "                line      1785                 next_indices,\n",
      "                line      1786                 pad_token_id=pad_token_id,\n",
      "                line      1787                 eos_token_id=eos_token_id,\n",
      "                line      1781             beam_outputs = beam_scorer.process(\n",
      "    Source path:... generation_beam_search.py\n",
      "    Starting var:.. self = <transformers.generation_beam_search.BeamSearchScorer object>\n",
      "    Starting var:.. input_ids = tensor<(2, 1), int64, cuda:0>\n",
      "    Starting var:.. next_scores = tensor<(1, 4), float32, cuda:0, grad>\n",
      "    Starting var:.. next_tokens = tensor<(1, 4), int64, cuda:0>\n",
      "    Starting var:.. next_indices = tensor<(1, 4), int64, cuda:0>\n",
      "    Starting var:.. pad_token_id = 0\n",
      "    Starting var:.. eos_token_id = 1\n",
      "                    call       199     def process(\n",
      "                    line       208         cur_len = input_ids.shape[-1]\n",
      "    New var:....... cur_len = 1\n",
      "                    line       209         batch_size = len(self._beam_hyps)\n",
      "    New var:....... batch_size = 1\n",
      "                    line       210         assert batch_size == (input_ids.shape[0] // self.group_size)\n",
      "                    line       212         device = input_ids.device\n",
      "    New var:....... device = device(type='cuda', index=0)\n",
      "                    line       213         next_beam_scores = torch.zeros((batch_size, self.group_size), dtype=next_scores.dtype, device=device)\n",
      "    New var:....... next_beam_scores = tensor<(1, 2), float32, cuda:0>\n",
      "                    line       214         next_beam_tokens = torch.zeros((batch_size, self.group_size), dtype=next_tokens.dtype, device=device)\n",
      "    New var:....... next_beam_tokens = tensor<(1, 2), int64, cuda:0>\n",
      "                    line       215         next_beam_indices = torch.zeros((batch_size, self.group_size), dtype=next_indices.dtype, device=device)\n",
      "    New var:....... next_beam_indices = tensor<(1, 2), int64, cuda:0>\n",
      "                    line       217         for batch_idx, beam_hyp in enumerate(self._beam_hyps):\n",
      "    New var:....... batch_idx = 0\n",
      "    New var:....... beam_hyp = <transformers.generation_beam_search.BeamHypotheses object>\n",
      "                    line       218             if self._done[batch_idx]:\n",
      "                    line       232             beam_idx = 0\n",
      "    New var:....... beam_idx = 0\n",
      "                    line       233             for beam_token_rank, (next_token, next_score, next_index) in enumerate(\n",
      "                    line       234                 zip(next_tokens[batch_idx], next_scores[batch_idx], next_indices[batch_idx])\n",
      "        Source path:... tensor.py\n",
      "        Starting var:.. self = tensor<(4,), int64, cuda:0>\n",
      "                        call       576     def __iter__(self):\n",
      "                        line       583         relevant_args = (self,)\n",
      "        New var:....... relevant_args = (tensor<(4,), int64, cuda:0>,)\n",
      "                        line       584         from torch.overrides import has_torch_function, handle_torch_function\n",
      "        New var:....... has_torch_function = <function has_torch_function>\n",
      "        New var:....... handle_torch_function = <function handle_torch_function>\n",
      "                        line       585         if type(self) is not Tensor and has_torch_function(relevant_args):\n",
      "                        line       587         if self.dim() == 0:\n",
      "                        line       589         if torch._C._get_tracing_state():\n",
      "                        line       594         return iter(self.unbind(0))\n",
      "                        return     594         return iter(self.unbind(0))\n",
      "        Return value:.. <tuple_iterator object>\n",
      "        Starting var:.. self = tensor<(4,), float32, cuda:0, grad>\n",
      "                        call       576     def __iter__(self):\n",
      "                        line       583         relevant_args = (self,)\n",
      "        New var:....... relevant_args = (tensor<(4,), float32, cuda:0, grad>,)\n",
      "                        line       584         from torch.overrides import has_torch_function, handle_torch_function\n",
      "        New var:....... has_torch_function = <function has_torch_function>\n",
      "        New var:....... handle_torch_function = <function handle_torch_function>\n",
      "                        line       585         if type(self) is not Tensor and has_torch_function(relevant_args):\n",
      "                        line       587         if self.dim() == 0:\n",
      "                        line       589         if torch._C._get_tracing_state():\n",
      "                        line       594         return iter(self.unbind(0))\n",
      "                        return     594         return iter(self.unbind(0))\n",
      "        Return value:.. <tuple_iterator object>\n",
      "        Starting var:.. self = tensor<(4,), int64, cuda:0>\n",
      "                        call       576     def __iter__(self):\n",
      "                        line       583         relevant_args = (self,)\n",
      "        New var:....... relevant_args = (tensor<(4,), int64, cuda:0>,)\n",
      "                        line       584         from torch.overrides import has_torch_function, handle_torch_function\n",
      "        New var:....... has_torch_function = <function has_torch_function>\n",
      "        New var:....... handle_torch_function = <function handle_torch_function>\n",
      "                        line       585         if type(self) is not Tensor and has_torch_function(relevant_args):\n",
      "                        line       587         if self.dim() == 0:\n",
      "                        line       589         if torch._C._get_tracing_state():\n",
      "                        line       594         return iter(self.unbind(0))\n",
      "                        return     594         return iter(self.unbind(0))\n",
      "        Return value:.. <tuple_iterator object>\n",
      "    Source path:... generation_beam_search.py\n",
      "                    line       233             for beam_token_rank, (next_token, next_score, next_index) in enumerate(\n",
      "    New var:....... beam_token_rank = 0\n",
      "    New var:....... next_token = tensor<(), int64, cuda:0>\n",
      "    New var:....... next_score = tensor<(), float32, cuda:0, grad>\n",
      "    New var:....... next_index = tensor<(), int64, cuda:0>\n",
      "                    line       236                 batch_beam_idx = batch_idx * self.group_size + next_index\n",
      "    New var:....... batch_beam_idx = tensor<(), int64, cuda:0>\n",
      "                    line       238                 if (eos_token_id is not None) and (next_token.item() == eos_token_id):\n",
      "                    line       249                     next_beam_scores[batch_idx, beam_idx] = next_score\n",
      "    Modified var:.. next_beam_scores = tensor<(1, 2), float32, cuda:0, grad>\n",
      "                    line       250                     next_beam_tokens[batch_idx, beam_idx] = next_token\n",
      "                    line       251                     next_beam_indices[batch_idx, beam_idx] = batch_beam_idx\n",
      "                    line       252                     beam_idx += 1\n",
      "    Modified var:.. beam_idx = 1\n",
      "                    line       255                 if beam_idx == self.group_size:\n",
      "                    line       233             for beam_token_rank, (next_token, next_score, next_index) in enumerate(\n",
      "    Modified var:.. beam_token_rank = 1\n",
      "                    line       236                 batch_beam_idx = batch_idx * self.group_size + next_index\n",
      "                    line       238                 if (eos_token_id is not None) and (next_token.item() == eos_token_id):\n",
      "                    line       249                     next_beam_scores[batch_idx, beam_idx] = next_score\n",
      "                    line       250                     next_beam_tokens[batch_idx, beam_idx] = next_token\n",
      "                    line       251                     next_beam_indices[batch_idx, beam_idx] = batch_beam_idx\n",
      "                    line       252                     beam_idx += 1\n",
      "    Modified var:.. beam_idx = 2\n",
      "                    line       255                 if beam_idx == self.group_size:\n",
      "                    line       256                     break\n",
      "                    line       258             if beam_idx < self.group_size:\n",
      "                    line       264             self._done[batch_idx] = self._done[batch_idx] or beam_hyp.is_done(\n",
      "                    line       265                 next_scores[batch_idx].max().item(), cur_len\n",
      "                    line       264             self._done[batch_idx] = self._done[batch_idx] or beam_hyp.is_done(\n",
      "        Starting var:.. self = <transformers.generation_beam_search.BeamHypotheses object>\n",
      "        Starting var:.. best_sum_logprobs = -1.223442792892456\n",
      "        Starting var:.. cur_len = 1\n",
      "                        call       371     def is_done(self, best_sum_logprobs: float, cur_len: int) -> bool:\n",
      "                        line       377         if len(self) < self.num_beams:\n",
      "                        line       378             return False\n",
      "                        return     378             return False\n",
      "        Return value:.. False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                    line       217         for batch_idx, beam_hyp in enumerate(self._beam_hyps):\n",
      "                    line       268         return UserDict(\n",
      "                    line       270                 \"next_beam_scores\": next_beam_scores.view(-1),\n",
      "                    line       271                 \"next_beam_tokens\": next_beam_tokens.view(-1),\n",
      "                    line       272                 \"next_beam_indices\": next_beam_indices.view(-1),\n",
      "                    line       269             {\n",
      "                    line       268         return UserDict(\n",
      "        Source path:... __init__.py\n",
      "        Starting var:.. args = REPR FAILED\n",
      "        Starting var:.. kwargs = {}\n",
      "                        call       981     def __init__(*args, **kwargs):\n",
      "                        line       982         if not args:\n",
      "                        line       985         self, *args = args\n",
      "        Modified var:.. args = [{'next_beam_scores': tensor<(2,), float32, cuda:0, grad>, 'next_beam_tokens': tensor<(2,), int64, cuda:0>, 'next_beam_indices': tensor<(2,), int64, cuda:0>}]\n",
      "        New var:....... self = REPR FAILED\n",
      "                        line       986         if len(args) > 1:\n",
      "                        line       988         if args:\n",
      "                        line       989             dict = args[0]\n",
      "        New var:....... dict = {'next_beam_scores': tensor<(2,), float32, cuda:0, grad>, 'next_beam_tokens': tensor<(2,), int64, cuda:0>, 'next_beam_indices': tensor<(2,), int64, cuda:0>}\n",
      "                        line       997         self.data = {}\n",
      "        Modified var:.. self = {}\n",
      "                        line       998         if dict is not None:\n",
      "                        line       999             self.update(dict)\n",
      "        Modified var:.. self = {'next_beam_scores': tensor([-1.2234, -1.6809], device='cuda:0', grad_fn=<ViewBackward>), 'next_be...kens': tensor([3227,  125], device='cuda:0'), 'next_beam_indices': tensor([0, 0], device='cuda:0')}\n",
      "                        line      1000         if kwargs:\n",
      "                        return    1000         if kwargs:\n",
      "        Return value:.. None\n",
      "    Source path:... generation_beam_search.py\n",
      "                    return     268         return UserDict(\n",
      "    Return value:.. {'next_beam_scores': tensor([-1.2234, -1.6809], device='cuda:0', grad_fn=<ViewBackward>), 'next_be...kens': tensor([3227,  125], device='cuda:0'), 'next_beam_indices': tensor([0, 0], device='cuda:0')}\n",
      "Source path:... generation_utils.py\n",
      "New var:....... beam_outputs = {'next_beam_scores': tensor([-1.2234, -1.6809], device='cuda:0', grad_fn=<ViewBackward>), 'next_be...kens': tensor([3227,  125], device='cuda:0'), 'next_beam_indices': tensor([0, 0], device='cuda:0')}\n",
      "                line      1789             beam_scores = beam_outputs[\"next_beam_scores\"]\n",
      "    Source path:... __init__.py\n",
      "    Starting var:.. self = {'next_beam_scores': tensor([-1.2234, -1.6809], device='cuda:0', grad_fn=<ViewBackward>), 'next_be...kens': tensor([3227,  125], device='cuda:0'), 'next_beam_indices': tensor([0, 0], device='cuda:0')}\n",
      "    Starting var:.. key = 'next_beam_scores'\n",
      "                    call      1005     def __getitem__(self, key):\n",
      "                    line      1006         if key in self.data:\n",
      "                    line      1007             return self.data[key]\n",
      "                    return    1007             return self.data[key]\n",
      "    Return value:.. tensor<(2,), float32, cuda:0, grad>\n",
      "Source path:... generation_utils.py\n",
      "Modified var:.. beam_scores = tensor<(2,), float32, cuda:0, grad>\n",
      "                line      1790             beam_next_tokens = beam_outputs[\"next_beam_tokens\"]\n",
      "    Source path:... __init__.py\n",
      "    Starting var:.. self = {'next_beam_scores': tensor([-1.2234, -1.6809], device='cuda:0', grad_fn=<ViewBackward>), 'next_be...kens': tensor([3227,  125], device='cuda:0'), 'next_beam_indices': tensor([0, 0], device='cuda:0')}\n",
      "    Starting var:.. key = 'next_beam_tokens'\n",
      "                    call      1005     def __getitem__(self, key):\n",
      "                    line      1006         if key in self.data:\n",
      "                    line      1007             return self.data[key]\n",
      "                    return    1007             return self.data[key]\n",
      "    Return value:.. tensor<(2,), int64, cuda:0>\n",
      "Source path:... generation_utils.py\n",
      "New var:....... beam_next_tokens = tensor<(2,), int64, cuda:0>\n",
      "                line      1791             beam_idx = beam_outputs[\"next_beam_indices\"]\n",
      "    Source path:... __init__.py\n",
      "    Starting var:.. self = {'next_beam_scores': tensor([-1.2234, -1.6809], device='cuda:0', grad_fn=<ViewBackward>), 'next_be...kens': tensor([3227,  125], device='cuda:0'), 'next_beam_indices': tensor([0, 0], device='cuda:0')}\n",
      "    Starting var:.. key = 'next_beam_indices'\n",
      "                    call      1005     def __getitem__(self, key):\n",
      "                    line      1006         if key in self.data:\n",
      "                    line      1007             return self.data[key]\n",
      "                    return    1007             return self.data[key]\n",
      "    Return value:.. tensor<(2,), int64, cuda:0>\n",
      "Source path:... generation_utils.py\n",
      "New var:....... beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                line      1793             input_ids = torch.cat([input_ids[beam_idx, :], beam_next_tokens.unsqueeze(-1)], dim=-1)\n",
      "Modified var:.. input_ids = tensor<(2, 2), int64, cuda:0>\n",
      "                line      1795             cur_len = cur_len + 1\n",
      "Modified var:.. cur_len = 2\n",
      "                line      1797             model_kwargs = self._update_model_kwargs_for_generation(\n",
      "                line      1798                 outputs, model_kwargs, is_encoder_decoder=self.config.is_encoder_decoder\n",
      "                line      1797             model_kwargs = self._update_model_kwargs_for_generation(\n",
      "    Starting var:.. outputs = {'logits': tensor<(2, 1, 96103), float32, cuda:0, grad>, 'past_key_values': ((tensor<(2, 16, 1, 64...float32, cuda:0, grad>)), 'encoder_last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0, grad>}\n",
      "    Starting var:.. model_kwargs = {'use_cache': None, 'attention_mask': tensor<(2, 6), int64, cuda:0>, 'encoder_outputs': {'last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0, grad>}}\n",
      "    Starting var:.. is_encoder_decoder = True\n",
      "                    call       511     def _update_model_kwargs_for_generation(\n",
      "                    line       515         if \"past_key_values\" in outputs:\n",
      "                    line       516             model_kwargs[\"past\"] = outputs.past_key_values\n",
      "    Modified var:.. model_kwargs = {'use_cache': None, 'attention_mask': tensor<(2, 6), int64, cuda:0>, 'encoder_outputs': {'last_hid...d>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>))}\n",
      "                    line       525         if \"token_type_ids\" in model_kwargs:\n",
      "                    line       530         if not is_encoder_decoder:\n",
      "                    line       537         return model_kwargs\n",
      "                    return     537         return model_kwargs\n",
      "    Return value:.. {'use_cache': None, 'attention_mask': tensor<(2, 6), int64, cuda:0>, 'encoder_outputs': {'last_hid...d>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>))}\n",
      "Modified var:.. model_kwargs = {'use_cache': None, 'attention_mask': tensor<(2, 6), int64, cuda:0>, 'encoder_outputs': {'last_hid...d>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>))}\n",
      "                line      1800             if model_kwargs[\"past\"] is not None:\n",
      "                line      1801                 model_kwargs[\"past\"] = self._reorder_cache(model_kwargs[\"past\"], beam_idx)\n",
      "    Source path:... modeling_pegasus.py\n",
      "    Starting var:.. past = ((tensor<(2, 16, 1, 64), float32, cuda:0, grad>, tensor<(2, 16, 1, 64), float32, cuda:0, grad>, te...ad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>))\n",
      "    Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                    call      1333     def _reorder_cache(past, beam_idx):\n",
      "                    line      1334         reordered_past = ()\n",
      "    New var:....... reordered_past = ()\n",
      "                    line      1335         for layer_past in past:\n",
      "    New var:....... layer_past = (tensor<(2, 16, 1, 64), float32, cuda:0, grad>, tensor<(2, 16, 1, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>)\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 1, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 1, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 1, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 1, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 1, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "    Modified var:.. reordered_past = ((tensor<(2, 16, 1, 64), float32, cuda:0, grad>, tensor<(2, 16, 1, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>),)\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 1, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 1, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 1, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 1, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 1, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    Modified var:.. reordered_past = ((tensor<(2, 16, 1, 64), float32, cuda:0, grad>, tensor<(2, 16, 1, 64), float32, cuda:0, grad>, te...ad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>))\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 1, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 1, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 1, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 1, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 1, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 1, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 1, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 1, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 1, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 1, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 1, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 1, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 1, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 1, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 1, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 1, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 1, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 1, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 1, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 1, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 1, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 1, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 1, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 1, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 1, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 1, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 1, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 1, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 1, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 1, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 1, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 1, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 1, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 1, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 1, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 1, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 1, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 1, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 1, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 1, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 1, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 1, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 1, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 1, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 1, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 1, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 1, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 1, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 1, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 1, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 1, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 1, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 1, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 1, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 1, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 1, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 1, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 1, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 1, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 1, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 1, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 1, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 1, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 1, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 1, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 1, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 1, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 1, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 1, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 1, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1340         return reordered_past\n",
      "                    return    1340         return reordered_past\n",
      "    Return value:.. ((tensor<(2, 16, 1, 64), float32, cuda:0, grad>, tensor<(2, 16, 1, 64), float32, cuda:0, grad>, te...ad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>))\n",
      "Source path:... generation_utils.py\n",
      "                line      1803             if beam_scorer.is_done:\n",
      "    Source path:... generation_beam_search.py\n",
      "    Starting var:.. self = <transformers.generation_beam_search.BeamSearchScorer object>\n",
      "                    call       196     def is_done(self) -> bool:\n",
      "                    line       197         return self._done.all()\n",
      "                    return     197         return self._done.all()\n",
      "    Return value:.. tensor<(), bool, cuda:0>\n",
      "Source path:... generation_utils.py\n",
      "                line      1806             if stopping_criteria(input_ids, scores):\n",
      "    Source path:... generation_stopping_criteria.py\n",
      "    Starting var:.. self = [<transformers.generation_stopping_criteria.MaxLengthCriteria object>]\n",
      "    Starting var:.. input_ids = tensor<(2, 2), int64, cuda:0>\n",
      "    Starting var:.. scores = (tensor<(2, 96103), float32, cuda:0, grad>,)\n",
      "    Starting var:.. kwargs = {}\n",
      "                    call        83     def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor, **kwargs) -> bool:\n",
      "                    line        84         return any(criteria(input_ids, scores) for criteria in self)\n",
      "        Starting var:.. .0 = <list_iterator object>\n",
      "        Starting var:.. input_ids = tensor<(2, 2), int64, cuda:0>\n",
      "        Starting var:.. scores = (tensor<(2, 96103), float32, cuda:0, grad>,)\n",
      "                        call        84         return any(criteria(input_ids, scores) for criteria in self)\n",
      "                        line        84         return any(criteria(input_ids, scores) for criteria in self)\n",
      "        New var:....... criteria = <transformers.generation_stopping_criteria.MaxLengthCriteria object>\n",
      "                        return      84         return any(criteria(input_ids, scores) for criteria in self)\n",
      "        Return value:.. False\n",
      "        Starting var:.. .0 = <list_iterator object>\n",
      "        Starting var:.. criteria = <transformers.generation_stopping_criteria.MaxLengthCriteria object>\n",
      "        Starting var:.. input_ids = tensor<(2, 2), int64, cuda:0>\n",
      "        Starting var:.. scores = (tensor<(2, 96103), float32, cuda:0, grad>,)\n",
      "                        call        84         return any(criteria(input_ids, scores) for criteria in self)\n",
      "                        line        84         return any(criteria(input_ids, scores) for criteria in self)\n",
      "                        return      84         return any(criteria(input_ids, scores) for criteria in self)\n",
      "        Return value:.. None\n",
      "                    return      84         return any(criteria(input_ids, scores) for criteria in self)\n",
      "    Return value:.. False\n",
      "Source path:... generation_utils.py\n",
      "                line      1729         while cur_len < max_length:\n",
      "                line      1730             model_inputs = self.prepare_inputs_for_generation(input_ids, **model_kwargs)\n",
      "    Source path:... modeling_pegasus.py\n",
      "    Starting var:.. self = PegasusForConditionalGeneration(  (model): PegasusModel(    (shared): Embedding(96103, 1024, paddi...mentwise_affine=True)    )  )  (lm_head): Linear(in_features=1024, out_features=96103, bias=False))\n",
      "    Starting var:.. decoder_input_ids = tensor<(2, 2), int64, cuda:0>\n",
      "    Starting var:.. past = ((tensor<(2, 16, 1, 64), float32, cuda:0, grad>, tensor<(2, 16, 1, 64), float32, cuda:0, grad>, te...ad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>))\n",
      "    Starting var:.. attention_mask = tensor<(2, 6), int64, cuda:0>\n",
      "    Starting var:.. head_mask = None\n",
      "    Starting var:.. use_cache = None\n",
      "    Starting var:.. encoder_outputs = {'last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0, grad>}\n",
      "    Starting var:.. kwargs = {}\n",
      "                    call      1305     def prepare_inputs_for_generation(\n",
      "                    line      1316         if past is not None:\n",
      "                    line      1317             decoder_input_ids = decoder_input_ids[:, -1:]\n",
      "    Modified var:.. decoder_input_ids = tensor<(2, 1), int64, cuda:0>\n",
      "                    line      1320             \"input_ids\": None,  # encoder_outputs is defined. input_ids not needed\n",
      "                    line      1321             \"encoder_outputs\": encoder_outputs,\n",
      "                    line      1322             \"past_key_values\": past,\n",
      "                    line      1323             \"decoder_input_ids\": decoder_input_ids,\n",
      "                    line      1324             \"attention_mask\": attention_mask,\n",
      "                    line      1325             \"head_mask\": head_mask,\n",
      "                    line      1326             \"use_cache\": use_cache,  # change this to avoid caching (presumably for debugging)\n",
      "                    line      1319         return {\n",
      "                    return    1319         return {\n",
      "    Return value:.. {'input_ids': None, 'encoder_outputs': {'last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0,...64, cuda:0>, 'attention_mask': tensor<(2, 6), int64, cuda:0>, 'head_mask': None, 'use_cache': None}\n",
      "Source path:... generation_utils.py\n",
      "                line      1732             outputs = self(\n",
      "                line      1733                 **model_inputs,\n",
      "                line      1734                 return_dict=True,\n",
      "                line      1735                 output_attentions=output_attentions,\n",
      "                line      1736                 output_hidden_states=output_hidden_states,\n",
      "                line      1732             outputs = self(\n",
      "    Source path:... module.py\n",
      "    Starting var:.. self = PegasusForConditionalGeneration(  (model): PegasusModel(    (shared): Embedding(96103, 1024, paddi...mentwise_affine=True)    )  )  (lm_head): Linear(in_features=1024, out_features=96103, bias=False))\n",
      "    Starting var:.. input = ()\n",
      "    Starting var:.. kwargs = {'input_ids': None, 'encoder_outputs': {'last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0,... 'use_cache': None, 'return_dict': True, 'output_attentions': False, 'output_hidden_states': False}\n",
      "                    call       715     def _call_impl(self, *input, **kwargs):\n",
      "                    line       716         for hook in itertools.chain(\n",
      "                    line       717                 _global_forward_pre_hooks.values(),\n",
      "                    line       718                 self._forward_pre_hooks.values()):\n",
      "                    line       716         for hook in itertools.chain(\n",
      "                    line       724         if torch._C._get_tracing_state():\n",
      "                    line       727             result = self.forward(*input, **kwargs)\n",
      "        Source path:... modeling_pegasus.py\n",
      "        Starting var:.. self = PegasusForConditionalGeneration(  (model): PegasusModel(    (shared): Embedding(96103, 1024, paddi...mentwise_affine=True)    )  )  (lm_head): Linear(in_features=1024, out_features=96103, bias=False))\n",
      "        Starting var:.. input_ids = None\n",
      "        Starting var:.. attention_mask = tensor<(2, 6), int64, cuda:0>\n",
      "        Starting var:.. decoder_input_ids = tensor<(2, 1), int64, cuda:0>\n",
      "        Starting var:.. decoder_attention_mask = None\n",
      "        Starting var:.. head_mask = None\n",
      "        Starting var:.. decoder_head_mask = None\n",
      "        Starting var:.. encoder_outputs = {'last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0, grad>}\n",
      "        Starting var:.. past_key_values = ((tensor<(2, 16, 1, 64), float32, cuda:0, grad>, tensor<(2, 16, 1, 64), float32, cuda:0, grad>, te...ad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>))\n",
      "        Starting var:.. inputs_embeds = None\n",
      "        Starting var:.. decoder_inputs_embeds = None\n",
      "        Starting var:.. labels = None\n",
      "        Starting var:.. use_cache = None\n",
      "        Starting var:.. output_attentions = False\n",
      "        Starting var:.. output_hidden_states = False\n",
      "        Starting var:.. return_dict = True\n",
      "                        call      1231     def forward(\n",
      "                        line      1258         return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
      "                        line      1260         if labels is not None:\n",
      "                        line      1266         outputs = self.model(\n",
      "                        line      1267             input_ids,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                        line      1268             attention_mask=attention_mask,\n",
      "                        line      1269             decoder_input_ids=decoder_input_ids,\n",
      "                        line      1270             encoder_outputs=encoder_outputs,\n",
      "                        line      1271             decoder_attention_mask=decoder_attention_mask,\n",
      "                        line      1272             head_mask=head_mask,\n",
      "                        line      1273             decoder_head_mask=decoder_head_mask,\n",
      "                        line      1274             past_key_values=past_key_values,\n",
      "                        line      1275             inputs_embeds=inputs_embeds,\n",
      "                        line      1276             decoder_inputs_embeds=decoder_inputs_embeds,\n",
      "                        line      1277             use_cache=use_cache,\n",
      "                        line      1278             output_attentions=output_attentions,\n",
      "                        line      1279             output_hidden_states=output_hidden_states,\n",
      "                        line      1280             return_dict=return_dict,\n",
      "                        line      1266         outputs = self.model(\n",
      "        New var:....... outputs = {'last_hidden_state': tensor<(2, 1, 1024), float32, cuda:0, grad>, 'past_key_values': ((tensor<(2,...float32, cuda:0, grad>)), 'encoder_last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0, grad>}\n",
      "                        line      1282         lm_logits = self.lm_head(outputs[0]) + self.final_logits_bias\n",
      "        New var:....... lm_logits = tensor<(2, 1, 96103), float32, cuda:0, grad>\n",
      "                        line      1284         masked_lm_loss = None\n",
      "        New var:....... masked_lm_loss = None\n",
      "                        line      1285         if labels is not None:\n",
      "                        line      1289         if not return_dict:\n",
      "                        line      1293         return Seq2SeqLMOutput(\n",
      "                        line      1294             loss=masked_lm_loss,\n",
      "                        line      1295             logits=lm_logits,\n",
      "                        line      1296             past_key_values=outputs.past_key_values,\n",
      "                        line      1297             decoder_hidden_states=outputs.decoder_hidden_states,\n",
      "                        line      1298             decoder_attentions=outputs.decoder_attentions,\n",
      "                        line      1299             cross_attentions=outputs.cross_attentions,\n",
      "                        line      1300             encoder_last_hidden_state=outputs.encoder_last_hidden_state,\n",
      "                        line      1301             encoder_hidden_states=outputs.encoder_hidden_states,\n",
      "                        line      1302             encoder_attentions=outputs.encoder_attentions,\n",
      "                        line      1293         return Seq2SeqLMOutput(\n",
      "                        return    1293         return Seq2SeqLMOutput(\n",
      "        Return value:.. {'logits': tensor<(2, 1, 96103), float32, cuda:0, grad>, 'past_key_values': ((tensor<(2, 16, 2, 64...float32, cuda:0, grad>)), 'encoder_last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0, grad>}\n",
      "    Source path:... module.py\n",
      "    New var:....... result = {'logits': tensor<(2, 1, 96103), float32, cuda:0, grad>, 'past_key_values': ((tensor<(2, 16, 2, 64...float32, cuda:0, grad>)), 'encoder_last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0, grad>}\n",
      "                    line       728         for hook in itertools.chain(\n",
      "                    line       729                 _global_forward_hooks.values(),\n",
      "                    line       730                 self._forward_hooks.values()):\n",
      "                    line       728         for hook in itertools.chain(\n",
      "                    line       734         if (len(self._backward_hooks) > 0) or (len(_global_backward_hooks) > 0):\n",
      "                    line       749         return result\n",
      "                    return     749         return result\n",
      "    Return value:.. {'logits': tensor<(2, 1, 96103), float32, cuda:0, grad>, 'past_key_values': ((tensor<(2, 16, 2, 64...float32, cuda:0, grad>)), 'encoder_last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0, grad>}\n",
      "Source path:... generation_utils.py\n",
      "Modified var:.. outputs = {'logits': tensor<(2, 1, 96103), float32, cuda:0, grad>, 'past_key_values': ((tensor<(2, 16, 2, 64...float32, cuda:0, grad>)), 'encoder_last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0, grad>}\n",
      "                line      1738             next_token_logits = outputs.logits[:, -1, :]\n",
      "                line      1742             next_token_logits = self.adjust_logits_during_generation(\n",
      "                line      1743                 next_token_logits, cur_len=cur_len, max_length=max_length\n",
      "                line      1742             next_token_logits = self.adjust_logits_during_generation(\n",
      "    Starting var:.. self = PegasusForConditionalGeneration(  (model): PegasusModel(    (shared): Embedding(96103, 1024, paddi...mentwise_affine=True)    )  )  (lm_head): Linear(in_features=1024, out_features=96103, bias=False))\n",
      "    Starting var:.. logits = tensor<(2, 96103), float32, cuda:0, grad>\n",
      "    Starting var:.. kwargs = {'cur_len': 2, 'max_length': 60}\n",
      "                    call       373     def adjust_logits_during_generation(self, logits: torch.FloatTensor, **kwargs) -> torch.FloatTensor:\n",
      "                    line       378         return logits\n",
      "                    return     378         return logits\n",
      "    Return value:.. tensor<(2, 96103), float32, cuda:0, grad>\n",
      "                line      1746             next_token_scores = F.log_softmax(next_token_logits, dim=-1)  # (batch_size * num_beams, vocab_size)\n",
      "    Source path:... functional.py\n",
      "    Starting var:.. input = tensor<(2, 96103), float32, cuda:0, grad>\n",
      "    Starting var:.. dim = -1\n",
      "    Starting var:.. _stacklevel = 3\n",
      "    Starting var:.. dtype = None\n",
      "                    call      1581 def log_softmax(input, dim=None, _stacklevel=3, dtype=None):\n",
      "                    line      1598     if not torch.jit.is_scripting():\n",
      "        Source path:... _jit_internal.py\n",
      "                        call       750 def is_scripting():\n",
      "                        line       769     return False\n",
      "                        return     769     return False\n",
      "        Return value:.. False\n",
      "    Source path:... functional.py\n",
      "                    line      1599         if type(input) is not Tensor and has_torch_function((input,)):\n",
      "                    line      1602     if dim is None:\n",
      "                    line      1604     if dtype is None:\n",
      "                    line      1605         ret = input.log_softmax(dim)\n",
      "    New var:....... ret = tensor<(2, 96103), float32, cuda:0, grad>\n",
      "                    line      1608     return ret\n",
      "                    return    1608     return ret\n",
      "    Return value:.. tensor<(2, 96103), float32, cuda:0, grad>\n",
      "Source path:... generation_utils.py\n",
      "Modified var:.. next_token_scores = tensor<(2, 96103), float32, cuda:0, grad>\n",
      "                line      1748             next_token_scores = logits_processor(input_ids, next_token_scores)\n",
      "    Source path:... generation_logits_process.py\n",
      "    Starting var:.. self = [<transformers.generation_logits_process.MinLengthLogitsProcessor object>, <transformers.generation_logits_process.ForcedEOSTokenLogitsProcessor object>]\n",
      "    Starting var:.. input_ids = tensor<(2, 2), int64, cuda:0>\n",
      "    Starting var:.. scores = tensor<(2, 96103), float32, cuda:0, grad>\n",
      "    Starting var:.. kwargs = {}\n",
      "                    call        84     def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor, **kwargs) -> torch.FloatTensor:\n",
      "                    line        85         for processor in self:\n",
      "    New var:....... processor = <transformers.generation_logits_process.MinLengthLogitsProcessor object>\n",
      "                    line        86             function_args = inspect.signature(processor.__call__).parameters\n",
      "        Source path:... inspect.py\n",
      "        Starting var:.. obj = <bound method MinLengthLogitsProcessor.__call__ of <transformers.generation_logits_process.MinLengthLogitsProcessor object>>\n",
      "        Starting var:.. follow_wrapped = True\n",
      "                        call      3091 def signature(obj, *, follow_wrapped=True):\n",
      "                        line      3093     return Signature.from_callable(obj, follow_wrapped=follow_wrapped)\n",
      "                        return    3093     return Signature.from_callable(obj, follow_wrapped=follow_wrapped)\n",
      "        Return value:.. <Signature (input_ids: torch.LongTensor, scores: torch.FloatTensor) -> torch.FloatTensor>\n",
      "        Starting var:.. self = <Signature (input_ids: torch.LongTensor, scores: torch.FloatTensor) -> torch.FloatTensor>\n",
      "                        call      2846     def parameters(self):\n",
      "                        line      2847         return self._parameters\n",
      "                        return    2847         return self._parameters\n",
      "        Return value:.. mappingproxy(OrderedDict([('input_ids', <Parameter \"input_ids: torch.LongTensor\">), ('scores', <Parameter \"scores: torch.FloatTensor\">)]))\n",
      "    Source path:... generation_logits_process.py\n",
      "    New var:....... function_args = mappingproxy(OrderedDict([('input_ids', <Parameter \"input_ids: torch.LongTensor\">), ('scores', <Parameter \"scores: torch.FloatTensor\">)]))\n",
      "                    line        87             if len(function_args) > 2:\n",
      "                    line        93                 scores = processor(input_ids, scores)\n",
      "        Starting var:.. self = <transformers.generation_logits_process.MinLengthLogitsProcessor object>\n",
      "        Starting var:.. input_ids = tensor<(2, 2), int64, cuda:0>\n",
      "        Starting var:.. scores = tensor<(2, 96103), float32, cuda:0, grad>\n",
      "                        call       118     def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor) -> torch.FloatTensor:\n",
      "                        line       119         cur_len = input_ids.shape[-1]\n",
      "        New var:....... cur_len = 2\n",
      "                        line       120         if cur_len < self.min_length:\n",
      "                        line       122         return scores\n",
      "                        return     122         return scores\n",
      "        Return value:.. tensor<(2, 96103), float32, cuda:0, grad>\n",
      "                    line        85         for processor in self:\n",
      "    Modified var:.. processor = <transformers.generation_logits_process.ForcedEOSTokenLogitsProcessor object>\n",
      "                    line        86             function_args = inspect.signature(processor.__call__).parameters\n",
      "        Source path:... inspect.py\n",
      "        Starting var:.. obj = <bound method ForcedEOSTokenLogitsProcessor.__call__ of <transformers.generation_logits_process.ForcedEOSTokenLogitsProcessor object>>\n",
      "        Starting var:.. follow_wrapped = True\n",
      "                        call      3091 def signature(obj, *, follow_wrapped=True):\n",
      "                        line      3093     return Signature.from_callable(obj, follow_wrapped=follow_wrapped)\n",
      "                        return    3093     return Signature.from_callable(obj, follow_wrapped=follow_wrapped)\n",
      "        Return value:.. <Signature (input_ids: torch.LongTensor, scores: torch.FloatTensor) -> torch.FloatTensor>\n",
      "        Starting var:.. self = <Signature (input_ids: torch.LongTensor, scores: torch.FloatTensor) -> torch.FloatTensor>\n",
      "                        call      2846     def parameters(self):\n",
      "                        line      2847         return self._parameters\n",
      "                        return    2847         return self._parameters\n",
      "        Return value:.. mappingproxy(OrderedDict([('input_ids', <Parameter \"input_ids: torch.LongTensor\">), ('scores', <Parameter \"scores: torch.FloatTensor\">)]))\n",
      "    Source path:... generation_logits_process.py\n",
      "                    line        87             if len(function_args) > 2:\n",
      "                    line        93                 scores = processor(input_ids, scores)\n",
      "        Starting var:.. self = <transformers.generation_logits_process.ForcedEOSTokenLogitsProcessor object>\n",
      "        Starting var:.. input_ids = tensor<(2, 2), int64, cuda:0>\n",
      "        Starting var:.. scores = tensor<(2, 96103), float32, cuda:0, grad>\n",
      "                        call       571     def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor) -> torch.FloatTensor:\n",
      "                        line       572         cur_len = input_ids.shape[-1]\n",
      "        New var:....... cur_len = 2\n",
      "                        line       573         if cur_len == self.max_length - 1:\n",
      "                        line       577         return scores\n",
      "                        return     577         return scores\n",
      "        Return value:.. tensor<(2, 96103), float32, cuda:0, grad>\n",
      "                    line        85         for processor in self:\n",
      "                    line        94         return scores\n",
      "                    return      94         return scores\n",
      "    Return value:.. tensor<(2, 96103), float32, cuda:0, grad>\n",
      "Source path:... generation_utils.py\n",
      "                line      1749             next_token_scores = next_token_scores + beam_scores[:, None].expand_as(next_token_scores)\n",
      "                line      1752             if return_dict_in_generate:\n",
      "                line      1753                 if output_scores:\n",
      "                line      1754                     scores += (next_token_scores,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Modified var:.. scores = (tensor<(2, 96103), float32, cuda:0, grad>, tensor<(2, 96103), float32, cuda:0, grad>)\n",
      "                line      1755                 if output_attentions:\n",
      "                line      1762                 if output_hidden_states:\n",
      "                line      1770             vocab_size = next_token_scores.shape[-1]\n",
      "                line      1771             next_token_scores = next_token_scores.view(batch_size, num_beams * vocab_size)\n",
      "Modified var:.. next_token_scores = tensor<(1, 192206), float32, cuda:0, grad>\n",
      "                line      1773             next_token_scores, next_tokens = torch.topk(\n",
      "                line      1774                 next_token_scores, 2 * num_beams, dim=1, largest=True, sorted=True\n",
      "                line      1773             next_token_scores, next_tokens = torch.topk(\n",
      "Modified var:.. next_token_scores = tensor<(1, 4), float32, cuda:0, grad>\n",
      "                line      1777             next_indices = next_tokens // vocab_size\n",
      "    Source path:... tensor.py\n",
      "    Starting var:.. args = (tensor<(1, 4), int64, cuda:0>, 96103)\n",
      "    Starting var:.. kwargs = {}\n",
      "    Starting var:.. f = <function Tensor.__floordiv__>\n",
      "    Starting var:.. wrapped = <function Tensor.__floordiv__>\n",
      "                    call        22     def wrapped(*args, **kwargs):\n",
      "                    line        23         from torch.overrides import has_torch_function, handle_torch_function\n",
      "    New var:....... has_torch_function = <function has_torch_function>\n",
      "    New var:....... handle_torch_function = <function handle_torch_function>\n",
      "                    line        24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "                        call        24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "                        line        24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "        New var:....... t = tensor<(1, 4), int64, cuda:0>\n",
      "                        return      24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "        Return value:.. True\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. t = tensor<(1, 4), int64, cuda:0>\n",
      "                        call        24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "                        line        24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "        Modified var:.. t = 96103\n",
      "                        return      24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "        Return value:.. False\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. t = 96103\n",
      "                        call        24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "                        exception   24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "        Exception:..... GeneratorExit\n",
      "                        return      24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "        Return value:.. None\n",
      "        Source path:... overrides.py\n",
      "        Starting var:.. relevant_args = (tensor<(1, 4), int64, cuda:0>, 96103)\n",
      "                        call      1070 def has_torch_function(relevant_args: Iterable[Any]) -> bool:\n",
      "                        line      1083     return _is_torch_function_enabled() and any(\n",
      "                        line      1087         for a in relevant_args\n",
      "                        line      1083     return _is_torch_function_enabled() and any(\n",
      "                        return    1083     return _is_torch_function_enabled() and any(\n",
      "        Return value:.. False\n",
      "    Source path:... tensor.py\n",
      "                    line        26         try:\n",
      "                    line        27             return f(*args, **kwargs)\n",
      "        Starting var:.. self = tensor<(1, 4), int64, cuda:0>\n",
      "        Starting var:.. other = 96103\n",
      "                        call       550     def __floordiv__(self, other):\n",
      "                        line       551         return torch.floor_divide(self, other)\n",
      "                        return     551         return torch.floor_divide(self, other)\n",
      "        Return value:.. tensor<(1, 4), int64, cuda:0>\n",
      "                    return      27             return f(*args, **kwargs)\n",
      "    Return value:.. tensor<(1, 4), int64, cuda:0>\n",
      "Source path:... generation_utils.py\n",
      "                line      1778             next_tokens = next_tokens % vocab_size\n",
      "                line      1781             beam_outputs = beam_scorer.process(\n",
      "                line      1782                 input_ids,\n",
      "                line      1783                 next_token_scores,\n",
      "                line      1784                 next_tokens,\n",
      "                line      1785                 next_indices,\n",
      "                line      1786                 pad_token_id=pad_token_id,\n",
      "                line      1787                 eos_token_id=eos_token_id,\n",
      "                line      1781             beam_outputs = beam_scorer.process(\n",
      "    Source path:... generation_beam_search.py\n",
      "    Starting var:.. self = <transformers.generation_beam_search.BeamSearchScorer object>\n",
      "    Starting var:.. input_ids = tensor<(2, 2), int64, cuda:0>\n",
      "    Starting var:.. next_scores = tensor<(1, 4), float32, cuda:0, grad>\n",
      "    Starting var:.. next_tokens = tensor<(1, 4), int64, cuda:0>\n",
      "    Starting var:.. next_indices = tensor<(1, 4), int64, cuda:0>\n",
      "    Starting var:.. pad_token_id = 0\n",
      "    Starting var:.. eos_token_id = 1\n",
      "                    call       199     def process(\n",
      "                    line       208         cur_len = input_ids.shape[-1]\n",
      "    New var:....... cur_len = 2\n",
      "                    line       209         batch_size = len(self._beam_hyps)\n",
      "    New var:....... batch_size = 1\n",
      "                    line       210         assert batch_size == (input_ids.shape[0] // self.group_size)\n",
      "                    line       212         device = input_ids.device\n",
      "    New var:....... device = device(type='cuda', index=0)\n",
      "                    line       213         next_beam_scores = torch.zeros((batch_size, self.group_size), dtype=next_scores.dtype, device=device)\n",
      "    New var:....... next_beam_scores = tensor<(1, 2), float32, cuda:0>\n",
      "                    line       214         next_beam_tokens = torch.zeros((batch_size, self.group_size), dtype=next_tokens.dtype, device=device)\n",
      "    New var:....... next_beam_tokens = tensor<(1, 2), int64, cuda:0>\n",
      "                    line       215         next_beam_indices = torch.zeros((batch_size, self.group_size), dtype=next_indices.dtype, device=device)\n",
      "    New var:....... next_beam_indices = tensor<(1, 2), int64, cuda:0>\n",
      "                    line       217         for batch_idx, beam_hyp in enumerate(self._beam_hyps):\n",
      "    New var:....... batch_idx = 0\n",
      "    New var:....... beam_hyp = <transformers.generation_beam_search.BeamHypotheses object>\n",
      "                    line       218             if self._done[batch_idx]:\n",
      "                    line       232             beam_idx = 0\n",
      "    New var:....... beam_idx = 0\n",
      "                    line       233             for beam_token_rank, (next_token, next_score, next_index) in enumerate(\n",
      "                    line       234                 zip(next_tokens[batch_idx], next_scores[batch_idx], next_indices[batch_idx])\n",
      "        Source path:... tensor.py\n",
      "        Starting var:.. self = tensor<(4,), int64, cuda:0>\n",
      "                        call       576     def __iter__(self):\n",
      "                        line       583         relevant_args = (self,)\n",
      "        New var:....... relevant_args = (tensor<(4,), int64, cuda:0>,)\n",
      "                        line       584         from torch.overrides import has_torch_function, handle_torch_function\n",
      "        New var:....... has_torch_function = <function has_torch_function>\n",
      "        New var:....... handle_torch_function = <function handle_torch_function>\n",
      "                        line       585         if type(self) is not Tensor and has_torch_function(relevant_args):\n",
      "                        line       587         if self.dim() == 0:\n",
      "                        line       589         if torch._C._get_tracing_state():\n",
      "                        line       594         return iter(self.unbind(0))\n",
      "                        return     594         return iter(self.unbind(0))\n",
      "        Return value:.. <tuple_iterator object>\n",
      "        Starting var:.. self = tensor<(4,), float32, cuda:0, grad>\n",
      "                        call       576     def __iter__(self):\n",
      "                        line       583         relevant_args = (self,)\n",
      "        New var:....... relevant_args = (tensor<(4,), float32, cuda:0, grad>,)\n",
      "                        line       584         from torch.overrides import has_torch_function, handle_torch_function\n",
      "        New var:....... has_torch_function = <function has_torch_function>\n",
      "        New var:....... handle_torch_function = <function handle_torch_function>\n",
      "                        line       585         if type(self) is not Tensor and has_torch_function(relevant_args):\n",
      "                        line       587         if self.dim() == 0:\n",
      "                        line       589         if torch._C._get_tracing_state():\n",
      "                        line       594         return iter(self.unbind(0))\n",
      "                        return     594         return iter(self.unbind(0))\n",
      "        Return value:.. <tuple_iterator object>\n",
      "        Starting var:.. self = tensor<(4,), int64, cuda:0>\n",
      "                        call       576     def __iter__(self):\n",
      "                        line       583         relevant_args = (self,)\n",
      "        New var:....... relevant_args = (tensor<(4,), int64, cuda:0>,)\n",
      "                        line       584         from torch.overrides import has_torch_function, handle_torch_function\n",
      "        New var:....... has_torch_function = <function has_torch_function>\n",
      "        New var:....... handle_torch_function = <function handle_torch_function>\n",
      "                        line       585         if type(self) is not Tensor and has_torch_function(relevant_args):\n",
      "                        line       587         if self.dim() == 0:\n",
      "                        line       589         if torch._C._get_tracing_state():\n",
      "                        line       594         return iter(self.unbind(0))\n",
      "                        return     594         return iter(self.unbind(0))\n",
      "        Return value:.. <tuple_iterator object>\n",
      "    Source path:... generation_beam_search.py\n",
      "                    line       233             for beam_token_rank, (next_token, next_score, next_index) in enumerate(\n",
      "    New var:....... beam_token_rank = 0\n",
      "    New var:....... next_token = tensor<(), int64, cuda:0>\n",
      "    New var:....... next_score = tensor<(), float32, cuda:0, grad>\n",
      "    New var:....... next_index = tensor<(), int64, cuda:0>\n",
      "                    line       236                 batch_beam_idx = batch_idx * self.group_size + next_index\n",
      "    New var:....... batch_beam_idx = tensor<(), int64, cuda:0>\n",
      "                    line       238                 if (eos_token_id is not None) and (next_token.item() == eos_token_id):\n",
      "                    line       249                     next_beam_scores[batch_idx, beam_idx] = next_score\n",
      "    Modified var:.. next_beam_scores = tensor<(1, 2), float32, cuda:0, grad>\n",
      "                    line       250                     next_beam_tokens[batch_idx, beam_idx] = next_token\n",
      "                    line       251                     next_beam_indices[batch_idx, beam_idx] = batch_beam_idx\n",
      "                    line       252                     beam_idx += 1\n",
      "    Modified var:.. beam_idx = 1\n",
      "                    line       255                 if beam_idx == self.group_size:\n",
      "                    line       233             for beam_token_rank, (next_token, next_score, next_index) in enumerate(\n",
      "    Modified var:.. beam_token_rank = 1\n",
      "                    line       236                 batch_beam_idx = batch_idx * self.group_size + next_index\n",
      "                    line       238                 if (eos_token_id is not None) and (next_token.item() == eos_token_id):\n",
      "                    line       249                     next_beam_scores[batch_idx, beam_idx] = next_score\n",
      "                    line       250                     next_beam_tokens[batch_idx, beam_idx] = next_token\n",
      "                    line       251                     next_beam_indices[batch_idx, beam_idx] = batch_beam_idx\n",
      "                    line       252                     beam_idx += 1\n",
      "    Modified var:.. beam_idx = 2\n",
      "                    line       255                 if beam_idx == self.group_size:\n",
      "                    line       256                     break\n",
      "                    line       258             if beam_idx < self.group_size:\n",
      "                    line       264             self._done[batch_idx] = self._done[batch_idx] or beam_hyp.is_done(\n",
      "                    line       265                 next_scores[batch_idx].max().item(), cur_len\n",
      "                    line       264             self._done[batch_idx] = self._done[batch_idx] or beam_hyp.is_done(\n",
      "        Starting var:.. self = <transformers.generation_beam_search.BeamHypotheses object>\n",
      "        Starting var:.. best_sum_logprobs = -1.4722709655761719\n",
      "        Starting var:.. cur_len = 2\n",
      "                        call       371     def is_done(self, best_sum_logprobs: float, cur_len: int) -> bool:\n",
      "                        line       377         if len(self) < self.num_beams:\n",
      "                        line       378             return False\n",
      "                        return     378             return False\n",
      "        Return value:.. False\n",
      "                    line       217         for batch_idx, beam_hyp in enumerate(self._beam_hyps):\n",
      "                    line       268         return UserDict(\n",
      "                    line       270                 \"next_beam_scores\": next_beam_scores.view(-1),\n",
      "                    line       271                 \"next_beam_tokens\": next_beam_tokens.view(-1),\n",
      "                    line       272                 \"next_beam_indices\": next_beam_indices.view(-1),\n",
      "                    line       269             {\n",
      "                    line       268         return UserDict(\n",
      "        Source path:... __init__.py\n",
      "        Starting var:.. args = REPR FAILED\n",
      "        Starting var:.. kwargs = {}\n",
      "                        call       981     def __init__(*args, **kwargs):\n",
      "                        line       982         if not args:\n",
      "                        line       985         self, *args = args\n",
      "        Modified var:.. args = [{'next_beam_scores': tensor<(2,), float32, cuda:0, grad>, 'next_beam_tokens': tensor<(2,), int64, cuda:0>, 'next_beam_indices': tensor<(2,), int64, cuda:0>}]\n",
      "        New var:....... self = REPR FAILED\n",
      "                        line       986         if len(args) > 1:\n",
      "                        line       988         if args:\n",
      "                        line       989             dict = args[0]\n",
      "        New var:....... dict = {'next_beam_scores': tensor<(2,), float32, cuda:0, grad>, 'next_beam_tokens': tensor<(2,), int64, cuda:0>, 'next_beam_indices': tensor<(2,), int64, cuda:0>}\n",
      "                        line       997         self.data = {}\n",
      "        Modified var:.. self = {}\n",
      "                        line       998         if dict is not None:\n",
      "                        line       999             self.update(dict)\n",
      "        Modified var:.. self = {'next_beam_scores': tensor([-1.4723, -2.7266], device='cuda:0', grad_fn=<ViewBackward>), 'next_beam_tokens': tensor([117, 131], device='cuda:0'), 'next_beam_indices': tensor([0, 1], device='cuda:0')}\n",
      "                        line      1000         if kwargs:\n",
      "                        return    1000         if kwargs:\n",
      "        Return value:.. None\n",
      "    Source path:... generation_beam_search.py\n",
      "                    return     268         return UserDict(\n",
      "    Return value:.. {'next_beam_scores': tensor([-1.4723, -2.7266], device='cuda:0', grad_fn=<ViewBackward>), 'next_beam_tokens': tensor([117, 131], device='cuda:0'), 'next_beam_indices': tensor([0, 1], device='cuda:0')}\n",
      "Source path:... generation_utils.py\n",
      "Modified var:.. beam_outputs = {'next_beam_scores': tensor([-1.4723, -2.7266], device='cuda:0', grad_fn=<ViewBackward>), 'next_beam_tokens': tensor([117, 131], device='cuda:0'), 'next_beam_indices': tensor([0, 1], device='cuda:0')}\n",
      "                line      1789             beam_scores = beam_outputs[\"next_beam_scores\"]\n",
      "    Source path:... __init__.py\n",
      "    Starting var:.. self = {'next_beam_scores': tensor([-1.4723, -2.7266], device='cuda:0', grad_fn=<ViewBackward>), 'next_beam_tokens': tensor([117, 131], device='cuda:0'), 'next_beam_indices': tensor([0, 1], device='cuda:0')}\n",
      "    Starting var:.. key = 'next_beam_scores'\n",
      "                    call      1005     def __getitem__(self, key):\n",
      "                    line      1006         if key in self.data:\n",
      "                    line      1007             return self.data[key]\n",
      "                    return    1007             return self.data[key]\n",
      "    Return value:.. tensor<(2,), float32, cuda:0, grad>\n",
      "Source path:... generation_utils.py\n",
      "                line      1790             beam_next_tokens = beam_outputs[\"next_beam_tokens\"]\n",
      "    Source path:... __init__.py\n",
      "    Starting var:.. self = {'next_beam_scores': tensor([-1.4723, -2.7266], device='cuda:0', grad_fn=<ViewBackward>), 'next_beam_tokens': tensor([117, 131], device='cuda:0'), 'next_beam_indices': tensor([0, 1], device='cuda:0')}\n",
      "    Starting var:.. key = 'next_beam_tokens'\n",
      "                    call      1005     def __getitem__(self, key):\n",
      "                    line      1006         if key in self.data:\n",
      "                    line      1007             return self.data[key]\n",
      "                    return    1007             return self.data[key]\n",
      "    Return value:.. tensor<(2,), int64, cuda:0>\n",
      "Source path:... generation_utils.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                line      1791             beam_idx = beam_outputs[\"next_beam_indices\"]\n",
      "    Source path:... __init__.py\n",
      "    Starting var:.. self = {'next_beam_scores': tensor([-1.4723, -2.7266], device='cuda:0', grad_fn=<ViewBackward>), 'next_beam_tokens': tensor([117, 131], device='cuda:0'), 'next_beam_indices': tensor([0, 1], device='cuda:0')}\n",
      "    Starting var:.. key = 'next_beam_indices'\n",
      "                    call      1005     def __getitem__(self, key):\n",
      "                    line      1006         if key in self.data:\n",
      "                    line      1007             return self.data[key]\n",
      "                    return    1007             return self.data[key]\n",
      "    Return value:.. tensor<(2,), int64, cuda:0>\n",
      "Source path:... generation_utils.py\n",
      "                line      1793             input_ids = torch.cat([input_ids[beam_idx, :], beam_next_tokens.unsqueeze(-1)], dim=-1)\n",
      "Modified var:.. input_ids = tensor<(2, 3), int64, cuda:0>\n",
      "                line      1795             cur_len = cur_len + 1\n",
      "Modified var:.. cur_len = 3\n",
      "                line      1797             model_kwargs = self._update_model_kwargs_for_generation(\n",
      "                line      1798                 outputs, model_kwargs, is_encoder_decoder=self.config.is_encoder_decoder\n",
      "                line      1797             model_kwargs = self._update_model_kwargs_for_generation(\n",
      "    Starting var:.. outputs = {'logits': tensor<(2, 1, 96103), float32, cuda:0, grad>, 'past_key_values': ((tensor<(2, 16, 2, 64...float32, cuda:0, grad>)), 'encoder_last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0, grad>}\n",
      "    Starting var:.. model_kwargs = {'use_cache': None, 'attention_mask': tensor<(2, 6), int64, cuda:0>, 'encoder_outputs': {'last_hid...d>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>))}\n",
      "    Starting var:.. is_encoder_decoder = True\n",
      "                    call       511     def _update_model_kwargs_for_generation(\n",
      "                    line       515         if \"past_key_values\" in outputs:\n",
      "                    line       516             model_kwargs[\"past\"] = outputs.past_key_values\n",
      "                    line       525         if \"token_type_ids\" in model_kwargs:\n",
      "                    line       530         if not is_encoder_decoder:\n",
      "                    line       537         return model_kwargs\n",
      "                    return     537         return model_kwargs\n",
      "    Return value:.. {'use_cache': None, 'attention_mask': tensor<(2, 6), int64, cuda:0>, 'encoder_outputs': {'last_hid...d>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>))}\n",
      "                line      1800             if model_kwargs[\"past\"] is not None:\n",
      "                line      1801                 model_kwargs[\"past\"] = self._reorder_cache(model_kwargs[\"past\"], beam_idx)\n",
      "    Source path:... modeling_pegasus.py\n",
      "    Starting var:.. past = ((tensor<(2, 16, 2, 64), float32, cuda:0, grad>, tensor<(2, 16, 2, 64), float32, cuda:0, grad>, te...ad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>))\n",
      "    Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                    call      1333     def _reorder_cache(past, beam_idx):\n",
      "                    line      1334         reordered_past = ()\n",
      "    New var:....... reordered_past = ()\n",
      "                    line      1335         for layer_past in past:\n",
      "    New var:....... layer_past = (tensor<(2, 16, 2, 64), float32, cuda:0, grad>, tensor<(2, 16, 2, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>)\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 2, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 2, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 2, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 2, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 2, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "    Modified var:.. reordered_past = ((tensor<(2, 16, 2, 64), float32, cuda:0, grad>, tensor<(2, 16, 2, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>),)\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 2, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 2, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 2, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 2, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 2, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "    Modified var:.. reordered_past = ((tensor<(2, 16, 2, 64), float32, cuda:0, grad>, tensor<(2, 16, 2, 64), float32, cuda:0, grad>, te...ad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>))\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 2, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 2, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 2, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 2, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 2, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 2, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 2, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 2, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 2, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 2, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 2, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 2, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 2, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 2, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 2, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 2, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 2, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 2, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 2, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 2, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 2, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 2, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 2, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 2, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 2, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 2, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 2, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 2, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 2, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 2, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 2, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 2, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 2, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 2, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 2, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 2, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 2, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 2, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 2, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 2, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 2, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 2, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 2, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 2, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 2, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 2, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 2, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 2, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 2, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 2, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 2, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 2, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 2, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 2, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 2, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 2, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 2, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 2, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 2, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 2, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 2, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 2, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 2, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 2, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 2, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 2, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 2, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 2, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 2, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 2, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1340         return reordered_past\n",
      "                    return    1340         return reordered_past\n",
      "    Return value:.. ((tensor<(2, 16, 2, 64), float32, cuda:0, grad>, tensor<(2, 16, 2, 64), float32, cuda:0, grad>, te...ad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>))\n",
      "Source path:... generation_utils.py\n",
      "                line      1803             if beam_scorer.is_done:\n",
      "    Source path:... generation_beam_search.py\n",
      "    Starting var:.. self = <transformers.generation_beam_search.BeamSearchScorer object>\n",
      "                    call       196     def is_done(self) -> bool:\n",
      "                    line       197         return self._done.all()\n",
      "                    return     197         return self._done.all()\n",
      "    Return value:.. tensor<(), bool, cuda:0>\n",
      "Source path:... generation_utils.py\n",
      "                line      1806             if stopping_criteria(input_ids, scores):\n",
      "    Source path:... generation_stopping_criteria.py\n",
      "    Starting var:.. self = [<transformers.generation_stopping_criteria.MaxLengthCriteria object>]\n",
      "    Starting var:.. input_ids = tensor<(2, 3), int64, cuda:0>\n",
      "    Starting var:.. scores = (tensor<(2, 96103), float32, cuda:0, grad>, tensor<(2, 96103), float32, cuda:0, grad>)\n",
      "    Starting var:.. kwargs = {}\n",
      "                    call        83     def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor, **kwargs) -> bool:\n",
      "                    line        84         return any(criteria(input_ids, scores) for criteria in self)\n",
      "        Starting var:.. .0 = <list_iterator object>\n",
      "        Starting var:.. input_ids = tensor<(2, 3), int64, cuda:0>\n",
      "        Starting var:.. scores = (tensor<(2, 96103), float32, cuda:0, grad>, tensor<(2, 96103), float32, cuda:0, grad>)\n",
      "                        call        84         return any(criteria(input_ids, scores) for criteria in self)\n",
      "                        line        84         return any(criteria(input_ids, scores) for criteria in self)\n",
      "        New var:....... criteria = <transformers.generation_stopping_criteria.MaxLengthCriteria object>\n",
      "                        return      84         return any(criteria(input_ids, scores) for criteria in self)\n",
      "        Return value:.. False\n",
      "        Starting var:.. .0 = <list_iterator object>\n",
      "        Starting var:.. criteria = <transformers.generation_stopping_criteria.MaxLengthCriteria object>\n",
      "        Starting var:.. input_ids = tensor<(2, 3), int64, cuda:0>\n",
      "        Starting var:.. scores = (tensor<(2, 96103), float32, cuda:0, grad>, tensor<(2, 96103), float32, cuda:0, grad>)\n",
      "                        call        84         return any(criteria(input_ids, scores) for criteria in self)\n",
      "                        line        84         return any(criteria(input_ids, scores) for criteria in self)\n",
      "                        return      84         return any(criteria(input_ids, scores) for criteria in self)\n",
      "        Return value:.. None\n",
      "                    return      84         return any(criteria(input_ids, scores) for criteria in self)\n",
      "    Return value:.. False\n",
      "Source path:... generation_utils.py\n",
      "                line      1729         while cur_len < max_length:\n",
      "                line      1730             model_inputs = self.prepare_inputs_for_generation(input_ids, **model_kwargs)\n",
      "    Source path:... modeling_pegasus.py\n",
      "    Starting var:.. self = PegasusForConditionalGeneration(  (model): PegasusModel(    (shared): Embedding(96103, 1024, paddi...mentwise_affine=True)    )  )  (lm_head): Linear(in_features=1024, out_features=96103, bias=False))\n",
      "    Starting var:.. decoder_input_ids = tensor<(2, 3), int64, cuda:0>\n",
      "    Starting var:.. past = ((tensor<(2, 16, 2, 64), float32, cuda:0, grad>, tensor<(2, 16, 2, 64), float32, cuda:0, grad>, te...ad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>))\n",
      "    Starting var:.. attention_mask = tensor<(2, 6), int64, cuda:0>\n",
      "    Starting var:.. head_mask = None\n",
      "    Starting var:.. use_cache = None\n",
      "    Starting var:.. encoder_outputs = {'last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0, grad>}\n",
      "    Starting var:.. kwargs = {}\n",
      "                    call      1305     def prepare_inputs_for_generation(\n",
      "                    line      1316         if past is not None:\n",
      "                    line      1317             decoder_input_ids = decoder_input_ids[:, -1:]\n",
      "    Modified var:.. decoder_input_ids = tensor<(2, 1), int64, cuda:0>\n",
      "                    line      1320             \"input_ids\": None,  # encoder_outputs is defined. input_ids not needed\n",
      "                    line      1321             \"encoder_outputs\": encoder_outputs,\n",
      "                    line      1322             \"past_key_values\": past,\n",
      "                    line      1323             \"decoder_input_ids\": decoder_input_ids,\n",
      "                    line      1324             \"attention_mask\": attention_mask,\n",
      "                    line      1325             \"head_mask\": head_mask,\n",
      "                    line      1326             \"use_cache\": use_cache,  # change this to avoid caching (presumably for debugging)\n",
      "                    line      1319         return {\n",
      "                    return    1319         return {\n",
      "    Return value:.. {'input_ids': None, 'encoder_outputs': {'last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0,...64, cuda:0>, 'attention_mask': tensor<(2, 6), int64, cuda:0>, 'head_mask': None, 'use_cache': None}\n",
      "Source path:... generation_utils.py\n",
      "                line      1732             outputs = self(\n",
      "                line      1733                 **model_inputs,\n",
      "                line      1734                 return_dict=True,\n",
      "                line      1735                 output_attentions=output_attentions,\n",
      "                line      1736                 output_hidden_states=output_hidden_states,\n",
      "                line      1732             outputs = self(\n",
      "    Source path:... module.py\n",
      "    Starting var:.. self = PegasusForConditionalGeneration(  (model): PegasusModel(    (shared): Embedding(96103, 1024, paddi...mentwise_affine=True)    )  )  (lm_head): Linear(in_features=1024, out_features=96103, bias=False))\n",
      "    Starting var:.. input = ()\n",
      "    Starting var:.. kwargs = {'input_ids': None, 'encoder_outputs': {'last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0,... 'use_cache': None, 'return_dict': True, 'output_attentions': False, 'output_hidden_states': False}\n",
      "                    call       715     def _call_impl(self, *input, **kwargs):\n",
      "                    line       716         for hook in itertools.chain(\n",
      "                    line       717                 _global_forward_pre_hooks.values(),\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                    line       718                 self._forward_pre_hooks.values()):\n",
      "                    line       716         for hook in itertools.chain(\n",
      "                    line       724         if torch._C._get_tracing_state():\n",
      "                    line       727             result = self.forward(*input, **kwargs)\n",
      "        Source path:... modeling_pegasus.py\n",
      "        Starting var:.. self = PegasusForConditionalGeneration(  (model): PegasusModel(    (shared): Embedding(96103, 1024, paddi...mentwise_affine=True)    )  )  (lm_head): Linear(in_features=1024, out_features=96103, bias=False))\n",
      "        Starting var:.. input_ids = None\n",
      "        Starting var:.. attention_mask = tensor<(2, 6), int64, cuda:0>\n",
      "        Starting var:.. decoder_input_ids = tensor<(2, 1), int64, cuda:0>\n",
      "        Starting var:.. decoder_attention_mask = None\n",
      "        Starting var:.. head_mask = None\n",
      "        Starting var:.. decoder_head_mask = None\n",
      "        Starting var:.. encoder_outputs = {'last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0, grad>}\n",
      "        Starting var:.. past_key_values = ((tensor<(2, 16, 2, 64), float32, cuda:0, grad>, tensor<(2, 16, 2, 64), float32, cuda:0, grad>, te...ad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>))\n",
      "        Starting var:.. inputs_embeds = None\n",
      "        Starting var:.. decoder_inputs_embeds = None\n",
      "        Starting var:.. labels = None\n",
      "        Starting var:.. use_cache = None\n",
      "        Starting var:.. output_attentions = False\n",
      "        Starting var:.. output_hidden_states = False\n",
      "        Starting var:.. return_dict = True\n",
      "                        call      1231     def forward(\n",
      "                        line      1258         return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
      "                        line      1260         if labels is not None:\n",
      "                        line      1266         outputs = self.model(\n",
      "                        line      1267             input_ids,\n",
      "                        line      1268             attention_mask=attention_mask,\n",
      "                        line      1269             decoder_input_ids=decoder_input_ids,\n",
      "                        line      1270             encoder_outputs=encoder_outputs,\n",
      "                        line      1271             decoder_attention_mask=decoder_attention_mask,\n",
      "                        line      1272             head_mask=head_mask,\n",
      "                        line      1273             decoder_head_mask=decoder_head_mask,\n",
      "                        line      1274             past_key_values=past_key_values,\n",
      "                        line      1275             inputs_embeds=inputs_embeds,\n",
      "                        line      1276             decoder_inputs_embeds=decoder_inputs_embeds,\n",
      "                        line      1277             use_cache=use_cache,\n",
      "                        line      1278             output_attentions=output_attentions,\n",
      "                        line      1279             output_hidden_states=output_hidden_states,\n",
      "                        line      1280             return_dict=return_dict,\n",
      "                        line      1266         outputs = self.model(\n",
      "        New var:....... outputs = {'last_hidden_state': tensor<(2, 1, 1024), float32, cuda:0, grad>, 'past_key_values': ((tensor<(2,...float32, cuda:0, grad>)), 'encoder_last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0, grad>}\n",
      "                        line      1282         lm_logits = self.lm_head(outputs[0]) + self.final_logits_bias\n",
      "        New var:....... lm_logits = tensor<(2, 1, 96103), float32, cuda:0, grad>\n",
      "                        line      1284         masked_lm_loss = None\n",
      "        New var:....... masked_lm_loss = None\n",
      "                        line      1285         if labels is not None:\n",
      "                        line      1289         if not return_dict:\n",
      "                        line      1293         return Seq2SeqLMOutput(\n",
      "                        line      1294             loss=masked_lm_loss,\n",
      "                        line      1295             logits=lm_logits,\n",
      "                        line      1296             past_key_values=outputs.past_key_values,\n",
      "                        line      1297             decoder_hidden_states=outputs.decoder_hidden_states,\n",
      "                        line      1298             decoder_attentions=outputs.decoder_attentions,\n",
      "                        line      1299             cross_attentions=outputs.cross_attentions,\n",
      "                        line      1300             encoder_last_hidden_state=outputs.encoder_last_hidden_state,\n",
      "                        line      1301             encoder_hidden_states=outputs.encoder_hidden_states,\n",
      "                        line      1302             encoder_attentions=outputs.encoder_attentions,\n",
      "                        line      1293         return Seq2SeqLMOutput(\n",
      "                        return    1293         return Seq2SeqLMOutput(\n",
      "        Return value:.. {'logits': tensor<(2, 1, 96103), float32, cuda:0, grad>, 'past_key_values': ((tensor<(2, 16, 3, 64...float32, cuda:0, grad>)), 'encoder_last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0, grad>}\n",
      "    Source path:... module.py\n",
      "    New var:....... result = {'logits': tensor<(2, 1, 96103), float32, cuda:0, grad>, 'past_key_values': ((tensor<(2, 16, 3, 64...float32, cuda:0, grad>)), 'encoder_last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0, grad>}\n",
      "                    line       728         for hook in itertools.chain(\n",
      "                    line       729                 _global_forward_hooks.values(),\n",
      "                    line       730                 self._forward_hooks.values()):\n",
      "                    line       728         for hook in itertools.chain(\n",
      "                    line       734         if (len(self._backward_hooks) > 0) or (len(_global_backward_hooks) > 0):\n",
      "                    line       749         return result\n",
      "                    return     749         return result\n",
      "    Return value:.. {'logits': tensor<(2, 1, 96103), float32, cuda:0, grad>, 'past_key_values': ((tensor<(2, 16, 3, 64...float32, cuda:0, grad>)), 'encoder_last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0, grad>}\n",
      "Source path:... generation_utils.py\n",
      "Modified var:.. outputs = {'logits': tensor<(2, 1, 96103), float32, cuda:0, grad>, 'past_key_values': ((tensor<(2, 16, 3, 64...float32, cuda:0, grad>)), 'encoder_last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0, grad>}\n",
      "                line      1738             next_token_logits = outputs.logits[:, -1, :]\n",
      "                line      1742             next_token_logits = self.adjust_logits_during_generation(\n",
      "                line      1743                 next_token_logits, cur_len=cur_len, max_length=max_length\n",
      "                line      1742             next_token_logits = self.adjust_logits_during_generation(\n",
      "    Starting var:.. self = PegasusForConditionalGeneration(  (model): PegasusModel(    (shared): Embedding(96103, 1024, paddi...mentwise_affine=True)    )  )  (lm_head): Linear(in_features=1024, out_features=96103, bias=False))\n",
      "    Starting var:.. logits = tensor<(2, 96103), float32, cuda:0, grad>\n",
      "    Starting var:.. kwargs = {'cur_len': 3, 'max_length': 60}\n",
      "                    call       373     def adjust_logits_during_generation(self, logits: torch.FloatTensor, **kwargs) -> torch.FloatTensor:\n",
      "                    line       378         return logits\n",
      "                    return     378         return logits\n",
      "    Return value:.. tensor<(2, 96103), float32, cuda:0, grad>\n",
      "                line      1746             next_token_scores = F.log_softmax(next_token_logits, dim=-1)  # (batch_size * num_beams, vocab_size)\n",
      "    Source path:... functional.py\n",
      "    Starting var:.. input = tensor<(2, 96103), float32, cuda:0, grad>\n",
      "    Starting var:.. dim = -1\n",
      "    Starting var:.. _stacklevel = 3\n",
      "    Starting var:.. dtype = None\n",
      "                    call      1581 def log_softmax(input, dim=None, _stacklevel=3, dtype=None):\n",
      "                    line      1598     if not torch.jit.is_scripting():\n",
      "        Source path:... _jit_internal.py\n",
      "                        call       750 def is_scripting():\n",
      "                        line       769     return False\n",
      "                        return     769     return False\n",
      "        Return value:.. False\n",
      "    Source path:... functional.py\n",
      "                    line      1599         if type(input) is not Tensor and has_torch_function((input,)):\n",
      "                    line      1602     if dim is None:\n",
      "                    line      1604     if dtype is None:\n",
      "                    line      1605         ret = input.log_softmax(dim)\n",
      "    New var:....... ret = tensor<(2, 96103), float32, cuda:0, grad>\n",
      "                    line      1608     return ret\n",
      "                    return    1608     return ret\n",
      "    Return value:.. tensor<(2, 96103), float32, cuda:0, grad>\n",
      "Source path:... generation_utils.py\n",
      "Modified var:.. next_token_scores = tensor<(2, 96103), float32, cuda:0, grad>\n",
      "                line      1748             next_token_scores = logits_processor(input_ids, next_token_scores)\n",
      "    Source path:... generation_logits_process.py\n",
      "    Starting var:.. self = [<transformers.generation_logits_process.MinLengthLogitsProcessor object>, <transformers.generation_logits_process.ForcedEOSTokenLogitsProcessor object>]\n",
      "    Starting var:.. input_ids = tensor<(2, 3), int64, cuda:0>\n",
      "    Starting var:.. scores = tensor<(2, 96103), float32, cuda:0, grad>\n",
      "    Starting var:.. kwargs = {}\n",
      "                    call        84     def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor, **kwargs) -> torch.FloatTensor:\n",
      "                    line        85         for processor in self:\n",
      "    New var:....... processor = <transformers.generation_logits_process.MinLengthLogitsProcessor object>\n",
      "                    line        86             function_args = inspect.signature(processor.__call__).parameters\n",
      "        Source path:... inspect.py\n",
      "        Starting var:.. obj = <bound method MinLengthLogitsProcessor.__call__ of <transformers.generation_logits_process.MinLengthLogitsProcessor object>>\n",
      "        Starting var:.. follow_wrapped = True\n",
      "                        call      3091 def signature(obj, *, follow_wrapped=True):\n",
      "                        line      3093     return Signature.from_callable(obj, follow_wrapped=follow_wrapped)\n",
      "                        return    3093     return Signature.from_callable(obj, follow_wrapped=follow_wrapped)\n",
      "        Return value:.. <Signature (input_ids: torch.LongTensor, scores: torch.FloatTensor) -> torch.FloatTensor>\n",
      "        Starting var:.. self = <Signature (input_ids: torch.LongTensor, scores: torch.FloatTensor) -> torch.FloatTensor>\n",
      "                        call      2846     def parameters(self):\n",
      "                        line      2847         return self._parameters\n",
      "                        return    2847         return self._parameters\n",
      "        Return value:.. mappingproxy(OrderedDict([('input_ids', <Parameter \"input_ids: torch.LongTensor\">), ('scores', <Parameter \"scores: torch.FloatTensor\">)]))\n",
      "    Source path:... generation_logits_process.py\n",
      "    New var:....... function_args = mappingproxy(OrderedDict([('input_ids', <Parameter \"input_ids: torch.LongTensor\">), ('scores', <Parameter \"scores: torch.FloatTensor\">)]))\n",
      "                    line        87             if len(function_args) > 2:\n",
      "                    line        93                 scores = processor(input_ids, scores)\n",
      "        Starting var:.. self = <transformers.generation_logits_process.MinLengthLogitsProcessor object>\n",
      "        Starting var:.. input_ids = tensor<(2, 3), int64, cuda:0>\n",
      "        Starting var:.. scores = tensor<(2, 96103), float32, cuda:0, grad>\n",
      "                        call       118     def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor) -> torch.FloatTensor:\n",
      "                        line       119         cur_len = input_ids.shape[-1]\n",
      "        New var:....... cur_len = 3\n",
      "                        line       120         if cur_len < self.min_length:\n",
      "                        line       122         return scores\n",
      "                        return     122         return scores\n",
      "        Return value:.. tensor<(2, 96103), float32, cuda:0, grad>\n",
      "                    line        85         for processor in self:\n",
      "    Modified var:.. processor = <transformers.generation_logits_process.ForcedEOSTokenLogitsProcessor object>\n",
      "                    line        86             function_args = inspect.signature(processor.__call__).parameters\n",
      "        Source path:... inspect.py\n",
      "        Starting var:.. obj = <bound method ForcedEOSTokenLogitsProcessor.__call__ of <transformers.generation_logits_process.ForcedEOSTokenLogitsProcessor object>>\n",
      "        Starting var:.. follow_wrapped = True\n",
      "                        call      3091 def signature(obj, *, follow_wrapped=True):\n",
      "                        line      3093     return Signature.from_callable(obj, follow_wrapped=follow_wrapped)\n",
      "                        return    3093     return Signature.from_callable(obj, follow_wrapped=follow_wrapped)\n",
      "        Return value:.. <Signature (input_ids: torch.LongTensor, scores: torch.FloatTensor) -> torch.FloatTensor>\n",
      "        Starting var:.. self = <Signature (input_ids: torch.LongTensor, scores: torch.FloatTensor) -> torch.FloatTensor>\n",
      "                        call      2846     def parameters(self):\n",
      "                        line      2847         return self._parameters\n",
      "                        return    2847         return self._parameters\n",
      "        Return value:.. mappingproxy(OrderedDict([('input_ids', <Parameter \"input_ids: torch.LongTensor\">), ('scores', <Parameter \"scores: torch.FloatTensor\">)]))\n",
      "    Source path:... generation_logits_process.py\n",
      "                    line        87             if len(function_args) > 2:\n",
      "                    line        93                 scores = processor(input_ids, scores)\n",
      "        Starting var:.. self = <transformers.generation_logits_process.ForcedEOSTokenLogitsProcessor object>\n",
      "        Starting var:.. input_ids = tensor<(2, 3), int64, cuda:0>\n",
      "        Starting var:.. scores = tensor<(2, 96103), float32, cuda:0, grad>\n",
      "                        call       571     def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor) -> torch.FloatTensor:\n",
      "                        line       572         cur_len = input_ids.shape[-1]\n",
      "        New var:....... cur_len = 3\n",
      "                        line       573         if cur_len == self.max_length - 1:\n",
      "                        line       577         return scores\n",
      "                        return     577         return scores\n",
      "        Return value:.. tensor<(2, 96103), float32, cuda:0, grad>\n",
      "                    line        85         for processor in self:\n",
      "                    line        94         return scores\n",
      "                    return      94         return scores\n",
      "    Return value:.. tensor<(2, 96103), float32, cuda:0, grad>\n",
      "Source path:... generation_utils.py\n",
      "                line      1749             next_token_scores = next_token_scores + beam_scores[:, None].expand_as(next_token_scores)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                line      1752             if return_dict_in_generate:\n",
      "                line      1753                 if output_scores:\n",
      "                line      1754                     scores += (next_token_scores,)\n",
      "Modified var:.. scores = (tensor<(2, 96103), float32, cuda:0, grad>, tensor<(2, 96103), float32, cuda:0, grad>, tensor<(2, 96103), float32, cuda:0, grad>)\n",
      "                line      1755                 if output_attentions:\n",
      "                line      1762                 if output_hidden_states:\n",
      "                line      1770             vocab_size = next_token_scores.shape[-1]\n",
      "                line      1771             next_token_scores = next_token_scores.view(batch_size, num_beams * vocab_size)\n",
      "Modified var:.. next_token_scores = tensor<(1, 192206), float32, cuda:0, grad>\n",
      "                line      1773             next_token_scores, next_tokens = torch.topk(\n",
      "                line      1774                 next_token_scores, 2 * num_beams, dim=1, largest=True, sorted=True\n",
      "                line      1773             next_token_scores, next_tokens = torch.topk(\n",
      "Modified var:.. next_token_scores = tensor<(1, 4), float32, cuda:0, grad>\n",
      "                line      1777             next_indices = next_tokens // vocab_size\n",
      "    Source path:... tensor.py\n",
      "    Starting var:.. args = (tensor<(1, 4), int64, cuda:0>, 96103)\n",
      "    Starting var:.. kwargs = {}\n",
      "    Starting var:.. f = <function Tensor.__floordiv__>\n",
      "    Starting var:.. wrapped = <function Tensor.__floordiv__>\n",
      "                    call        22     def wrapped(*args, **kwargs):\n",
      "                    line        23         from torch.overrides import has_torch_function, handle_torch_function\n",
      "    New var:....... has_torch_function = <function has_torch_function>\n",
      "    New var:....... handle_torch_function = <function handle_torch_function>\n",
      "                    line        24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "                        call        24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "                        line        24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "        New var:....... t = tensor<(1, 4), int64, cuda:0>\n",
      "                        return      24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "        Return value:.. True\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. t = tensor<(1, 4), int64, cuda:0>\n",
      "                        call        24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "                        line        24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "        Modified var:.. t = 96103\n",
      "                        return      24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "        Return value:.. False\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. t = 96103\n",
      "                        call        24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "                        exception   24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "        Exception:..... GeneratorExit\n",
      "                        return      24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "        Return value:.. None\n",
      "        Source path:... overrides.py\n",
      "        Starting var:.. relevant_args = (tensor<(1, 4), int64, cuda:0>, 96103)\n",
      "                        call      1070 def has_torch_function(relevant_args: Iterable[Any]) -> bool:\n",
      "                        line      1083     return _is_torch_function_enabled() and any(\n",
      "                        line      1087         for a in relevant_args\n",
      "                        line      1083     return _is_torch_function_enabled() and any(\n",
      "                        return    1083     return _is_torch_function_enabled() and any(\n",
      "        Return value:.. False\n",
      "    Source path:... tensor.py\n",
      "                    line        26         try:\n",
      "                    line        27             return f(*args, **kwargs)\n",
      "        Starting var:.. self = tensor<(1, 4), int64, cuda:0>\n",
      "        Starting var:.. other = 96103\n",
      "                        call       550     def __floordiv__(self, other):\n",
      "                        line       551         return torch.floor_divide(self, other)\n",
      "                        return     551         return torch.floor_divide(self, other)\n",
      "        Return value:.. tensor<(1, 4), int64, cuda:0>\n",
      "                    return      27             return f(*args, **kwargs)\n",
      "    Return value:.. tensor<(1, 4), int64, cuda:0>\n",
      "Source path:... generation_utils.py\n",
      "                line      1778             next_tokens = next_tokens % vocab_size\n",
      "                line      1781             beam_outputs = beam_scorer.process(\n",
      "                line      1782                 input_ids,\n",
      "                line      1783                 next_token_scores,\n",
      "                line      1784                 next_tokens,\n",
      "                line      1785                 next_indices,\n",
      "                line      1786                 pad_token_id=pad_token_id,\n",
      "                line      1787                 eos_token_id=eos_token_id,\n",
      "                line      1781             beam_outputs = beam_scorer.process(\n",
      "    Source path:... generation_beam_search.py\n",
      "    Starting var:.. self = <transformers.generation_beam_search.BeamSearchScorer object>\n",
      "    Starting var:.. input_ids = tensor<(2, 3), int64, cuda:0>\n",
      "    Starting var:.. next_scores = tensor<(1, 4), float32, cuda:0, grad>\n",
      "    Starting var:.. next_tokens = tensor<(1, 4), int64, cuda:0>\n",
      "    Starting var:.. next_indices = tensor<(1, 4), int64, cuda:0>\n",
      "    Starting var:.. pad_token_id = 0\n",
      "    Starting var:.. eos_token_id = 1\n",
      "                    call       199     def process(\n",
      "                    line       208         cur_len = input_ids.shape[-1]\n",
      "    New var:....... cur_len = 3\n",
      "                    line       209         batch_size = len(self._beam_hyps)\n",
      "    New var:....... batch_size = 1\n",
      "                    line       210         assert batch_size == (input_ids.shape[0] // self.group_size)\n",
      "                    line       212         device = input_ids.device\n",
      "    New var:....... device = device(type='cuda', index=0)\n",
      "                    line       213         next_beam_scores = torch.zeros((batch_size, self.group_size), dtype=next_scores.dtype, device=device)\n",
      "    New var:....... next_beam_scores = tensor<(1, 2), float32, cuda:0>\n",
      "                    line       214         next_beam_tokens = torch.zeros((batch_size, self.group_size), dtype=next_tokens.dtype, device=device)\n",
      "    New var:....... next_beam_tokens = tensor<(1, 2), int64, cuda:0>\n",
      "                    line       215         next_beam_indices = torch.zeros((batch_size, self.group_size), dtype=next_indices.dtype, device=device)\n",
      "    New var:....... next_beam_indices = tensor<(1, 2), int64, cuda:0>\n",
      "                    line       217         for batch_idx, beam_hyp in enumerate(self._beam_hyps):\n",
      "    New var:....... batch_idx = 0\n",
      "    New var:....... beam_hyp = <transformers.generation_beam_search.BeamHypotheses object>\n",
      "                    line       218             if self._done[batch_idx]:\n",
      "                    line       232             beam_idx = 0\n",
      "    New var:....... beam_idx = 0\n",
      "                    line       233             for beam_token_rank, (next_token, next_score, next_index) in enumerate(\n",
      "                    line       234                 zip(next_tokens[batch_idx], next_scores[batch_idx], next_indices[batch_idx])\n",
      "        Source path:... tensor.py\n",
      "        Starting var:.. self = tensor<(4,), int64, cuda:0>\n",
      "                        call       576     def __iter__(self):\n",
      "                        line       583         relevant_args = (self,)\n",
      "        New var:....... relevant_args = (tensor<(4,), int64, cuda:0>,)\n",
      "                        line       584         from torch.overrides import has_torch_function, handle_torch_function\n",
      "        New var:....... has_torch_function = <function has_torch_function>\n",
      "        New var:....... handle_torch_function = <function handle_torch_function>\n",
      "                        line       585         if type(self) is not Tensor and has_torch_function(relevant_args):\n",
      "                        line       587         if self.dim() == 0:\n",
      "                        line       589         if torch._C._get_tracing_state():\n",
      "                        line       594         return iter(self.unbind(0))\n",
      "                        return     594         return iter(self.unbind(0))\n",
      "        Return value:.. <tuple_iterator object>\n",
      "        Starting var:.. self = tensor<(4,), float32, cuda:0, grad>\n",
      "                        call       576     def __iter__(self):\n",
      "                        line       583         relevant_args = (self,)\n",
      "        New var:....... relevant_args = (tensor<(4,), float32, cuda:0, grad>,)\n",
      "                        line       584         from torch.overrides import has_torch_function, handle_torch_function\n",
      "        New var:....... has_torch_function = <function has_torch_function>\n",
      "        New var:....... handle_torch_function = <function handle_torch_function>\n",
      "                        line       585         if type(self) is not Tensor and has_torch_function(relevant_args):\n",
      "                        line       587         if self.dim() == 0:\n",
      "                        line       589         if torch._C._get_tracing_state():\n",
      "                        line       594         return iter(self.unbind(0))\n",
      "                        return     594         return iter(self.unbind(0))\n",
      "        Return value:.. <tuple_iterator object>\n",
      "        Starting var:.. self = tensor<(4,), int64, cuda:0>\n",
      "                        call       576     def __iter__(self):\n",
      "                        line       583         relevant_args = (self,)\n",
      "        New var:....... relevant_args = (tensor<(4,), int64, cuda:0>,)\n",
      "                        line       584         from torch.overrides import has_torch_function, handle_torch_function\n",
      "        New var:....... has_torch_function = <function has_torch_function>\n",
      "        New var:....... handle_torch_function = <function handle_torch_function>\n",
      "                        line       585         if type(self) is not Tensor and has_torch_function(relevant_args):\n",
      "                        line       587         if self.dim() == 0:\n",
      "                        line       589         if torch._C._get_tracing_state():\n",
      "                        line       594         return iter(self.unbind(0))\n",
      "                        return     594         return iter(self.unbind(0))\n",
      "        Return value:.. <tuple_iterator object>\n",
      "    Source path:... generation_beam_search.py\n",
      "                    line       233             for beam_token_rank, (next_token, next_score, next_index) in enumerate(\n",
      "    New var:....... beam_token_rank = 0\n",
      "    New var:....... next_token = tensor<(), int64, cuda:0>\n",
      "    New var:....... next_score = tensor<(), float32, cuda:0, grad>\n",
      "    New var:....... next_index = tensor<(), int64, cuda:0>\n",
      "                    line       236                 batch_beam_idx = batch_idx * self.group_size + next_index\n",
      "    New var:....... batch_beam_idx = tensor<(), int64, cuda:0>\n",
      "                    line       238                 if (eos_token_id is not None) and (next_token.item() == eos_token_id):\n",
      "                    line       249                     next_beam_scores[batch_idx, beam_idx] = next_score\n",
      "    Modified var:.. next_beam_scores = tensor<(1, 2), float32, cuda:0, grad>\n",
      "                    line       250                     next_beam_tokens[batch_idx, beam_idx] = next_token\n",
      "                    line       251                     next_beam_indices[batch_idx, beam_idx] = batch_beam_idx\n",
      "                    line       252                     beam_idx += 1\n",
      "    Modified var:.. beam_idx = 1\n",
      "                    line       255                 if beam_idx == self.group_size:\n",
      "                    line       233             for beam_token_rank, (next_token, next_score, next_index) in enumerate(\n",
      "    Modified var:.. beam_token_rank = 1\n",
      "                    line       236                 batch_beam_idx = batch_idx * self.group_size + next_index\n",
      "                    line       238                 if (eos_token_id is not None) and (next_token.item() == eos_token_id):\n",
      "                    line       249                     next_beam_scores[batch_idx, beam_idx] = next_score\n",
      "                    line       250                     next_beam_tokens[batch_idx, beam_idx] = next_token\n",
      "                    line       251                     next_beam_indices[batch_idx, beam_idx] = batch_beam_idx\n",
      "                    line       252                     beam_idx += 1\n",
      "    Modified var:.. beam_idx = 2\n",
      "                    line       255                 if beam_idx == self.group_size:\n",
      "                    line       256                     break\n",
      "                    line       258             if beam_idx < self.group_size:\n",
      "                    line       264             self._done[batch_idx] = self._done[batch_idx] or beam_hyp.is_done(\n",
      "                    line       265                 next_scores[batch_idx].max().item(), cur_len\n",
      "                    line       264             self._done[batch_idx] = self._done[batch_idx] or beam_hyp.is_done(\n",
      "        Starting var:.. self = <transformers.generation_beam_search.BeamHypotheses object>\n",
      "        Starting var:.. best_sum_logprobs = -1.5838068723678589\n",
      "        Starting var:.. cur_len = 3\n",
      "                        call       371     def is_done(self, best_sum_logprobs: float, cur_len: int) -> bool:\n",
      "                        line       377         if len(self) < self.num_beams:\n",
      "                        line       378             return False\n",
      "                        return     378             return False\n",
      "        Return value:.. False\n",
      "                    line       217         for batch_idx, beam_hyp in enumerate(self._beam_hyps):\n",
      "                    line       268         return UserDict(\n",
      "                    line       270                 \"next_beam_scores\": next_beam_scores.view(-1),\n",
      "                    line       271                 \"next_beam_tokens\": next_beam_tokens.view(-1),\n",
      "                    line       272                 \"next_beam_indices\": next_beam_indices.view(-1),\n",
      "                    line       269             {\n",
      "                    line       268         return UserDict(\n",
      "        Source path:... __init__.py\n",
      "        Starting var:.. args = REPR FAILED\n",
      "        Starting var:.. kwargs = {}\n",
      "                        call       981     def __init__(*args, **kwargs):\n",
      "                        line       982         if not args:\n",
      "                        line       985         self, *args = args\n",
      "        Modified var:.. args = [{'next_beam_scores': tensor<(2,), float32, cuda:0, grad>, 'next_beam_tokens': tensor<(2,), int64, cuda:0>, 'next_beam_indices': tensor<(2,), int64, cuda:0>}]\n",
      "        New var:....... self = REPR FAILED\n",
      "                        line       986         if len(args) > 1:\n",
      "                        line       988         if args:\n",
      "                        line       989             dict = args[0]\n",
      "        New var:....... dict = {'next_beam_scores': tensor<(2,), float32, cuda:0, grad>, 'next_beam_tokens': tensor<(2,), int64, cuda:0>, 'next_beam_indices': tensor<(2,), int64, cuda:0>}\n",
      "                        line       997         self.data = {}\n",
      "        Modified var:.. self = {}\n",
      "                        line       998         if dict is not None:\n",
      "                        line       999             self.update(dict)\n",
      "        Modified var:.. self = {'next_beam_scores': tensor([-1.5838, -2.8241], device='cuda:0', grad_fn=<ViewBackward>), 'next_beam_tokens': tensor([161, 208], device='cuda:0'), 'next_beam_indices': tensor([0, 1], device='cuda:0')}\n",
      "                        line      1000         if kwargs:\n",
      "                        return    1000         if kwargs:\n",
      "        Return value:.. None\n",
      "    Source path:... generation_beam_search.py\n",
      "                    return     268         return UserDict(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    Return value:.. {'next_beam_scores': tensor([-1.5838, -2.8241], device='cuda:0', grad_fn=<ViewBackward>), 'next_beam_tokens': tensor([161, 208], device='cuda:0'), 'next_beam_indices': tensor([0, 1], device='cuda:0')}\n",
      "Source path:... generation_utils.py\n",
      "Modified var:.. beam_outputs = {'next_beam_scores': tensor([-1.5838, -2.8241], device='cuda:0', grad_fn=<ViewBackward>), 'next_beam_tokens': tensor([161, 208], device='cuda:0'), 'next_beam_indices': tensor([0, 1], device='cuda:0')}\n",
      "                line      1789             beam_scores = beam_outputs[\"next_beam_scores\"]\n",
      "    Source path:... __init__.py\n",
      "    Starting var:.. self = {'next_beam_scores': tensor([-1.5838, -2.8241], device='cuda:0', grad_fn=<ViewBackward>), 'next_beam_tokens': tensor([161, 208], device='cuda:0'), 'next_beam_indices': tensor([0, 1], device='cuda:0')}\n",
      "    Starting var:.. key = 'next_beam_scores'\n",
      "                    call      1005     def __getitem__(self, key):\n",
      "                    line      1006         if key in self.data:\n",
      "                    line      1007             return self.data[key]\n",
      "                    return    1007             return self.data[key]\n",
      "    Return value:.. tensor<(2,), float32, cuda:0, grad>\n",
      "Source path:... generation_utils.py\n",
      "                line      1790             beam_next_tokens = beam_outputs[\"next_beam_tokens\"]\n",
      "    Source path:... __init__.py\n",
      "    Starting var:.. self = {'next_beam_scores': tensor([-1.5838, -2.8241], device='cuda:0', grad_fn=<ViewBackward>), 'next_beam_tokens': tensor([161, 208], device='cuda:0'), 'next_beam_indices': tensor([0, 1], device='cuda:0')}\n",
      "    Starting var:.. key = 'next_beam_tokens'\n",
      "                    call      1005     def __getitem__(self, key):\n",
      "                    line      1006         if key in self.data:\n",
      "                    line      1007             return self.data[key]\n",
      "                    return    1007             return self.data[key]\n",
      "    Return value:.. tensor<(2,), int64, cuda:0>\n",
      "Source path:... generation_utils.py\n",
      "                line      1791             beam_idx = beam_outputs[\"next_beam_indices\"]\n",
      "    Source path:... __init__.py\n",
      "    Starting var:.. self = {'next_beam_scores': tensor([-1.5838, -2.8241], device='cuda:0', grad_fn=<ViewBackward>), 'next_beam_tokens': tensor([161, 208], device='cuda:0'), 'next_beam_indices': tensor([0, 1], device='cuda:0')}\n",
      "    Starting var:.. key = 'next_beam_indices'\n",
      "                    call      1005     def __getitem__(self, key):\n",
      "                    line      1006         if key in self.data:\n",
      "                    line      1007             return self.data[key]\n",
      "                    return    1007             return self.data[key]\n",
      "    Return value:.. tensor<(2,), int64, cuda:0>\n",
      "Source path:... generation_utils.py\n",
      "                line      1793             input_ids = torch.cat([input_ids[beam_idx, :], beam_next_tokens.unsqueeze(-1)], dim=-1)\n",
      "Modified var:.. input_ids = tensor<(2, 4), int64, cuda:0>\n",
      "                line      1795             cur_len = cur_len + 1\n",
      "Modified var:.. cur_len = 4\n",
      "                line      1797             model_kwargs = self._update_model_kwargs_for_generation(\n",
      "                line      1798                 outputs, model_kwargs, is_encoder_decoder=self.config.is_encoder_decoder\n",
      "                line      1797             model_kwargs = self._update_model_kwargs_for_generation(\n",
      "    Starting var:.. outputs = {'logits': tensor<(2, 1, 96103), float32, cuda:0, grad>, 'past_key_values': ((tensor<(2, 16, 3, 64...float32, cuda:0, grad>)), 'encoder_last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0, grad>}\n",
      "    Starting var:.. model_kwargs = {'use_cache': None, 'attention_mask': tensor<(2, 6), int64, cuda:0>, 'encoder_outputs': {'last_hid...d>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>))}\n",
      "    Starting var:.. is_encoder_decoder = True\n",
      "                    call       511     def _update_model_kwargs_for_generation(\n",
      "                    line       515         if \"past_key_values\" in outputs:\n",
      "                    line       516             model_kwargs[\"past\"] = outputs.past_key_values\n",
      "                    line       525         if \"token_type_ids\" in model_kwargs:\n",
      "                    line       530         if not is_encoder_decoder:\n",
      "                    line       537         return model_kwargs\n",
      "                    return     537         return model_kwargs\n",
      "    Return value:.. {'use_cache': None, 'attention_mask': tensor<(2, 6), int64, cuda:0>, 'encoder_outputs': {'last_hid...d>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>))}\n",
      "                line      1800             if model_kwargs[\"past\"] is not None:\n",
      "                line      1801                 model_kwargs[\"past\"] = self._reorder_cache(model_kwargs[\"past\"], beam_idx)\n",
      "    Source path:... modeling_pegasus.py\n",
      "    Starting var:.. past = ((tensor<(2, 16, 3, 64), float32, cuda:0, grad>, tensor<(2, 16, 3, 64), float32, cuda:0, grad>, te...ad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>))\n",
      "    Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                    call      1333     def _reorder_cache(past, beam_idx):\n",
      "                    line      1334         reordered_past = ()\n",
      "    New var:....... reordered_past = ()\n",
      "                    line      1335         for layer_past in past:\n",
      "    New var:....... layer_past = (tensor<(2, 16, 3, 64), float32, cuda:0, grad>, tensor<(2, 16, 3, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>)\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 3, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 3, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 3, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 3, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 3, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "    Modified var:.. reordered_past = ((tensor<(2, 16, 3, 64), float32, cuda:0, grad>, tensor<(2, 16, 3, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>),)\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 3, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 3, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 3, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 3, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 3, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "    Modified var:.. reordered_past = ((tensor<(2, 16, 3, 64), float32, cuda:0, grad>, tensor<(2, 16, 3, 64), float32, cuda:0, grad>, te...ad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>))\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 3, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 3, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 3, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 3, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 3, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 3, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 3, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 3, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 3, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 3, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 3, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 3, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 3, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 3, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 3, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 3, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 3, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 3, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 3, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 3, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 3, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 3, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 3, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 3, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 3, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 3, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 3, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 3, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 3, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 3, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 3, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 3, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 3, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 3, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 3, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 3, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 3, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 3, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 3, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 3, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 3, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 3, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 3, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 3, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 3, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 3, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 3, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 3, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 3, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 3, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 3, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 3, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 3, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 3, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 3, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 3, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 3, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 3, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 3, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 3, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 3, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 3, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 3, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 3, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 3, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 3, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 3, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 3, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 3, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 3, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1340         return reordered_past\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                    return    1340         return reordered_past\n",
      "    Return value:.. ((tensor<(2, 16, 3, 64), float32, cuda:0, grad>, tensor<(2, 16, 3, 64), float32, cuda:0, grad>, te...ad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>))\n",
      "Source path:... generation_utils.py\n",
      "                line      1803             if beam_scorer.is_done:\n",
      "    Source path:... generation_beam_search.py\n",
      "    Starting var:.. self = <transformers.generation_beam_search.BeamSearchScorer object>\n",
      "                    call       196     def is_done(self) -> bool:\n",
      "                    line       197         return self._done.all()\n",
      "                    return     197         return self._done.all()\n",
      "    Return value:.. tensor<(), bool, cuda:0>\n",
      "Source path:... generation_utils.py\n",
      "                line      1806             if stopping_criteria(input_ids, scores):\n",
      "    Source path:... generation_stopping_criteria.py\n",
      "    Starting var:.. self = [<transformers.generation_stopping_criteria.MaxLengthCriteria object>]\n",
      "    Starting var:.. input_ids = tensor<(2, 4), int64, cuda:0>\n",
      "    Starting var:.. scores = (tensor<(2, 96103), float32, cuda:0, grad>, tensor<(2, 96103), float32, cuda:0, grad>, tensor<(2, 96103), float32, cuda:0, grad>)\n",
      "    Starting var:.. kwargs = {}\n",
      "                    call        83     def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor, **kwargs) -> bool:\n",
      "                    line        84         return any(criteria(input_ids, scores) for criteria in self)\n",
      "        Starting var:.. .0 = <list_iterator object>\n",
      "        Starting var:.. input_ids = tensor<(2, 4), int64, cuda:0>\n",
      "        Starting var:.. scores = (tensor<(2, 96103), float32, cuda:0, grad>, tensor<(2, 96103), float32, cuda:0, grad>, tensor<(2, 96103), float32, cuda:0, grad>)\n",
      "                        call        84         return any(criteria(input_ids, scores) for criteria in self)\n",
      "                        line        84         return any(criteria(input_ids, scores) for criteria in self)\n",
      "        New var:....... criteria = <transformers.generation_stopping_criteria.MaxLengthCriteria object>\n",
      "                        return      84         return any(criteria(input_ids, scores) for criteria in self)\n",
      "        Return value:.. False\n",
      "        Starting var:.. .0 = <list_iterator object>\n",
      "        Starting var:.. criteria = <transformers.generation_stopping_criteria.MaxLengthCriteria object>\n",
      "        Starting var:.. input_ids = tensor<(2, 4), int64, cuda:0>\n",
      "        Starting var:.. scores = (tensor<(2, 96103), float32, cuda:0, grad>, tensor<(2, 96103), float32, cuda:0, grad>, tensor<(2, 96103), float32, cuda:0, grad>)\n",
      "                        call        84         return any(criteria(input_ids, scores) for criteria in self)\n",
      "                        line        84         return any(criteria(input_ids, scores) for criteria in self)\n",
      "                        return      84         return any(criteria(input_ids, scores) for criteria in self)\n",
      "        Return value:.. None\n",
      "                    return      84         return any(criteria(input_ids, scores) for criteria in self)\n",
      "    Return value:.. False\n",
      "Source path:... generation_utils.py\n",
      "                line      1729         while cur_len < max_length:\n",
      "                line      1730             model_inputs = self.prepare_inputs_for_generation(input_ids, **model_kwargs)\n",
      "    Source path:... modeling_pegasus.py\n",
      "    Starting var:.. self = PegasusForConditionalGeneration(  (model): PegasusModel(    (shared): Embedding(96103, 1024, paddi...mentwise_affine=True)    )  )  (lm_head): Linear(in_features=1024, out_features=96103, bias=False))\n",
      "    Starting var:.. decoder_input_ids = tensor<(2, 4), int64, cuda:0>\n",
      "    Starting var:.. past = ((tensor<(2, 16, 3, 64), float32, cuda:0, grad>, tensor<(2, 16, 3, 64), float32, cuda:0, grad>, te...ad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>))\n",
      "    Starting var:.. attention_mask = tensor<(2, 6), int64, cuda:0>\n",
      "    Starting var:.. head_mask = None\n",
      "    Starting var:.. use_cache = None\n",
      "    Starting var:.. encoder_outputs = {'last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0, grad>}\n",
      "    Starting var:.. kwargs = {}\n",
      "                    call      1305     def prepare_inputs_for_generation(\n",
      "                    line      1316         if past is not None:\n",
      "                    line      1317             decoder_input_ids = decoder_input_ids[:, -1:]\n",
      "    Modified var:.. decoder_input_ids = tensor<(2, 1), int64, cuda:0>\n",
      "                    line      1320             \"input_ids\": None,  # encoder_outputs is defined. input_ids not needed\n",
      "                    line      1321             \"encoder_outputs\": encoder_outputs,\n",
      "                    line      1322             \"past_key_values\": past,\n",
      "                    line      1323             \"decoder_input_ids\": decoder_input_ids,\n",
      "                    line      1324             \"attention_mask\": attention_mask,\n",
      "                    line      1325             \"head_mask\": head_mask,\n",
      "                    line      1326             \"use_cache\": use_cache,  # change this to avoid caching (presumably for debugging)\n",
      "                    line      1319         return {\n",
      "                    return    1319         return {\n",
      "    Return value:.. {'input_ids': None, 'encoder_outputs': {'last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0,...64, cuda:0>, 'attention_mask': tensor<(2, 6), int64, cuda:0>, 'head_mask': None, 'use_cache': None}\n",
      "Source path:... generation_utils.py\n",
      "                line      1732             outputs = self(\n",
      "                line      1733                 **model_inputs,\n",
      "                line      1734                 return_dict=True,\n",
      "                line      1735                 output_attentions=output_attentions,\n",
      "                line      1736                 output_hidden_states=output_hidden_states,\n",
      "                line      1732             outputs = self(\n",
      "    Source path:... module.py\n",
      "    Starting var:.. self = PegasusForConditionalGeneration(  (model): PegasusModel(    (shared): Embedding(96103, 1024, paddi...mentwise_affine=True)    )  )  (lm_head): Linear(in_features=1024, out_features=96103, bias=False))\n",
      "    Starting var:.. input = ()\n",
      "    Starting var:.. kwargs = {'input_ids': None, 'encoder_outputs': {'last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0,... 'use_cache': None, 'return_dict': True, 'output_attentions': False, 'output_hidden_states': False}\n",
      "                    call       715     def _call_impl(self, *input, **kwargs):\n",
      "                    line       716         for hook in itertools.chain(\n",
      "                    line       717                 _global_forward_pre_hooks.values(),\n",
      "                    line       718                 self._forward_pre_hooks.values()):\n",
      "                    line       716         for hook in itertools.chain(\n",
      "                    line       724         if torch._C._get_tracing_state():\n",
      "                    line       727             result = self.forward(*input, **kwargs)\n",
      "        Source path:... modeling_pegasus.py\n",
      "        Starting var:.. self = PegasusForConditionalGeneration(  (model): PegasusModel(    (shared): Embedding(96103, 1024, paddi...mentwise_affine=True)    )  )  (lm_head): Linear(in_features=1024, out_features=96103, bias=False))\n",
      "        Starting var:.. input_ids = None\n",
      "        Starting var:.. attention_mask = tensor<(2, 6), int64, cuda:0>\n",
      "        Starting var:.. decoder_input_ids = tensor<(2, 1), int64, cuda:0>\n",
      "        Starting var:.. decoder_attention_mask = None\n",
      "        Starting var:.. head_mask = None\n",
      "        Starting var:.. decoder_head_mask = None\n",
      "        Starting var:.. encoder_outputs = {'last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0, grad>}\n",
      "        Starting var:.. past_key_values = ((tensor<(2, 16, 3, 64), float32, cuda:0, grad>, tensor<(2, 16, 3, 64), float32, cuda:0, grad>, te...ad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>))\n",
      "        Starting var:.. inputs_embeds = None\n",
      "        Starting var:.. decoder_inputs_embeds = None\n",
      "        Starting var:.. labels = None\n",
      "        Starting var:.. use_cache = None\n",
      "        Starting var:.. output_attentions = False\n",
      "        Starting var:.. output_hidden_states = False\n",
      "        Starting var:.. return_dict = True\n",
      "                        call      1231     def forward(\n",
      "                        line      1258         return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
      "                        line      1260         if labels is not None:\n",
      "                        line      1266         outputs = self.model(\n",
      "                        line      1267             input_ids,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                        line      1268             attention_mask=attention_mask,\n",
      "                        line      1269             decoder_input_ids=decoder_input_ids,\n",
      "                        line      1270             encoder_outputs=encoder_outputs,\n",
      "                        line      1271             decoder_attention_mask=decoder_attention_mask,\n",
      "                        line      1272             head_mask=head_mask,\n",
      "                        line      1273             decoder_head_mask=decoder_head_mask,\n",
      "                        line      1274             past_key_values=past_key_values,\n",
      "                        line      1275             inputs_embeds=inputs_embeds,\n",
      "                        line      1276             decoder_inputs_embeds=decoder_inputs_embeds,\n",
      "                        line      1277             use_cache=use_cache,\n",
      "                        line      1278             output_attentions=output_attentions,\n",
      "                        line      1279             output_hidden_states=output_hidden_states,\n",
      "                        line      1280             return_dict=return_dict,\n",
      "                        line      1266         outputs = self.model(\n",
      "        New var:....... outputs = {'last_hidden_state': tensor<(2, 1, 1024), float32, cuda:0, grad>, 'past_key_values': ((tensor<(2,...float32, cuda:0, grad>)), 'encoder_last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0, grad>}\n",
      "                        line      1282         lm_logits = self.lm_head(outputs[0]) + self.final_logits_bias\n",
      "        New var:....... lm_logits = tensor<(2, 1, 96103), float32, cuda:0, grad>\n",
      "                        line      1284         masked_lm_loss = None\n",
      "        New var:....... masked_lm_loss = None\n",
      "                        line      1285         if labels is not None:\n",
      "                        line      1289         if not return_dict:\n",
      "                        line      1293         return Seq2SeqLMOutput(\n",
      "                        line      1294             loss=masked_lm_loss,\n",
      "                        line      1295             logits=lm_logits,\n",
      "                        line      1296             past_key_values=outputs.past_key_values,\n",
      "                        line      1297             decoder_hidden_states=outputs.decoder_hidden_states,\n",
      "                        line      1298             decoder_attentions=outputs.decoder_attentions,\n",
      "                        line      1299             cross_attentions=outputs.cross_attentions,\n",
      "                        line      1300             encoder_last_hidden_state=outputs.encoder_last_hidden_state,\n",
      "                        line      1301             encoder_hidden_states=outputs.encoder_hidden_states,\n",
      "                        line      1302             encoder_attentions=outputs.encoder_attentions,\n",
      "                        line      1293         return Seq2SeqLMOutput(\n",
      "                        return    1293         return Seq2SeqLMOutput(\n",
      "        Return value:.. {'logits': tensor<(2, 1, 96103), float32, cuda:0, grad>, 'past_key_values': ((tensor<(2, 16, 4, 64...float32, cuda:0, grad>)), 'encoder_last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0, grad>}\n",
      "    Source path:... module.py\n",
      "    New var:....... result = {'logits': tensor<(2, 1, 96103), float32, cuda:0, grad>, 'past_key_values': ((tensor<(2, 16, 4, 64...float32, cuda:0, grad>)), 'encoder_last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0, grad>}\n",
      "                    line       728         for hook in itertools.chain(\n",
      "                    line       729                 _global_forward_hooks.values(),\n",
      "                    line       730                 self._forward_hooks.values()):\n",
      "                    line       728         for hook in itertools.chain(\n",
      "                    line       734         if (len(self._backward_hooks) > 0) or (len(_global_backward_hooks) > 0):\n",
      "                    line       749         return result\n",
      "                    return     749         return result\n",
      "    Return value:.. {'logits': tensor<(2, 1, 96103), float32, cuda:0, grad>, 'past_key_values': ((tensor<(2, 16, 4, 64...float32, cuda:0, grad>)), 'encoder_last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0, grad>}\n",
      "Source path:... generation_utils.py\n",
      "Modified var:.. outputs = {'logits': tensor<(2, 1, 96103), float32, cuda:0, grad>, 'past_key_values': ((tensor<(2, 16, 4, 64...float32, cuda:0, grad>)), 'encoder_last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0, grad>}\n",
      "                line      1738             next_token_logits = outputs.logits[:, -1, :]\n",
      "                line      1742             next_token_logits = self.adjust_logits_during_generation(\n",
      "                line      1743                 next_token_logits, cur_len=cur_len, max_length=max_length\n",
      "                line      1742             next_token_logits = self.adjust_logits_during_generation(\n",
      "    Starting var:.. self = PegasusForConditionalGeneration(  (model): PegasusModel(    (shared): Embedding(96103, 1024, paddi...mentwise_affine=True)    )  )  (lm_head): Linear(in_features=1024, out_features=96103, bias=False))\n",
      "    Starting var:.. logits = tensor<(2, 96103), float32, cuda:0, grad>\n",
      "    Starting var:.. kwargs = {'cur_len': 4, 'max_length': 60}\n",
      "                    call       373     def adjust_logits_during_generation(self, logits: torch.FloatTensor, **kwargs) -> torch.FloatTensor:\n",
      "                    line       378         return logits\n",
      "                    return     378         return logits\n",
      "    Return value:.. tensor<(2, 96103), float32, cuda:0, grad>\n",
      "                line      1746             next_token_scores = F.log_softmax(next_token_logits, dim=-1)  # (batch_size * num_beams, vocab_size)\n",
      "    Source path:... functional.py\n",
      "    Starting var:.. input = tensor<(2, 96103), float32, cuda:0, grad>\n",
      "    Starting var:.. dim = -1\n",
      "    Starting var:.. _stacklevel = 3\n",
      "    Starting var:.. dtype = None\n",
      "                    call      1581 def log_softmax(input, dim=None, _stacklevel=3, dtype=None):\n",
      "                    line      1598     if not torch.jit.is_scripting():\n",
      "        Source path:... _jit_internal.py\n",
      "                        call       750 def is_scripting():\n",
      "                        line       769     return False\n",
      "                        return     769     return False\n",
      "        Return value:.. False\n",
      "    Source path:... functional.py\n",
      "                    line      1599         if type(input) is not Tensor and has_torch_function((input,)):\n",
      "                    line      1602     if dim is None:\n",
      "                    line      1604     if dtype is None:\n",
      "                    line      1605         ret = input.log_softmax(dim)\n",
      "    New var:....... ret = tensor<(2, 96103), float32, cuda:0, grad>\n",
      "                    line      1608     return ret\n",
      "                    return    1608     return ret\n",
      "    Return value:.. tensor<(2, 96103), float32, cuda:0, grad>\n",
      "Source path:... generation_utils.py\n",
      "Modified var:.. next_token_scores = tensor<(2, 96103), float32, cuda:0, grad>\n",
      "                line      1748             next_token_scores = logits_processor(input_ids, next_token_scores)\n",
      "    Source path:... generation_logits_process.py\n",
      "    Starting var:.. self = [<transformers.generation_logits_process.MinLengthLogitsProcessor object>, <transformers.generation_logits_process.ForcedEOSTokenLogitsProcessor object>]\n",
      "    Starting var:.. input_ids = tensor<(2, 4), int64, cuda:0>\n",
      "    Starting var:.. scores = tensor<(2, 96103), float32, cuda:0, grad>\n",
      "    Starting var:.. kwargs = {}\n",
      "                    call        84     def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor, **kwargs) -> torch.FloatTensor:\n",
      "                    line        85         for processor in self:\n",
      "    New var:....... processor = <transformers.generation_logits_process.MinLengthLogitsProcessor object>\n",
      "                    line        86             function_args = inspect.signature(processor.__call__).parameters\n",
      "        Source path:... inspect.py\n",
      "        Starting var:.. obj = <bound method MinLengthLogitsProcessor.__call__ of <transformers.generation_logits_process.MinLengthLogitsProcessor object>>\n",
      "        Starting var:.. follow_wrapped = True\n",
      "                        call      3091 def signature(obj, *, follow_wrapped=True):\n",
      "                        line      3093     return Signature.from_callable(obj, follow_wrapped=follow_wrapped)\n",
      "                        return    3093     return Signature.from_callable(obj, follow_wrapped=follow_wrapped)\n",
      "        Return value:.. <Signature (input_ids: torch.LongTensor, scores: torch.FloatTensor) -> torch.FloatTensor>\n",
      "        Starting var:.. self = <Signature (input_ids: torch.LongTensor, scores: torch.FloatTensor) -> torch.FloatTensor>\n",
      "                        call      2846     def parameters(self):\n",
      "                        line      2847         return self._parameters\n",
      "                        return    2847         return self._parameters\n",
      "        Return value:.. mappingproxy(OrderedDict([('input_ids', <Parameter \"input_ids: torch.LongTensor\">), ('scores', <Parameter \"scores: torch.FloatTensor\">)]))\n",
      "    Source path:... generation_logits_process.py\n",
      "    New var:....... function_args = mappingproxy(OrderedDict([('input_ids', <Parameter \"input_ids: torch.LongTensor\">), ('scores', <Parameter \"scores: torch.FloatTensor\">)]))\n",
      "                    line        87             if len(function_args) > 2:\n",
      "                    line        93                 scores = processor(input_ids, scores)\n",
      "        Starting var:.. self = <transformers.generation_logits_process.MinLengthLogitsProcessor object>\n",
      "        Starting var:.. input_ids = tensor<(2, 4), int64, cuda:0>\n",
      "        Starting var:.. scores = tensor<(2, 96103), float32, cuda:0, grad>\n",
      "                        call       118     def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor) -> torch.FloatTensor:\n",
      "                        line       119         cur_len = input_ids.shape[-1]\n",
      "        New var:....... cur_len = 4\n",
      "                        line       120         if cur_len < self.min_length:\n",
      "                        line       122         return scores\n",
      "                        return     122         return scores\n",
      "        Return value:.. tensor<(2, 96103), float32, cuda:0, grad>\n",
      "                    line        85         for processor in self:\n",
      "    Modified var:.. processor = <transformers.generation_logits_process.ForcedEOSTokenLogitsProcessor object>\n",
      "                    line        86             function_args = inspect.signature(processor.__call__).parameters\n",
      "        Source path:... inspect.py\n",
      "        Starting var:.. obj = <bound method ForcedEOSTokenLogitsProcessor.__call__ of <transformers.generation_logits_process.ForcedEOSTokenLogitsProcessor object>>\n",
      "        Starting var:.. follow_wrapped = True\n",
      "                        call      3091 def signature(obj, *, follow_wrapped=True):\n",
      "                        line      3093     return Signature.from_callable(obj, follow_wrapped=follow_wrapped)\n",
      "                        return    3093     return Signature.from_callable(obj, follow_wrapped=follow_wrapped)\n",
      "        Return value:.. <Signature (input_ids: torch.LongTensor, scores: torch.FloatTensor) -> torch.FloatTensor>\n",
      "        Starting var:.. self = <Signature (input_ids: torch.LongTensor, scores: torch.FloatTensor) -> torch.FloatTensor>\n",
      "                        call      2846     def parameters(self):\n",
      "                        line      2847         return self._parameters\n",
      "                        return    2847         return self._parameters\n",
      "        Return value:.. mappingproxy(OrderedDict([('input_ids', <Parameter \"input_ids: torch.LongTensor\">), ('scores', <Parameter \"scores: torch.FloatTensor\">)]))\n",
      "    Source path:... generation_logits_process.py\n",
      "                    line        87             if len(function_args) > 2:\n",
      "                    line        93                 scores = processor(input_ids, scores)\n",
      "        Starting var:.. self = <transformers.generation_logits_process.ForcedEOSTokenLogitsProcessor object>\n",
      "        Starting var:.. input_ids = tensor<(2, 4), int64, cuda:0>\n",
      "        Starting var:.. scores = tensor<(2, 96103), float32, cuda:0, grad>\n",
      "                        call       571     def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor) -> torch.FloatTensor:\n",
      "                        line       572         cur_len = input_ids.shape[-1]\n",
      "        New var:....... cur_len = 4\n",
      "                        line       573         if cur_len == self.max_length - 1:\n",
      "                        line       577         return scores\n",
      "                        return     577         return scores\n",
      "        Return value:.. tensor<(2, 96103), float32, cuda:0, grad>\n",
      "                    line        85         for processor in self:\n",
      "                    line        94         return scores\n",
      "                    return      94         return scores\n",
      "    Return value:.. tensor<(2, 96103), float32, cuda:0, grad>\n",
      "Source path:... generation_utils.py\n",
      "                line      1749             next_token_scores = next_token_scores + beam_scores[:, None].expand_as(next_token_scores)\n",
      "                line      1752             if return_dict_in_generate:\n",
      "                line      1753                 if output_scores:\n",
      "                line      1754                     scores += (next_token_scores,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Modified var:.. scores = (tensor<(2, 96103), float32, cuda:0, grad>, tensor<(2, 96103), float32, cuda:0, grad>, tensor<(2, 96103), float32, cuda:0, grad>, tensor<(2, 96103), float32, cuda:0, grad>)\n",
      "                line      1755                 if output_attentions:\n",
      "                line      1762                 if output_hidden_states:\n",
      "                line      1770             vocab_size = next_token_scores.shape[-1]\n",
      "                line      1771             next_token_scores = next_token_scores.view(batch_size, num_beams * vocab_size)\n",
      "Modified var:.. next_token_scores = tensor<(1, 192206), float32, cuda:0, grad>\n",
      "                line      1773             next_token_scores, next_tokens = torch.topk(\n",
      "                line      1774                 next_token_scores, 2 * num_beams, dim=1, largest=True, sorted=True\n",
      "                line      1773             next_token_scores, next_tokens = torch.topk(\n",
      "Modified var:.. next_token_scores = tensor<(1, 4), float32, cuda:0, grad>\n",
      "                line      1777             next_indices = next_tokens // vocab_size\n",
      "    Source path:... tensor.py\n",
      "    Starting var:.. args = (tensor<(1, 4), int64, cuda:0>, 96103)\n",
      "    Starting var:.. kwargs = {}\n",
      "    Starting var:.. f = <function Tensor.__floordiv__>\n",
      "    Starting var:.. wrapped = <function Tensor.__floordiv__>\n",
      "                    call        22     def wrapped(*args, **kwargs):\n",
      "                    line        23         from torch.overrides import has_torch_function, handle_torch_function\n",
      "    New var:....... has_torch_function = <function has_torch_function>\n",
      "    New var:....... handle_torch_function = <function handle_torch_function>\n",
      "                    line        24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "                        call        24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "                        line        24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "        New var:....... t = tensor<(1, 4), int64, cuda:0>\n",
      "                        return      24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "        Return value:.. True\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. t = tensor<(1, 4), int64, cuda:0>\n",
      "                        call        24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "                        line        24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "        Modified var:.. t = 96103\n",
      "                        return      24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "        Return value:.. False\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. t = 96103\n",
      "                        call        24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "                        exception   24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "        Exception:..... GeneratorExit\n",
      "                        return      24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "        Return value:.. None\n",
      "        Source path:... overrides.py\n",
      "        Starting var:.. relevant_args = (tensor<(1, 4), int64, cuda:0>, 96103)\n",
      "                        call      1070 def has_torch_function(relevant_args: Iterable[Any]) -> bool:\n",
      "                        line      1083     return _is_torch_function_enabled() and any(\n",
      "                        line      1087         for a in relevant_args\n",
      "                        line      1083     return _is_torch_function_enabled() and any(\n",
      "                        return    1083     return _is_torch_function_enabled() and any(\n",
      "        Return value:.. False\n",
      "    Source path:... tensor.py\n",
      "                    line        26         try:\n",
      "                    line        27             return f(*args, **kwargs)\n",
      "        Starting var:.. self = tensor<(1, 4), int64, cuda:0>\n",
      "        Starting var:.. other = 96103\n",
      "                        call       550     def __floordiv__(self, other):\n",
      "                        line       551         return torch.floor_divide(self, other)\n",
      "                        return     551         return torch.floor_divide(self, other)\n",
      "        Return value:.. tensor<(1, 4), int64, cuda:0>\n",
      "                    return      27             return f(*args, **kwargs)\n",
      "    Return value:.. tensor<(1, 4), int64, cuda:0>\n",
      "Source path:... generation_utils.py\n",
      "                line      1778             next_tokens = next_tokens % vocab_size\n",
      "                line      1781             beam_outputs = beam_scorer.process(\n",
      "                line      1782                 input_ids,\n",
      "                line      1783                 next_token_scores,\n",
      "                line      1784                 next_tokens,\n",
      "                line      1785                 next_indices,\n",
      "                line      1786                 pad_token_id=pad_token_id,\n",
      "                line      1787                 eos_token_id=eos_token_id,\n",
      "                line      1781             beam_outputs = beam_scorer.process(\n",
      "    Source path:... generation_beam_search.py\n",
      "    Starting var:.. self = <transformers.generation_beam_search.BeamSearchScorer object>\n",
      "    Starting var:.. input_ids = tensor<(2, 4), int64, cuda:0>\n",
      "    Starting var:.. next_scores = tensor<(1, 4), float32, cuda:0, grad>\n",
      "    Starting var:.. next_tokens = tensor<(1, 4), int64, cuda:0>\n",
      "    Starting var:.. next_indices = tensor<(1, 4), int64, cuda:0>\n",
      "    Starting var:.. pad_token_id = 0\n",
      "    Starting var:.. eos_token_id = 1\n",
      "                    call       199     def process(\n",
      "                    line       208         cur_len = input_ids.shape[-1]\n",
      "    New var:....... cur_len = 4\n",
      "                    line       209         batch_size = len(self._beam_hyps)\n",
      "    New var:....... batch_size = 1\n",
      "                    line       210         assert batch_size == (input_ids.shape[0] // self.group_size)\n",
      "                    line       212         device = input_ids.device\n",
      "    New var:....... device = device(type='cuda', index=0)\n",
      "                    line       213         next_beam_scores = torch.zeros((batch_size, self.group_size), dtype=next_scores.dtype, device=device)\n",
      "    New var:....... next_beam_scores = tensor<(1, 2), float32, cuda:0>\n",
      "                    line       214         next_beam_tokens = torch.zeros((batch_size, self.group_size), dtype=next_tokens.dtype, device=device)\n",
      "    New var:....... next_beam_tokens = tensor<(1, 2), int64, cuda:0>\n",
      "                    line       215         next_beam_indices = torch.zeros((batch_size, self.group_size), dtype=next_indices.dtype, device=device)\n",
      "    New var:....... next_beam_indices = tensor<(1, 2), int64, cuda:0>\n",
      "                    line       217         for batch_idx, beam_hyp in enumerate(self._beam_hyps):\n",
      "    New var:....... batch_idx = 0\n",
      "    New var:....... beam_hyp = <transformers.generation_beam_search.BeamHypotheses object>\n",
      "                    line       218             if self._done[batch_idx]:\n",
      "                    line       232             beam_idx = 0\n",
      "    New var:....... beam_idx = 0\n",
      "                    line       233             for beam_token_rank, (next_token, next_score, next_index) in enumerate(\n",
      "                    line       234                 zip(next_tokens[batch_idx], next_scores[batch_idx], next_indices[batch_idx])\n",
      "        Source path:... tensor.py\n",
      "        Starting var:.. self = tensor<(4,), int64, cuda:0>\n",
      "                        call       576     def __iter__(self):\n",
      "                        line       583         relevant_args = (self,)\n",
      "        New var:....... relevant_args = (tensor<(4,), int64, cuda:0>,)\n",
      "                        line       584         from torch.overrides import has_torch_function, handle_torch_function\n",
      "        New var:....... has_torch_function = <function has_torch_function>\n",
      "        New var:....... handle_torch_function = <function handle_torch_function>\n",
      "                        line       585         if type(self) is not Tensor and has_torch_function(relevant_args):\n",
      "                        line       587         if self.dim() == 0:\n",
      "                        line       589         if torch._C._get_tracing_state():\n",
      "                        line       594         return iter(self.unbind(0))\n",
      "                        return     594         return iter(self.unbind(0))\n",
      "        Return value:.. <tuple_iterator object>\n",
      "        Starting var:.. self = tensor<(4,), float32, cuda:0, grad>\n",
      "                        call       576     def __iter__(self):\n",
      "                        line       583         relevant_args = (self,)\n",
      "        New var:....... relevant_args = (tensor<(4,), float32, cuda:0, grad>,)\n",
      "                        line       584         from torch.overrides import has_torch_function, handle_torch_function\n",
      "        New var:....... has_torch_function = <function has_torch_function>\n",
      "        New var:....... handle_torch_function = <function handle_torch_function>\n",
      "                        line       585         if type(self) is not Tensor and has_torch_function(relevant_args):\n",
      "                        line       587         if self.dim() == 0:\n",
      "                        line       589         if torch._C._get_tracing_state():\n",
      "                        line       594         return iter(self.unbind(0))\n",
      "                        return     594         return iter(self.unbind(0))\n",
      "        Return value:.. <tuple_iterator object>\n",
      "        Starting var:.. self = tensor<(4,), int64, cuda:0>\n",
      "                        call       576     def __iter__(self):\n",
      "                        line       583         relevant_args = (self,)\n",
      "        New var:....... relevant_args = (tensor<(4,), int64, cuda:0>,)\n",
      "                        line       584         from torch.overrides import has_torch_function, handle_torch_function\n",
      "        New var:....... has_torch_function = <function has_torch_function>\n",
      "        New var:....... handle_torch_function = <function handle_torch_function>\n",
      "                        line       585         if type(self) is not Tensor and has_torch_function(relevant_args):\n",
      "                        line       587         if self.dim() == 0:\n",
      "                        line       589         if torch._C._get_tracing_state():\n",
      "                        line       594         return iter(self.unbind(0))\n",
      "                        return     594         return iter(self.unbind(0))\n",
      "        Return value:.. <tuple_iterator object>\n",
      "    Source path:... generation_beam_search.py\n",
      "                    line       233             for beam_token_rank, (next_token, next_score, next_index) in enumerate(\n",
      "    New var:....... beam_token_rank = 0\n",
      "    New var:....... next_token = tensor<(), int64, cuda:0>\n",
      "    New var:....... next_score = tensor<(), float32, cuda:0, grad>\n",
      "    New var:....... next_index = tensor<(), int64, cuda:0>\n",
      "                    line       236                 batch_beam_idx = batch_idx * self.group_size + next_index\n",
      "    New var:....... batch_beam_idx = tensor<(), int64, cuda:0>\n",
      "                    line       238                 if (eos_token_id is not None) and (next_token.item() == eos_token_id):\n",
      "                    line       249                     next_beam_scores[batch_idx, beam_idx] = next_score\n",
      "    Modified var:.. next_beam_scores = tensor<(1, 2), float32, cuda:0, grad>\n",
      "                    line       250                     next_beam_tokens[batch_idx, beam_idx] = next_token\n",
      "                    line       251                     next_beam_indices[batch_idx, beam_idx] = batch_beam_idx\n",
      "                    line       252                     beam_idx += 1\n",
      "    Modified var:.. beam_idx = 1\n",
      "                    line       255                 if beam_idx == self.group_size:\n",
      "                    line       233             for beam_token_rank, (next_token, next_score, next_index) in enumerate(\n",
      "    Modified var:.. beam_token_rank = 1\n",
      "                    line       236                 batch_beam_idx = batch_idx * self.group_size + next_index\n",
      "                    line       238                 if (eos_token_id is not None) and (next_token.item() == eos_token_id):\n",
      "                    line       249                     next_beam_scores[batch_idx, beam_idx] = next_score\n",
      "                    line       250                     next_beam_tokens[batch_idx, beam_idx] = next_token\n",
      "                    line       251                     next_beam_indices[batch_idx, beam_idx] = batch_beam_idx\n",
      "                    line       252                     beam_idx += 1\n",
      "    Modified var:.. beam_idx = 2\n",
      "                    line       255                 if beam_idx == self.group_size:\n",
      "                    line       256                     break\n",
      "                    line       258             if beam_idx < self.group_size:\n",
      "                    line       264             self._done[batch_idx] = self._done[batch_idx] or beam_hyp.is_done(\n",
      "                    line       265                 next_scores[batch_idx].max().item(), cur_len\n",
      "                    line       264             self._done[batch_idx] = self._done[batch_idx] or beam_hyp.is_done(\n",
      "        Starting var:.. self = <transformers.generation_beam_search.BeamHypotheses object>\n",
      "        Starting var:.. best_sum_logprobs = -1.753554105758667\n",
      "        Starting var:.. cur_len = 4\n",
      "                        call       371     def is_done(self, best_sum_logprobs: float, cur_len: int) -> bool:\n",
      "                        line       377         if len(self) < self.num_beams:\n",
      "                        line       378             return False\n",
      "                        return     378             return False\n",
      "        Return value:.. False\n",
      "                    line       217         for batch_idx, beam_hyp in enumerate(self._beam_hyps):\n",
      "                    line       268         return UserDict(\n",
      "                    line       270                 \"next_beam_scores\": next_beam_scores.view(-1),\n",
      "                    line       271                 \"next_beam_tokens\": next_beam_tokens.view(-1),\n",
      "                    line       272                 \"next_beam_indices\": next_beam_indices.view(-1),\n",
      "                    line       269             {\n",
      "                    line       268         return UserDict(\n",
      "        Source path:... __init__.py\n",
      "        Starting var:.. args = REPR FAILED\n",
      "        Starting var:.. kwargs = {}\n",
      "                        call       981     def __init__(*args, **kwargs):\n",
      "                        line       982         if not args:\n",
      "                        line       985         self, *args = args\n",
      "        Modified var:.. args = [{'next_beam_scores': tensor<(2,), float32, cuda:0, grad>, 'next_beam_tokens': tensor<(2,), int64, cuda:0>, 'next_beam_indices': tensor<(2,), int64, cuda:0>}]\n",
      "        New var:....... self = REPR FAILED\n",
      "                        line       986         if len(args) > 1:\n",
      "                        line       988         if args:\n",
      "                        line       989             dict = args[0]\n",
      "        New var:....... dict = {'next_beam_scores': tensor<(2,), float32, cuda:0, grad>, 'next_beam_tokens': tensor<(2,), int64, cuda:0>, 'next_beam_indices': tensor<(2,), int64, cuda:0>}\n",
      "                        line       997         self.data = {}\n",
      "        Modified var:.. self = {}\n",
      "                        line       998         if dict is not None:\n",
      "                        line       999             self.update(dict)\n",
      "        Modified var:.. self = {'next_beam_scores': tensor([-1.7536, -3.4577], device='cuda:0', grad_fn=<ViewBackward>), 'next_be...kens': tensor([ 442, 3227], device='cuda:0'), 'next_beam_indices': tensor([0, 1], device='cuda:0')}\n",
      "                        line      1000         if kwargs:\n",
      "                        return    1000         if kwargs:\n",
      "        Return value:.. None\n",
      "    Source path:... generation_beam_search.py\n",
      "                    return     268         return UserDict(\n",
      "    Return value:.. {'next_beam_scores': tensor([-1.7536, -3.4577], device='cuda:0', grad_fn=<ViewBackward>), 'next_be...kens': tensor([ 442, 3227], device='cuda:0'), 'next_beam_indices': tensor([0, 1], device='cuda:0')}\n",
      "Source path:... generation_utils.py\n",
      "Modified var:.. beam_outputs = {'next_beam_scores': tensor([-1.7536, -3.4577], device='cuda:0', grad_fn=<ViewBackward>), 'next_be...kens': tensor([ 442, 3227], device='cuda:0'), 'next_beam_indices': tensor([0, 1], device='cuda:0')}\n",
      "                line      1789             beam_scores = beam_outputs[\"next_beam_scores\"]\n",
      "    Source path:... __init__.py\n",
      "    Starting var:.. self = {'next_beam_scores': tensor([-1.7536, -3.4577], device='cuda:0', grad_fn=<ViewBackward>), 'next_be...kens': tensor([ 442, 3227], device='cuda:0'), 'next_beam_indices': tensor([0, 1], device='cuda:0')}\n",
      "    Starting var:.. key = 'next_beam_scores'\n",
      "                    call      1005     def __getitem__(self, key):\n",
      "                    line      1006         if key in self.data:\n",
      "                    line      1007             return self.data[key]\n",
      "                    return    1007             return self.data[key]\n",
      "    Return value:.. tensor<(2,), float32, cuda:0, grad>\n",
      "Source path:... generation_utils.py\n",
      "                line      1790             beam_next_tokens = beam_outputs[\"next_beam_tokens\"]\n",
      "    Source path:... __init__.py\n",
      "    Starting var:.. self = {'next_beam_scores': tensor([-1.7536, -3.4577], device='cuda:0', grad_fn=<ViewBackward>), 'next_be...kens': tensor([ 442, 3227], device='cuda:0'), 'next_beam_indices': tensor([0, 1], device='cuda:0')}\n",
      "    Starting var:.. key = 'next_beam_tokens'\n",
      "                    call      1005     def __getitem__(self, key):\n",
      "                    line      1006         if key in self.data:\n",
      "                    line      1007             return self.data[key]\n",
      "                    return    1007             return self.data[key]\n",
      "    Return value:.. tensor<(2,), int64, cuda:0>\n",
      "Source path:... generation_utils.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                line      1791             beam_idx = beam_outputs[\"next_beam_indices\"]\n",
      "    Source path:... __init__.py\n",
      "    Starting var:.. self = {'next_beam_scores': tensor([-1.7536, -3.4577], device='cuda:0', grad_fn=<ViewBackward>), 'next_be...kens': tensor([ 442, 3227], device='cuda:0'), 'next_beam_indices': tensor([0, 1], device='cuda:0')}\n",
      "    Starting var:.. key = 'next_beam_indices'\n",
      "                    call      1005     def __getitem__(self, key):\n",
      "                    line      1006         if key in self.data:\n",
      "                    line      1007             return self.data[key]\n",
      "                    return    1007             return self.data[key]\n",
      "    Return value:.. tensor<(2,), int64, cuda:0>\n",
      "Source path:... generation_utils.py\n",
      "                line      1793             input_ids = torch.cat([input_ids[beam_idx, :], beam_next_tokens.unsqueeze(-1)], dim=-1)\n",
      "Modified var:.. input_ids = tensor<(2, 5), int64, cuda:0>\n",
      "                line      1795             cur_len = cur_len + 1\n",
      "Modified var:.. cur_len = 5\n",
      "                line      1797             model_kwargs = self._update_model_kwargs_for_generation(\n",
      "                line      1798                 outputs, model_kwargs, is_encoder_decoder=self.config.is_encoder_decoder\n",
      "                line      1797             model_kwargs = self._update_model_kwargs_for_generation(\n",
      "    Starting var:.. outputs = {'logits': tensor<(2, 1, 96103), float32, cuda:0, grad>, 'past_key_values': ((tensor<(2, 16, 4, 64...float32, cuda:0, grad>)), 'encoder_last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0, grad>}\n",
      "    Starting var:.. model_kwargs = {'use_cache': None, 'attention_mask': tensor<(2, 6), int64, cuda:0>, 'encoder_outputs': {'last_hid...d>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>))}\n",
      "    Starting var:.. is_encoder_decoder = True\n",
      "                    call       511     def _update_model_kwargs_for_generation(\n",
      "                    line       515         if \"past_key_values\" in outputs:\n",
      "                    line       516             model_kwargs[\"past\"] = outputs.past_key_values\n",
      "                    line       525         if \"token_type_ids\" in model_kwargs:\n",
      "                    line       530         if not is_encoder_decoder:\n",
      "                    line       537         return model_kwargs\n",
      "                    return     537         return model_kwargs\n",
      "    Return value:.. {'use_cache': None, 'attention_mask': tensor<(2, 6), int64, cuda:0>, 'encoder_outputs': {'last_hid...d>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>))}\n",
      "                line      1800             if model_kwargs[\"past\"] is not None:\n",
      "                line      1801                 model_kwargs[\"past\"] = self._reorder_cache(model_kwargs[\"past\"], beam_idx)\n",
      "    Source path:... modeling_pegasus.py\n",
      "    Starting var:.. past = ((tensor<(2, 16, 4, 64), float32, cuda:0, grad>, tensor<(2, 16, 4, 64), float32, cuda:0, grad>, te...ad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>))\n",
      "    Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                    call      1333     def _reorder_cache(past, beam_idx):\n",
      "                    line      1334         reordered_past = ()\n",
      "    New var:....... reordered_past = ()\n",
      "                    line      1335         for layer_past in past:\n",
      "    New var:....... layer_past = (tensor<(2, 16, 4, 64), float32, cuda:0, grad>, tensor<(2, 16, 4, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>)\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 4, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 4, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 4, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 4, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 4, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "    Modified var:.. reordered_past = ((tensor<(2, 16, 4, 64), float32, cuda:0, grad>, tensor<(2, 16, 4, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>),)\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 4, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 4, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 4, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 4, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 4, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "    Modified var:.. reordered_past = ((tensor<(2, 16, 4, 64), float32, cuda:0, grad>, tensor<(2, 16, 4, 64), float32, cuda:0, grad>, te...ad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>))\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 4, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 4, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 4, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 4, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 4, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 4, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 4, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 4, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 4, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 4, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 4, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 4, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 4, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 4, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 4, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 4, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 4, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 4, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 4, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 4, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 4, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 4, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 4, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 4, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 4, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 4, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 4, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 4, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 4, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 4, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 4, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 4, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 4, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 4, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 4, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 4, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 4, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 4, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 4, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 4, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 4, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 4, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 4, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 4, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 4, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 4, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 4, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 4, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 4, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 4, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 4, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 4, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 4, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 4, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 4, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 4, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 4, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 4, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 4, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 4, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 4, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 4, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 4, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 4, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 4, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 4, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 4, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 4, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 4, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 4, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1340         return reordered_past\n",
      "                    return    1340         return reordered_past\n",
      "    Return value:.. ((tensor<(2, 16, 4, 64), float32, cuda:0, grad>, tensor<(2, 16, 4, 64), float32, cuda:0, grad>, te...ad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>))\n",
      "Source path:... generation_utils.py\n",
      "                line      1803             if beam_scorer.is_done:\n",
      "    Source path:... generation_beam_search.py\n",
      "    Starting var:.. self = <transformers.generation_beam_search.BeamSearchScorer object>\n",
      "                    call       196     def is_done(self) -> bool:\n",
      "                    line       197         return self._done.all()\n",
      "                    return     197         return self._done.all()\n",
      "    Return value:.. tensor<(), bool, cuda:0>\n",
      "Source path:... generation_utils.py\n",
      "                line      1806             if stopping_criteria(input_ids, scores):\n",
      "    Source path:... generation_stopping_criteria.py\n",
      "    Starting var:.. self = [<transformers.generation_stopping_criteria.MaxLengthCriteria object>]\n",
      "    Starting var:.. input_ids = tensor<(2, 5), int64, cuda:0>\n",
      "    Starting var:.. scores = (tensor<(2, 96103), float32, cuda:0, grad>, tensor<(2, 96103), float32, cuda:0, grad>, tensor<(2, 96103), float32, cuda:0, grad>, tensor<(2, 96103), float32, cuda:0, grad>)\n",
      "    Starting var:.. kwargs = {}\n",
      "                    call        83     def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor, **kwargs) -> bool:\n",
      "                    line        84         return any(criteria(input_ids, scores) for criteria in self)\n",
      "        Starting var:.. .0 = <list_iterator object>\n",
      "        Starting var:.. input_ids = tensor<(2, 5), int64, cuda:0>\n",
      "        Starting var:.. scores = (tensor<(2, 96103), float32, cuda:0, grad>, tensor<(2, 96103), float32, cuda:0, grad>, tensor<(2, 96103), float32, cuda:0, grad>, tensor<(2, 96103), float32, cuda:0, grad>)\n",
      "                        call        84         return any(criteria(input_ids, scores) for criteria in self)\n",
      "                        line        84         return any(criteria(input_ids, scores) for criteria in self)\n",
      "        New var:....... criteria = <transformers.generation_stopping_criteria.MaxLengthCriteria object>\n",
      "                        return      84         return any(criteria(input_ids, scores) for criteria in self)\n",
      "        Return value:.. False\n",
      "        Starting var:.. .0 = <list_iterator object>\n",
      "        Starting var:.. criteria = <transformers.generation_stopping_criteria.MaxLengthCriteria object>\n",
      "        Starting var:.. input_ids = tensor<(2, 5), int64, cuda:0>\n",
      "        Starting var:.. scores = (tensor<(2, 96103), float32, cuda:0, grad>, tensor<(2, 96103), float32, cuda:0, grad>, tensor<(2, 96103), float32, cuda:0, grad>, tensor<(2, 96103), float32, cuda:0, grad>)\n",
      "                        call        84         return any(criteria(input_ids, scores) for criteria in self)\n",
      "                        line        84         return any(criteria(input_ids, scores) for criteria in self)\n",
      "                        return      84         return any(criteria(input_ids, scores) for criteria in self)\n",
      "        Return value:.. None\n",
      "                    return      84         return any(criteria(input_ids, scores) for criteria in self)\n",
      "    Return value:.. False\n",
      "Source path:... generation_utils.py\n",
      "                line      1729         while cur_len < max_length:\n",
      "                line      1730             model_inputs = self.prepare_inputs_for_generation(input_ids, **model_kwargs)\n",
      "    Source path:... modeling_pegasus.py\n",
      "    Starting var:.. self = PegasusForConditionalGeneration(  (model): PegasusModel(    (shared): Embedding(96103, 1024, paddi...mentwise_affine=True)    )  )  (lm_head): Linear(in_features=1024, out_features=96103, bias=False))\n",
      "    Starting var:.. decoder_input_ids = tensor<(2, 5), int64, cuda:0>\n",
      "    Starting var:.. past = ((tensor<(2, 16, 4, 64), float32, cuda:0, grad>, tensor<(2, 16, 4, 64), float32, cuda:0, grad>, te...ad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>))\n",
      "    Starting var:.. attention_mask = tensor<(2, 6), int64, cuda:0>\n",
      "    Starting var:.. head_mask = None\n",
      "    Starting var:.. use_cache = None\n",
      "    Starting var:.. encoder_outputs = {'last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0, grad>}\n",
      "    Starting var:.. kwargs = {}\n",
      "                    call      1305     def prepare_inputs_for_generation(\n",
      "                    line      1316         if past is not None:\n",
      "                    line      1317             decoder_input_ids = decoder_input_ids[:, -1:]\n",
      "    Modified var:.. decoder_input_ids = tensor<(2, 1), int64, cuda:0>\n",
      "                    line      1320             \"input_ids\": None,  # encoder_outputs is defined. input_ids not needed\n",
      "                    line      1321             \"encoder_outputs\": encoder_outputs,\n",
      "                    line      1322             \"past_key_values\": past,\n",
      "                    line      1323             \"decoder_input_ids\": decoder_input_ids,\n",
      "                    line      1324             \"attention_mask\": attention_mask,\n",
      "                    line      1325             \"head_mask\": head_mask,\n",
      "                    line      1326             \"use_cache\": use_cache,  # change this to avoid caching (presumably for debugging)\n",
      "                    line      1319         return {\n",
      "                    return    1319         return {\n",
      "    Return value:.. {'input_ids': None, 'encoder_outputs': {'last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0,...64, cuda:0>, 'attention_mask': tensor<(2, 6), int64, cuda:0>, 'head_mask': None, 'use_cache': None}\n",
      "Source path:... generation_utils.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                line      1732             outputs = self(\n",
      "                line      1733                 **model_inputs,\n",
      "                line      1734                 return_dict=True,\n",
      "                line      1735                 output_attentions=output_attentions,\n",
      "                line      1736                 output_hidden_states=output_hidden_states,\n",
      "                line      1732             outputs = self(\n",
      "    Source path:... module.py\n",
      "    Starting var:.. self = PegasusForConditionalGeneration(  (model): PegasusModel(    (shared): Embedding(96103, 1024, paddi...mentwise_affine=True)    )  )  (lm_head): Linear(in_features=1024, out_features=96103, bias=False))\n",
      "    Starting var:.. input = ()\n",
      "    Starting var:.. kwargs = {'input_ids': None, 'encoder_outputs': {'last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0,... 'use_cache': None, 'return_dict': True, 'output_attentions': False, 'output_hidden_states': False}\n",
      "                    call       715     def _call_impl(self, *input, **kwargs):\n",
      "                    line       716         for hook in itertools.chain(\n",
      "                    line       717                 _global_forward_pre_hooks.values(),\n",
      "                    line       718                 self._forward_pre_hooks.values()):\n",
      "                    line       716         for hook in itertools.chain(\n",
      "                    line       724         if torch._C._get_tracing_state():\n",
      "                    line       727             result = self.forward(*input, **kwargs)\n",
      "        Source path:... modeling_pegasus.py\n",
      "        Starting var:.. self = PegasusForConditionalGeneration(  (model): PegasusModel(    (shared): Embedding(96103, 1024, paddi...mentwise_affine=True)    )  )  (lm_head): Linear(in_features=1024, out_features=96103, bias=False))\n",
      "        Starting var:.. input_ids = None\n",
      "        Starting var:.. attention_mask = tensor<(2, 6), int64, cuda:0>\n",
      "        Starting var:.. decoder_input_ids = tensor<(2, 1), int64, cuda:0>\n",
      "        Starting var:.. decoder_attention_mask = None\n",
      "        Starting var:.. head_mask = None\n",
      "        Starting var:.. decoder_head_mask = None\n",
      "        Starting var:.. encoder_outputs = {'last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0, grad>}\n",
      "        Starting var:.. past_key_values = ((tensor<(2, 16, 4, 64), float32, cuda:0, grad>, tensor<(2, 16, 4, 64), float32, cuda:0, grad>, te...ad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>))\n",
      "        Starting var:.. inputs_embeds = None\n",
      "        Starting var:.. decoder_inputs_embeds = None\n",
      "        Starting var:.. labels = None\n",
      "        Starting var:.. use_cache = None\n",
      "        Starting var:.. output_attentions = False\n",
      "        Starting var:.. output_hidden_states = False\n",
      "        Starting var:.. return_dict = True\n",
      "                        call      1231     def forward(\n",
      "                        line      1258         return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
      "                        line      1260         if labels is not None:\n",
      "                        line      1266         outputs = self.model(\n",
      "                        line      1267             input_ids,\n",
      "                        line      1268             attention_mask=attention_mask,\n",
      "                        line      1269             decoder_input_ids=decoder_input_ids,\n",
      "                        line      1270             encoder_outputs=encoder_outputs,\n",
      "                        line      1271             decoder_attention_mask=decoder_attention_mask,\n",
      "                        line      1272             head_mask=head_mask,\n",
      "                        line      1273             decoder_head_mask=decoder_head_mask,\n",
      "                        line      1274             past_key_values=past_key_values,\n",
      "                        line      1275             inputs_embeds=inputs_embeds,\n",
      "                        line      1276             decoder_inputs_embeds=decoder_inputs_embeds,\n",
      "                        line      1277             use_cache=use_cache,\n",
      "                        line      1278             output_attentions=output_attentions,\n",
      "                        line      1279             output_hidden_states=output_hidden_states,\n",
      "                        line      1280             return_dict=return_dict,\n",
      "                        line      1266         outputs = self.model(\n",
      "        New var:....... outputs = {'last_hidden_state': tensor<(2, 1, 1024), float32, cuda:0, grad>, 'past_key_values': ((tensor<(2,...float32, cuda:0, grad>)), 'encoder_last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0, grad>}\n",
      "                        line      1282         lm_logits = self.lm_head(outputs[0]) + self.final_logits_bias\n",
      "        New var:....... lm_logits = tensor<(2, 1, 96103), float32, cuda:0, grad>\n",
      "                        line      1284         masked_lm_loss = None\n",
      "        New var:....... masked_lm_loss = None\n",
      "                        line      1285         if labels is not None:\n",
      "                        line      1289         if not return_dict:\n",
      "                        line      1293         return Seq2SeqLMOutput(\n",
      "                        line      1294             loss=masked_lm_loss,\n",
      "                        line      1295             logits=lm_logits,\n",
      "                        line      1296             past_key_values=outputs.past_key_values,\n",
      "                        line      1297             decoder_hidden_states=outputs.decoder_hidden_states,\n",
      "                        line      1298             decoder_attentions=outputs.decoder_attentions,\n",
      "                        line      1299             cross_attentions=outputs.cross_attentions,\n",
      "                        line      1300             encoder_last_hidden_state=outputs.encoder_last_hidden_state,\n",
      "                        line      1301             encoder_hidden_states=outputs.encoder_hidden_states,\n",
      "                        line      1302             encoder_attentions=outputs.encoder_attentions,\n",
      "                        line      1293         return Seq2SeqLMOutput(\n",
      "                        return    1293         return Seq2SeqLMOutput(\n",
      "        Return value:.. {'logits': tensor<(2, 1, 96103), float32, cuda:0, grad>, 'past_key_values': ((tensor<(2, 16, 5, 64...float32, cuda:0, grad>)), 'encoder_last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0, grad>}\n",
      "    Source path:... module.py\n",
      "    New var:....... result = {'logits': tensor<(2, 1, 96103), float32, cuda:0, grad>, 'past_key_values': ((tensor<(2, 16, 5, 64...float32, cuda:0, grad>)), 'encoder_last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0, grad>}\n",
      "                    line       728         for hook in itertools.chain(\n",
      "                    line       729                 _global_forward_hooks.values(),\n",
      "                    line       730                 self._forward_hooks.values()):\n",
      "                    line       728         for hook in itertools.chain(\n",
      "                    line       734         if (len(self._backward_hooks) > 0) or (len(_global_backward_hooks) > 0):\n",
      "                    line       749         return result\n",
      "                    return     749         return result\n",
      "    Return value:.. {'logits': tensor<(2, 1, 96103), float32, cuda:0, grad>, 'past_key_values': ((tensor<(2, 16, 5, 64...float32, cuda:0, grad>)), 'encoder_last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0, grad>}\n",
      "Source path:... generation_utils.py\n",
      "Modified var:.. outputs = {'logits': tensor<(2, 1, 96103), float32, cuda:0, grad>, 'past_key_values': ((tensor<(2, 16, 5, 64...float32, cuda:0, grad>)), 'encoder_last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0, grad>}\n",
      "                line      1738             next_token_logits = outputs.logits[:, -1, :]\n",
      "                line      1742             next_token_logits = self.adjust_logits_during_generation(\n",
      "                line      1743                 next_token_logits, cur_len=cur_len, max_length=max_length\n",
      "                line      1742             next_token_logits = self.adjust_logits_during_generation(\n",
      "    Starting var:.. self = PegasusForConditionalGeneration(  (model): PegasusModel(    (shared): Embedding(96103, 1024, paddi...mentwise_affine=True)    )  )  (lm_head): Linear(in_features=1024, out_features=96103, bias=False))\n",
      "    Starting var:.. logits = tensor<(2, 96103), float32, cuda:0, grad>\n",
      "    Starting var:.. kwargs = {'cur_len': 5, 'max_length': 60}\n",
      "                    call       373     def adjust_logits_during_generation(self, logits: torch.FloatTensor, **kwargs) -> torch.FloatTensor:\n",
      "                    line       378         return logits\n",
      "                    return     378         return logits\n",
      "    Return value:.. tensor<(2, 96103), float32, cuda:0, grad>\n",
      "                line      1746             next_token_scores = F.log_softmax(next_token_logits, dim=-1)  # (batch_size * num_beams, vocab_size)\n",
      "    Source path:... functional.py\n",
      "    Starting var:.. input = tensor<(2, 96103), float32, cuda:0, grad>\n",
      "    Starting var:.. dim = -1\n",
      "    Starting var:.. _stacklevel = 3\n",
      "    Starting var:.. dtype = None\n",
      "                    call      1581 def log_softmax(input, dim=None, _stacklevel=3, dtype=None):\n",
      "                    line      1598     if not torch.jit.is_scripting():\n",
      "        Source path:... _jit_internal.py\n",
      "                        call       750 def is_scripting():\n",
      "                        line       769     return False\n",
      "                        return     769     return False\n",
      "        Return value:.. False\n",
      "    Source path:... functional.py\n",
      "                    line      1599         if type(input) is not Tensor and has_torch_function((input,)):\n",
      "                    line      1602     if dim is None:\n",
      "                    line      1604     if dtype is None:\n",
      "                    line      1605         ret = input.log_softmax(dim)\n",
      "    New var:....... ret = tensor<(2, 96103), float32, cuda:0, grad>\n",
      "                    line      1608     return ret\n",
      "                    return    1608     return ret\n",
      "    Return value:.. tensor<(2, 96103), float32, cuda:0, grad>\n",
      "Source path:... generation_utils.py\n",
      "Modified var:.. next_token_scores = tensor<(2, 96103), float32, cuda:0, grad>\n",
      "                line      1748             next_token_scores = logits_processor(input_ids, next_token_scores)\n",
      "    Source path:... generation_logits_process.py\n",
      "    Starting var:.. self = [<transformers.generation_logits_process.MinLengthLogitsProcessor object>, <transformers.generation_logits_process.ForcedEOSTokenLogitsProcessor object>]\n",
      "    Starting var:.. input_ids = tensor<(2, 5), int64, cuda:0>\n",
      "    Starting var:.. scores = tensor<(2, 96103), float32, cuda:0, grad>\n",
      "    Starting var:.. kwargs = {}\n",
      "                    call        84     def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor, **kwargs) -> torch.FloatTensor:\n",
      "                    line        85         for processor in self:\n",
      "    New var:....... processor = <transformers.generation_logits_process.MinLengthLogitsProcessor object>\n",
      "                    line        86             function_args = inspect.signature(processor.__call__).parameters\n",
      "        Source path:... inspect.py\n",
      "        Starting var:.. obj = <bound method MinLengthLogitsProcessor.__call__ of <transformers.generation_logits_process.MinLengthLogitsProcessor object>>\n",
      "        Starting var:.. follow_wrapped = True\n",
      "                        call      3091 def signature(obj, *, follow_wrapped=True):\n",
      "                        line      3093     return Signature.from_callable(obj, follow_wrapped=follow_wrapped)\n",
      "                        return    3093     return Signature.from_callable(obj, follow_wrapped=follow_wrapped)\n",
      "        Return value:.. <Signature (input_ids: torch.LongTensor, scores: torch.FloatTensor) -> torch.FloatTensor>\n",
      "        Starting var:.. self = <Signature (input_ids: torch.LongTensor, scores: torch.FloatTensor) -> torch.FloatTensor>\n",
      "                        call      2846     def parameters(self):\n",
      "                        line      2847         return self._parameters\n",
      "                        return    2847         return self._parameters\n",
      "        Return value:.. mappingproxy(OrderedDict([('input_ids', <Parameter \"input_ids: torch.LongTensor\">), ('scores', <Parameter \"scores: torch.FloatTensor\">)]))\n",
      "    Source path:... generation_logits_process.py\n",
      "    New var:....... function_args = mappingproxy(OrderedDict([('input_ids', <Parameter \"input_ids: torch.LongTensor\">), ('scores', <Parameter \"scores: torch.FloatTensor\">)]))\n",
      "                    line        87             if len(function_args) > 2:\n",
      "                    line        93                 scores = processor(input_ids, scores)\n",
      "        Starting var:.. self = <transformers.generation_logits_process.MinLengthLogitsProcessor object>\n",
      "        Starting var:.. input_ids = tensor<(2, 5), int64, cuda:0>\n",
      "        Starting var:.. scores = tensor<(2, 96103), float32, cuda:0, grad>\n",
      "                        call       118     def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor) -> torch.FloatTensor:\n",
      "                        line       119         cur_len = input_ids.shape[-1]\n",
      "        New var:....... cur_len = 5\n",
      "                        line       120         if cur_len < self.min_length:\n",
      "                        line       122         return scores\n",
      "                        return     122         return scores\n",
      "        Return value:.. tensor<(2, 96103), float32, cuda:0, grad>\n",
      "                    line        85         for processor in self:\n",
      "    Modified var:.. processor = <transformers.generation_logits_process.ForcedEOSTokenLogitsProcessor object>\n",
      "                    line        86             function_args = inspect.signature(processor.__call__).parameters\n",
      "        Source path:... inspect.py\n",
      "        Starting var:.. obj = <bound method ForcedEOSTokenLogitsProcessor.__call__ of <transformers.generation_logits_process.ForcedEOSTokenLogitsProcessor object>>\n",
      "        Starting var:.. follow_wrapped = True\n",
      "                        call      3091 def signature(obj, *, follow_wrapped=True):\n",
      "                        line      3093     return Signature.from_callable(obj, follow_wrapped=follow_wrapped)\n",
      "                        return    3093     return Signature.from_callable(obj, follow_wrapped=follow_wrapped)\n",
      "        Return value:.. <Signature (input_ids: torch.LongTensor, scores: torch.FloatTensor) -> torch.FloatTensor>\n",
      "        Starting var:.. self = <Signature (input_ids: torch.LongTensor, scores: torch.FloatTensor) -> torch.FloatTensor>\n",
      "                        call      2846     def parameters(self):\n",
      "                        line      2847         return self._parameters\n",
      "                        return    2847         return self._parameters\n",
      "        Return value:.. mappingproxy(OrderedDict([('input_ids', <Parameter \"input_ids: torch.LongTensor\">), ('scores', <Parameter \"scores: torch.FloatTensor\">)]))\n",
      "    Source path:... generation_logits_process.py\n",
      "                    line        87             if len(function_args) > 2:\n",
      "                    line        93                 scores = processor(input_ids, scores)\n",
      "        Starting var:.. self = <transformers.generation_logits_process.ForcedEOSTokenLogitsProcessor object>\n",
      "        Starting var:.. input_ids = tensor<(2, 5), int64, cuda:0>\n",
      "        Starting var:.. scores = tensor<(2, 96103), float32, cuda:0, grad>\n",
      "                        call       571     def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor) -> torch.FloatTensor:\n",
      "                        line       572         cur_len = input_ids.shape[-1]\n",
      "        New var:....... cur_len = 5\n",
      "                        line       573         if cur_len == self.max_length - 1:\n",
      "                        line       577         return scores\n",
      "                        return     577         return scores\n",
      "        Return value:.. tensor<(2, 96103), float32, cuda:0, grad>\n",
      "                    line        85         for processor in self:\n",
      "                    line        94         return scores\n",
      "                    return      94         return scores\n",
      "    Return value:.. tensor<(2, 96103), float32, cuda:0, grad>\n",
      "Source path:... generation_utils.py\n",
      "                line      1749             next_token_scores = next_token_scores + beam_scores[:, None].expand_as(next_token_scores)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                line      1752             if return_dict_in_generate:\n",
      "                line      1753                 if output_scores:\n",
      "                line      1754                     scores += (next_token_scores,)\n",
      "Modified var:.. scores = (tensor<(2, 96103), float32, cuda:0, grad>, tensor<(2, 96103), float32, cuda:0, grad>, tensor<(2, ...uda:0, grad>, tensor<(2, 96103), float32, cuda:0, grad>, tensor<(2, 96103), float32, cuda:0, grad>)\n",
      "                line      1755                 if output_attentions:\n",
      "                line      1762                 if output_hidden_states:\n",
      "                line      1770             vocab_size = next_token_scores.shape[-1]\n",
      "                line      1771             next_token_scores = next_token_scores.view(batch_size, num_beams * vocab_size)\n",
      "Modified var:.. next_token_scores = tensor<(1, 192206), float32, cuda:0, grad>\n",
      "                line      1773             next_token_scores, next_tokens = torch.topk(\n",
      "                line      1774                 next_token_scores, 2 * num_beams, dim=1, largest=True, sorted=True\n",
      "                line      1773             next_token_scores, next_tokens = torch.topk(\n",
      "Modified var:.. next_token_scores = tensor<(1, 4), float32, cuda:0, grad>\n",
      "                line      1777             next_indices = next_tokens // vocab_size\n",
      "    Source path:... tensor.py\n",
      "    Starting var:.. args = (tensor<(1, 4), int64, cuda:0>, 96103)\n",
      "    Starting var:.. kwargs = {}\n",
      "    Starting var:.. f = <function Tensor.__floordiv__>\n",
      "    Starting var:.. wrapped = <function Tensor.__floordiv__>\n",
      "                    call        22     def wrapped(*args, **kwargs):\n",
      "                    line        23         from torch.overrides import has_torch_function, handle_torch_function\n",
      "    New var:....... has_torch_function = <function has_torch_function>\n",
      "    New var:....... handle_torch_function = <function handle_torch_function>\n",
      "                    line        24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "                        call        24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "                        line        24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "        New var:....... t = tensor<(1, 4), int64, cuda:0>\n",
      "                        return      24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "        Return value:.. True\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. t = tensor<(1, 4), int64, cuda:0>\n",
      "                        call        24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "                        line        24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "        Modified var:.. t = 96103\n",
      "                        return      24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "        Return value:.. False\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. t = 96103\n",
      "                        call        24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "                        exception   24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "        Exception:..... GeneratorExit\n",
      "                        return      24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "        Return value:.. None\n",
      "        Source path:... overrides.py\n",
      "        Starting var:.. relevant_args = (tensor<(1, 4), int64, cuda:0>, 96103)\n",
      "                        call      1070 def has_torch_function(relevant_args: Iterable[Any]) -> bool:\n",
      "                        line      1083     return _is_torch_function_enabled() and any(\n",
      "                        line      1087         for a in relevant_args\n",
      "                        line      1083     return _is_torch_function_enabled() and any(\n",
      "                        return    1083     return _is_torch_function_enabled() and any(\n",
      "        Return value:.. False\n",
      "    Source path:... tensor.py\n",
      "                    line        26         try:\n",
      "                    line        27             return f(*args, **kwargs)\n",
      "        Starting var:.. self = tensor<(1, 4), int64, cuda:0>\n",
      "        Starting var:.. other = 96103\n",
      "                        call       550     def __floordiv__(self, other):\n",
      "                        line       551         return torch.floor_divide(self, other)\n",
      "                        return     551         return torch.floor_divide(self, other)\n",
      "        Return value:.. tensor<(1, 4), int64, cuda:0>\n",
      "                    return      27             return f(*args, **kwargs)\n",
      "    Return value:.. tensor<(1, 4), int64, cuda:0>\n",
      "Source path:... generation_utils.py\n",
      "                line      1778             next_tokens = next_tokens % vocab_size\n",
      "                line      1781             beam_outputs = beam_scorer.process(\n",
      "                line      1782                 input_ids,\n",
      "                line      1783                 next_token_scores,\n",
      "                line      1784                 next_tokens,\n",
      "                line      1785                 next_indices,\n",
      "                line      1786                 pad_token_id=pad_token_id,\n",
      "                line      1787                 eos_token_id=eos_token_id,\n",
      "                line      1781             beam_outputs = beam_scorer.process(\n",
      "    Source path:... generation_beam_search.py\n",
      "    Starting var:.. self = <transformers.generation_beam_search.BeamSearchScorer object>\n",
      "    Starting var:.. input_ids = tensor<(2, 5), int64, cuda:0>\n",
      "    Starting var:.. next_scores = tensor<(1, 4), float32, cuda:0, grad>\n",
      "    Starting var:.. next_tokens = tensor<(1, 4), int64, cuda:0>\n",
      "    Starting var:.. next_indices = tensor<(1, 4), int64, cuda:0>\n",
      "    Starting var:.. pad_token_id = 0\n",
      "    Starting var:.. eos_token_id = 1\n",
      "                    call       199     def process(\n",
      "                    line       208         cur_len = input_ids.shape[-1]\n",
      "    New var:....... cur_len = 5\n",
      "                    line       209         batch_size = len(self._beam_hyps)\n",
      "    New var:....... batch_size = 1\n",
      "                    line       210         assert batch_size == (input_ids.shape[0] // self.group_size)\n",
      "                    line       212         device = input_ids.device\n",
      "    New var:....... device = device(type='cuda', index=0)\n",
      "                    line       213         next_beam_scores = torch.zeros((batch_size, self.group_size), dtype=next_scores.dtype, device=device)\n",
      "    New var:....... next_beam_scores = tensor<(1, 2), float32, cuda:0>\n",
      "                    line       214         next_beam_tokens = torch.zeros((batch_size, self.group_size), dtype=next_tokens.dtype, device=device)\n",
      "    New var:....... next_beam_tokens = tensor<(1, 2), int64, cuda:0>\n",
      "                    line       215         next_beam_indices = torch.zeros((batch_size, self.group_size), dtype=next_indices.dtype, device=device)\n",
      "    New var:....... next_beam_indices = tensor<(1, 2), int64, cuda:0>\n",
      "                    line       217         for batch_idx, beam_hyp in enumerate(self._beam_hyps):\n",
      "    New var:....... batch_idx = 0\n",
      "    New var:....... beam_hyp = <transformers.generation_beam_search.BeamHypotheses object>\n",
      "                    line       218             if self._done[batch_idx]:\n",
      "                    line       232             beam_idx = 0\n",
      "    New var:....... beam_idx = 0\n",
      "                    line       233             for beam_token_rank, (next_token, next_score, next_index) in enumerate(\n",
      "                    line       234                 zip(next_tokens[batch_idx], next_scores[batch_idx], next_indices[batch_idx])\n",
      "        Source path:... tensor.py\n",
      "        Starting var:.. self = tensor<(4,), int64, cuda:0>\n",
      "                        call       576     def __iter__(self):\n",
      "                        line       583         relevant_args = (self,)\n",
      "        New var:....... relevant_args = (tensor<(4,), int64, cuda:0>,)\n",
      "                        line       584         from torch.overrides import has_torch_function, handle_torch_function\n",
      "        New var:....... has_torch_function = <function has_torch_function>\n",
      "        New var:....... handle_torch_function = <function handle_torch_function>\n",
      "                        line       585         if type(self) is not Tensor and has_torch_function(relevant_args):\n",
      "                        line       587         if self.dim() == 0:\n",
      "                        line       589         if torch._C._get_tracing_state():\n",
      "                        line       594         return iter(self.unbind(0))\n",
      "                        return     594         return iter(self.unbind(0))\n",
      "        Return value:.. <tuple_iterator object>\n",
      "        Starting var:.. self = tensor<(4,), float32, cuda:0, grad>\n",
      "                        call       576     def __iter__(self):\n",
      "                        line       583         relevant_args = (self,)\n",
      "        New var:....... relevant_args = (tensor<(4,), float32, cuda:0, grad>,)\n",
      "                        line       584         from torch.overrides import has_torch_function, handle_torch_function\n",
      "        New var:....... has_torch_function = <function has_torch_function>\n",
      "        New var:....... handle_torch_function = <function handle_torch_function>\n",
      "                        line       585         if type(self) is not Tensor and has_torch_function(relevant_args):\n",
      "                        line       587         if self.dim() == 0:\n",
      "                        line       589         if torch._C._get_tracing_state():\n",
      "                        line       594         return iter(self.unbind(0))\n",
      "                        return     594         return iter(self.unbind(0))\n",
      "        Return value:.. <tuple_iterator object>\n",
      "        Starting var:.. self = tensor<(4,), int64, cuda:0>\n",
      "                        call       576     def __iter__(self):\n",
      "                        line       583         relevant_args = (self,)\n",
      "        New var:....... relevant_args = (tensor<(4,), int64, cuda:0>,)\n",
      "                        line       584         from torch.overrides import has_torch_function, handle_torch_function\n",
      "        New var:....... has_torch_function = <function has_torch_function>\n",
      "        New var:....... handle_torch_function = <function handle_torch_function>\n",
      "                        line       585         if type(self) is not Tensor and has_torch_function(relevant_args):\n",
      "                        line       587         if self.dim() == 0:\n",
      "                        line       589         if torch._C._get_tracing_state():\n",
      "                        line       594         return iter(self.unbind(0))\n",
      "                        return     594         return iter(self.unbind(0))\n",
      "        Return value:.. <tuple_iterator object>\n",
      "    Source path:... generation_beam_search.py\n",
      "                    line       233             for beam_token_rank, (next_token, next_score, next_index) in enumerate(\n",
      "    New var:....... beam_token_rank = 0\n",
      "    New var:....... next_token = tensor<(), int64, cuda:0>\n",
      "    New var:....... next_score = tensor<(), float32, cuda:0, grad>\n",
      "    New var:....... next_index = tensor<(), int64, cuda:0>\n",
      "                    line       236                 batch_beam_idx = batch_idx * self.group_size + next_index\n",
      "    New var:....... batch_beam_idx = tensor<(), int64, cuda:0>\n",
      "                    line       238                 if (eos_token_id is not None) and (next_token.item() == eos_token_id):\n",
      "                    line       249                     next_beam_scores[batch_idx, beam_idx] = next_score\n",
      "    Modified var:.. next_beam_scores = tensor<(1, 2), float32, cuda:0, grad>\n",
      "                    line       250                     next_beam_tokens[batch_idx, beam_idx] = next_token\n",
      "                    line       251                     next_beam_indices[batch_idx, beam_idx] = batch_beam_idx\n",
      "                    line       252                     beam_idx += 1\n",
      "    Modified var:.. beam_idx = 1\n",
      "                    line       255                 if beam_idx == self.group_size:\n",
      "                    line       233             for beam_token_rank, (next_token, next_score, next_index) in enumerate(\n",
      "    Modified var:.. beam_token_rank = 1\n",
      "                    line       236                 batch_beam_idx = batch_idx * self.group_size + next_index\n",
      "                    line       238                 if (eos_token_id is not None) and (next_token.item() == eos_token_id):\n",
      "                    line       249                     next_beam_scores[batch_idx, beam_idx] = next_score\n",
      "                    line       250                     next_beam_tokens[batch_idx, beam_idx] = next_token\n",
      "                    line       251                     next_beam_indices[batch_idx, beam_idx] = batch_beam_idx\n",
      "                    line       252                     beam_idx += 1\n",
      "    Modified var:.. beam_idx = 2\n",
      "                    line       255                 if beam_idx == self.group_size:\n",
      "                    line       256                     break\n",
      "                    line       258             if beam_idx < self.group_size:\n",
      "                    line       264             self._done[batch_idx] = self._done[batch_idx] or beam_hyp.is_done(\n",
      "                    line       265                 next_scores[batch_idx].max().item(), cur_len\n",
      "                    line       264             self._done[batch_idx] = self._done[batch_idx] or beam_hyp.is_done(\n",
      "        Starting var:.. self = <transformers.generation_beam_search.BeamHypotheses object>\n",
      "        Starting var:.. best_sum_logprobs = -2.1390438079833984\n",
      "        Starting var:.. cur_len = 5\n",
      "                        call       371     def is_done(self, best_sum_logprobs: float, cur_len: int) -> bool:\n",
      "                        line       377         if len(self) < self.num_beams:\n",
      "                        line       378             return False\n",
      "                        return     378             return False\n",
      "        Return value:.. False\n",
      "                    line       217         for batch_idx, beam_hyp in enumerate(self._beam_hyps):\n",
      "                    line       268         return UserDict(\n",
      "                    line       270                 \"next_beam_scores\": next_beam_scores.view(-1),\n",
      "                    line       271                 \"next_beam_tokens\": next_beam_tokens.view(-1),\n",
      "                    line       272                 \"next_beam_indices\": next_beam_indices.view(-1),\n",
      "                    line       269             {\n",
      "                    line       268         return UserDict(\n",
      "        Source path:... __init__.py\n",
      "        Starting var:.. args = REPR FAILED\n",
      "        Starting var:.. kwargs = {}\n",
      "                        call       981     def __init__(*args, **kwargs):\n",
      "                        line       982         if not args:\n",
      "                        line       985         self, *args = args\n",
      "        Modified var:.. args = [{'next_beam_scores': tensor<(2,), float32, cuda:0, grad>, 'next_beam_tokens': tensor<(2,), int64, cuda:0>, 'next_beam_indices': tensor<(2,), int64, cuda:0>}]\n",
      "        New var:....... self = REPR FAILED\n",
      "                        line       986         if len(args) > 1:\n",
      "                        line       988         if args:\n",
      "                        line       989             dict = args[0]\n",
      "        New var:....... dict = {'next_beam_scores': tensor<(2,), float32, cuda:0, grad>, 'next_beam_tokens': tensor<(2,), int64, cuda:0>, 'next_beam_indices': tensor<(2,), int64, cuda:0>}\n",
      "                        line       997         self.data = {}\n",
      "        Modified var:.. self = {}\n",
      "                        line       998         if dict is not None:\n",
      "                        line       999             self.update(dict)\n",
      "        Modified var:.. self = {'next_beam_scores': tensor([-2.1390, -3.9068], device='cuda:0', grad_fn=<ViewBackward>), 'next_beam_tokens': tensor([107, 111], device='cuda:0'), 'next_beam_indices': tensor([0, 1], device='cuda:0')}\n",
      "                        line      1000         if kwargs:\n",
      "                        return    1000         if kwargs:\n",
      "        Return value:.. None\n",
      "    Source path:... generation_beam_search.py\n",
      "                    return     268         return UserDict(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    Return value:.. {'next_beam_scores': tensor([-2.1390, -3.9068], device='cuda:0', grad_fn=<ViewBackward>), 'next_beam_tokens': tensor([107, 111], device='cuda:0'), 'next_beam_indices': tensor([0, 1], device='cuda:0')}\n",
      "Source path:... generation_utils.py\n",
      "Modified var:.. beam_outputs = {'next_beam_scores': tensor([-2.1390, -3.9068], device='cuda:0', grad_fn=<ViewBackward>), 'next_beam_tokens': tensor([107, 111], device='cuda:0'), 'next_beam_indices': tensor([0, 1], device='cuda:0')}\n",
      "                line      1789             beam_scores = beam_outputs[\"next_beam_scores\"]\n",
      "    Source path:... __init__.py\n",
      "    Starting var:.. self = {'next_beam_scores': tensor([-2.1390, -3.9068], device='cuda:0', grad_fn=<ViewBackward>), 'next_beam_tokens': tensor([107, 111], device='cuda:0'), 'next_beam_indices': tensor([0, 1], device='cuda:0')}\n",
      "    Starting var:.. key = 'next_beam_scores'\n",
      "                    call      1005     def __getitem__(self, key):\n",
      "                    line      1006         if key in self.data:\n",
      "                    line      1007             return self.data[key]\n",
      "                    return    1007             return self.data[key]\n",
      "    Return value:.. tensor<(2,), float32, cuda:0, grad>\n",
      "Source path:... generation_utils.py\n",
      "                line      1790             beam_next_tokens = beam_outputs[\"next_beam_tokens\"]\n",
      "    Source path:... __init__.py\n",
      "    Starting var:.. self = {'next_beam_scores': tensor([-2.1390, -3.9068], device='cuda:0', grad_fn=<ViewBackward>), 'next_beam_tokens': tensor([107, 111], device='cuda:0'), 'next_beam_indices': tensor([0, 1], device='cuda:0')}\n",
      "    Starting var:.. key = 'next_beam_tokens'\n",
      "                    call      1005     def __getitem__(self, key):\n",
      "                    line      1006         if key in self.data:\n",
      "                    line      1007             return self.data[key]\n",
      "                    return    1007             return self.data[key]\n",
      "    Return value:.. tensor<(2,), int64, cuda:0>\n",
      "Source path:... generation_utils.py\n",
      "                line      1791             beam_idx = beam_outputs[\"next_beam_indices\"]\n",
      "    Source path:... __init__.py\n",
      "    Starting var:.. self = {'next_beam_scores': tensor([-2.1390, -3.9068], device='cuda:0', grad_fn=<ViewBackward>), 'next_beam_tokens': tensor([107, 111], device='cuda:0'), 'next_beam_indices': tensor([0, 1], device='cuda:0')}\n",
      "    Starting var:.. key = 'next_beam_indices'\n",
      "                    call      1005     def __getitem__(self, key):\n",
      "                    line      1006         if key in self.data:\n",
      "                    line      1007             return self.data[key]\n",
      "                    return    1007             return self.data[key]\n",
      "    Return value:.. tensor<(2,), int64, cuda:0>\n",
      "Source path:... generation_utils.py\n",
      "                line      1793             input_ids = torch.cat([input_ids[beam_idx, :], beam_next_tokens.unsqueeze(-1)], dim=-1)\n",
      "Modified var:.. input_ids = tensor<(2, 6), int64, cuda:0>\n",
      "                line      1795             cur_len = cur_len + 1\n",
      "Modified var:.. cur_len = 6\n",
      "                line      1797             model_kwargs = self._update_model_kwargs_for_generation(\n",
      "                line      1798                 outputs, model_kwargs, is_encoder_decoder=self.config.is_encoder_decoder\n",
      "                line      1797             model_kwargs = self._update_model_kwargs_for_generation(\n",
      "    Starting var:.. outputs = {'logits': tensor<(2, 1, 96103), float32, cuda:0, grad>, 'past_key_values': ((tensor<(2, 16, 5, 64...float32, cuda:0, grad>)), 'encoder_last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0, grad>}\n",
      "    Starting var:.. model_kwargs = {'use_cache': None, 'attention_mask': tensor<(2, 6), int64, cuda:0>, 'encoder_outputs': {'last_hid...d>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>))}\n",
      "    Starting var:.. is_encoder_decoder = True\n",
      "                    call       511     def _update_model_kwargs_for_generation(\n",
      "                    line       515         if \"past_key_values\" in outputs:\n",
      "                    line       516             model_kwargs[\"past\"] = outputs.past_key_values\n",
      "                    line       525         if \"token_type_ids\" in model_kwargs:\n",
      "                    line       530         if not is_encoder_decoder:\n",
      "                    line       537         return model_kwargs\n",
      "                    return     537         return model_kwargs\n",
      "    Return value:.. {'use_cache': None, 'attention_mask': tensor<(2, 6), int64, cuda:0>, 'encoder_outputs': {'last_hid...d>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>))}\n",
      "                line      1800             if model_kwargs[\"past\"] is not None:\n",
      "                line      1801                 model_kwargs[\"past\"] = self._reorder_cache(model_kwargs[\"past\"], beam_idx)\n",
      "    Source path:... modeling_pegasus.py\n",
      "    Starting var:.. past = ((tensor<(2, 16, 5, 64), float32, cuda:0, grad>, tensor<(2, 16, 5, 64), float32, cuda:0, grad>, te...ad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>))\n",
      "    Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                    call      1333     def _reorder_cache(past, beam_idx):\n",
      "                    line      1334         reordered_past = ()\n",
      "    New var:....... reordered_past = ()\n",
      "                    line      1335         for layer_past in past:\n",
      "    New var:....... layer_past = (tensor<(2, 16, 5, 64), float32, cuda:0, grad>, tensor<(2, 16, 5, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>)\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 5, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 5, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 5, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 5, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 5, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "    Modified var:.. reordered_past = ((tensor<(2, 16, 5, 64), float32, cuda:0, grad>, tensor<(2, 16, 5, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>),)\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 5, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 5, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 5, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 5, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 5, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "    Modified var:.. reordered_past = ((tensor<(2, 16, 5, 64), float32, cuda:0, grad>, tensor<(2, 16, 5, 64), float32, cuda:0, grad>, te...ad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>))\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 5, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 5, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 5, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 5, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 5, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 5, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 5, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 5, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 5, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 5, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 5, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 5, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 5, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 5, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 5, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 5, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 5, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 5, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 5, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 5, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 5, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 5, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 5, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 5, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 5, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 5, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 5, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 5, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 5, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 5, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 5, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 5, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 5, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 5, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 5, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 5, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 5, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 5, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 5, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 5, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 5, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 5, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 5, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 5, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 5, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 5, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 5, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 5, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 5, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 5, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 5, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 5, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 5, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 5, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 5, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 5, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 5, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 5, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 5, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 5, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 5, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 5, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 5, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 5, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 5, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 5, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 5, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 5, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 5, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 5, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1340         return reordered_past\n",
      "                    return    1340         return reordered_past\n",
      "    Return value:.. ((tensor<(2, 16, 5, 64), float32, cuda:0, grad>, tensor<(2, 16, 5, 64), float32, cuda:0, grad>, te...ad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>))\n",
      "Source path:... generation_utils.py\n",
      "                line      1803             if beam_scorer.is_done:\n",
      "    Source path:... generation_beam_search.py\n",
      "    Starting var:.. self = <transformers.generation_beam_search.BeamSearchScorer object>\n",
      "                    call       196     def is_done(self) -> bool:\n",
      "                    line       197         return self._done.all()\n",
      "                    return     197         return self._done.all()\n",
      "    Return value:.. tensor<(), bool, cuda:0>\n",
      "Source path:... generation_utils.py\n",
      "                line      1806             if stopping_criteria(input_ids, scores):\n",
      "    Source path:... generation_stopping_criteria.py\n",
      "    Starting var:.. self = [<transformers.generation_stopping_criteria.MaxLengthCriteria object>]\n",
      "    Starting var:.. input_ids = tensor<(2, 6), int64, cuda:0>\n",
      "    Starting var:.. scores = (tensor<(2, 96103), float32, cuda:0, grad>, tensor<(2, 96103), float32, cuda:0, grad>, tensor<(2, ...uda:0, grad>, tensor<(2, 96103), float32, cuda:0, grad>, tensor<(2, 96103), float32, cuda:0, grad>)\n",
      "    Starting var:.. kwargs = {}\n",
      "                    call        83     def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor, **kwargs) -> bool:\n",
      "                    line        84         return any(criteria(input_ids, scores) for criteria in self)\n",
      "        Starting var:.. .0 = <list_iterator object>\n",
      "        Starting var:.. input_ids = tensor<(2, 6), int64, cuda:0>\n",
      "        Starting var:.. scores = (tensor<(2, 96103), float32, cuda:0, grad>, tensor<(2, 96103), float32, cuda:0, grad>, tensor<(2, ...uda:0, grad>, tensor<(2, 96103), float32, cuda:0, grad>, tensor<(2, 96103), float32, cuda:0, grad>)\n",
      "                        call        84         return any(criteria(input_ids, scores) for criteria in self)\n",
      "                        line        84         return any(criteria(input_ids, scores) for criteria in self)\n",
      "        New var:....... criteria = <transformers.generation_stopping_criteria.MaxLengthCriteria object>\n",
      "                        return      84         return any(criteria(input_ids, scores) for criteria in self)\n",
      "        Return value:.. False\n",
      "        Starting var:.. .0 = <list_iterator object>\n",
      "        Starting var:.. criteria = <transformers.generation_stopping_criteria.MaxLengthCriteria object>\n",
      "        Starting var:.. input_ids = tensor<(2, 6), int64, cuda:0>\n",
      "        Starting var:.. scores = (tensor<(2, 96103), float32, cuda:0, grad>, tensor<(2, 96103), float32, cuda:0, grad>, tensor<(2, ...uda:0, grad>, tensor<(2, 96103), float32, cuda:0, grad>, tensor<(2, 96103), float32, cuda:0, grad>)\n",
      "                        call        84         return any(criteria(input_ids, scores) for criteria in self)\n",
      "                        line        84         return any(criteria(input_ids, scores) for criteria in self)\n",
      "                        return      84         return any(criteria(input_ids, scores) for criteria in self)\n",
      "        Return value:.. None\n",
      "                    return      84         return any(criteria(input_ids, scores) for criteria in self)\n",
      "    Return value:.. False\n",
      "Source path:... generation_utils.py\n",
      "                line      1729         while cur_len < max_length:\n",
      "                line      1730             model_inputs = self.prepare_inputs_for_generation(input_ids, **model_kwargs)\n",
      "    Source path:... modeling_pegasus.py\n",
      "    Starting var:.. self = PegasusForConditionalGeneration(  (model): PegasusModel(    (shared): Embedding(96103, 1024, paddi...mentwise_affine=True)    )  )  (lm_head): Linear(in_features=1024, out_features=96103, bias=False))\n",
      "    Starting var:.. decoder_input_ids = tensor<(2, 6), int64, cuda:0>\n",
      "    Starting var:.. past = ((tensor<(2, 16, 5, 64), float32, cuda:0, grad>, tensor<(2, 16, 5, 64), float32, cuda:0, grad>, te...ad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>))\n",
      "    Starting var:.. attention_mask = tensor<(2, 6), int64, cuda:0>\n",
      "    Starting var:.. head_mask = None\n",
      "    Starting var:.. use_cache = None\n",
      "    Starting var:.. encoder_outputs = {'last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0, grad>}\n",
      "    Starting var:.. kwargs = {}\n",
      "                    call      1305     def prepare_inputs_for_generation(\n",
      "                    line      1316         if past is not None:\n",
      "                    line      1317             decoder_input_ids = decoder_input_ids[:, -1:]\n",
      "    Modified var:.. decoder_input_ids = tensor<(2, 1), int64, cuda:0>\n",
      "                    line      1320             \"input_ids\": None,  # encoder_outputs is defined. input_ids not needed\n",
      "                    line      1321             \"encoder_outputs\": encoder_outputs,\n",
      "                    line      1322             \"past_key_values\": past,\n",
      "                    line      1323             \"decoder_input_ids\": decoder_input_ids,\n",
      "                    line      1324             \"attention_mask\": attention_mask,\n",
      "                    line      1325             \"head_mask\": head_mask,\n",
      "                    line      1326             \"use_cache\": use_cache,  # change this to avoid caching (presumably for debugging)\n",
      "                    line      1319         return {\n",
      "                    return    1319         return {\n",
      "    Return value:.. {'input_ids': None, 'encoder_outputs': {'last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0,...64, cuda:0>, 'attention_mask': tensor<(2, 6), int64, cuda:0>, 'head_mask': None, 'use_cache': None}\n",
      "Source path:... generation_utils.py\n",
      "                line      1732             outputs = self(\n",
      "                line      1733                 **model_inputs,\n",
      "                line      1734                 return_dict=True,\n",
      "                line      1735                 output_attentions=output_attentions,\n",
      "                line      1736                 output_hidden_states=output_hidden_states,\n",
      "                line      1732             outputs = self(\n",
      "    Source path:... module.py\n",
      "    Starting var:.. self = PegasusForConditionalGeneration(  (model): PegasusModel(    (shared): Embedding(96103, 1024, paddi...mentwise_affine=True)    )  )  (lm_head): Linear(in_features=1024, out_features=96103, bias=False))\n",
      "    Starting var:.. input = ()\n",
      "    Starting var:.. kwargs = {'input_ids': None, 'encoder_outputs': {'last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0,... 'use_cache': None, 'return_dict': True, 'output_attentions': False, 'output_hidden_states': False}\n",
      "                    call       715     def _call_impl(self, *input, **kwargs):\n",
      "                    line       716         for hook in itertools.chain(\n",
      "                    line       717                 _global_forward_pre_hooks.values(),\n",
      "                    line       718                 self._forward_pre_hooks.values()):\n",
      "                    line       716         for hook in itertools.chain(\n",
      "                    line       724         if torch._C._get_tracing_state():\n",
      "                    line       727             result = self.forward(*input, **kwargs)\n",
      "        Source path:... modeling_pegasus.py\n",
      "        Starting var:.. self = PegasusForConditionalGeneration(  (model): PegasusModel(    (shared): Embedding(96103, 1024, paddi...mentwise_affine=True)    )  )  (lm_head): Linear(in_features=1024, out_features=96103, bias=False))\n",
      "        Starting var:.. input_ids = None\n",
      "        Starting var:.. attention_mask = tensor<(2, 6), int64, cuda:0>\n",
      "        Starting var:.. decoder_input_ids = tensor<(2, 1), int64, cuda:0>\n",
      "        Starting var:.. decoder_attention_mask = None\n",
      "        Starting var:.. head_mask = None\n",
      "        Starting var:.. decoder_head_mask = None\n",
      "        Starting var:.. encoder_outputs = {'last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0, grad>}\n",
      "        Starting var:.. past_key_values = ((tensor<(2, 16, 5, 64), float32, cuda:0, grad>, tensor<(2, 16, 5, 64), float32, cuda:0, grad>, te...ad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>))\n",
      "        Starting var:.. inputs_embeds = None\n",
      "        Starting var:.. decoder_inputs_embeds = None\n",
      "        Starting var:.. labels = None\n",
      "        Starting var:.. use_cache = None\n",
      "        Starting var:.. output_attentions = False\n",
      "        Starting var:.. output_hidden_states = False\n",
      "        Starting var:.. return_dict = True\n",
      "                        call      1231     def forward(\n",
      "                        line      1258         return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
      "                        line      1260         if labels is not None:\n",
      "                        line      1266         outputs = self.model(\n",
      "                        line      1267             input_ids,\n",
      "                        line      1268             attention_mask=attention_mask,\n",
      "                        line      1269             decoder_input_ids=decoder_input_ids,\n",
      "                        line      1270             encoder_outputs=encoder_outputs,\n",
      "                        line      1271             decoder_attention_mask=decoder_attention_mask,\n",
      "                        line      1272             head_mask=head_mask,\n",
      "                        line      1273             decoder_head_mask=decoder_head_mask,\n",
      "                        line      1274             past_key_values=past_key_values,\n",
      "                        line      1275             inputs_embeds=inputs_embeds,\n",
      "                        line      1276             decoder_inputs_embeds=decoder_inputs_embeds,\n",
      "                        line      1277             use_cache=use_cache,\n",
      "                        line      1278             output_attentions=output_attentions,\n",
      "                        line      1279             output_hidden_states=output_hidden_states,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                        line      1280             return_dict=return_dict,\n",
      "                        line      1266         outputs = self.model(\n",
      "        New var:....... outputs = {'last_hidden_state': tensor<(2, 1, 1024), float32, cuda:0, grad>, 'past_key_values': ((tensor<(2,...float32, cuda:0, grad>)), 'encoder_last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0, grad>}\n",
      "                        line      1282         lm_logits = self.lm_head(outputs[0]) + self.final_logits_bias\n",
      "        New var:....... lm_logits = tensor<(2, 1, 96103), float32, cuda:0, grad>\n",
      "                        line      1284         masked_lm_loss = None\n",
      "        New var:....... masked_lm_loss = None\n",
      "                        line      1285         if labels is not None:\n",
      "                        line      1289         if not return_dict:\n",
      "                        line      1293         return Seq2SeqLMOutput(\n",
      "                        line      1294             loss=masked_lm_loss,\n",
      "                        line      1295             logits=lm_logits,\n",
      "                        line      1296             past_key_values=outputs.past_key_values,\n",
      "                        line      1297             decoder_hidden_states=outputs.decoder_hidden_states,\n",
      "                        line      1298             decoder_attentions=outputs.decoder_attentions,\n",
      "                        line      1299             cross_attentions=outputs.cross_attentions,\n",
      "                        line      1300             encoder_last_hidden_state=outputs.encoder_last_hidden_state,\n",
      "                        line      1301             encoder_hidden_states=outputs.encoder_hidden_states,\n",
      "                        line      1302             encoder_attentions=outputs.encoder_attentions,\n",
      "                        line      1293         return Seq2SeqLMOutput(\n",
      "                        return    1293         return Seq2SeqLMOutput(\n",
      "        Return value:.. {'logits': tensor<(2, 1, 96103), float32, cuda:0, grad>, 'past_key_values': ((tensor<(2, 16, 6, 64...float32, cuda:0, grad>)), 'encoder_last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0, grad>}\n",
      "    Source path:... module.py\n",
      "    New var:....... result = {'logits': tensor<(2, 1, 96103), float32, cuda:0, grad>, 'past_key_values': ((tensor<(2, 16, 6, 64...float32, cuda:0, grad>)), 'encoder_last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0, grad>}\n",
      "                    line       728         for hook in itertools.chain(\n",
      "                    line       729                 _global_forward_hooks.values(),\n",
      "                    line       730                 self._forward_hooks.values()):\n",
      "                    line       728         for hook in itertools.chain(\n",
      "                    line       734         if (len(self._backward_hooks) > 0) or (len(_global_backward_hooks) > 0):\n",
      "                    line       749         return result\n",
      "                    return     749         return result\n",
      "    Return value:.. {'logits': tensor<(2, 1, 96103), float32, cuda:0, grad>, 'past_key_values': ((tensor<(2, 16, 6, 64...float32, cuda:0, grad>)), 'encoder_last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0, grad>}\n",
      "Source path:... generation_utils.py\n",
      "Modified var:.. outputs = {'logits': tensor<(2, 1, 96103), float32, cuda:0, grad>, 'past_key_values': ((tensor<(2, 16, 6, 64...float32, cuda:0, grad>)), 'encoder_last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0, grad>}\n",
      "                line      1738             next_token_logits = outputs.logits[:, -1, :]\n",
      "                line      1742             next_token_logits = self.adjust_logits_during_generation(\n",
      "                line      1743                 next_token_logits, cur_len=cur_len, max_length=max_length\n",
      "                line      1742             next_token_logits = self.adjust_logits_during_generation(\n",
      "    Starting var:.. self = PegasusForConditionalGeneration(  (model): PegasusModel(    (shared): Embedding(96103, 1024, paddi...mentwise_affine=True)    )  )  (lm_head): Linear(in_features=1024, out_features=96103, bias=False))\n",
      "    Starting var:.. logits = tensor<(2, 96103), float32, cuda:0, grad>\n",
      "    Starting var:.. kwargs = {'cur_len': 6, 'max_length': 60}\n",
      "                    call       373     def adjust_logits_during_generation(self, logits: torch.FloatTensor, **kwargs) -> torch.FloatTensor:\n",
      "                    line       378         return logits\n",
      "                    return     378         return logits\n",
      "    Return value:.. tensor<(2, 96103), float32, cuda:0, grad>\n",
      "                line      1746             next_token_scores = F.log_softmax(next_token_logits, dim=-1)  # (batch_size * num_beams, vocab_size)\n",
      "    Source path:... functional.py\n",
      "    Starting var:.. input = tensor<(2, 96103), float32, cuda:0, grad>\n",
      "    Starting var:.. dim = -1\n",
      "    Starting var:.. _stacklevel = 3\n",
      "    Starting var:.. dtype = None\n",
      "                    call      1581 def log_softmax(input, dim=None, _stacklevel=3, dtype=None):\n",
      "                    line      1598     if not torch.jit.is_scripting():\n",
      "        Source path:... _jit_internal.py\n",
      "                        call       750 def is_scripting():\n",
      "                        line       769     return False\n",
      "                        return     769     return False\n",
      "        Return value:.. False\n",
      "    Source path:... functional.py\n",
      "                    line      1599         if type(input) is not Tensor and has_torch_function((input,)):\n",
      "                    line      1602     if dim is None:\n",
      "                    line      1604     if dtype is None:\n",
      "                    line      1605         ret = input.log_softmax(dim)\n",
      "    New var:....... ret = tensor<(2, 96103), float32, cuda:0, grad>\n",
      "                    line      1608     return ret\n",
      "                    return    1608     return ret\n",
      "    Return value:.. tensor<(2, 96103), float32, cuda:0, grad>\n",
      "Source path:... generation_utils.py\n",
      "Modified var:.. next_token_scores = tensor<(2, 96103), float32, cuda:0, grad>\n",
      "                line      1748             next_token_scores = logits_processor(input_ids, next_token_scores)\n",
      "    Source path:... generation_logits_process.py\n",
      "    Starting var:.. self = [<transformers.generation_logits_process.MinLengthLogitsProcessor object>, <transformers.generation_logits_process.ForcedEOSTokenLogitsProcessor object>]\n",
      "    Starting var:.. input_ids = tensor<(2, 6), int64, cuda:0>\n",
      "    Starting var:.. scores = tensor<(2, 96103), float32, cuda:0, grad>\n",
      "    Starting var:.. kwargs = {}\n",
      "                    call        84     def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor, **kwargs) -> torch.FloatTensor:\n",
      "                    line        85         for processor in self:\n",
      "    New var:....... processor = <transformers.generation_logits_process.MinLengthLogitsProcessor object>\n",
      "                    line        86             function_args = inspect.signature(processor.__call__).parameters\n",
      "        Source path:... inspect.py\n",
      "        Starting var:.. obj = <bound method MinLengthLogitsProcessor.__call__ of <transformers.generation_logits_process.MinLengthLogitsProcessor object>>\n",
      "        Starting var:.. follow_wrapped = True\n",
      "                        call      3091 def signature(obj, *, follow_wrapped=True):\n",
      "                        line      3093     return Signature.from_callable(obj, follow_wrapped=follow_wrapped)\n",
      "                        return    3093     return Signature.from_callable(obj, follow_wrapped=follow_wrapped)\n",
      "        Return value:.. <Signature (input_ids: torch.LongTensor, scores: torch.FloatTensor) -> torch.FloatTensor>\n",
      "        Starting var:.. self = <Signature (input_ids: torch.LongTensor, scores: torch.FloatTensor) -> torch.FloatTensor>\n",
      "                        call      2846     def parameters(self):\n",
      "                        line      2847         return self._parameters\n",
      "                        return    2847         return self._parameters\n",
      "        Return value:.. mappingproxy(OrderedDict([('input_ids', <Parameter \"input_ids: torch.LongTensor\">), ('scores', <Parameter \"scores: torch.FloatTensor\">)]))\n",
      "    Source path:... generation_logits_process.py\n",
      "    New var:....... function_args = mappingproxy(OrderedDict([('input_ids', <Parameter \"input_ids: torch.LongTensor\">), ('scores', <Parameter \"scores: torch.FloatTensor\">)]))\n",
      "                    line        87             if len(function_args) > 2:\n",
      "                    line        93                 scores = processor(input_ids, scores)\n",
      "        Starting var:.. self = <transformers.generation_logits_process.MinLengthLogitsProcessor object>\n",
      "        Starting var:.. input_ids = tensor<(2, 6), int64, cuda:0>\n",
      "        Starting var:.. scores = tensor<(2, 96103), float32, cuda:0, grad>\n",
      "                        call       118     def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor) -> torch.FloatTensor:\n",
      "                        line       119         cur_len = input_ids.shape[-1]\n",
      "        New var:....... cur_len = 6\n",
      "                        line       120         if cur_len < self.min_length:\n",
      "                        line       122         return scores\n",
      "                        return     122         return scores\n",
      "        Return value:.. tensor<(2, 96103), float32, cuda:0, grad>\n",
      "                    line        85         for processor in self:\n",
      "    Modified var:.. processor = <transformers.generation_logits_process.ForcedEOSTokenLogitsProcessor object>\n",
      "                    line        86             function_args = inspect.signature(processor.__call__).parameters\n",
      "        Source path:... inspect.py\n",
      "        Starting var:.. obj = <bound method ForcedEOSTokenLogitsProcessor.__call__ of <transformers.generation_logits_process.ForcedEOSTokenLogitsProcessor object>>\n",
      "        Starting var:.. follow_wrapped = True\n",
      "                        call      3091 def signature(obj, *, follow_wrapped=True):\n",
      "                        line      3093     return Signature.from_callable(obj, follow_wrapped=follow_wrapped)\n",
      "                        return    3093     return Signature.from_callable(obj, follow_wrapped=follow_wrapped)\n",
      "        Return value:.. <Signature (input_ids: torch.LongTensor, scores: torch.FloatTensor) -> torch.FloatTensor>\n",
      "        Starting var:.. self = <Signature (input_ids: torch.LongTensor, scores: torch.FloatTensor) -> torch.FloatTensor>\n",
      "                        call      2846     def parameters(self):\n",
      "                        line      2847         return self._parameters\n",
      "                        return    2847         return self._parameters\n",
      "        Return value:.. mappingproxy(OrderedDict([('input_ids', <Parameter \"input_ids: torch.LongTensor\">), ('scores', <Parameter \"scores: torch.FloatTensor\">)]))\n",
      "    Source path:... generation_logits_process.py\n",
      "                    line        87             if len(function_args) > 2:\n",
      "                    line        93                 scores = processor(input_ids, scores)\n",
      "        Starting var:.. self = <transformers.generation_logits_process.ForcedEOSTokenLogitsProcessor object>\n",
      "        Starting var:.. input_ids = tensor<(2, 6), int64, cuda:0>\n",
      "        Starting var:.. scores = tensor<(2, 96103), float32, cuda:0, grad>\n",
      "                        call       571     def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor) -> torch.FloatTensor:\n",
      "                        line       572         cur_len = input_ids.shape[-1]\n",
      "        New var:....... cur_len = 6\n",
      "                        line       573         if cur_len == self.max_length - 1:\n",
      "                        line       577         return scores\n",
      "                        return     577         return scores\n",
      "        Return value:.. tensor<(2, 96103), float32, cuda:0, grad>\n",
      "                    line        85         for processor in self:\n",
      "                    line        94         return scores\n",
      "                    return      94         return scores\n",
      "    Return value:.. tensor<(2, 96103), float32, cuda:0, grad>\n",
      "Source path:... generation_utils.py\n",
      "                line      1749             next_token_scores = next_token_scores + beam_scores[:, None].expand_as(next_token_scores)\n",
      "                line      1752             if return_dict_in_generate:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                line      1753                 if output_scores:\n",
      "                line      1754                     scores += (next_token_scores,)\n",
      "                line      1755                 if output_attentions:\n",
      "                line      1762                 if output_hidden_states:\n",
      "                line      1770             vocab_size = next_token_scores.shape[-1]\n",
      "                line      1771             next_token_scores = next_token_scores.view(batch_size, num_beams * vocab_size)\n",
      "Modified var:.. next_token_scores = tensor<(1, 192206), float32, cuda:0, grad>\n",
      "                line      1773             next_token_scores, next_tokens = torch.topk(\n",
      "                line      1774                 next_token_scores, 2 * num_beams, dim=1, largest=True, sorted=True\n",
      "                line      1773             next_token_scores, next_tokens = torch.topk(\n",
      "Modified var:.. next_token_scores = tensor<(1, 4), float32, cuda:0, grad>\n",
      "                line      1777             next_indices = next_tokens // vocab_size\n",
      "    Source path:... tensor.py\n",
      "    Starting var:.. args = (tensor<(1, 4), int64, cuda:0>, 96103)\n",
      "    Starting var:.. kwargs = {}\n",
      "    Starting var:.. f = <function Tensor.__floordiv__>\n",
      "    Starting var:.. wrapped = <function Tensor.__floordiv__>\n",
      "                    call        22     def wrapped(*args, **kwargs):\n",
      "                    line        23         from torch.overrides import has_torch_function, handle_torch_function\n",
      "    New var:....... has_torch_function = <function has_torch_function>\n",
      "    New var:....... handle_torch_function = <function handle_torch_function>\n",
      "                    line        24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "                        call        24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "                        line        24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "        New var:....... t = tensor<(1, 4), int64, cuda:0>\n",
      "                        return      24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "        Return value:.. True\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. t = tensor<(1, 4), int64, cuda:0>\n",
      "                        call        24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "                        line        24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "        Modified var:.. t = 96103\n",
      "                        return      24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "        Return value:.. False\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. t = 96103\n",
      "                        call        24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "                        exception   24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "        Exception:..... GeneratorExit\n",
      "                        return      24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "        Return value:.. None\n",
      "        Source path:... overrides.py\n",
      "        Starting var:.. relevant_args = (tensor<(1, 4), int64, cuda:0>, 96103)\n",
      "                        call      1070 def has_torch_function(relevant_args: Iterable[Any]) -> bool:\n",
      "                        line      1083     return _is_torch_function_enabled() and any(\n",
      "                        line      1087         for a in relevant_args\n",
      "                        line      1083     return _is_torch_function_enabled() and any(\n",
      "                        return    1083     return _is_torch_function_enabled() and any(\n",
      "        Return value:.. False\n",
      "    Source path:... tensor.py\n",
      "                    line        26         try:\n",
      "                    line        27             return f(*args, **kwargs)\n",
      "        Starting var:.. self = tensor<(1, 4), int64, cuda:0>\n",
      "        Starting var:.. other = 96103\n",
      "                        call       550     def __floordiv__(self, other):\n",
      "                        line       551         return torch.floor_divide(self, other)\n",
      "                        return     551         return torch.floor_divide(self, other)\n",
      "        Return value:.. tensor<(1, 4), int64, cuda:0>\n",
      "                    return      27             return f(*args, **kwargs)\n",
      "    Return value:.. tensor<(1, 4), int64, cuda:0>\n",
      "Source path:... generation_utils.py\n",
      "                line      1778             next_tokens = next_tokens % vocab_size\n",
      "                line      1781             beam_outputs = beam_scorer.process(\n",
      "                line      1782                 input_ids,\n",
      "                line      1783                 next_token_scores,\n",
      "                line      1784                 next_tokens,\n",
      "                line      1785                 next_indices,\n",
      "                line      1786                 pad_token_id=pad_token_id,\n",
      "                line      1787                 eos_token_id=eos_token_id,\n",
      "                line      1781             beam_outputs = beam_scorer.process(\n",
      "    Source path:... generation_beam_search.py\n",
      "    Starting var:.. self = <transformers.generation_beam_search.BeamSearchScorer object>\n",
      "    Starting var:.. input_ids = tensor<(2, 6), int64, cuda:0>\n",
      "    Starting var:.. next_scores = tensor<(1, 4), float32, cuda:0, grad>\n",
      "    Starting var:.. next_tokens = tensor<(1, 4), int64, cuda:0>\n",
      "    Starting var:.. next_indices = tensor<(1, 4), int64, cuda:0>\n",
      "    Starting var:.. pad_token_id = 0\n",
      "    Starting var:.. eos_token_id = 1\n",
      "                    call       199     def process(\n",
      "                    line       208         cur_len = input_ids.shape[-1]\n",
      "    New var:....... cur_len = 6\n",
      "                    line       209         batch_size = len(self._beam_hyps)\n",
      "    New var:....... batch_size = 1\n",
      "                    line       210         assert batch_size == (input_ids.shape[0] // self.group_size)\n",
      "                    line       212         device = input_ids.device\n",
      "    New var:....... device = device(type='cuda', index=0)\n",
      "                    line       213         next_beam_scores = torch.zeros((batch_size, self.group_size), dtype=next_scores.dtype, device=device)\n",
      "    New var:....... next_beam_scores = tensor<(1, 2), float32, cuda:0>\n",
      "                    line       214         next_beam_tokens = torch.zeros((batch_size, self.group_size), dtype=next_tokens.dtype, device=device)\n",
      "    New var:....... next_beam_tokens = tensor<(1, 2), int64, cuda:0>\n",
      "                    line       215         next_beam_indices = torch.zeros((batch_size, self.group_size), dtype=next_indices.dtype, device=device)\n",
      "    New var:....... next_beam_indices = tensor<(1, 2), int64, cuda:0>\n",
      "                    line       217         for batch_idx, beam_hyp in enumerate(self._beam_hyps):\n",
      "    New var:....... batch_idx = 0\n",
      "    New var:....... beam_hyp = <transformers.generation_beam_search.BeamHypotheses object>\n",
      "                    line       218             if self._done[batch_idx]:\n",
      "                    line       232             beam_idx = 0\n",
      "    New var:....... beam_idx = 0\n",
      "                    line       233             for beam_token_rank, (next_token, next_score, next_index) in enumerate(\n",
      "                    line       234                 zip(next_tokens[batch_idx], next_scores[batch_idx], next_indices[batch_idx])\n",
      "        Source path:... tensor.py\n",
      "        Starting var:.. self = tensor<(4,), int64, cuda:0>\n",
      "                        call       576     def __iter__(self):\n",
      "                        line       583         relevant_args = (self,)\n",
      "        New var:....... relevant_args = (tensor<(4,), int64, cuda:0>,)\n",
      "                        line       584         from torch.overrides import has_torch_function, handle_torch_function\n",
      "        New var:....... has_torch_function = <function has_torch_function>\n",
      "        New var:....... handle_torch_function = <function handle_torch_function>\n",
      "                        line       585         if type(self) is not Tensor and has_torch_function(relevant_args):\n",
      "                        line       587         if self.dim() == 0:\n",
      "                        line       589         if torch._C._get_tracing_state():\n",
      "                        line       594         return iter(self.unbind(0))\n",
      "                        return     594         return iter(self.unbind(0))\n",
      "        Return value:.. <tuple_iterator object>\n",
      "        Starting var:.. self = tensor<(4,), float32, cuda:0, grad>\n",
      "                        call       576     def __iter__(self):\n",
      "                        line       583         relevant_args = (self,)\n",
      "        New var:....... relevant_args = (tensor<(4,), float32, cuda:0, grad>,)\n",
      "                        line       584         from torch.overrides import has_torch_function, handle_torch_function\n",
      "        New var:....... has_torch_function = <function has_torch_function>\n",
      "        New var:....... handle_torch_function = <function handle_torch_function>\n",
      "                        line       585         if type(self) is not Tensor and has_torch_function(relevant_args):\n",
      "                        line       587         if self.dim() == 0:\n",
      "                        line       589         if torch._C._get_tracing_state():\n",
      "                        line       594         return iter(self.unbind(0))\n",
      "                        return     594         return iter(self.unbind(0))\n",
      "        Return value:.. <tuple_iterator object>\n",
      "        Starting var:.. self = tensor<(4,), int64, cuda:0>\n",
      "                        call       576     def __iter__(self):\n",
      "                        line       583         relevant_args = (self,)\n",
      "        New var:....... relevant_args = (tensor<(4,), int64, cuda:0>,)\n",
      "                        line       584         from torch.overrides import has_torch_function, handle_torch_function\n",
      "        New var:....... has_torch_function = <function has_torch_function>\n",
      "        New var:....... handle_torch_function = <function handle_torch_function>\n",
      "                        line       585         if type(self) is not Tensor and has_torch_function(relevant_args):\n",
      "                        line       587         if self.dim() == 0:\n",
      "                        line       589         if torch._C._get_tracing_state():\n",
      "                        line       594         return iter(self.unbind(0))\n",
      "                        return     594         return iter(self.unbind(0))\n",
      "        Return value:.. <tuple_iterator object>\n",
      "    Source path:... generation_beam_search.py\n",
      "                    line       233             for beam_token_rank, (next_token, next_score, next_index) in enumerate(\n",
      "    New var:....... beam_token_rank = 0\n",
      "    New var:....... next_token = tensor<(), int64, cuda:0>\n",
      "    New var:....... next_score = tensor<(), float32, cuda:0, grad>\n",
      "    New var:....... next_index = tensor<(), int64, cuda:0>\n",
      "                    line       236                 batch_beam_idx = batch_idx * self.group_size + next_index\n",
      "    New var:....... batch_beam_idx = tensor<(), int64, cuda:0>\n",
      "                    line       238                 if (eos_token_id is not None) and (next_token.item() == eos_token_id):\n",
      "                    line       240                     is_beam_token_worse_than_top_num_beams = beam_token_rank >= self.group_size\n",
      "    New var:....... is_beam_token_worse_than_top_num_beams = False\n",
      "                    line       241                     if is_beam_token_worse_than_top_num_beams:\n",
      "                    line       243                     beam_hyp.add(\n",
      "                    line       244                         input_ids[batch_beam_idx].clone(),\n",
      "                    line       245                         next_score.item(),\n",
      "                    line       243                     beam_hyp.add(\n",
      "        Starting var:.. self = <transformers.generation_beam_search.BeamHypotheses object>\n",
      "        Starting var:.. hyp = tensor<(6,), int64, cuda:0>\n",
      "        Starting var:.. sum_logprobs = -2.241197347640991\n",
      "                        call       357     def add(self, hyp: torch.LongTensor, sum_logprobs: float):\n",
      "                        line       361         score = sum_logprobs / (hyp.shape[-1] ** self.length_penalty)\n",
      "        New var:....... score = -0.37353289127349854\n",
      "                        line       362         if len(self) < self.num_beams or score > self.worst_score:\n",
      "                        line       363             self.beams.append((score, hyp))\n",
      "                        line       364             if len(self) > self.num_beams:\n",
      "                        line       369                 self.worst_score = min(score, self.worst_score)\n",
      "                        return     369                 self.worst_score = min(score, self.worst_score)\n",
      "        Return value:.. None\n",
      "                    line       255                 if beam_idx == self.group_size:\n",
      "                    line       233             for beam_token_rank, (next_token, next_score, next_index) in enumerate(\n",
      "    Modified var:.. beam_token_rank = 1\n",
      "                    line       236                 batch_beam_idx = batch_idx * self.group_size + next_index\n",
      "                    line       238                 if (eos_token_id is not None) and (next_token.item() == eos_token_id):\n",
      "                    line       249                     next_beam_scores[batch_idx, beam_idx] = next_score\n",
      "    Modified var:.. next_beam_scores = tensor<(1, 2), float32, cuda:0, grad>\n",
      "                    line       250                     next_beam_tokens[batch_idx, beam_idx] = next_token\n",
      "                    line       251                     next_beam_indices[batch_idx, beam_idx] = batch_beam_idx\n",
      "                    line       252                     beam_idx += 1\n",
      "    Modified var:.. beam_idx = 1\n",
      "                    line       255                 if beam_idx == self.group_size:\n",
      "                    line       233             for beam_token_rank, (next_token, next_score, next_index) in enumerate(\n",
      "    Modified var:.. beam_token_rank = 2\n",
      "                    line       236                 batch_beam_idx = batch_idx * self.group_size + next_index\n",
      "                    line       238                 if (eos_token_id is not None) and (next_token.item() == eos_token_id):\n",
      "                    line       249                     next_beam_scores[batch_idx, beam_idx] = next_score\n",
      "                    line       250                     next_beam_tokens[batch_idx, beam_idx] = next_token\n",
      "                    line       251                     next_beam_indices[batch_idx, beam_idx] = batch_beam_idx\n",
      "                    line       252                     beam_idx += 1\n",
      "    Modified var:.. beam_idx = 2\n",
      "                    line       255                 if beam_idx == self.group_size:\n",
      "                    line       256                     break\n",
      "                    line       258             if beam_idx < self.group_size:\n",
      "                    line       264             self._done[batch_idx] = self._done[batch_idx] or beam_hyp.is_done(\n",
      "                    line       265                 next_scores[batch_idx].max().item(), cur_len\n",
      "                    line       264             self._done[batch_idx] = self._done[batch_idx] or beam_hyp.is_done(\n",
      "        Starting var:.. self = <transformers.generation_beam_search.BeamHypotheses object>\n",
      "        Starting var:.. best_sum_logprobs = -2.241197347640991\n",
      "        Starting var:.. cur_len = 6\n",
      "                        call       371     def is_done(self, best_sum_logprobs: float, cur_len: int) -> bool:\n",
      "                        line       377         if len(self) < self.num_beams:\n",
      "                        line       378             return False\n",
      "                        return     378             return False\n",
      "        Return value:.. False\n",
      "                    line       217         for batch_idx, beam_hyp in enumerate(self._beam_hyps):\n",
      "                    line       268         return UserDict(\n",
      "                    line       270                 \"next_beam_scores\": next_beam_scores.view(-1),\n",
      "                    line       271                 \"next_beam_tokens\": next_beam_tokens.view(-1),\n",
      "                    line       272                 \"next_beam_indices\": next_beam_indices.view(-1),\n",
      "                    line       269             {\n",
      "                    line       268         return UserDict(\n",
      "        Source path:... __init__.py\n",
      "        Starting var:.. args = REPR FAILED\n",
      "        Starting var:.. kwargs = {}\n",
      "                        call       981     def __init__(*args, **kwargs):\n",
      "                        line       982         if not args:\n",
      "                        line       985         self, *args = args\n",
      "        Modified var:.. args = [{'next_beam_scores': tensor<(2,), float32, cuda:0, grad>, 'next_beam_tokens': tensor<(2,), int64, cuda:0>, 'next_beam_indices': tensor<(2,), int64, cuda:0>}]\n",
      "        New var:....... self = REPR FAILED\n",
      "                        line       986         if len(args) > 1:\n",
      "                        line       988         if args:\n",
      "                        line       989             dict = args[0]\n",
      "        New var:....... dict = {'next_beam_scores': tensor<(2,), float32, cuda:0, grad>, 'next_beam_tokens': tensor<(2,), int64, cuda:0>, 'next_beam_indices': tensor<(2,), int64, cuda:0>}\n",
      "                        line       997         self.data = {}\n",
      "        Modified var:.. self = {}\n",
      "                        line       998         if dict is not None:\n",
      "                        line       999             self.update(dict)\n",
      "        Modified var:.. self = {'next_beam_scores': tensor([-4.3012, -7.3791], device='cuda:0', grad_fn=<ViewBackward>), 'next_beam_tokens': tensor([125, 161], device='cuda:0'), 'next_beam_indices': tensor([1, 1], device='cuda:0')}\n",
      "                        line      1000         if kwargs:\n",
      "                        return    1000         if kwargs:\n",
      "        Return value:.. None\n",
      "    Source path:... generation_beam_search.py\n",
      "                    return     268         return UserDict(\n",
      "    Return value:.. {'next_beam_scores': tensor([-4.3012, -7.3791], device='cuda:0', grad_fn=<ViewBackward>), 'next_beam_tokens': tensor([125, 161], device='cuda:0'), 'next_beam_indices': tensor([1, 1], device='cuda:0')}\n",
      "Source path:... generation_utils.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Modified var:.. beam_outputs = {'next_beam_scores': tensor([-4.3012, -7.3791], device='cuda:0', grad_fn=<ViewBackward>), 'next_beam_tokens': tensor([125, 161], device='cuda:0'), 'next_beam_indices': tensor([1, 1], device='cuda:0')}\n",
      "                line      1789             beam_scores = beam_outputs[\"next_beam_scores\"]\n",
      "    Source path:... __init__.py\n",
      "    Starting var:.. self = {'next_beam_scores': tensor([-4.3012, -7.3791], device='cuda:0', grad_fn=<ViewBackward>), 'next_beam_tokens': tensor([125, 161], device='cuda:0'), 'next_beam_indices': tensor([1, 1], device='cuda:0')}\n",
      "    Starting var:.. key = 'next_beam_scores'\n",
      "                    call      1005     def __getitem__(self, key):\n",
      "                    line      1006         if key in self.data:\n",
      "                    line      1007             return self.data[key]\n",
      "                    return    1007             return self.data[key]\n",
      "    Return value:.. tensor<(2,), float32, cuda:0, grad>\n",
      "Source path:... generation_utils.py\n",
      "                line      1790             beam_next_tokens = beam_outputs[\"next_beam_tokens\"]\n",
      "    Source path:... __init__.py\n",
      "    Starting var:.. self = {'next_beam_scores': tensor([-4.3012, -7.3791], device='cuda:0', grad_fn=<ViewBackward>), 'next_beam_tokens': tensor([125, 161], device='cuda:0'), 'next_beam_indices': tensor([1, 1], device='cuda:0')}\n",
      "    Starting var:.. key = 'next_beam_tokens'\n",
      "                    call      1005     def __getitem__(self, key):\n",
      "                    line      1006         if key in self.data:\n",
      "                    line      1007             return self.data[key]\n",
      "                    return    1007             return self.data[key]\n",
      "    Return value:.. tensor<(2,), int64, cuda:0>\n",
      "Source path:... generation_utils.py\n",
      "                line      1791             beam_idx = beam_outputs[\"next_beam_indices\"]\n",
      "    Source path:... __init__.py\n",
      "    Starting var:.. self = {'next_beam_scores': tensor([-4.3012, -7.3791], device='cuda:0', grad_fn=<ViewBackward>), 'next_beam_tokens': tensor([125, 161], device='cuda:0'), 'next_beam_indices': tensor([1, 1], device='cuda:0')}\n",
      "    Starting var:.. key = 'next_beam_indices'\n",
      "                    call      1005     def __getitem__(self, key):\n",
      "                    line      1006         if key in self.data:\n",
      "                    line      1007             return self.data[key]\n",
      "                    return    1007             return self.data[key]\n",
      "    Return value:.. tensor<(2,), int64, cuda:0>\n",
      "Source path:... generation_utils.py\n",
      "                line      1793             input_ids = torch.cat([input_ids[beam_idx, :], beam_next_tokens.unsqueeze(-1)], dim=-1)\n",
      "Modified var:.. input_ids = tensor<(2, 7), int64, cuda:0>\n",
      "                line      1795             cur_len = cur_len + 1\n",
      "Modified var:.. cur_len = 7\n",
      "                line      1797             model_kwargs = self._update_model_kwargs_for_generation(\n",
      "                line      1798                 outputs, model_kwargs, is_encoder_decoder=self.config.is_encoder_decoder\n",
      "                line      1797             model_kwargs = self._update_model_kwargs_for_generation(\n",
      "    Starting var:.. outputs = {'logits': tensor<(2, 1, 96103), float32, cuda:0, grad>, 'past_key_values': ((tensor<(2, 16, 6, 64...float32, cuda:0, grad>)), 'encoder_last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0, grad>}\n",
      "    Starting var:.. model_kwargs = {'use_cache': None, 'attention_mask': tensor<(2, 6), int64, cuda:0>, 'encoder_outputs': {'last_hid...d>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>))}\n",
      "    Starting var:.. is_encoder_decoder = True\n",
      "                    call       511     def _update_model_kwargs_for_generation(\n",
      "                    line       515         if \"past_key_values\" in outputs:\n",
      "                    line       516             model_kwargs[\"past\"] = outputs.past_key_values\n",
      "                    line       525         if \"token_type_ids\" in model_kwargs:\n",
      "                    line       530         if not is_encoder_decoder:\n",
      "                    line       537         return model_kwargs\n",
      "                    return     537         return model_kwargs\n",
      "    Return value:.. {'use_cache': None, 'attention_mask': tensor<(2, 6), int64, cuda:0>, 'encoder_outputs': {'last_hid...d>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>))}\n",
      "                line      1800             if model_kwargs[\"past\"] is not None:\n",
      "                line      1801                 model_kwargs[\"past\"] = self._reorder_cache(model_kwargs[\"past\"], beam_idx)\n",
      "    Source path:... modeling_pegasus.py\n",
      "    Starting var:.. past = ((tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, te...ad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>))\n",
      "    Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                    call      1333     def _reorder_cache(past, beam_idx):\n",
      "                    line      1334         reordered_past = ()\n",
      "    New var:....... reordered_past = ()\n",
      "                    line      1335         for layer_past in past:\n",
      "    New var:....... layer_past = (tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>)\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 6, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 6, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 6, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 6, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 6, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "    Modified var:.. reordered_past = ((tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>),)\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 6, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 6, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 6, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 6, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 6, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "    Modified var:.. reordered_past = ((tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, te...ad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>))\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 6, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 6, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 6, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 6, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 6, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 6, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 6, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 6, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 6, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 6, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 6, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 6, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 6, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 6, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 6, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 6, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 6, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 6, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 6, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 6, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 6, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 6, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 6, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 6, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 6, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 6, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 6, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 6, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 6, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 6, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 6, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 6, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 6, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 6, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 6, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 6, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 6, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 6, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 6, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 6, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 6, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 6, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 6, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 6, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 6, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 6, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 6, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 6, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 6, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 6, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 6, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 6, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 6, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 6, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 6, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 6, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 6, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 6, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 6, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 6, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 6, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 6, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 6, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 6, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 6, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 6, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 6, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 6, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 6, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 6, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1340         return reordered_past\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                    return    1340         return reordered_past\n",
      "    Return value:.. ((tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, te...ad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>))\n",
      "Source path:... generation_utils.py\n",
      "                line      1803             if beam_scorer.is_done:\n",
      "    Source path:... generation_beam_search.py\n",
      "    Starting var:.. self = <transformers.generation_beam_search.BeamSearchScorer object>\n",
      "                    call       196     def is_done(self) -> bool:\n",
      "                    line       197         return self._done.all()\n",
      "                    return     197         return self._done.all()\n",
      "    Return value:.. tensor<(), bool, cuda:0>\n",
      "Source path:... generation_utils.py\n",
      "                line      1806             if stopping_criteria(input_ids, scores):\n",
      "    Source path:... generation_stopping_criteria.py\n",
      "    Starting var:.. self = [<transformers.generation_stopping_criteria.MaxLengthCriteria object>]\n",
      "    Starting var:.. input_ids = tensor<(2, 7), int64, cuda:0>\n",
      "    Starting var:.. scores = (tensor<(2, 96103), float32, cuda:0, grad>, tensor<(2, 96103), float32, cuda:0, grad>, tensor<(2, ...uda:0, grad>, tensor<(2, 96103), float32, cuda:0, grad>, tensor<(2, 96103), float32, cuda:0, grad>)\n",
      "    Starting var:.. kwargs = {}\n",
      "                    call        83     def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor, **kwargs) -> bool:\n",
      "                    line        84         return any(criteria(input_ids, scores) for criteria in self)\n",
      "        Starting var:.. .0 = <list_iterator object>\n",
      "        Starting var:.. input_ids = tensor<(2, 7), int64, cuda:0>\n",
      "        Starting var:.. scores = (tensor<(2, 96103), float32, cuda:0, grad>, tensor<(2, 96103), float32, cuda:0, grad>, tensor<(2, ...uda:0, grad>, tensor<(2, 96103), float32, cuda:0, grad>, tensor<(2, 96103), float32, cuda:0, grad>)\n",
      "                        call        84         return any(criteria(input_ids, scores) for criteria in self)\n",
      "                        line        84         return any(criteria(input_ids, scores) for criteria in self)\n",
      "        New var:....... criteria = <transformers.generation_stopping_criteria.MaxLengthCriteria object>\n",
      "                        return      84         return any(criteria(input_ids, scores) for criteria in self)\n",
      "        Return value:.. False\n",
      "        Starting var:.. .0 = <list_iterator object>\n",
      "        Starting var:.. criteria = <transformers.generation_stopping_criteria.MaxLengthCriteria object>\n",
      "        Starting var:.. input_ids = tensor<(2, 7), int64, cuda:0>\n",
      "        Starting var:.. scores = (tensor<(2, 96103), float32, cuda:0, grad>, tensor<(2, 96103), float32, cuda:0, grad>, tensor<(2, ...uda:0, grad>, tensor<(2, 96103), float32, cuda:0, grad>, tensor<(2, 96103), float32, cuda:0, grad>)\n",
      "                        call        84         return any(criteria(input_ids, scores) for criteria in self)\n",
      "                        line        84         return any(criteria(input_ids, scores) for criteria in self)\n",
      "                        return      84         return any(criteria(input_ids, scores) for criteria in self)\n",
      "        Return value:.. None\n",
      "                    return      84         return any(criteria(input_ids, scores) for criteria in self)\n",
      "    Return value:.. False\n",
      "Source path:... generation_utils.py\n",
      "                line      1729         while cur_len < max_length:\n",
      "                line      1730             model_inputs = self.prepare_inputs_for_generation(input_ids, **model_kwargs)\n",
      "    Source path:... modeling_pegasus.py\n",
      "    Starting var:.. self = PegasusForConditionalGeneration(  (model): PegasusModel(    (shared): Embedding(96103, 1024, paddi...mentwise_affine=True)    )  )  (lm_head): Linear(in_features=1024, out_features=96103, bias=False))\n",
      "    Starting var:.. decoder_input_ids = tensor<(2, 7), int64, cuda:0>\n",
      "    Starting var:.. past = ((tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, te...ad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>))\n",
      "    Starting var:.. attention_mask = tensor<(2, 6), int64, cuda:0>\n",
      "    Starting var:.. head_mask = None\n",
      "    Starting var:.. use_cache = None\n",
      "    Starting var:.. encoder_outputs = {'last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0, grad>}\n",
      "    Starting var:.. kwargs = {}\n",
      "                    call      1305     def prepare_inputs_for_generation(\n",
      "                    line      1316         if past is not None:\n",
      "                    line      1317             decoder_input_ids = decoder_input_ids[:, -1:]\n",
      "    Modified var:.. decoder_input_ids = tensor<(2, 1), int64, cuda:0>\n",
      "                    line      1320             \"input_ids\": None,  # encoder_outputs is defined. input_ids not needed\n",
      "                    line      1321             \"encoder_outputs\": encoder_outputs,\n",
      "                    line      1322             \"past_key_values\": past,\n",
      "                    line      1323             \"decoder_input_ids\": decoder_input_ids,\n",
      "                    line      1324             \"attention_mask\": attention_mask,\n",
      "                    line      1325             \"head_mask\": head_mask,\n",
      "                    line      1326             \"use_cache\": use_cache,  # change this to avoid caching (presumably for debugging)\n",
      "                    line      1319         return {\n",
      "                    return    1319         return {\n",
      "    Return value:.. {'input_ids': None, 'encoder_outputs': {'last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0,...64, cuda:0>, 'attention_mask': tensor<(2, 6), int64, cuda:0>, 'head_mask': None, 'use_cache': None}\n",
      "Source path:... generation_utils.py\n",
      "                line      1732             outputs = self(\n",
      "                line      1733                 **model_inputs,\n",
      "                line      1734                 return_dict=True,\n",
      "                line      1735                 output_attentions=output_attentions,\n",
      "                line      1736                 output_hidden_states=output_hidden_states,\n",
      "                line      1732             outputs = self(\n",
      "    Source path:... module.py\n",
      "    Starting var:.. self = PegasusForConditionalGeneration(  (model): PegasusModel(    (shared): Embedding(96103, 1024, paddi...mentwise_affine=True)    )  )  (lm_head): Linear(in_features=1024, out_features=96103, bias=False))\n",
      "    Starting var:.. input = ()\n",
      "    Starting var:.. kwargs = {'input_ids': None, 'encoder_outputs': {'last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0,... 'use_cache': None, 'return_dict': True, 'output_attentions': False, 'output_hidden_states': False}\n",
      "                    call       715     def _call_impl(self, *input, **kwargs):\n",
      "                    line       716         for hook in itertools.chain(\n",
      "                    line       717                 _global_forward_pre_hooks.values(),\n",
      "                    line       718                 self._forward_pre_hooks.values()):\n",
      "                    line       716         for hook in itertools.chain(\n",
      "                    line       724         if torch._C._get_tracing_state():\n",
      "                    line       727             result = self.forward(*input, **kwargs)\n",
      "        Source path:... modeling_pegasus.py\n",
      "        Starting var:.. self = PegasusForConditionalGeneration(  (model): PegasusModel(    (shared): Embedding(96103, 1024, paddi...mentwise_affine=True)    )  )  (lm_head): Linear(in_features=1024, out_features=96103, bias=False))\n",
      "        Starting var:.. input_ids = None\n",
      "        Starting var:.. attention_mask = tensor<(2, 6), int64, cuda:0>\n",
      "        Starting var:.. decoder_input_ids = tensor<(2, 1), int64, cuda:0>\n",
      "        Starting var:.. decoder_attention_mask = None\n",
      "        Starting var:.. head_mask = None\n",
      "        Starting var:.. decoder_head_mask = None\n",
      "        Starting var:.. encoder_outputs = {'last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0, grad>}\n",
      "        Starting var:.. past_key_values = ((tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, te...ad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>))\n",
      "        Starting var:.. inputs_embeds = None\n",
      "        Starting var:.. decoder_inputs_embeds = None\n",
      "        Starting var:.. labels = None\n",
      "        Starting var:.. use_cache = None\n",
      "        Starting var:.. output_attentions = False\n",
      "        Starting var:.. output_hidden_states = False\n",
      "        Starting var:.. return_dict = True\n",
      "                        call      1231     def forward(\n",
      "                        line      1258         return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
      "                        line      1260         if labels is not None:\n",
      "                        line      1266         outputs = self.model(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                        line      1267             input_ids,\n",
      "                        line      1268             attention_mask=attention_mask,\n",
      "                        line      1269             decoder_input_ids=decoder_input_ids,\n",
      "                        line      1270             encoder_outputs=encoder_outputs,\n",
      "                        line      1271             decoder_attention_mask=decoder_attention_mask,\n",
      "                        line      1272             head_mask=head_mask,\n",
      "                        line      1273             decoder_head_mask=decoder_head_mask,\n",
      "                        line      1274             past_key_values=past_key_values,\n",
      "                        line      1275             inputs_embeds=inputs_embeds,\n",
      "                        line      1276             decoder_inputs_embeds=decoder_inputs_embeds,\n",
      "                        line      1277             use_cache=use_cache,\n",
      "                        line      1278             output_attentions=output_attentions,\n",
      "                        line      1279             output_hidden_states=output_hidden_states,\n",
      "                        line      1280             return_dict=return_dict,\n",
      "                        line      1266         outputs = self.model(\n",
      "        New var:....... outputs = {'last_hidden_state': tensor<(2, 1, 1024), float32, cuda:0, grad>, 'past_key_values': ((tensor<(2,...float32, cuda:0, grad>)), 'encoder_last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0, grad>}\n",
      "                        line      1282         lm_logits = self.lm_head(outputs[0]) + self.final_logits_bias\n",
      "        New var:....... lm_logits = tensor<(2, 1, 96103), float32, cuda:0, grad>\n",
      "                        line      1284         masked_lm_loss = None\n",
      "        New var:....... masked_lm_loss = None\n",
      "                        line      1285         if labels is not None:\n",
      "                        line      1289         if not return_dict:\n",
      "                        line      1293         return Seq2SeqLMOutput(\n",
      "                        line      1294             loss=masked_lm_loss,\n",
      "                        line      1295             logits=lm_logits,\n",
      "                        line      1296             past_key_values=outputs.past_key_values,\n",
      "                        line      1297             decoder_hidden_states=outputs.decoder_hidden_states,\n",
      "                        line      1298             decoder_attentions=outputs.decoder_attentions,\n",
      "                        line      1299             cross_attentions=outputs.cross_attentions,\n",
      "                        line      1300             encoder_last_hidden_state=outputs.encoder_last_hidden_state,\n",
      "                        line      1301             encoder_hidden_states=outputs.encoder_hidden_states,\n",
      "                        line      1302             encoder_attentions=outputs.encoder_attentions,\n",
      "                        line      1293         return Seq2SeqLMOutput(\n",
      "                        return    1293         return Seq2SeqLMOutput(\n",
      "        Return value:.. {'logits': tensor<(2, 1, 96103), float32, cuda:0, grad>, 'past_key_values': ((tensor<(2, 16, 7, 64...float32, cuda:0, grad>)), 'encoder_last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0, grad>}\n",
      "    Source path:... module.py\n",
      "    New var:....... result = {'logits': tensor<(2, 1, 96103), float32, cuda:0, grad>, 'past_key_values': ((tensor<(2, 16, 7, 64...float32, cuda:0, grad>)), 'encoder_last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0, grad>}\n",
      "                    line       728         for hook in itertools.chain(\n",
      "                    line       729                 _global_forward_hooks.values(),\n",
      "                    line       730                 self._forward_hooks.values()):\n",
      "                    line       728         for hook in itertools.chain(\n",
      "                    line       734         if (len(self._backward_hooks) > 0) or (len(_global_backward_hooks) > 0):\n",
      "                    line       749         return result\n",
      "                    return     749         return result\n",
      "    Return value:.. {'logits': tensor<(2, 1, 96103), float32, cuda:0, grad>, 'past_key_values': ((tensor<(2, 16, 7, 64...float32, cuda:0, grad>)), 'encoder_last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0, grad>}\n",
      "Source path:... generation_utils.py\n",
      "Modified var:.. outputs = {'logits': tensor<(2, 1, 96103), float32, cuda:0, grad>, 'past_key_values': ((tensor<(2, 16, 7, 64...float32, cuda:0, grad>)), 'encoder_last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0, grad>}\n",
      "                line      1738             next_token_logits = outputs.logits[:, -1, :]\n",
      "                line      1742             next_token_logits = self.adjust_logits_during_generation(\n",
      "                line      1743                 next_token_logits, cur_len=cur_len, max_length=max_length\n",
      "                line      1742             next_token_logits = self.adjust_logits_during_generation(\n",
      "    Starting var:.. self = PegasusForConditionalGeneration(  (model): PegasusModel(    (shared): Embedding(96103, 1024, paddi...mentwise_affine=True)    )  )  (lm_head): Linear(in_features=1024, out_features=96103, bias=False))\n",
      "    Starting var:.. logits = tensor<(2, 96103), float32, cuda:0, grad>\n",
      "    Starting var:.. kwargs = {'cur_len': 7, 'max_length': 60}\n",
      "                    call       373     def adjust_logits_during_generation(self, logits: torch.FloatTensor, **kwargs) -> torch.FloatTensor:\n",
      "                    line       378         return logits\n",
      "                    return     378         return logits\n",
      "    Return value:.. tensor<(2, 96103), float32, cuda:0, grad>\n",
      "                line      1746             next_token_scores = F.log_softmax(next_token_logits, dim=-1)  # (batch_size * num_beams, vocab_size)\n",
      "    Source path:... functional.py\n",
      "    Starting var:.. input = tensor<(2, 96103), float32, cuda:0, grad>\n",
      "    Starting var:.. dim = -1\n",
      "    Starting var:.. _stacklevel = 3\n",
      "    Starting var:.. dtype = None\n",
      "                    call      1581 def log_softmax(input, dim=None, _stacklevel=3, dtype=None):\n",
      "                    line      1598     if not torch.jit.is_scripting():\n",
      "        Source path:... _jit_internal.py\n",
      "                        call       750 def is_scripting():\n",
      "                        line       769     return False\n",
      "                        return     769     return False\n",
      "        Return value:.. False\n",
      "    Source path:... functional.py\n",
      "                    line      1599         if type(input) is not Tensor and has_torch_function((input,)):\n",
      "                    line      1602     if dim is None:\n",
      "                    line      1604     if dtype is None:\n",
      "                    line      1605         ret = input.log_softmax(dim)\n",
      "    New var:....... ret = tensor<(2, 96103), float32, cuda:0, grad>\n",
      "                    line      1608     return ret\n",
      "                    return    1608     return ret\n",
      "    Return value:.. tensor<(2, 96103), float32, cuda:0, grad>\n",
      "Source path:... generation_utils.py\n",
      "Modified var:.. next_token_scores = tensor<(2, 96103), float32, cuda:0, grad>\n",
      "                line      1748             next_token_scores = logits_processor(input_ids, next_token_scores)\n",
      "    Source path:... generation_logits_process.py\n",
      "    Starting var:.. self = [<transformers.generation_logits_process.MinLengthLogitsProcessor object>, <transformers.generation_logits_process.ForcedEOSTokenLogitsProcessor object>]\n",
      "    Starting var:.. input_ids = tensor<(2, 7), int64, cuda:0>\n",
      "    Starting var:.. scores = tensor<(2, 96103), float32, cuda:0, grad>\n",
      "    Starting var:.. kwargs = {}\n",
      "                    call        84     def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor, **kwargs) -> torch.FloatTensor:\n",
      "                    line        85         for processor in self:\n",
      "    New var:....... processor = <transformers.generation_logits_process.MinLengthLogitsProcessor object>\n",
      "                    line        86             function_args = inspect.signature(processor.__call__).parameters\n",
      "        Source path:... inspect.py\n",
      "        Starting var:.. obj = <bound method MinLengthLogitsProcessor.__call__ of <transformers.generation_logits_process.MinLengthLogitsProcessor object>>\n",
      "        Starting var:.. follow_wrapped = True\n",
      "                        call      3091 def signature(obj, *, follow_wrapped=True):\n",
      "                        line      3093     return Signature.from_callable(obj, follow_wrapped=follow_wrapped)\n",
      "                        return    3093     return Signature.from_callable(obj, follow_wrapped=follow_wrapped)\n",
      "        Return value:.. <Signature (input_ids: torch.LongTensor, scores: torch.FloatTensor) -> torch.FloatTensor>\n",
      "        Starting var:.. self = <Signature (input_ids: torch.LongTensor, scores: torch.FloatTensor) -> torch.FloatTensor>\n",
      "                        call      2846     def parameters(self):\n",
      "                        line      2847         return self._parameters\n",
      "                        return    2847         return self._parameters\n",
      "        Return value:.. mappingproxy(OrderedDict([('input_ids', <Parameter \"input_ids: torch.LongTensor\">), ('scores', <Parameter \"scores: torch.FloatTensor\">)]))\n",
      "    Source path:... generation_logits_process.py\n",
      "    New var:....... function_args = mappingproxy(OrderedDict([('input_ids', <Parameter \"input_ids: torch.LongTensor\">), ('scores', <Parameter \"scores: torch.FloatTensor\">)]))\n",
      "                    line        87             if len(function_args) > 2:\n",
      "                    line        93                 scores = processor(input_ids, scores)\n",
      "        Starting var:.. self = <transformers.generation_logits_process.MinLengthLogitsProcessor object>\n",
      "        Starting var:.. input_ids = tensor<(2, 7), int64, cuda:0>\n",
      "        Starting var:.. scores = tensor<(2, 96103), float32, cuda:0, grad>\n",
      "                        call       118     def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor) -> torch.FloatTensor:\n",
      "                        line       119         cur_len = input_ids.shape[-1]\n",
      "        New var:....... cur_len = 7\n",
      "                        line       120         if cur_len < self.min_length:\n",
      "                        line       122         return scores\n",
      "                        return     122         return scores\n",
      "        Return value:.. tensor<(2, 96103), float32, cuda:0, grad>\n",
      "                    line        85         for processor in self:\n",
      "    Modified var:.. processor = <transformers.generation_logits_process.ForcedEOSTokenLogitsProcessor object>\n",
      "                    line        86             function_args = inspect.signature(processor.__call__).parameters\n",
      "        Source path:... inspect.py\n",
      "        Starting var:.. obj = <bound method ForcedEOSTokenLogitsProcessor.__call__ of <transformers.generation_logits_process.ForcedEOSTokenLogitsProcessor object>>\n",
      "        Starting var:.. follow_wrapped = True\n",
      "                        call      3091 def signature(obj, *, follow_wrapped=True):\n",
      "                        line      3093     return Signature.from_callable(obj, follow_wrapped=follow_wrapped)\n",
      "                        return    3093     return Signature.from_callable(obj, follow_wrapped=follow_wrapped)\n",
      "        Return value:.. <Signature (input_ids: torch.LongTensor, scores: torch.FloatTensor) -> torch.FloatTensor>\n",
      "        Starting var:.. self = <Signature (input_ids: torch.LongTensor, scores: torch.FloatTensor) -> torch.FloatTensor>\n",
      "                        call      2846     def parameters(self):\n",
      "                        line      2847         return self._parameters\n",
      "                        return    2847         return self._parameters\n",
      "        Return value:.. mappingproxy(OrderedDict([('input_ids', <Parameter \"input_ids: torch.LongTensor\">), ('scores', <Parameter \"scores: torch.FloatTensor\">)]))\n",
      "    Source path:... generation_logits_process.py\n",
      "                    line        87             if len(function_args) > 2:\n",
      "                    line        93                 scores = processor(input_ids, scores)\n",
      "        Starting var:.. self = <transformers.generation_logits_process.ForcedEOSTokenLogitsProcessor object>\n",
      "        Starting var:.. input_ids = tensor<(2, 7), int64, cuda:0>\n",
      "        Starting var:.. scores = tensor<(2, 96103), float32, cuda:0, grad>\n",
      "                        call       571     def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor) -> torch.FloatTensor:\n",
      "                        line       572         cur_len = input_ids.shape[-1]\n",
      "        New var:....... cur_len = 7\n",
      "                        line       573         if cur_len == self.max_length - 1:\n",
      "                        line       577         return scores\n",
      "                        return     577         return scores\n",
      "        Return value:.. tensor<(2, 96103), float32, cuda:0, grad>\n",
      "                    line        85         for processor in self:\n",
      "                    line        94         return scores\n",
      "                    return      94         return scores\n",
      "    Return value:.. tensor<(2, 96103), float32, cuda:0, grad>\n",
      "Source path:... generation_utils.py\n",
      "                line      1749             next_token_scores = next_token_scores + beam_scores[:, None].expand_as(next_token_scores)\n",
      "                line      1752             if return_dict_in_generate:\n",
      "                line      1753                 if output_scores:\n",
      "                line      1754                     scores += (next_token_scores,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                line      1755                 if output_attentions:\n",
      "                line      1762                 if output_hidden_states:\n",
      "                line      1770             vocab_size = next_token_scores.shape[-1]\n",
      "                line      1771             next_token_scores = next_token_scores.view(batch_size, num_beams * vocab_size)\n",
      "Modified var:.. next_token_scores = tensor<(1, 192206), float32, cuda:0, grad>\n",
      "                line      1773             next_token_scores, next_tokens = torch.topk(\n",
      "                line      1774                 next_token_scores, 2 * num_beams, dim=1, largest=True, sorted=True\n",
      "                line      1773             next_token_scores, next_tokens = torch.topk(\n",
      "Modified var:.. next_token_scores = tensor<(1, 4), float32, cuda:0, grad>\n",
      "                line      1777             next_indices = next_tokens // vocab_size\n",
      "    Source path:... tensor.py\n",
      "    Starting var:.. args = (tensor<(1, 4), int64, cuda:0>, 96103)\n",
      "    Starting var:.. kwargs = {}\n",
      "    Starting var:.. f = <function Tensor.__floordiv__>\n",
      "    Starting var:.. wrapped = <function Tensor.__floordiv__>\n",
      "                    call        22     def wrapped(*args, **kwargs):\n",
      "                    line        23         from torch.overrides import has_torch_function, handle_torch_function\n",
      "    New var:....... has_torch_function = <function has_torch_function>\n",
      "    New var:....... handle_torch_function = <function handle_torch_function>\n",
      "                    line        24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "                        call        24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "                        line        24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "        New var:....... t = tensor<(1, 4), int64, cuda:0>\n",
      "                        return      24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "        Return value:.. True\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. t = tensor<(1, 4), int64, cuda:0>\n",
      "                        call        24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "                        line        24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "        Modified var:.. t = 96103\n",
      "                        return      24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "        Return value:.. False\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. t = 96103\n",
      "                        call        24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "                        exception   24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "        Exception:..... GeneratorExit\n",
      "                        return      24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "        Return value:.. None\n",
      "        Source path:... overrides.py\n",
      "        Starting var:.. relevant_args = (tensor<(1, 4), int64, cuda:0>, 96103)\n",
      "                        call      1070 def has_torch_function(relevant_args: Iterable[Any]) -> bool:\n",
      "                        line      1083     return _is_torch_function_enabled() and any(\n",
      "                        line      1087         for a in relevant_args\n",
      "                        line      1083     return _is_torch_function_enabled() and any(\n",
      "                        return    1083     return _is_torch_function_enabled() and any(\n",
      "        Return value:.. False\n",
      "    Source path:... tensor.py\n",
      "                    line        26         try:\n",
      "                    line        27             return f(*args, **kwargs)\n",
      "        Starting var:.. self = tensor<(1, 4), int64, cuda:0>\n",
      "        Starting var:.. other = 96103\n",
      "                        call       550     def __floordiv__(self, other):\n",
      "                        line       551         return torch.floor_divide(self, other)\n",
      "                        return     551         return torch.floor_divide(self, other)\n",
      "        Return value:.. tensor<(1, 4), int64, cuda:0>\n",
      "                    return      27             return f(*args, **kwargs)\n",
      "    Return value:.. tensor<(1, 4), int64, cuda:0>\n",
      "Source path:... generation_utils.py\n",
      "                line      1778             next_tokens = next_tokens % vocab_size\n",
      "                line      1781             beam_outputs = beam_scorer.process(\n",
      "                line      1782                 input_ids,\n",
      "                line      1783                 next_token_scores,\n",
      "                line      1784                 next_tokens,\n",
      "                line      1785                 next_indices,\n",
      "                line      1786                 pad_token_id=pad_token_id,\n",
      "                line      1787                 eos_token_id=eos_token_id,\n",
      "                line      1781             beam_outputs = beam_scorer.process(\n",
      "    Source path:... generation_beam_search.py\n",
      "    Starting var:.. self = <transformers.generation_beam_search.BeamSearchScorer object>\n",
      "    Starting var:.. input_ids = tensor<(2, 7), int64, cuda:0>\n",
      "    Starting var:.. next_scores = tensor<(1, 4), float32, cuda:0, grad>\n",
      "    Starting var:.. next_tokens = tensor<(1, 4), int64, cuda:0>\n",
      "    Starting var:.. next_indices = tensor<(1, 4), int64, cuda:0>\n",
      "    Starting var:.. pad_token_id = 0\n",
      "    Starting var:.. eos_token_id = 1\n",
      "                    call       199     def process(\n",
      "                    line       208         cur_len = input_ids.shape[-1]\n",
      "    New var:....... cur_len = 7\n",
      "                    line       209         batch_size = len(self._beam_hyps)\n",
      "    New var:....... batch_size = 1\n",
      "                    line       210         assert batch_size == (input_ids.shape[0] // self.group_size)\n",
      "                    line       212         device = input_ids.device\n",
      "    New var:....... device = device(type='cuda', index=0)\n",
      "                    line       213         next_beam_scores = torch.zeros((batch_size, self.group_size), dtype=next_scores.dtype, device=device)\n",
      "    New var:....... next_beam_scores = tensor<(1, 2), float32, cuda:0>\n",
      "                    line       214         next_beam_tokens = torch.zeros((batch_size, self.group_size), dtype=next_tokens.dtype, device=device)\n",
      "    New var:....... next_beam_tokens = tensor<(1, 2), int64, cuda:0>\n",
      "                    line       215         next_beam_indices = torch.zeros((batch_size, self.group_size), dtype=next_indices.dtype, device=device)\n",
      "    New var:....... next_beam_indices = tensor<(1, 2), int64, cuda:0>\n",
      "                    line       217         for batch_idx, beam_hyp in enumerate(self._beam_hyps):\n",
      "    New var:....... batch_idx = 0\n",
      "    New var:....... beam_hyp = <transformers.generation_beam_search.BeamHypotheses object>\n",
      "                    line       218             if self._done[batch_idx]:\n",
      "                    line       232             beam_idx = 0\n",
      "    New var:....... beam_idx = 0\n",
      "                    line       233             for beam_token_rank, (next_token, next_score, next_index) in enumerate(\n",
      "                    line       234                 zip(next_tokens[batch_idx], next_scores[batch_idx], next_indices[batch_idx])\n",
      "        Source path:... tensor.py\n",
      "        Starting var:.. self = tensor<(4,), int64, cuda:0>\n",
      "                        call       576     def __iter__(self):\n",
      "                        line       583         relevant_args = (self,)\n",
      "        New var:....... relevant_args = (tensor<(4,), int64, cuda:0>,)\n",
      "                        line       584         from torch.overrides import has_torch_function, handle_torch_function\n",
      "        New var:....... has_torch_function = <function has_torch_function>\n",
      "        New var:....... handle_torch_function = <function handle_torch_function>\n",
      "                        line       585         if type(self) is not Tensor and has_torch_function(relevant_args):\n",
      "                        line       587         if self.dim() == 0:\n",
      "                        line       589         if torch._C._get_tracing_state():\n",
      "                        line       594         return iter(self.unbind(0))\n",
      "                        return     594         return iter(self.unbind(0))\n",
      "        Return value:.. <tuple_iterator object>\n",
      "        Starting var:.. self = tensor<(4,), float32, cuda:0, grad>\n",
      "                        call       576     def __iter__(self):\n",
      "                        line       583         relevant_args = (self,)\n",
      "        New var:....... relevant_args = (tensor<(4,), float32, cuda:0, grad>,)\n",
      "                        line       584         from torch.overrides import has_torch_function, handle_torch_function\n",
      "        New var:....... has_torch_function = <function has_torch_function>\n",
      "        New var:....... handle_torch_function = <function handle_torch_function>\n",
      "                        line       585         if type(self) is not Tensor and has_torch_function(relevant_args):\n",
      "                        line       587         if self.dim() == 0:\n",
      "                        line       589         if torch._C._get_tracing_state():\n",
      "                        line       594         return iter(self.unbind(0))\n",
      "                        return     594         return iter(self.unbind(0))\n",
      "        Return value:.. <tuple_iterator object>\n",
      "        Starting var:.. self = tensor<(4,), int64, cuda:0>\n",
      "                        call       576     def __iter__(self):\n",
      "                        line       583         relevant_args = (self,)\n",
      "        New var:....... relevant_args = (tensor<(4,), int64, cuda:0>,)\n",
      "                        line       584         from torch.overrides import has_torch_function, handle_torch_function\n",
      "        New var:....... has_torch_function = <function has_torch_function>\n",
      "        New var:....... handle_torch_function = <function handle_torch_function>\n",
      "                        line       585         if type(self) is not Tensor and has_torch_function(relevant_args):\n",
      "                        line       587         if self.dim() == 0:\n",
      "                        line       589         if torch._C._get_tracing_state():\n",
      "                        line       594         return iter(self.unbind(0))\n",
      "                        return     594         return iter(self.unbind(0))\n",
      "        Return value:.. <tuple_iterator object>\n",
      "    Source path:... generation_beam_search.py\n",
      "                    line       233             for beam_token_rank, (next_token, next_score, next_index) in enumerate(\n",
      "    New var:....... beam_token_rank = 0\n",
      "    New var:....... next_token = tensor<(), int64, cuda:0>\n",
      "    New var:....... next_score = tensor<(), float32, cuda:0, grad>\n",
      "    New var:....... next_index = tensor<(), int64, cuda:0>\n",
      "                    line       236                 batch_beam_idx = batch_idx * self.group_size + next_index\n",
      "    New var:....... batch_beam_idx = tensor<(), int64, cuda:0>\n",
      "                    line       238                 if (eos_token_id is not None) and (next_token.item() == eos_token_id):\n",
      "                    line       249                     next_beam_scores[batch_idx, beam_idx] = next_score\n",
      "    Modified var:.. next_beam_scores = tensor<(1, 2), float32, cuda:0, grad>\n",
      "                    line       250                     next_beam_tokens[batch_idx, beam_idx] = next_token\n",
      "                    line       251                     next_beam_indices[batch_idx, beam_idx] = batch_beam_idx\n",
      "                    line       252                     beam_idx += 1\n",
      "    Modified var:.. beam_idx = 1\n",
      "                    line       255                 if beam_idx == self.group_size:\n",
      "                    line       233             for beam_token_rank, (next_token, next_score, next_index) in enumerate(\n",
      "    Modified var:.. beam_token_rank = 1\n",
      "                    line       236                 batch_beam_idx = batch_idx * self.group_size + next_index\n",
      "                    line       238                 if (eos_token_id is not None) and (next_token.item() == eos_token_id):\n",
      "                    line       249                     next_beam_scores[batch_idx, beam_idx] = next_score\n",
      "                    line       250                     next_beam_tokens[batch_idx, beam_idx] = next_token\n",
      "                    line       251                     next_beam_indices[batch_idx, beam_idx] = batch_beam_idx\n",
      "                    line       252                     beam_idx += 1\n",
      "    Modified var:.. beam_idx = 2\n",
      "                    line       255                 if beam_idx == self.group_size:\n",
      "                    line       256                     break\n",
      "                    line       258             if beam_idx < self.group_size:\n",
      "                    line       264             self._done[batch_idx] = self._done[batch_idx] or beam_hyp.is_done(\n",
      "                    line       265                 next_scores[batch_idx].max().item(), cur_len\n",
      "                    line       264             self._done[batch_idx] = self._done[batch_idx] or beam_hyp.is_done(\n",
      "        Starting var:.. self = <transformers.generation_beam_search.BeamHypotheses object>\n",
      "        Starting var:.. best_sum_logprobs = -5.261275291442871\n",
      "        Starting var:.. cur_len = 7\n",
      "                        call       371     def is_done(self, best_sum_logprobs: float, cur_len: int) -> bool:\n",
      "                        line       377         if len(self) < self.num_beams:\n",
      "                        line       378             return False\n",
      "                        return     378             return False\n",
      "        Return value:.. False\n",
      "                    line       217         for batch_idx, beam_hyp in enumerate(self._beam_hyps):\n",
      "                    line       268         return UserDict(\n",
      "                    line       270                 \"next_beam_scores\": next_beam_scores.view(-1),\n",
      "                    line       271                 \"next_beam_tokens\": next_beam_tokens.view(-1),\n",
      "                    line       272                 \"next_beam_indices\": next_beam_indices.view(-1),\n",
      "                    line       269             {\n",
      "                    line       268         return UserDict(\n",
      "        Source path:... __init__.py\n",
      "        Starting var:.. args = REPR FAILED\n",
      "        Starting var:.. kwargs = {}\n",
      "                        call       981     def __init__(*args, **kwargs):\n",
      "                        line       982         if not args:\n",
      "                        line       985         self, *args = args\n",
      "        Modified var:.. args = [{'next_beam_scores': tensor<(2,), float32, cuda:0, grad>, 'next_beam_tokens': tensor<(2,), int64, cuda:0>, 'next_beam_indices': tensor<(2,), int64, cuda:0>}]\n",
      "        New var:....... self = REPR FAILED\n",
      "                        line       986         if len(args) > 1:\n",
      "                        line       988         if args:\n",
      "                        line       989             dict = args[0]\n",
      "        New var:....... dict = {'next_beam_scores': tensor<(2,), float32, cuda:0, grad>, 'next_beam_tokens': tensor<(2,), int64, cuda:0>, 'next_beam_indices': tensor<(2,), int64, cuda:0>}\n",
      "                        line       997         self.data = {}\n",
      "        Modified var:.. self = {}\n",
      "                        line       998         if dict is not None:\n",
      "                        line       999             self.update(dict)\n",
      "        Modified var:.. self = {'next_beam_scores': tensor([-5.2613, -7.1020], device='cuda:0', grad_fn=<ViewBackward>), 'next_beam_tokens': tensor([131, 346], device='cuda:0'), 'next_beam_indices': tensor([0, 0], device='cuda:0')}\n",
      "                        line      1000         if kwargs:\n",
      "                        return    1000         if kwargs:\n",
      "        Return value:.. None\n",
      "    Source path:... generation_beam_search.py\n",
      "                    return     268         return UserDict(\n",
      "    Return value:.. {'next_beam_scores': tensor([-5.2613, -7.1020], device='cuda:0', grad_fn=<ViewBackward>), 'next_beam_tokens': tensor([131, 346], device='cuda:0'), 'next_beam_indices': tensor([0, 0], device='cuda:0')}\n",
      "Source path:... generation_utils.py\n",
      "Modified var:.. beam_outputs = {'next_beam_scores': tensor([-5.2613, -7.1020], device='cuda:0', grad_fn=<ViewBackward>), 'next_beam_tokens': tensor([131, 346], device='cuda:0'), 'next_beam_indices': tensor([0, 0], device='cuda:0')}\n",
      "                line      1789             beam_scores = beam_outputs[\"next_beam_scores\"]\n",
      "    Source path:... __init__.py\n",
      "    Starting var:.. self = {'next_beam_scores': tensor([-5.2613, -7.1020], device='cuda:0', grad_fn=<ViewBackward>), 'next_beam_tokens': tensor([131, 346], device='cuda:0'), 'next_beam_indices': tensor([0, 0], device='cuda:0')}\n",
      "    Starting var:.. key = 'next_beam_scores'\n",
      "                    call      1005     def __getitem__(self, key):\n",
      "                    line      1006         if key in self.data:\n",
      "                    line      1007             return self.data[key]\n",
      "                    return    1007             return self.data[key]\n",
      "    Return value:.. tensor<(2,), float32, cuda:0, grad>\n",
      "Source path:... generation_utils.py\n",
      "                line      1790             beam_next_tokens = beam_outputs[\"next_beam_tokens\"]\n",
      "    Source path:... __init__.py\n",
      "    Starting var:.. self = {'next_beam_scores': tensor([-5.2613, -7.1020], device='cuda:0', grad_fn=<ViewBackward>), 'next_beam_tokens': tensor([131, 346], device='cuda:0'), 'next_beam_indices': tensor([0, 0], device='cuda:0')}\n",
      "    Starting var:.. key = 'next_beam_tokens'\n",
      "                    call      1005     def __getitem__(self, key):\n",
      "                    line      1006         if key in self.data:\n",
      "                    line      1007             return self.data[key]\n",
      "                    return    1007             return self.data[key]\n",
      "    Return value:.. tensor<(2,), int64, cuda:0>\n",
      "Source path:... generation_utils.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                line      1791             beam_idx = beam_outputs[\"next_beam_indices\"]\n",
      "    Source path:... __init__.py\n",
      "    Starting var:.. self = {'next_beam_scores': tensor([-5.2613, -7.1020], device='cuda:0', grad_fn=<ViewBackward>), 'next_beam_tokens': tensor([131, 346], device='cuda:0'), 'next_beam_indices': tensor([0, 0], device='cuda:0')}\n",
      "    Starting var:.. key = 'next_beam_indices'\n",
      "                    call      1005     def __getitem__(self, key):\n",
      "                    line      1006         if key in self.data:\n",
      "                    line      1007             return self.data[key]\n",
      "                    return    1007             return self.data[key]\n",
      "    Return value:.. tensor<(2,), int64, cuda:0>\n",
      "Source path:... generation_utils.py\n",
      "                line      1793             input_ids = torch.cat([input_ids[beam_idx, :], beam_next_tokens.unsqueeze(-1)], dim=-1)\n",
      "Modified var:.. input_ids = tensor<(2, 8), int64, cuda:0>\n",
      "                line      1795             cur_len = cur_len + 1\n",
      "Modified var:.. cur_len = 8\n",
      "                line      1797             model_kwargs = self._update_model_kwargs_for_generation(\n",
      "                line      1798                 outputs, model_kwargs, is_encoder_decoder=self.config.is_encoder_decoder\n",
      "                line      1797             model_kwargs = self._update_model_kwargs_for_generation(\n",
      "    Starting var:.. outputs = {'logits': tensor<(2, 1, 96103), float32, cuda:0, grad>, 'past_key_values': ((tensor<(2, 16, 7, 64...float32, cuda:0, grad>)), 'encoder_last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0, grad>}\n",
      "    Starting var:.. model_kwargs = {'use_cache': None, 'attention_mask': tensor<(2, 6), int64, cuda:0>, 'encoder_outputs': {'last_hid...d>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>))}\n",
      "    Starting var:.. is_encoder_decoder = True\n",
      "                    call       511     def _update_model_kwargs_for_generation(\n",
      "                    line       515         if \"past_key_values\" in outputs:\n",
      "                    line       516             model_kwargs[\"past\"] = outputs.past_key_values\n",
      "                    line       525         if \"token_type_ids\" in model_kwargs:\n",
      "                    line       530         if not is_encoder_decoder:\n",
      "                    line       537         return model_kwargs\n",
      "                    return     537         return model_kwargs\n",
      "    Return value:.. {'use_cache': None, 'attention_mask': tensor<(2, 6), int64, cuda:0>, 'encoder_outputs': {'last_hid...d>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>))}\n",
      "                line      1800             if model_kwargs[\"past\"] is not None:\n",
      "                line      1801                 model_kwargs[\"past\"] = self._reorder_cache(model_kwargs[\"past\"], beam_idx)\n",
      "    Source path:... modeling_pegasus.py\n",
      "    Starting var:.. past = ((tensor<(2, 16, 7, 64), float32, cuda:0, grad>, tensor<(2, 16, 7, 64), float32, cuda:0, grad>, te...ad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>))\n",
      "    Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                    call      1333     def _reorder_cache(past, beam_idx):\n",
      "                    line      1334         reordered_past = ()\n",
      "    New var:....... reordered_past = ()\n",
      "                    line      1335         for layer_past in past:\n",
      "    New var:....... layer_past = (tensor<(2, 16, 7, 64), float32, cuda:0, grad>, tensor<(2, 16, 7, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>)\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 7, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 7, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 7, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 7, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 7, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "    Modified var:.. reordered_past = ((tensor<(2, 16, 7, 64), float32, cuda:0, grad>, tensor<(2, 16, 7, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>),)\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 7, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 7, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 7, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 7, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 7, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "    Modified var:.. reordered_past = ((tensor<(2, 16, 7, 64), float32, cuda:0, grad>, tensor<(2, 16, 7, 64), float32, cuda:0, grad>, te...ad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>))\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 7, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 7, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 7, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 7, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 7, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 7, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 7, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 7, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 7, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 7, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        New var:....... past_state = tensor<(2, 16, 7, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 7, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 7, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 7, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 7, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 7, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 7, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 7, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 7, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 7, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 7, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 7, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 7, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 7, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 7, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 7, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 7, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 7, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 7, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 7, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 7, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 7, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 7, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 7, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 7, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 7, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 7, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 7, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 7, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 7, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 7, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 7, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 7, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 7, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 7, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 7, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 7, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 7, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 7, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 7, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 7, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 7, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 7, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 7, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 7, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 7, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 7, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 7, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 7, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 7, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 7, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 7, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 7, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 7, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 7, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 7, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 7, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 7, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 7, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 7, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1340         return reordered_past\n",
      "                    return    1340         return reordered_past\n",
      "    Return value:.. ((tensor<(2, 16, 7, 64), float32, cuda:0, grad>, tensor<(2, 16, 7, 64), float32, cuda:0, grad>, te...ad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>))\n",
      "Source path:... generation_utils.py\n",
      "                line      1803             if beam_scorer.is_done:\n",
      "    Source path:... generation_beam_search.py\n",
      "    Starting var:.. self = <transformers.generation_beam_search.BeamSearchScorer object>\n",
      "                    call       196     def is_done(self) -> bool:\n",
      "                    line       197         return self._done.all()\n",
      "                    return     197         return self._done.all()\n",
      "    Return value:.. tensor<(), bool, cuda:0>\n",
      "Source path:... generation_utils.py\n",
      "                line      1806             if stopping_criteria(input_ids, scores):\n",
      "    Source path:... generation_stopping_criteria.py\n",
      "    Starting var:.. self = [<transformers.generation_stopping_criteria.MaxLengthCriteria object>]\n",
      "    Starting var:.. input_ids = tensor<(2, 8), int64, cuda:0>\n",
      "    Starting var:.. scores = (tensor<(2, 96103), float32, cuda:0, grad>, tensor<(2, 96103), float32, cuda:0, grad>, tensor<(2, ...uda:0, grad>, tensor<(2, 96103), float32, cuda:0, grad>, tensor<(2, 96103), float32, cuda:0, grad>)\n",
      "    Starting var:.. kwargs = {}\n",
      "                    call        83     def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor, **kwargs) -> bool:\n",
      "                    line        84         return any(criteria(input_ids, scores) for criteria in self)\n",
      "        Starting var:.. .0 = <list_iterator object>\n",
      "        Starting var:.. input_ids = tensor<(2, 8), int64, cuda:0>\n",
      "        Starting var:.. scores = (tensor<(2, 96103), float32, cuda:0, grad>, tensor<(2, 96103), float32, cuda:0, grad>, tensor<(2, ...uda:0, grad>, tensor<(2, 96103), float32, cuda:0, grad>, tensor<(2, 96103), float32, cuda:0, grad>)\n",
      "                        call        84         return any(criteria(input_ids, scores) for criteria in self)\n",
      "                        line        84         return any(criteria(input_ids, scores) for criteria in self)\n",
      "        New var:....... criteria = <transformers.generation_stopping_criteria.MaxLengthCriteria object>\n",
      "                        return      84         return any(criteria(input_ids, scores) for criteria in self)\n",
      "        Return value:.. False\n",
      "        Starting var:.. .0 = <list_iterator object>\n",
      "        Starting var:.. criteria = <transformers.generation_stopping_criteria.MaxLengthCriteria object>\n",
      "        Starting var:.. input_ids = tensor<(2, 8), int64, cuda:0>\n",
      "        Starting var:.. scores = (tensor<(2, 96103), float32, cuda:0, grad>, tensor<(2, 96103), float32, cuda:0, grad>, tensor<(2, ...uda:0, grad>, tensor<(2, 96103), float32, cuda:0, grad>, tensor<(2, 96103), float32, cuda:0, grad>)\n",
      "                        call        84         return any(criteria(input_ids, scores) for criteria in self)\n",
      "                        line        84         return any(criteria(input_ids, scores) for criteria in self)\n",
      "                        return      84         return any(criteria(input_ids, scores) for criteria in self)\n",
      "        Return value:.. None\n",
      "                    return      84         return any(criteria(input_ids, scores) for criteria in self)\n",
      "    Return value:.. False\n",
      "Source path:... generation_utils.py\n",
      "                line      1729         while cur_len < max_length:\n",
      "                line      1730             model_inputs = self.prepare_inputs_for_generation(input_ids, **model_kwargs)\n",
      "    Source path:... modeling_pegasus.py\n",
      "    Starting var:.. self = PegasusForConditionalGeneration(  (model): PegasusModel(    (shared): Embedding(96103, 1024, paddi...mentwise_affine=True)    )  )  (lm_head): Linear(in_features=1024, out_features=96103, bias=False))\n",
      "    Starting var:.. decoder_input_ids = tensor<(2, 8), int64, cuda:0>\n",
      "    Starting var:.. past = ((tensor<(2, 16, 7, 64), float32, cuda:0, grad>, tensor<(2, 16, 7, 64), float32, cuda:0, grad>, te...ad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>))\n",
      "    Starting var:.. attention_mask = tensor<(2, 6), int64, cuda:0>\n",
      "    Starting var:.. head_mask = None\n",
      "    Starting var:.. use_cache = None\n",
      "    Starting var:.. encoder_outputs = {'last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0, grad>}\n",
      "    Starting var:.. kwargs = {}\n",
      "                    call      1305     def prepare_inputs_for_generation(\n",
      "                    line      1316         if past is not None:\n",
      "                    line      1317             decoder_input_ids = decoder_input_ids[:, -1:]\n",
      "    Modified var:.. decoder_input_ids = tensor<(2, 1), int64, cuda:0>\n",
      "                    line      1320             \"input_ids\": None,  # encoder_outputs is defined. input_ids not needed\n",
      "                    line      1321             \"encoder_outputs\": encoder_outputs,\n",
      "                    line      1322             \"past_key_values\": past,\n",
      "                    line      1323             \"decoder_input_ids\": decoder_input_ids,\n",
      "                    line      1324             \"attention_mask\": attention_mask,\n",
      "                    line      1325             \"head_mask\": head_mask,\n",
      "                    line      1326             \"use_cache\": use_cache,  # change this to avoid caching (presumably for debugging)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                    line      1319         return {\n",
      "                    return    1319         return {\n",
      "    Return value:.. {'input_ids': None, 'encoder_outputs': {'last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0,...64, cuda:0>, 'attention_mask': tensor<(2, 6), int64, cuda:0>, 'head_mask': None, 'use_cache': None}\n",
      "Source path:... generation_utils.py\n",
      "                line      1732             outputs = self(\n",
      "                line      1733                 **model_inputs,\n",
      "                line      1734                 return_dict=True,\n",
      "                line      1735                 output_attentions=output_attentions,\n",
      "                line      1736                 output_hidden_states=output_hidden_states,\n",
      "                line      1732             outputs = self(\n",
      "    Source path:... module.py\n",
      "    Starting var:.. self = PegasusForConditionalGeneration(  (model): PegasusModel(    (shared): Embedding(96103, 1024, paddi...mentwise_affine=True)    )  )  (lm_head): Linear(in_features=1024, out_features=96103, bias=False))\n",
      "    Starting var:.. input = ()\n",
      "    Starting var:.. kwargs = {'input_ids': None, 'encoder_outputs': {'last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0,... 'use_cache': None, 'return_dict': True, 'output_attentions': False, 'output_hidden_states': False}\n",
      "                    call       715     def _call_impl(self, *input, **kwargs):\n",
      "                    line       716         for hook in itertools.chain(\n",
      "                    line       717                 _global_forward_pre_hooks.values(),\n",
      "                    line       718                 self._forward_pre_hooks.values()):\n",
      "                    line       716         for hook in itertools.chain(\n",
      "                    line       724         if torch._C._get_tracing_state():\n",
      "                    line       727             result = self.forward(*input, **kwargs)\n",
      "        Source path:... modeling_pegasus.py\n",
      "        Starting var:.. self = PegasusForConditionalGeneration(  (model): PegasusModel(    (shared): Embedding(96103, 1024, paddi...mentwise_affine=True)    )  )  (lm_head): Linear(in_features=1024, out_features=96103, bias=False))\n",
      "        Starting var:.. input_ids = None\n",
      "        Starting var:.. attention_mask = tensor<(2, 6), int64, cuda:0>\n",
      "        Starting var:.. decoder_input_ids = tensor<(2, 1), int64, cuda:0>\n",
      "        Starting var:.. decoder_attention_mask = None\n",
      "        Starting var:.. head_mask = None\n",
      "        Starting var:.. decoder_head_mask = None\n",
      "        Starting var:.. encoder_outputs = {'last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0, grad>}\n",
      "        Starting var:.. past_key_values = ((tensor<(2, 16, 7, 64), float32, cuda:0, grad>, tensor<(2, 16, 7, 64), float32, cuda:0, grad>, te...ad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>))\n",
      "        Starting var:.. inputs_embeds = None\n",
      "        Starting var:.. decoder_inputs_embeds = None\n",
      "        Starting var:.. labels = None\n",
      "        Starting var:.. use_cache = None\n",
      "        Starting var:.. output_attentions = False\n",
      "        Starting var:.. output_hidden_states = False\n",
      "        Starting var:.. return_dict = True\n",
      "                        call      1231     def forward(\n",
      "                        line      1258         return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
      "                        line      1260         if labels is not None:\n",
      "                        line      1266         outputs = self.model(\n",
      "                        line      1267             input_ids,\n",
      "                        line      1268             attention_mask=attention_mask,\n",
      "                        line      1269             decoder_input_ids=decoder_input_ids,\n",
      "                        line      1270             encoder_outputs=encoder_outputs,\n",
      "                        line      1271             decoder_attention_mask=decoder_attention_mask,\n",
      "                        line      1272             head_mask=head_mask,\n",
      "                        line      1273             decoder_head_mask=decoder_head_mask,\n",
      "                        line      1274             past_key_values=past_key_values,\n",
      "                        line      1275             inputs_embeds=inputs_embeds,\n",
      "                        line      1276             decoder_inputs_embeds=decoder_inputs_embeds,\n",
      "                        line      1277             use_cache=use_cache,\n",
      "                        line      1278             output_attentions=output_attentions,\n",
      "                        line      1279             output_hidden_states=output_hidden_states,\n",
      "                        line      1280             return_dict=return_dict,\n",
      "                        line      1266         outputs = self.model(\n",
      "        New var:....... outputs = {'last_hidden_state': tensor<(2, 1, 1024), float32, cuda:0, grad>, 'past_key_values': ((tensor<(2,...float32, cuda:0, grad>)), 'encoder_last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0, grad>}\n",
      "                        line      1282         lm_logits = self.lm_head(outputs[0]) + self.final_logits_bias\n",
      "        New var:....... lm_logits = tensor<(2, 1, 96103), float32, cuda:0, grad>\n",
      "                        line      1284         masked_lm_loss = None\n",
      "        New var:....... masked_lm_loss = None\n",
      "                        line      1285         if labels is not None:\n",
      "                        line      1289         if not return_dict:\n",
      "                        line      1293         return Seq2SeqLMOutput(\n",
      "                        line      1294             loss=masked_lm_loss,\n",
      "                        line      1295             logits=lm_logits,\n",
      "                        line      1296             past_key_values=outputs.past_key_values,\n",
      "                        line      1297             decoder_hidden_states=outputs.decoder_hidden_states,\n",
      "                        line      1298             decoder_attentions=outputs.decoder_attentions,\n",
      "                        line      1299             cross_attentions=outputs.cross_attentions,\n",
      "                        line      1300             encoder_last_hidden_state=outputs.encoder_last_hidden_state,\n",
      "                        line      1301             encoder_hidden_states=outputs.encoder_hidden_states,\n",
      "                        line      1302             encoder_attentions=outputs.encoder_attentions,\n",
      "                        line      1293         return Seq2SeqLMOutput(\n",
      "                        return    1293         return Seq2SeqLMOutput(\n",
      "        Return value:.. {'logits': tensor<(2, 1, 96103), float32, cuda:0, grad>, 'past_key_values': ((tensor<(2, 16, 8, 64...float32, cuda:0, grad>)), 'encoder_last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0, grad>}\n",
      "    Source path:... module.py\n",
      "    New var:....... result = {'logits': tensor<(2, 1, 96103), float32, cuda:0, grad>, 'past_key_values': ((tensor<(2, 16, 8, 64...float32, cuda:0, grad>)), 'encoder_last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0, grad>}\n",
      "                    line       728         for hook in itertools.chain(\n",
      "                    line       729                 _global_forward_hooks.values(),\n",
      "                    line       730                 self._forward_hooks.values()):\n",
      "                    line       728         for hook in itertools.chain(\n",
      "                    line       734         if (len(self._backward_hooks) > 0) or (len(_global_backward_hooks) > 0):\n",
      "                    line       749         return result\n",
      "                    return     749         return result\n",
      "    Return value:.. {'logits': tensor<(2, 1, 96103), float32, cuda:0, grad>, 'past_key_values': ((tensor<(2, 16, 8, 64...float32, cuda:0, grad>)), 'encoder_last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0, grad>}\n",
      "Source path:... generation_utils.py\n",
      "Modified var:.. outputs = {'logits': tensor<(2, 1, 96103), float32, cuda:0, grad>, 'past_key_values': ((tensor<(2, 16, 8, 64...float32, cuda:0, grad>)), 'encoder_last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0, grad>}\n",
      "                line      1738             next_token_logits = outputs.logits[:, -1, :]\n",
      "                line      1742             next_token_logits = self.adjust_logits_during_generation(\n",
      "                line      1743                 next_token_logits, cur_len=cur_len, max_length=max_length\n",
      "                line      1742             next_token_logits = self.adjust_logits_during_generation(\n",
      "    Starting var:.. self = PegasusForConditionalGeneration(  (model): PegasusModel(    (shared): Embedding(96103, 1024, paddi...mentwise_affine=True)    )  )  (lm_head): Linear(in_features=1024, out_features=96103, bias=False))\n",
      "    Starting var:.. logits = tensor<(2, 96103), float32, cuda:0, grad>\n",
      "    Starting var:.. kwargs = {'cur_len': 8, 'max_length': 60}\n",
      "                    call       373     def adjust_logits_during_generation(self, logits: torch.FloatTensor, **kwargs) -> torch.FloatTensor:\n",
      "                    line       378         return logits\n",
      "                    return     378         return logits\n",
      "    Return value:.. tensor<(2, 96103), float32, cuda:0, grad>\n",
      "                line      1746             next_token_scores = F.log_softmax(next_token_logits, dim=-1)  # (batch_size * num_beams, vocab_size)\n",
      "    Source path:... functional.py\n",
      "    Starting var:.. input = tensor<(2, 96103), float32, cuda:0, grad>\n",
      "    Starting var:.. dim = -1\n",
      "    Starting var:.. _stacklevel = 3\n",
      "    Starting var:.. dtype = None\n",
      "                    call      1581 def log_softmax(input, dim=None, _stacklevel=3, dtype=None):\n",
      "                    line      1598     if not torch.jit.is_scripting():\n",
      "        Source path:... _jit_internal.py\n",
      "                        call       750 def is_scripting():\n",
      "                        line       769     return False\n",
      "                        return     769     return False\n",
      "        Return value:.. False\n",
      "    Source path:... functional.py\n",
      "                    line      1599         if type(input) is not Tensor and has_torch_function((input,)):\n",
      "                    line      1602     if dim is None:\n",
      "                    line      1604     if dtype is None:\n",
      "                    line      1605         ret = input.log_softmax(dim)\n",
      "    New var:....... ret = tensor<(2, 96103), float32, cuda:0, grad>\n",
      "                    line      1608     return ret\n",
      "                    return    1608     return ret\n",
      "    Return value:.. tensor<(2, 96103), float32, cuda:0, grad>\n",
      "Source path:... generation_utils.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Modified var:.. next_token_scores = tensor<(2, 96103), float32, cuda:0, grad>\n",
      "                line      1748             next_token_scores = logits_processor(input_ids, next_token_scores)\n",
      "    Source path:... generation_logits_process.py\n",
      "    Starting var:.. self = [<transformers.generation_logits_process.MinLengthLogitsProcessor object>, <transformers.generation_logits_process.ForcedEOSTokenLogitsProcessor object>]\n",
      "    Starting var:.. input_ids = tensor<(2, 8), int64, cuda:0>\n",
      "    Starting var:.. scores = tensor<(2, 96103), float32, cuda:0, grad>\n",
      "    Starting var:.. kwargs = {}\n",
      "                    call        84     def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor, **kwargs) -> torch.FloatTensor:\n",
      "                    line        85         for processor in self:\n",
      "    New var:....... processor = <transformers.generation_logits_process.MinLengthLogitsProcessor object>\n",
      "                    line        86             function_args = inspect.signature(processor.__call__).parameters\n",
      "        Source path:... inspect.py\n",
      "        Starting var:.. obj = <bound method MinLengthLogitsProcessor.__call__ of <transformers.generation_logits_process.MinLengthLogitsProcessor object>>\n",
      "        Starting var:.. follow_wrapped = True\n",
      "                        call      3091 def signature(obj, *, follow_wrapped=True):\n",
      "                        line      3093     return Signature.from_callable(obj, follow_wrapped=follow_wrapped)\n",
      "                        return    3093     return Signature.from_callable(obj, follow_wrapped=follow_wrapped)\n",
      "        Return value:.. <Signature (input_ids: torch.LongTensor, scores: torch.FloatTensor) -> torch.FloatTensor>\n",
      "        Starting var:.. self = <Signature (input_ids: torch.LongTensor, scores: torch.FloatTensor) -> torch.FloatTensor>\n",
      "                        call      2846     def parameters(self):\n",
      "                        line      2847         return self._parameters\n",
      "                        return    2847         return self._parameters\n",
      "        Return value:.. mappingproxy(OrderedDict([('input_ids', <Parameter \"input_ids: torch.LongTensor\">), ('scores', <Parameter \"scores: torch.FloatTensor\">)]))\n",
      "    Source path:... generation_logits_process.py\n",
      "    New var:....... function_args = mappingproxy(OrderedDict([('input_ids', <Parameter \"input_ids: torch.LongTensor\">), ('scores', <Parameter \"scores: torch.FloatTensor\">)]))\n",
      "                    line        87             if len(function_args) > 2:\n",
      "                    line        93                 scores = processor(input_ids, scores)\n",
      "        Starting var:.. self = <transformers.generation_logits_process.MinLengthLogitsProcessor object>\n",
      "        Starting var:.. input_ids = tensor<(2, 8), int64, cuda:0>\n",
      "        Starting var:.. scores = tensor<(2, 96103), float32, cuda:0, grad>\n",
      "                        call       118     def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor) -> torch.FloatTensor:\n",
      "                        line       119         cur_len = input_ids.shape[-1]\n",
      "        New var:....... cur_len = 8\n",
      "                        line       120         if cur_len < self.min_length:\n",
      "                        line       122         return scores\n",
      "                        return     122         return scores\n",
      "        Return value:.. tensor<(2, 96103), float32, cuda:0, grad>\n",
      "                    line        85         for processor in self:\n",
      "    Modified var:.. processor = <transformers.generation_logits_process.ForcedEOSTokenLogitsProcessor object>\n",
      "                    line        86             function_args = inspect.signature(processor.__call__).parameters\n",
      "        Source path:... inspect.py\n",
      "        Starting var:.. obj = <bound method ForcedEOSTokenLogitsProcessor.__call__ of <transformers.generation_logits_process.ForcedEOSTokenLogitsProcessor object>>\n",
      "        Starting var:.. follow_wrapped = True\n",
      "                        call      3091 def signature(obj, *, follow_wrapped=True):\n",
      "                        line      3093     return Signature.from_callable(obj, follow_wrapped=follow_wrapped)\n",
      "                        return    3093     return Signature.from_callable(obj, follow_wrapped=follow_wrapped)\n",
      "        Return value:.. <Signature (input_ids: torch.LongTensor, scores: torch.FloatTensor) -> torch.FloatTensor>\n",
      "        Starting var:.. self = <Signature (input_ids: torch.LongTensor, scores: torch.FloatTensor) -> torch.FloatTensor>\n",
      "                        call      2846     def parameters(self):\n",
      "                        line      2847         return self._parameters\n",
      "                        return    2847         return self._parameters\n",
      "        Return value:.. mappingproxy(OrderedDict([('input_ids', <Parameter \"input_ids: torch.LongTensor\">), ('scores', <Parameter \"scores: torch.FloatTensor\">)]))\n",
      "    Source path:... generation_logits_process.py\n",
      "                    line        87             if len(function_args) > 2:\n",
      "                    line        93                 scores = processor(input_ids, scores)\n",
      "        Starting var:.. self = <transformers.generation_logits_process.ForcedEOSTokenLogitsProcessor object>\n",
      "        Starting var:.. input_ids = tensor<(2, 8), int64, cuda:0>\n",
      "        Starting var:.. scores = tensor<(2, 96103), float32, cuda:0, grad>\n",
      "                        call       571     def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor) -> torch.FloatTensor:\n",
      "                        line       572         cur_len = input_ids.shape[-1]\n",
      "        New var:....... cur_len = 8\n",
      "                        line       573         if cur_len == self.max_length - 1:\n",
      "                        line       577         return scores\n",
      "                        return     577         return scores\n",
      "        Return value:.. tensor<(2, 96103), float32, cuda:0, grad>\n",
      "                    line        85         for processor in self:\n",
      "                    line        94         return scores\n",
      "                    return      94         return scores\n",
      "    Return value:.. tensor<(2, 96103), float32, cuda:0, grad>\n",
      "Source path:... generation_utils.py\n",
      "                line      1749             next_token_scores = next_token_scores + beam_scores[:, None].expand_as(next_token_scores)\n",
      "                line      1752             if return_dict_in_generate:\n",
      "                line      1753                 if output_scores:\n",
      "                line      1754                     scores += (next_token_scores,)\n",
      "                line      1755                 if output_attentions:\n",
      "                line      1762                 if output_hidden_states:\n",
      "                line      1770             vocab_size = next_token_scores.shape[-1]\n",
      "                line      1771             next_token_scores = next_token_scores.view(batch_size, num_beams * vocab_size)\n",
      "Modified var:.. next_token_scores = tensor<(1, 192206), float32, cuda:0, grad>\n",
      "                line      1773             next_token_scores, next_tokens = torch.topk(\n",
      "                line      1774                 next_token_scores, 2 * num_beams, dim=1, largest=True, sorted=True\n",
      "                line      1773             next_token_scores, next_tokens = torch.topk(\n",
      "Modified var:.. next_token_scores = tensor<(1, 4), float32, cuda:0, grad>\n",
      "                line      1777             next_indices = next_tokens // vocab_size\n",
      "    Source path:... tensor.py\n",
      "    Starting var:.. args = (tensor<(1, 4), int64, cuda:0>, 96103)\n",
      "    Starting var:.. kwargs = {}\n",
      "    Starting var:.. f = <function Tensor.__floordiv__>\n",
      "    Starting var:.. wrapped = <function Tensor.__floordiv__>\n",
      "                    call        22     def wrapped(*args, **kwargs):\n",
      "                    line        23         from torch.overrides import has_torch_function, handle_torch_function\n",
      "    New var:....... has_torch_function = <function has_torch_function>\n",
      "    New var:....... handle_torch_function = <function handle_torch_function>\n",
      "                    line        24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "                        call        24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "                        line        24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "        New var:....... t = tensor<(1, 4), int64, cuda:0>\n",
      "                        return      24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "        Return value:.. True\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. t = tensor<(1, 4), int64, cuda:0>\n",
      "                        call        24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "                        line        24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "        Modified var:.. t = 96103\n",
      "                        return      24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "        Return value:.. False\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. t = 96103\n",
      "                        call        24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "                        exception   24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "        Exception:..... GeneratorExit\n",
      "                        return      24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "        Return value:.. None\n",
      "        Source path:... overrides.py\n",
      "        Starting var:.. relevant_args = (tensor<(1, 4), int64, cuda:0>, 96103)\n",
      "                        call      1070 def has_torch_function(relevant_args: Iterable[Any]) -> bool:\n",
      "                        line      1083     return _is_torch_function_enabled() and any(\n",
      "                        line      1087         for a in relevant_args\n",
      "                        line      1083     return _is_torch_function_enabled() and any(\n",
      "                        return    1083     return _is_torch_function_enabled() and any(\n",
      "        Return value:.. False\n",
      "    Source path:... tensor.py\n",
      "                    line        26         try:\n",
      "                    line        27             return f(*args, **kwargs)\n",
      "        Starting var:.. self = tensor<(1, 4), int64, cuda:0>\n",
      "        Starting var:.. other = 96103\n",
      "                        call       550     def __floordiv__(self, other):\n",
      "                        line       551         return torch.floor_divide(self, other)\n",
      "                        return     551         return torch.floor_divide(self, other)\n",
      "        Return value:.. tensor<(1, 4), int64, cuda:0>\n",
      "                    return      27             return f(*args, **kwargs)\n",
      "    Return value:.. tensor<(1, 4), int64, cuda:0>\n",
      "Source path:... generation_utils.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                line      1778             next_tokens = next_tokens % vocab_size\n",
      "                line      1781             beam_outputs = beam_scorer.process(\n",
      "                line      1782                 input_ids,\n",
      "                line      1783                 next_token_scores,\n",
      "                line      1784                 next_tokens,\n",
      "                line      1785                 next_indices,\n",
      "                line      1786                 pad_token_id=pad_token_id,\n",
      "                line      1787                 eos_token_id=eos_token_id,\n",
      "                line      1781             beam_outputs = beam_scorer.process(\n",
      "    Source path:... generation_beam_search.py\n",
      "    Starting var:.. self = <transformers.generation_beam_search.BeamSearchScorer object>\n",
      "    Starting var:.. input_ids = tensor<(2, 8), int64, cuda:0>\n",
      "    Starting var:.. next_scores = tensor<(1, 4), float32, cuda:0, grad>\n",
      "    Starting var:.. next_tokens = tensor<(1, 4), int64, cuda:0>\n",
      "    Starting var:.. next_indices = tensor<(1, 4), int64, cuda:0>\n",
      "    Starting var:.. pad_token_id = 0\n",
      "    Starting var:.. eos_token_id = 1\n",
      "                    call       199     def process(\n",
      "                    line       208         cur_len = input_ids.shape[-1]\n",
      "    New var:....... cur_len = 8\n",
      "                    line       209         batch_size = len(self._beam_hyps)\n",
      "    New var:....... batch_size = 1\n",
      "                    line       210         assert batch_size == (input_ids.shape[0] // self.group_size)\n",
      "                    line       212         device = input_ids.device\n",
      "    New var:....... device = device(type='cuda', index=0)\n",
      "                    line       213         next_beam_scores = torch.zeros((batch_size, self.group_size), dtype=next_scores.dtype, device=device)\n",
      "    New var:....... next_beam_scores = tensor<(1, 2), float32, cuda:0>\n",
      "                    line       214         next_beam_tokens = torch.zeros((batch_size, self.group_size), dtype=next_tokens.dtype, device=device)\n",
      "    New var:....... next_beam_tokens = tensor<(1, 2), int64, cuda:0>\n",
      "                    line       215         next_beam_indices = torch.zeros((batch_size, self.group_size), dtype=next_indices.dtype, device=device)\n",
      "    New var:....... next_beam_indices = tensor<(1, 2), int64, cuda:0>\n",
      "                    line       217         for batch_idx, beam_hyp in enumerate(self._beam_hyps):\n",
      "    New var:....... batch_idx = 0\n",
      "    New var:....... beam_hyp = <transformers.generation_beam_search.BeamHypotheses object>\n",
      "                    line       218             if self._done[batch_idx]:\n",
      "                    line       232             beam_idx = 0\n",
      "    New var:....... beam_idx = 0\n",
      "                    line       233             for beam_token_rank, (next_token, next_score, next_index) in enumerate(\n",
      "                    line       234                 zip(next_tokens[batch_idx], next_scores[batch_idx], next_indices[batch_idx])\n",
      "        Source path:... tensor.py\n",
      "        Starting var:.. self = tensor<(4,), int64, cuda:0>\n",
      "                        call       576     def __iter__(self):\n",
      "                        line       583         relevant_args = (self,)\n",
      "        New var:....... relevant_args = (tensor<(4,), int64, cuda:0>,)\n",
      "                        line       584         from torch.overrides import has_torch_function, handle_torch_function\n",
      "        New var:....... has_torch_function = <function has_torch_function>\n",
      "        New var:....... handle_torch_function = <function handle_torch_function>\n",
      "                        line       585         if type(self) is not Tensor and has_torch_function(relevant_args):\n",
      "                        line       587         if self.dim() == 0:\n",
      "                        line       589         if torch._C._get_tracing_state():\n",
      "                        line       594         return iter(self.unbind(0))\n",
      "                        return     594         return iter(self.unbind(0))\n",
      "        Return value:.. <tuple_iterator object>\n",
      "        Starting var:.. self = tensor<(4,), float32, cuda:0, grad>\n",
      "                        call       576     def __iter__(self):\n",
      "                        line       583         relevant_args = (self,)\n",
      "        New var:....... relevant_args = (tensor<(4,), float32, cuda:0, grad>,)\n",
      "                        line       584         from torch.overrides import has_torch_function, handle_torch_function\n",
      "        New var:....... has_torch_function = <function has_torch_function>\n",
      "        New var:....... handle_torch_function = <function handle_torch_function>\n",
      "                        line       585         if type(self) is not Tensor and has_torch_function(relevant_args):\n",
      "                        line       587         if self.dim() == 0:\n",
      "                        line       589         if torch._C._get_tracing_state():\n",
      "                        line       594         return iter(self.unbind(0))\n",
      "                        return     594         return iter(self.unbind(0))\n",
      "        Return value:.. <tuple_iterator object>\n",
      "        Starting var:.. self = tensor<(4,), int64, cuda:0>\n",
      "                        call       576     def __iter__(self):\n",
      "                        line       583         relevant_args = (self,)\n",
      "        New var:....... relevant_args = (tensor<(4,), int64, cuda:0>,)\n",
      "                        line       584         from torch.overrides import has_torch_function, handle_torch_function\n",
      "        New var:....... has_torch_function = <function has_torch_function>\n",
      "        New var:....... handle_torch_function = <function handle_torch_function>\n",
      "                        line       585         if type(self) is not Tensor and has_torch_function(relevant_args):\n",
      "                        line       587         if self.dim() == 0:\n",
      "                        line       589         if torch._C._get_tracing_state():\n",
      "                        line       594         return iter(self.unbind(0))\n",
      "                        return     594         return iter(self.unbind(0))\n",
      "        Return value:.. <tuple_iterator object>\n",
      "    Source path:... generation_beam_search.py\n",
      "                    line       233             for beam_token_rank, (next_token, next_score, next_index) in enumerate(\n",
      "    New var:....... beam_token_rank = 0\n",
      "    New var:....... next_token = tensor<(), int64, cuda:0>\n",
      "    New var:....... next_score = tensor<(), float32, cuda:0, grad>\n",
      "    New var:....... next_index = tensor<(), int64, cuda:0>\n",
      "                    line       236                 batch_beam_idx = batch_idx * self.group_size + next_index\n",
      "    New var:....... batch_beam_idx = tensor<(), int64, cuda:0>\n",
      "                    line       238                 if (eos_token_id is not None) and (next_token.item() == eos_token_id):\n",
      "                    line       249                     next_beam_scores[batch_idx, beam_idx] = next_score\n",
      "    Modified var:.. next_beam_scores = tensor<(1, 2), float32, cuda:0, grad>\n",
      "                    line       250                     next_beam_tokens[batch_idx, beam_idx] = next_token\n",
      "                    line       251                     next_beam_indices[batch_idx, beam_idx] = batch_beam_idx\n",
      "                    line       252                     beam_idx += 1\n",
      "    Modified var:.. beam_idx = 1\n",
      "                    line       255                 if beam_idx == self.group_size:\n",
      "                    line       233             for beam_token_rank, (next_token, next_score, next_index) in enumerate(\n",
      "    Modified var:.. beam_token_rank = 1\n",
      "                    line       236                 batch_beam_idx = batch_idx * self.group_size + next_index\n",
      "                    line       238                 if (eos_token_id is not None) and (next_token.item() == eos_token_id):\n",
      "                    line       249                     next_beam_scores[batch_idx, beam_idx] = next_score\n",
      "                    line       250                     next_beam_tokens[batch_idx, beam_idx] = next_token\n",
      "                    line       251                     next_beam_indices[batch_idx, beam_idx] = batch_beam_idx\n",
      "                    line       252                     beam_idx += 1\n",
      "    Modified var:.. beam_idx = 2\n",
      "                    line       255                 if beam_idx == self.group_size:\n",
      "                    line       256                     break\n",
      "                    line       258             if beam_idx < self.group_size:\n",
      "                    line       264             self._done[batch_idx] = self._done[batch_idx] or beam_hyp.is_done(\n",
      "                    line       265                 next_scores[batch_idx].max().item(), cur_len\n",
      "                    line       264             self._done[batch_idx] = self._done[batch_idx] or beam_hyp.is_done(\n",
      "        Starting var:.. self = <transformers.generation_beam_search.BeamHypotheses object>\n",
      "        Starting var:.. best_sum_logprobs = -5.5468292236328125\n",
      "        Starting var:.. cur_len = 8\n",
      "                        call       371     def is_done(self, best_sum_logprobs: float, cur_len: int) -> bool:\n",
      "                        line       377         if len(self) < self.num_beams:\n",
      "                        line       378             return False\n",
      "                        return     378             return False\n",
      "        Return value:.. False\n",
      "                    line       217         for batch_idx, beam_hyp in enumerate(self._beam_hyps):\n",
      "                    line       268         return UserDict(\n",
      "                    line       270                 \"next_beam_scores\": next_beam_scores.view(-1),\n",
      "                    line       271                 \"next_beam_tokens\": next_beam_tokens.view(-1),\n",
      "                    line       272                 \"next_beam_indices\": next_beam_indices.view(-1),\n",
      "                    line       269             {\n",
      "                    line       268         return UserDict(\n",
      "        Source path:... __init__.py\n",
      "        Starting var:.. args = REPR FAILED\n",
      "        Starting var:.. kwargs = {}\n",
      "                        call       981     def __init__(*args, **kwargs):\n",
      "                        line       982         if not args:\n",
      "                        line       985         self, *args = args\n",
      "        Modified var:.. args = [{'next_beam_scores': tensor<(2,), float32, cuda:0, grad>, 'next_beam_tokens': tensor<(2,), int64, cuda:0>, 'next_beam_indices': tensor<(2,), int64, cuda:0>}]\n",
      "        New var:....... self = REPR FAILED\n",
      "                        line       986         if len(args) > 1:\n",
      "                        line       988         if args:\n",
      "                        line       989             dict = args[0]\n",
      "        New var:....... dict = {'next_beam_scores': tensor<(2,), float32, cuda:0, grad>, 'next_beam_tokens': tensor<(2,), int64, cuda:0>, 'next_beam_indices': tensor<(2,), int64, cuda:0>}\n",
      "                        line       997         self.data = {}\n",
      "        Modified var:.. self = {}\n",
      "                        line       998         if dict is not None:\n",
      "                        line       999             self.update(dict)\n",
      "        Modified var:.. self = {'next_beam_scores': tensor([-5.5468, -8.7458], device='cuda:0', grad_fn=<ViewBackward>), 'next_beam_tokens': tensor([208, 261], device='cuda:0'), 'next_beam_indices': tensor([0, 0], device='cuda:0')}\n",
      "                        line      1000         if kwargs:\n",
      "                        return    1000         if kwargs:\n",
      "        Return value:.. None\n",
      "    Source path:... generation_beam_search.py\n",
      "                    return     268         return UserDict(\n",
      "    Return value:.. {'next_beam_scores': tensor([-5.5468, -8.7458], device='cuda:0', grad_fn=<ViewBackward>), 'next_beam_tokens': tensor([208, 261], device='cuda:0'), 'next_beam_indices': tensor([0, 0], device='cuda:0')}\n",
      "Source path:... generation_utils.py\n",
      "Modified var:.. beam_outputs = {'next_beam_scores': tensor([-5.5468, -8.7458], device='cuda:0', grad_fn=<ViewBackward>), 'next_beam_tokens': tensor([208, 261], device='cuda:0'), 'next_beam_indices': tensor([0, 0], device='cuda:0')}\n",
      "                line      1789             beam_scores = beam_outputs[\"next_beam_scores\"]\n",
      "    Source path:... __init__.py\n",
      "    Starting var:.. self = {'next_beam_scores': tensor([-5.5468, -8.7458], device='cuda:0', grad_fn=<ViewBackward>), 'next_beam_tokens': tensor([208, 261], device='cuda:0'), 'next_beam_indices': tensor([0, 0], device='cuda:0')}\n",
      "    Starting var:.. key = 'next_beam_scores'\n",
      "                    call      1005     def __getitem__(self, key):\n",
      "                    line      1006         if key in self.data:\n",
      "                    line      1007             return self.data[key]\n",
      "                    return    1007             return self.data[key]\n",
      "    Return value:.. tensor<(2,), float32, cuda:0, grad>\n",
      "Source path:... generation_utils.py\n",
      "                line      1790             beam_next_tokens = beam_outputs[\"next_beam_tokens\"]\n",
      "    Source path:... __init__.py\n",
      "    Starting var:.. self = {'next_beam_scores': tensor([-5.5468, -8.7458], device='cuda:0', grad_fn=<ViewBackward>), 'next_beam_tokens': tensor([208, 261], device='cuda:0'), 'next_beam_indices': tensor([0, 0], device='cuda:0')}\n",
      "    Starting var:.. key = 'next_beam_tokens'\n",
      "                    call      1005     def __getitem__(self, key):\n",
      "                    line      1006         if key in self.data:\n",
      "                    line      1007             return self.data[key]\n",
      "                    return    1007             return self.data[key]\n",
      "    Return value:.. tensor<(2,), int64, cuda:0>\n",
      "Source path:... generation_utils.py\n",
      "                line      1791             beam_idx = beam_outputs[\"next_beam_indices\"]\n",
      "    Source path:... __init__.py\n",
      "    Starting var:.. self = {'next_beam_scores': tensor([-5.5468, -8.7458], device='cuda:0', grad_fn=<ViewBackward>), 'next_beam_tokens': tensor([208, 261], device='cuda:0'), 'next_beam_indices': tensor([0, 0], device='cuda:0')}\n",
      "    Starting var:.. key = 'next_beam_indices'\n",
      "                    call      1005     def __getitem__(self, key):\n",
      "                    line      1006         if key in self.data:\n",
      "                    line      1007             return self.data[key]\n",
      "                    return    1007             return self.data[key]\n",
      "    Return value:.. tensor<(2,), int64, cuda:0>\n",
      "Source path:... generation_utils.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                line      1793             input_ids = torch.cat([input_ids[beam_idx, :], beam_next_tokens.unsqueeze(-1)], dim=-1)\n",
      "Modified var:.. input_ids = tensor<(2, 9), int64, cuda:0>\n",
      "                line      1795             cur_len = cur_len + 1\n",
      "Modified var:.. cur_len = 9\n",
      "                line      1797             model_kwargs = self._update_model_kwargs_for_generation(\n",
      "                line      1798                 outputs, model_kwargs, is_encoder_decoder=self.config.is_encoder_decoder\n",
      "                line      1797             model_kwargs = self._update_model_kwargs_for_generation(\n",
      "    Starting var:.. outputs = {'logits': tensor<(2, 1, 96103), float32, cuda:0, grad>, 'past_key_values': ((tensor<(2, 16, 8, 64...float32, cuda:0, grad>)), 'encoder_last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0, grad>}\n",
      "    Starting var:.. model_kwargs = {'use_cache': None, 'attention_mask': tensor<(2, 6), int64, cuda:0>, 'encoder_outputs': {'last_hid...d>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>))}\n",
      "    Starting var:.. is_encoder_decoder = True\n",
      "                    call       511     def _update_model_kwargs_for_generation(\n",
      "                    line       515         if \"past_key_values\" in outputs:\n",
      "                    line       516             model_kwargs[\"past\"] = outputs.past_key_values\n",
      "                    line       525         if \"token_type_ids\" in model_kwargs:\n",
      "                    line       530         if not is_encoder_decoder:\n",
      "                    line       537         return model_kwargs\n",
      "                    return     537         return model_kwargs\n",
      "    Return value:.. {'use_cache': None, 'attention_mask': tensor<(2, 6), int64, cuda:0>, 'encoder_outputs': {'last_hid...d>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>))}\n",
      "                line      1800             if model_kwargs[\"past\"] is not None:\n",
      "                line      1801                 model_kwargs[\"past\"] = self._reorder_cache(model_kwargs[\"past\"], beam_idx)\n",
      "    Source path:... modeling_pegasus.py\n",
      "    Starting var:.. past = ((tensor<(2, 16, 8, 64), float32, cuda:0, grad>, tensor<(2, 16, 8, 64), float32, cuda:0, grad>, te...ad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>))\n",
      "    Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                    call      1333     def _reorder_cache(past, beam_idx):\n",
      "                    line      1334         reordered_past = ()\n",
      "    New var:....... reordered_past = ()\n",
      "                    line      1335         for layer_past in past:\n",
      "    New var:....... layer_past = (tensor<(2, 16, 8, 64), float32, cuda:0, grad>, tensor<(2, 16, 8, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>)\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 8, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 8, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 8, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 8, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 8, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "    Modified var:.. reordered_past = ((tensor<(2, 16, 8, 64), float32, cuda:0, grad>, tensor<(2, 16, 8, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>),)\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 8, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 8, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 8, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 8, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 8, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "    Modified var:.. reordered_past = ((tensor<(2, 16, 8, 64), float32, cuda:0, grad>, tensor<(2, 16, 8, 64), float32, cuda:0, grad>, te...ad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>))\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 8, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 8, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 8, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 8, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 8, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 8, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 8, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 8, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 8, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 8, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 8, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 8, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 8, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 8, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 8, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 8, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 8, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 8, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 8, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 8, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 8, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 8, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 8, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 8, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 8, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 8, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 8, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 8, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 8, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 8, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 8, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 8, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 8, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 8, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 8, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 8, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 8, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 8, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 8, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 8, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 8, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 8, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 8, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 8, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 8, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 8, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 8, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 8, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 8, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 8, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 8, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 8, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 8, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 8, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 8, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 8, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 8, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 8, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 8, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 8, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 8, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 8, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 8, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 8, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 8, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 8, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 8, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 8, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 8, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 8, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1340         return reordered_past\n",
      "                    return    1340         return reordered_past\n",
      "    Return value:.. ((tensor<(2, 16, 8, 64), float32, cuda:0, grad>, tensor<(2, 16, 8, 64), float32, cuda:0, grad>, te...ad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>))\n",
      "Source path:... generation_utils.py\n",
      "                line      1803             if beam_scorer.is_done:\n",
      "    Source path:... generation_beam_search.py\n",
      "    Starting var:.. self = <transformers.generation_beam_search.BeamSearchScorer object>\n",
      "                    call       196     def is_done(self) -> bool:\n",
      "                    line       197         return self._done.all()\n",
      "                    return     197         return self._done.all()\n",
      "    Return value:.. tensor<(), bool, cuda:0>\n",
      "Source path:... generation_utils.py\n",
      "                line      1806             if stopping_criteria(input_ids, scores):\n",
      "    Source path:... generation_stopping_criteria.py\n",
      "    Starting var:.. self = [<transformers.generation_stopping_criteria.MaxLengthCriteria object>]\n",
      "    Starting var:.. input_ids = tensor<(2, 9), int64, cuda:0>\n",
      "    Starting var:.. scores = (tensor<(2, 96103), float32, cuda:0, grad>, tensor<(2, 96103), float32, cuda:0, grad>, tensor<(2, ...uda:0, grad>, tensor<(2, 96103), float32, cuda:0, grad>, tensor<(2, 96103), float32, cuda:0, grad>)\n",
      "    Starting var:.. kwargs = {}\n",
      "                    call        83     def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor, **kwargs) -> bool:\n",
      "                    line        84         return any(criteria(input_ids, scores) for criteria in self)\n",
      "        Starting var:.. .0 = <list_iterator object>\n",
      "        Starting var:.. input_ids = tensor<(2, 9), int64, cuda:0>\n",
      "        Starting var:.. scores = (tensor<(2, 96103), float32, cuda:0, grad>, tensor<(2, 96103), float32, cuda:0, grad>, tensor<(2, ...uda:0, grad>, tensor<(2, 96103), float32, cuda:0, grad>, tensor<(2, 96103), float32, cuda:0, grad>)\n",
      "                        call        84         return any(criteria(input_ids, scores) for criteria in self)\n",
      "                        line        84         return any(criteria(input_ids, scores) for criteria in self)\n",
      "        New var:....... criteria = <transformers.generation_stopping_criteria.MaxLengthCriteria object>\n",
      "                        return      84         return any(criteria(input_ids, scores) for criteria in self)\n",
      "        Return value:.. False\n",
      "        Starting var:.. .0 = <list_iterator object>\n",
      "        Starting var:.. criteria = <transformers.generation_stopping_criteria.MaxLengthCriteria object>\n",
      "        Starting var:.. input_ids = tensor<(2, 9), int64, cuda:0>\n",
      "        Starting var:.. scores = (tensor<(2, 96103), float32, cuda:0, grad>, tensor<(2, 96103), float32, cuda:0, grad>, tensor<(2, ...uda:0, grad>, tensor<(2, 96103), float32, cuda:0, grad>, tensor<(2, 96103), float32, cuda:0, grad>)\n",
      "                        call        84         return any(criteria(input_ids, scores) for criteria in self)\n",
      "                        line        84         return any(criteria(input_ids, scores) for criteria in self)\n",
      "                        return      84         return any(criteria(input_ids, scores) for criteria in self)\n",
      "        Return value:.. None\n",
      "                    return      84         return any(criteria(input_ids, scores) for criteria in self)\n",
      "    Return value:.. False\n",
      "Source path:... generation_utils.py\n",
      "                line      1729         while cur_len < max_length:\n",
      "                line      1730             model_inputs = self.prepare_inputs_for_generation(input_ids, **model_kwargs)\n",
      "    Source path:... modeling_pegasus.py\n",
      "    Starting var:.. self = PegasusForConditionalGeneration(  (model): PegasusModel(    (shared): Embedding(96103, 1024, paddi...mentwise_affine=True)    )  )  (lm_head): Linear(in_features=1024, out_features=96103, bias=False))\n",
      "    Starting var:.. decoder_input_ids = tensor<(2, 9), int64, cuda:0>\n",
      "    Starting var:.. past = ((tensor<(2, 16, 8, 64), float32, cuda:0, grad>, tensor<(2, 16, 8, 64), float32, cuda:0, grad>, te...ad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>))\n",
      "    Starting var:.. attention_mask = tensor<(2, 6), int64, cuda:0>\n",
      "    Starting var:.. head_mask = None\n",
      "    Starting var:.. use_cache = None\n",
      "    Starting var:.. encoder_outputs = {'last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0, grad>}\n",
      "    Starting var:.. kwargs = {}\n",
      "                    call      1305     def prepare_inputs_for_generation(\n",
      "                    line      1316         if past is not None:\n",
      "                    line      1317             decoder_input_ids = decoder_input_ids[:, -1:]\n",
      "    Modified var:.. decoder_input_ids = tensor<(2, 1), int64, cuda:0>\n",
      "                    line      1320             \"input_ids\": None,  # encoder_outputs is defined. input_ids not needed\n",
      "                    line      1321             \"encoder_outputs\": encoder_outputs,\n",
      "                    line      1322             \"past_key_values\": past,\n",
      "                    line      1323             \"decoder_input_ids\": decoder_input_ids,\n",
      "                    line      1324             \"attention_mask\": attention_mask,\n",
      "                    line      1325             \"head_mask\": head_mask,\n",
      "                    line      1326             \"use_cache\": use_cache,  # change this to avoid caching (presumably for debugging)\n",
      "                    line      1319         return {\n",
      "                    return    1319         return {\n",
      "    Return value:.. {'input_ids': None, 'encoder_outputs': {'last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0,...64, cuda:0>, 'attention_mask': tensor<(2, 6), int64, cuda:0>, 'head_mask': None, 'use_cache': None}\n",
      "Source path:... generation_utils.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                line      1732             outputs = self(\n",
      "                line      1733                 **model_inputs,\n",
      "                line      1734                 return_dict=True,\n",
      "                line      1735                 output_attentions=output_attentions,\n",
      "                line      1736                 output_hidden_states=output_hidden_states,\n",
      "                line      1732             outputs = self(\n",
      "    Source path:... module.py\n",
      "    Starting var:.. self = PegasusForConditionalGeneration(  (model): PegasusModel(    (shared): Embedding(96103, 1024, paddi...mentwise_affine=True)    )  )  (lm_head): Linear(in_features=1024, out_features=96103, bias=False))\n",
      "    Starting var:.. input = ()\n",
      "    Starting var:.. kwargs = {'input_ids': None, 'encoder_outputs': {'last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0,... 'use_cache': None, 'return_dict': True, 'output_attentions': False, 'output_hidden_states': False}\n",
      "                    call       715     def _call_impl(self, *input, **kwargs):\n",
      "                    line       716         for hook in itertools.chain(\n",
      "                    line       717                 _global_forward_pre_hooks.values(),\n",
      "                    line       718                 self._forward_pre_hooks.values()):\n",
      "                    line       716         for hook in itertools.chain(\n",
      "                    line       724         if torch._C._get_tracing_state():\n",
      "                    line       727             result = self.forward(*input, **kwargs)\n",
      "        Source path:... modeling_pegasus.py\n",
      "        Starting var:.. self = PegasusForConditionalGeneration(  (model): PegasusModel(    (shared): Embedding(96103, 1024, paddi...mentwise_affine=True)    )  )  (lm_head): Linear(in_features=1024, out_features=96103, bias=False))\n",
      "        Starting var:.. input_ids = None\n",
      "        Starting var:.. attention_mask = tensor<(2, 6), int64, cuda:0>\n",
      "        Starting var:.. decoder_input_ids = tensor<(2, 1), int64, cuda:0>\n",
      "        Starting var:.. decoder_attention_mask = None\n",
      "        Starting var:.. head_mask = None\n",
      "        Starting var:.. decoder_head_mask = None\n",
      "        Starting var:.. encoder_outputs = {'last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0, grad>}\n",
      "        Starting var:.. past_key_values = ((tensor<(2, 16, 8, 64), float32, cuda:0, grad>, tensor<(2, 16, 8, 64), float32, cuda:0, grad>, te...ad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>))\n",
      "        Starting var:.. inputs_embeds = None\n",
      "        Starting var:.. decoder_inputs_embeds = None\n",
      "        Starting var:.. labels = None\n",
      "        Starting var:.. use_cache = None\n",
      "        Starting var:.. output_attentions = False\n",
      "        Starting var:.. output_hidden_states = False\n",
      "        Starting var:.. return_dict = True\n",
      "                        call      1231     def forward(\n",
      "                        line      1258         return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
      "                        line      1260         if labels is not None:\n",
      "                        line      1266         outputs = self.model(\n",
      "                        line      1267             input_ids,\n",
      "                        line      1268             attention_mask=attention_mask,\n",
      "                        line      1269             decoder_input_ids=decoder_input_ids,\n",
      "                        line      1270             encoder_outputs=encoder_outputs,\n",
      "                        line      1271             decoder_attention_mask=decoder_attention_mask,\n",
      "                        line      1272             head_mask=head_mask,\n",
      "                        line      1273             decoder_head_mask=decoder_head_mask,\n",
      "                        line      1274             past_key_values=past_key_values,\n",
      "                        line      1275             inputs_embeds=inputs_embeds,\n",
      "                        line      1276             decoder_inputs_embeds=decoder_inputs_embeds,\n",
      "                        line      1277             use_cache=use_cache,\n",
      "                        line      1278             output_attentions=output_attentions,\n",
      "                        line      1279             output_hidden_states=output_hidden_states,\n",
      "                        line      1280             return_dict=return_dict,\n",
      "                        line      1266         outputs = self.model(\n",
      "        New var:....... outputs = {'last_hidden_state': tensor<(2, 1, 1024), float32, cuda:0, grad>, 'past_key_values': ((tensor<(2,...float32, cuda:0, grad>)), 'encoder_last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0, grad>}\n",
      "                        line      1282         lm_logits = self.lm_head(outputs[0]) + self.final_logits_bias\n",
      "        New var:....... lm_logits = tensor<(2, 1, 96103), float32, cuda:0, grad>\n",
      "                        line      1284         masked_lm_loss = None\n",
      "        New var:....... masked_lm_loss = None\n",
      "                        line      1285         if labels is not None:\n",
      "                        line      1289         if not return_dict:\n",
      "                        line      1293         return Seq2SeqLMOutput(\n",
      "                        line      1294             loss=masked_lm_loss,\n",
      "                        line      1295             logits=lm_logits,\n",
      "                        line      1296             past_key_values=outputs.past_key_values,\n",
      "                        line      1297             decoder_hidden_states=outputs.decoder_hidden_states,\n",
      "                        line      1298             decoder_attentions=outputs.decoder_attentions,\n",
      "                        line      1299             cross_attentions=outputs.cross_attentions,\n",
      "                        line      1300             encoder_last_hidden_state=outputs.encoder_last_hidden_state,\n",
      "                        line      1301             encoder_hidden_states=outputs.encoder_hidden_states,\n",
      "                        line      1302             encoder_attentions=outputs.encoder_attentions,\n",
      "                        line      1293         return Seq2SeqLMOutput(\n",
      "                        return    1293         return Seq2SeqLMOutput(\n",
      "        Return value:.. {'logits': tensor<(2, 1, 96103), float32, cuda:0, grad>, 'past_key_values': ((tensor<(2, 16, 9, 64...float32, cuda:0, grad>)), 'encoder_last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0, grad>}\n",
      "    Source path:... module.py\n",
      "    New var:....... result = {'logits': tensor<(2, 1, 96103), float32, cuda:0, grad>, 'past_key_values': ((tensor<(2, 16, 9, 64...float32, cuda:0, grad>)), 'encoder_last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0, grad>}\n",
      "                    line       728         for hook in itertools.chain(\n",
      "                    line       729                 _global_forward_hooks.values(),\n",
      "                    line       730                 self._forward_hooks.values()):\n",
      "                    line       728         for hook in itertools.chain(\n",
      "                    line       734         if (len(self._backward_hooks) > 0) or (len(_global_backward_hooks) > 0):\n",
      "                    line       749         return result\n",
      "                    return     749         return result\n",
      "    Return value:.. {'logits': tensor<(2, 1, 96103), float32, cuda:0, grad>, 'past_key_values': ((tensor<(2, 16, 9, 64...float32, cuda:0, grad>)), 'encoder_last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0, grad>}\n",
      "Source path:... generation_utils.py\n",
      "Modified var:.. outputs = {'logits': tensor<(2, 1, 96103), float32, cuda:0, grad>, 'past_key_values': ((tensor<(2, 16, 9, 64...float32, cuda:0, grad>)), 'encoder_last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0, grad>}\n",
      "                line      1738             next_token_logits = outputs.logits[:, -1, :]\n",
      "                line      1742             next_token_logits = self.adjust_logits_during_generation(\n",
      "                line      1743                 next_token_logits, cur_len=cur_len, max_length=max_length\n",
      "                line      1742             next_token_logits = self.adjust_logits_during_generation(\n",
      "    Starting var:.. self = PegasusForConditionalGeneration(  (model): PegasusModel(    (shared): Embedding(96103, 1024, paddi...mentwise_affine=True)    )  )  (lm_head): Linear(in_features=1024, out_features=96103, bias=False))\n",
      "    Starting var:.. logits = tensor<(2, 96103), float32, cuda:0, grad>\n",
      "    Starting var:.. kwargs = {'cur_len': 9, 'max_length': 60}\n",
      "                    call       373     def adjust_logits_during_generation(self, logits: torch.FloatTensor, **kwargs) -> torch.FloatTensor:\n",
      "                    line       378         return logits\n",
      "                    return     378         return logits\n",
      "    Return value:.. tensor<(2, 96103), float32, cuda:0, grad>\n",
      "                line      1746             next_token_scores = F.log_softmax(next_token_logits, dim=-1)  # (batch_size * num_beams, vocab_size)\n",
      "    Source path:... functional.py\n",
      "    Starting var:.. input = tensor<(2, 96103), float32, cuda:0, grad>\n",
      "    Starting var:.. dim = -1\n",
      "    Starting var:.. _stacklevel = 3\n",
      "    Starting var:.. dtype = None\n",
      "                    call      1581 def log_softmax(input, dim=None, _stacklevel=3, dtype=None):\n",
      "                    line      1598     if not torch.jit.is_scripting():\n",
      "        Source path:... _jit_internal.py\n",
      "                        call       750 def is_scripting():\n",
      "                        line       769     return False\n",
      "                        return     769     return False\n",
      "        Return value:.. False\n",
      "    Source path:... functional.py\n",
      "                    line      1599         if type(input) is not Tensor and has_torch_function((input,)):\n",
      "                    line      1602     if dim is None:\n",
      "                    line      1604     if dtype is None:\n",
      "                    line      1605         ret = input.log_softmax(dim)\n",
      "    New var:....... ret = tensor<(2, 96103), float32, cuda:0, grad>\n",
      "                    line      1608     return ret\n",
      "                    return    1608     return ret\n",
      "    Return value:.. tensor<(2, 96103), float32, cuda:0, grad>\n",
      "Source path:... generation_utils.py\n",
      "Modified var:.. next_token_scores = tensor<(2, 96103), float32, cuda:0, grad>\n",
      "                line      1748             next_token_scores = logits_processor(input_ids, next_token_scores)\n",
      "    Source path:... generation_logits_process.py\n",
      "    Starting var:.. self = [<transformers.generation_logits_process.MinLengthLogitsProcessor object>, <transformers.generation_logits_process.ForcedEOSTokenLogitsProcessor object>]\n",
      "    Starting var:.. input_ids = tensor<(2, 9), int64, cuda:0>\n",
      "    Starting var:.. scores = tensor<(2, 96103), float32, cuda:0, grad>\n",
      "    Starting var:.. kwargs = {}\n",
      "                    call        84     def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor, **kwargs) -> torch.FloatTensor:\n",
      "                    line        85         for processor in self:\n",
      "    New var:....... processor = <transformers.generation_logits_process.MinLengthLogitsProcessor object>\n",
      "                    line        86             function_args = inspect.signature(processor.__call__).parameters\n",
      "        Source path:... inspect.py\n",
      "        Starting var:.. obj = <bound method MinLengthLogitsProcessor.__call__ of <transformers.generation_logits_process.MinLengthLogitsProcessor object>>\n",
      "        Starting var:.. follow_wrapped = True\n",
      "                        call      3091 def signature(obj, *, follow_wrapped=True):\n",
      "                        line      3093     return Signature.from_callable(obj, follow_wrapped=follow_wrapped)\n",
      "                        return    3093     return Signature.from_callable(obj, follow_wrapped=follow_wrapped)\n",
      "        Return value:.. <Signature (input_ids: torch.LongTensor, scores: torch.FloatTensor) -> torch.FloatTensor>\n",
      "        Starting var:.. self = <Signature (input_ids: torch.LongTensor, scores: torch.FloatTensor) -> torch.FloatTensor>\n",
      "                        call      2846     def parameters(self):\n",
      "                        line      2847         return self._parameters\n",
      "                        return    2847         return self._parameters\n",
      "        Return value:.. mappingproxy(OrderedDict([('input_ids', <Parameter \"input_ids: torch.LongTensor\">), ('scores', <Parameter \"scores: torch.FloatTensor\">)]))\n",
      "    Source path:... generation_logits_process.py\n",
      "    New var:....... function_args = mappingproxy(OrderedDict([('input_ids', <Parameter \"input_ids: torch.LongTensor\">), ('scores', <Parameter \"scores: torch.FloatTensor\">)]))\n",
      "                    line        87             if len(function_args) > 2:\n",
      "                    line        93                 scores = processor(input_ids, scores)\n",
      "        Starting var:.. self = <transformers.generation_logits_process.MinLengthLogitsProcessor object>\n",
      "        Starting var:.. input_ids = tensor<(2, 9), int64, cuda:0>\n",
      "        Starting var:.. scores = tensor<(2, 96103), float32, cuda:0, grad>\n",
      "                        call       118     def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor) -> torch.FloatTensor:\n",
      "                        line       119         cur_len = input_ids.shape[-1]\n",
      "        New var:....... cur_len = 9\n",
      "                        line       120         if cur_len < self.min_length:\n",
      "                        line       122         return scores\n",
      "                        return     122         return scores\n",
      "        Return value:.. tensor<(2, 96103), float32, cuda:0, grad>\n",
      "                    line        85         for processor in self:\n",
      "    Modified var:.. processor = <transformers.generation_logits_process.ForcedEOSTokenLogitsProcessor object>\n",
      "                    line        86             function_args = inspect.signature(processor.__call__).parameters\n",
      "        Source path:... inspect.py\n",
      "        Starting var:.. obj = <bound method ForcedEOSTokenLogitsProcessor.__call__ of <transformers.generation_logits_process.ForcedEOSTokenLogitsProcessor object>>\n",
      "        Starting var:.. follow_wrapped = True\n",
      "                        call      3091 def signature(obj, *, follow_wrapped=True):\n",
      "                        line      3093     return Signature.from_callable(obj, follow_wrapped=follow_wrapped)\n",
      "                        return    3093     return Signature.from_callable(obj, follow_wrapped=follow_wrapped)\n",
      "        Return value:.. <Signature (input_ids: torch.LongTensor, scores: torch.FloatTensor) -> torch.FloatTensor>\n",
      "        Starting var:.. self = <Signature (input_ids: torch.LongTensor, scores: torch.FloatTensor) -> torch.FloatTensor>\n",
      "                        call      2846     def parameters(self):\n",
      "                        line      2847         return self._parameters\n",
      "                        return    2847         return self._parameters\n",
      "        Return value:.. mappingproxy(OrderedDict([('input_ids', <Parameter \"input_ids: torch.LongTensor\">), ('scores', <Parameter \"scores: torch.FloatTensor\">)]))\n",
      "    Source path:... generation_logits_process.py\n",
      "                    line        87             if len(function_args) > 2:\n",
      "                    line        93                 scores = processor(input_ids, scores)\n",
      "        Starting var:.. self = <transformers.generation_logits_process.ForcedEOSTokenLogitsProcessor object>\n",
      "        Starting var:.. input_ids = tensor<(2, 9), int64, cuda:0>\n",
      "        Starting var:.. scores = tensor<(2, 96103), float32, cuda:0, grad>\n",
      "                        call       571     def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor) -> torch.FloatTensor:\n",
      "                        line       572         cur_len = input_ids.shape[-1]\n",
      "        New var:....... cur_len = 9\n",
      "                        line       573         if cur_len == self.max_length - 1:\n",
      "                        line       577         return scores\n",
      "                        return     577         return scores\n",
      "        Return value:.. tensor<(2, 96103), float32, cuda:0, grad>\n",
      "                    line        85         for processor in self:\n",
      "                    line        94         return scores\n",
      "                    return      94         return scores\n",
      "    Return value:.. tensor<(2, 96103), float32, cuda:0, grad>\n",
      "Source path:... generation_utils.py\n",
      "                line      1749             next_token_scores = next_token_scores + beam_scores[:, None].expand_as(next_token_scores)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                line      1752             if return_dict_in_generate:\n",
      "                line      1753                 if output_scores:\n",
      "                line      1754                     scores += (next_token_scores,)\n",
      "                line      1755                 if output_attentions:\n",
      "                line      1762                 if output_hidden_states:\n",
      "                line      1770             vocab_size = next_token_scores.shape[-1]\n",
      "                line      1771             next_token_scores = next_token_scores.view(batch_size, num_beams * vocab_size)\n",
      "Modified var:.. next_token_scores = tensor<(1, 192206), float32, cuda:0, grad>\n",
      "                line      1773             next_token_scores, next_tokens = torch.topk(\n",
      "                line      1774                 next_token_scores, 2 * num_beams, dim=1, largest=True, sorted=True\n",
      "                line      1773             next_token_scores, next_tokens = torch.topk(\n",
      "Modified var:.. next_token_scores = tensor<(1, 4), float32, cuda:0, grad>\n",
      "                line      1777             next_indices = next_tokens // vocab_size\n",
      "    Source path:... tensor.py\n",
      "    Starting var:.. args = (tensor<(1, 4), int64, cuda:0>, 96103)\n",
      "    Starting var:.. kwargs = {}\n",
      "    Starting var:.. f = <function Tensor.__floordiv__>\n",
      "    Starting var:.. wrapped = <function Tensor.__floordiv__>\n",
      "                    call        22     def wrapped(*args, **kwargs):\n",
      "                    line        23         from torch.overrides import has_torch_function, handle_torch_function\n",
      "    New var:....... has_torch_function = <function has_torch_function>\n",
      "    New var:....... handle_torch_function = <function handle_torch_function>\n",
      "                    line        24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "                        call        24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "                        line        24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "        New var:....... t = tensor<(1, 4), int64, cuda:0>\n",
      "                        return      24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "        Return value:.. True\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. t = tensor<(1, 4), int64, cuda:0>\n",
      "                        call        24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "                        line        24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "        Modified var:.. t = 96103\n",
      "                        return      24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "        Return value:.. False\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. t = 96103\n",
      "                        call        24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "                        exception   24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "        Exception:..... GeneratorExit\n",
      "                        return      24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "        Return value:.. None\n",
      "        Source path:... overrides.py\n",
      "        Starting var:.. relevant_args = (tensor<(1, 4), int64, cuda:0>, 96103)\n",
      "                        call      1070 def has_torch_function(relevant_args: Iterable[Any]) -> bool:\n",
      "                        line      1083     return _is_torch_function_enabled() and any(\n",
      "                        line      1087         for a in relevant_args\n",
      "                        line      1083     return _is_torch_function_enabled() and any(\n",
      "                        return    1083     return _is_torch_function_enabled() and any(\n",
      "        Return value:.. False\n",
      "    Source path:... tensor.py\n",
      "                    line        26         try:\n",
      "                    line        27             return f(*args, **kwargs)\n",
      "        Starting var:.. self = tensor<(1, 4), int64, cuda:0>\n",
      "        Starting var:.. other = 96103\n",
      "                        call       550     def __floordiv__(self, other):\n",
      "                        line       551         return torch.floor_divide(self, other)\n",
      "                        return     551         return torch.floor_divide(self, other)\n",
      "        Return value:.. tensor<(1, 4), int64, cuda:0>\n",
      "                    return      27             return f(*args, **kwargs)\n",
      "    Return value:.. tensor<(1, 4), int64, cuda:0>\n",
      "Source path:... generation_utils.py\n",
      "                line      1778             next_tokens = next_tokens % vocab_size\n",
      "                line      1781             beam_outputs = beam_scorer.process(\n",
      "                line      1782                 input_ids,\n",
      "                line      1783                 next_token_scores,\n",
      "                line      1784                 next_tokens,\n",
      "                line      1785                 next_indices,\n",
      "                line      1786                 pad_token_id=pad_token_id,\n",
      "                line      1787                 eos_token_id=eos_token_id,\n",
      "                line      1781             beam_outputs = beam_scorer.process(\n",
      "    Source path:... generation_beam_search.py\n",
      "    Starting var:.. self = <transformers.generation_beam_search.BeamSearchScorer object>\n",
      "    Starting var:.. input_ids = tensor<(2, 9), int64, cuda:0>\n",
      "    Starting var:.. next_scores = tensor<(1, 4), float32, cuda:0, grad>\n",
      "    Starting var:.. next_tokens = tensor<(1, 4), int64, cuda:0>\n",
      "    Starting var:.. next_indices = tensor<(1, 4), int64, cuda:0>\n",
      "    Starting var:.. pad_token_id = 0\n",
      "    Starting var:.. eos_token_id = 1\n",
      "                    call       199     def process(\n",
      "                    line       208         cur_len = input_ids.shape[-1]\n",
      "    New var:....... cur_len = 9\n",
      "                    line       209         batch_size = len(self._beam_hyps)\n",
      "    New var:....... batch_size = 1\n",
      "                    line       210         assert batch_size == (input_ids.shape[0] // self.group_size)\n",
      "                    line       212         device = input_ids.device\n",
      "    New var:....... device = device(type='cuda', index=0)\n",
      "                    line       213         next_beam_scores = torch.zeros((batch_size, self.group_size), dtype=next_scores.dtype, device=device)\n",
      "    New var:....... next_beam_scores = tensor<(1, 2), float32, cuda:0>\n",
      "                    line       214         next_beam_tokens = torch.zeros((batch_size, self.group_size), dtype=next_tokens.dtype, device=device)\n",
      "    New var:....... next_beam_tokens = tensor<(1, 2), int64, cuda:0>\n",
      "                    line       215         next_beam_indices = torch.zeros((batch_size, self.group_size), dtype=next_indices.dtype, device=device)\n",
      "    New var:....... next_beam_indices = tensor<(1, 2), int64, cuda:0>\n",
      "                    line       217         for batch_idx, beam_hyp in enumerate(self._beam_hyps):\n",
      "    New var:....... batch_idx = 0\n",
      "    New var:....... beam_hyp = <transformers.generation_beam_search.BeamHypotheses object>\n",
      "                    line       218             if self._done[batch_idx]:\n",
      "                    line       232             beam_idx = 0\n",
      "    New var:....... beam_idx = 0\n",
      "                    line       233             for beam_token_rank, (next_token, next_score, next_index) in enumerate(\n",
      "                    line       234                 zip(next_tokens[batch_idx], next_scores[batch_idx], next_indices[batch_idx])\n",
      "        Source path:... tensor.py\n",
      "        Starting var:.. self = tensor<(4,), int64, cuda:0>\n",
      "                        call       576     def __iter__(self):\n",
      "                        line       583         relevant_args = (self,)\n",
      "        New var:....... relevant_args = (tensor<(4,), int64, cuda:0>,)\n",
      "                        line       584         from torch.overrides import has_torch_function, handle_torch_function\n",
      "        New var:....... has_torch_function = <function has_torch_function>\n",
      "        New var:....... handle_torch_function = <function handle_torch_function>\n",
      "                        line       585         if type(self) is not Tensor and has_torch_function(relevant_args):\n",
      "                        line       587         if self.dim() == 0:\n",
      "                        line       589         if torch._C._get_tracing_state():\n",
      "                        line       594         return iter(self.unbind(0))\n",
      "                        return     594         return iter(self.unbind(0))\n",
      "        Return value:.. <tuple_iterator object>\n",
      "        Starting var:.. self = tensor<(4,), float32, cuda:0, grad>\n",
      "                        call       576     def __iter__(self):\n",
      "                        line       583         relevant_args = (self,)\n",
      "        New var:....... relevant_args = (tensor<(4,), float32, cuda:0, grad>,)\n",
      "                        line       584         from torch.overrides import has_torch_function, handle_torch_function\n",
      "        New var:....... has_torch_function = <function has_torch_function>\n",
      "        New var:....... handle_torch_function = <function handle_torch_function>\n",
      "                        line       585         if type(self) is not Tensor and has_torch_function(relevant_args):\n",
      "                        line       587         if self.dim() == 0:\n",
      "                        line       589         if torch._C._get_tracing_state():\n",
      "                        line       594         return iter(self.unbind(0))\n",
      "                        return     594         return iter(self.unbind(0))\n",
      "        Return value:.. <tuple_iterator object>\n",
      "        Starting var:.. self = tensor<(4,), int64, cuda:0>\n",
      "                        call       576     def __iter__(self):\n",
      "                        line       583         relevant_args = (self,)\n",
      "        New var:....... relevant_args = (tensor<(4,), int64, cuda:0>,)\n",
      "                        line       584         from torch.overrides import has_torch_function, handle_torch_function\n",
      "        New var:....... has_torch_function = <function has_torch_function>\n",
      "        New var:....... handle_torch_function = <function handle_torch_function>\n",
      "                        line       585         if type(self) is not Tensor and has_torch_function(relevant_args):\n",
      "                        line       587         if self.dim() == 0:\n",
      "                        line       589         if torch._C._get_tracing_state():\n",
      "                        line       594         return iter(self.unbind(0))\n",
      "                        return     594         return iter(self.unbind(0))\n",
      "        Return value:.. <tuple_iterator object>\n",
      "    Source path:... generation_beam_search.py\n",
      "                    line       233             for beam_token_rank, (next_token, next_score, next_index) in enumerate(\n",
      "    New var:....... beam_token_rank = 0\n",
      "    New var:....... next_token = tensor<(), int64, cuda:0>\n",
      "    New var:....... next_score = tensor<(), float32, cuda:0, grad>\n",
      "    New var:....... next_index = tensor<(), int64, cuda:0>\n",
      "                    line       236                 batch_beam_idx = batch_idx * self.group_size + next_index\n",
      "    New var:....... batch_beam_idx = tensor<(), int64, cuda:0>\n",
      "                    line       238                 if (eos_token_id is not None) and (next_token.item() == eos_token_id):\n",
      "                    line       249                     next_beam_scores[batch_idx, beam_idx] = next_score\n",
      "    Modified var:.. next_beam_scores = tensor<(1, 2), float32, cuda:0, grad>\n",
      "                    line       250                     next_beam_tokens[batch_idx, beam_idx] = next_token\n",
      "                    line       251                     next_beam_indices[batch_idx, beam_idx] = batch_beam_idx\n",
      "                    line       252                     beam_idx += 1\n",
      "    Modified var:.. beam_idx = 1\n",
      "                    line       255                 if beam_idx == self.group_size:\n",
      "                    line       233             for beam_token_rank, (next_token, next_score, next_index) in enumerate(\n",
      "    Modified var:.. beam_token_rank = 1\n",
      "                    line       236                 batch_beam_idx = batch_idx * self.group_size + next_index\n",
      "                    line       238                 if (eos_token_id is not None) and (next_token.item() == eos_token_id):\n",
      "                    line       249                     next_beam_scores[batch_idx, beam_idx] = next_score\n",
      "                    line       250                     next_beam_tokens[batch_idx, beam_idx] = next_token\n",
      "                    line       251                     next_beam_indices[batch_idx, beam_idx] = batch_beam_idx\n",
      "                    line       252                     beam_idx += 1\n",
      "    Modified var:.. beam_idx = 2\n",
      "                    line       255                 if beam_idx == self.group_size:\n",
      "                    line       256                     break\n",
      "                    line       258             if beam_idx < self.group_size:\n",
      "                    line       264             self._done[batch_idx] = self._done[batch_idx] or beam_hyp.is_done(\n",
      "                    line       265                 next_scores[batch_idx].max().item(), cur_len\n",
      "                    line       264             self._done[batch_idx] = self._done[batch_idx] or beam_hyp.is_done(\n",
      "        Starting var:.. self = <transformers.generation_beam_search.BeamHypotheses object>\n",
      "        Starting var:.. best_sum_logprobs = -8.733839988708496\n",
      "        Starting var:.. cur_len = 9\n",
      "                        call       371     def is_done(self, best_sum_logprobs: float, cur_len: int) -> bool:\n",
      "                        line       377         if len(self) < self.num_beams:\n",
      "                        line       378             return False\n",
      "                        return     378             return False\n",
      "        Return value:.. False\n",
      "                    line       217         for batch_idx, beam_hyp in enumerate(self._beam_hyps):\n",
      "                    line       268         return UserDict(\n",
      "                    line       270                 \"next_beam_scores\": next_beam_scores.view(-1),\n",
      "                    line       271                 \"next_beam_tokens\": next_beam_tokens.view(-1),\n",
      "                    line       272                 \"next_beam_indices\": next_beam_indices.view(-1),\n",
      "                    line       269             {\n",
      "                    line       268         return UserDict(\n",
      "        Source path:... __init__.py\n",
      "        Starting var:.. args = REPR FAILED\n",
      "        Starting var:.. kwargs = {}\n",
      "                        call       981     def __init__(*args, **kwargs):\n",
      "                        line       982         if not args:\n",
      "                        line       985         self, *args = args\n",
      "        Modified var:.. args = [{'next_beam_scores': tensor<(2,), float32, cuda:0, grad>, 'next_beam_tokens': tensor<(2,), int64, cuda:0>, 'next_beam_indices': tensor<(2,), int64, cuda:0>}]\n",
      "        New var:....... self = REPR FAILED\n",
      "                        line       986         if len(args) > 1:\n",
      "                        line       988         if args:\n",
      "                        line       989             dict = args[0]\n",
      "        New var:....... dict = {'next_beam_scores': tensor<(2,), float32, cuda:0, grad>, 'next_beam_tokens': tensor<(2,), int64, cuda:0>, 'next_beam_indices': tensor<(2,), int64, cuda:0>}\n",
      "                        line       997         self.data = {}\n",
      "        Modified var:.. self = {}\n",
      "                        line       998         if dict is not None:\n",
      "                        line       999             self.update(dict)\n",
      "        Modified var:.. self = {'next_beam_scores': tensor([-8.7338, -8.7450], device='cuda:0', grad_fn=<ViewBackward>), 'next_beam_tokens': tensor([264, 128], device='cuda:0'), 'next_beam_indices': tensor([0, 0], device='cuda:0')}\n",
      "                        line      1000         if kwargs:\n",
      "                        return    1000         if kwargs:\n",
      "        Return value:.. None\n",
      "    Source path:... generation_beam_search.py\n",
      "                    return     268         return UserDict(\n",
      "    Return value:.. {'next_beam_scores': tensor([-8.7338, -8.7450], device='cuda:0', grad_fn=<ViewBackward>), 'next_beam_tokens': tensor([264, 128], device='cuda:0'), 'next_beam_indices': tensor([0, 0], device='cuda:0')}\n",
      "Source path:... generation_utils.py\n",
      "Modified var:.. beam_outputs = {'next_beam_scores': tensor([-8.7338, -8.7450], device='cuda:0', grad_fn=<ViewBackward>), 'next_beam_tokens': tensor([264, 128], device='cuda:0'), 'next_beam_indices': tensor([0, 0], device='cuda:0')}\n",
      "                line      1789             beam_scores = beam_outputs[\"next_beam_scores\"]\n",
      "    Source path:... __init__.py\n",
      "    Starting var:.. self = {'next_beam_scores': tensor([-8.7338, -8.7450], device='cuda:0', grad_fn=<ViewBackward>), 'next_beam_tokens': tensor([264, 128], device='cuda:0'), 'next_beam_indices': tensor([0, 0], device='cuda:0')}\n",
      "    Starting var:.. key = 'next_beam_scores'\n",
      "                    call      1005     def __getitem__(self, key):\n",
      "                    line      1006         if key in self.data:\n",
      "                    line      1007             return self.data[key]\n",
      "                    return    1007             return self.data[key]\n",
      "    Return value:.. tensor<(2,), float32, cuda:0, grad>\n",
      "Source path:... generation_utils.py\n",
      "                line      1790             beam_next_tokens = beam_outputs[\"next_beam_tokens\"]\n",
      "    Source path:... __init__.py\n",
      "    Starting var:.. self = {'next_beam_scores': tensor([-8.7338, -8.7450], device='cuda:0', grad_fn=<ViewBackward>), 'next_beam_tokens': tensor([264, 128], device='cuda:0'), 'next_beam_indices': tensor([0, 0], device='cuda:0')}\n",
      "    Starting var:.. key = 'next_beam_tokens'\n",
      "                    call      1005     def __getitem__(self, key):\n",
      "                    line      1006         if key in self.data:\n",
      "                    line      1007             return self.data[key]\n",
      "                    return    1007             return self.data[key]\n",
      "    Return value:.. tensor<(2,), int64, cuda:0>\n",
      "Source path:... generation_utils.py\n",
      "                line      1791             beam_idx = beam_outputs[\"next_beam_indices\"]\n",
      "    Source path:... __init__.py\n",
      "    Starting var:.. self = {'next_beam_scores': tensor([-8.7338, -8.7450], device='cuda:0', grad_fn=<ViewBackward>), 'next_beam_tokens': tensor([264, 128], device='cuda:0'), 'next_beam_indices': tensor([0, 0], device='cuda:0')}\n",
      "    Starting var:.. key = 'next_beam_indices'\n",
      "                    call      1005     def __getitem__(self, key):\n",
      "                    line      1006         if key in self.data:\n",
      "                    line      1007             return self.data[key]\n",
      "                    return    1007             return self.data[key]\n",
      "    Return value:.. tensor<(2,), int64, cuda:0>\n",
      "Source path:... generation_utils.py\n",
      "                line      1793             input_ids = torch.cat([input_ids[beam_idx, :], beam_next_tokens.unsqueeze(-1)], dim=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Modified var:.. input_ids = tensor<(2, 10), int64, cuda:0>\n",
      "                line      1795             cur_len = cur_len + 1\n",
      "Modified var:.. cur_len = 10\n",
      "                line      1797             model_kwargs = self._update_model_kwargs_for_generation(\n",
      "                line      1798                 outputs, model_kwargs, is_encoder_decoder=self.config.is_encoder_decoder\n",
      "                line      1797             model_kwargs = self._update_model_kwargs_for_generation(\n",
      "    Starting var:.. outputs = {'logits': tensor<(2, 1, 96103), float32, cuda:0, grad>, 'past_key_values': ((tensor<(2, 16, 9, 64...float32, cuda:0, grad>)), 'encoder_last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0, grad>}\n",
      "    Starting var:.. model_kwargs = {'use_cache': None, 'attention_mask': tensor<(2, 6), int64, cuda:0>, 'encoder_outputs': {'last_hid...d>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>))}\n",
      "    Starting var:.. is_encoder_decoder = True\n",
      "                    call       511     def _update_model_kwargs_for_generation(\n",
      "                    line       515         if \"past_key_values\" in outputs:\n",
      "                    line       516             model_kwargs[\"past\"] = outputs.past_key_values\n",
      "                    line       525         if \"token_type_ids\" in model_kwargs:\n",
      "                    line       530         if not is_encoder_decoder:\n",
      "                    line       537         return model_kwargs\n",
      "                    return     537         return model_kwargs\n",
      "    Return value:.. {'use_cache': None, 'attention_mask': tensor<(2, 6), int64, cuda:0>, 'encoder_outputs': {'last_hid...d>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>))}\n",
      "                line      1800             if model_kwargs[\"past\"] is not None:\n",
      "                line      1801                 model_kwargs[\"past\"] = self._reorder_cache(model_kwargs[\"past\"], beam_idx)\n",
      "    Source path:... modeling_pegasus.py\n",
      "    Starting var:.. past = ((tensor<(2, 16, 9, 64), float32, cuda:0, grad>, tensor<(2, 16, 9, 64), float32, cuda:0, grad>, te...ad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>))\n",
      "    Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                    call      1333     def _reorder_cache(past, beam_idx):\n",
      "                    line      1334         reordered_past = ()\n",
      "    New var:....... reordered_past = ()\n",
      "                    line      1335         for layer_past in past:\n",
      "    New var:....... layer_past = (tensor<(2, 16, 9, 64), float32, cuda:0, grad>, tensor<(2, 16, 9, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>)\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 9, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 9, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 9, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 9, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 9, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "    Modified var:.. reordered_past = ((tensor<(2, 16, 9, 64), float32, cuda:0, grad>, tensor<(2, 16, 9, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>),)\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 9, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 9, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 9, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 9, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 9, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "    Modified var:.. reordered_past = ((tensor<(2, 16, 9, 64), float32, cuda:0, grad>, tensor<(2, 16, 9, 64), float32, cuda:0, grad>, te...ad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>))\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 9, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 9, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 9, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 9, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 9, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 9, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 9, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 9, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 9, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 9, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 9, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 9, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 9, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 9, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 9, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 9, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 9, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 9, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 9, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 9, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 9, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 9, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 9, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 9, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 9, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 9, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 9, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 9, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 9, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 9, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 9, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 9, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 9, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 9, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 9, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 9, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 9, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 9, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 9, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 9, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 9, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 9, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 9, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 9, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 9, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 9, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 9, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 9, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 9, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 9, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 9, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 9, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 9, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 9, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 9, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 9, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 9, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 9, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 9, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 9, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 9, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 9, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 9, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 9, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 9, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        New var:....... past_state = tensor<(2, 16, 9, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 9, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 9, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 9, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 9, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1340         return reordered_past\n",
      "                    return    1340         return reordered_past\n",
      "    Return value:.. ((tensor<(2, 16, 9, 64), float32, cuda:0, grad>, tensor<(2, 16, 9, 64), float32, cuda:0, grad>, te...ad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>))\n",
      "Source path:... generation_utils.py\n",
      "                line      1803             if beam_scorer.is_done:\n",
      "    Source path:... generation_beam_search.py\n",
      "    Starting var:.. self = <transformers.generation_beam_search.BeamSearchScorer object>\n",
      "                    call       196     def is_done(self) -> bool:\n",
      "                    line       197         return self._done.all()\n",
      "                    return     197         return self._done.all()\n",
      "    Return value:.. tensor<(), bool, cuda:0>\n",
      "Source path:... generation_utils.py\n",
      "                line      1806             if stopping_criteria(input_ids, scores):\n",
      "    Source path:... generation_stopping_criteria.py\n",
      "    Starting var:.. self = [<transformers.generation_stopping_criteria.MaxLengthCriteria object>]\n",
      "    Starting var:.. input_ids = tensor<(2, 10), int64, cuda:0>\n",
      "    Starting var:.. scores = (tensor<(2, 96103), float32, cuda:0, grad>, tensor<(2, 96103), float32, cuda:0, grad>, tensor<(2, ...uda:0, grad>, tensor<(2, 96103), float32, cuda:0, grad>, tensor<(2, 96103), float32, cuda:0, grad>)\n",
      "    Starting var:.. kwargs = {}\n",
      "                    call        83     def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor, **kwargs) -> bool:\n",
      "                    line        84         return any(criteria(input_ids, scores) for criteria in self)\n",
      "        Starting var:.. .0 = <list_iterator object>\n",
      "        Starting var:.. input_ids = tensor<(2, 10), int64, cuda:0>\n",
      "        Starting var:.. scores = (tensor<(2, 96103), float32, cuda:0, grad>, tensor<(2, 96103), float32, cuda:0, grad>, tensor<(2, ...uda:0, grad>, tensor<(2, 96103), float32, cuda:0, grad>, tensor<(2, 96103), float32, cuda:0, grad>)\n",
      "                        call        84         return any(criteria(input_ids, scores) for criteria in self)\n",
      "                        line        84         return any(criteria(input_ids, scores) for criteria in self)\n",
      "        New var:....... criteria = <transformers.generation_stopping_criteria.MaxLengthCriteria object>\n",
      "                        return      84         return any(criteria(input_ids, scores) for criteria in self)\n",
      "        Return value:.. False\n",
      "        Starting var:.. .0 = <list_iterator object>\n",
      "        Starting var:.. criteria = <transformers.generation_stopping_criteria.MaxLengthCriteria object>\n",
      "        Starting var:.. input_ids = tensor<(2, 10), int64, cuda:0>\n",
      "        Starting var:.. scores = (tensor<(2, 96103), float32, cuda:0, grad>, tensor<(2, 96103), float32, cuda:0, grad>, tensor<(2, ...uda:0, grad>, tensor<(2, 96103), float32, cuda:0, grad>, tensor<(2, 96103), float32, cuda:0, grad>)\n",
      "                        call        84         return any(criteria(input_ids, scores) for criteria in self)\n",
      "                        line        84         return any(criteria(input_ids, scores) for criteria in self)\n",
      "                        return      84         return any(criteria(input_ids, scores) for criteria in self)\n",
      "        Return value:.. None\n",
      "                    return      84         return any(criteria(input_ids, scores) for criteria in self)\n",
      "    Return value:.. False\n",
      "Source path:... generation_utils.py\n",
      "                line      1729         while cur_len < max_length:\n",
      "                line      1730             model_inputs = self.prepare_inputs_for_generation(input_ids, **model_kwargs)\n",
      "    Source path:... modeling_pegasus.py\n",
      "    Starting var:.. self = PegasusForConditionalGeneration(  (model): PegasusModel(    (shared): Embedding(96103, 1024, paddi...mentwise_affine=True)    )  )  (lm_head): Linear(in_features=1024, out_features=96103, bias=False))\n",
      "    Starting var:.. decoder_input_ids = tensor<(2, 10), int64, cuda:0>\n",
      "    Starting var:.. past = ((tensor<(2, 16, 9, 64), float32, cuda:0, grad>, tensor<(2, 16, 9, 64), float32, cuda:0, grad>, te...ad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>))\n",
      "    Starting var:.. attention_mask = tensor<(2, 6), int64, cuda:0>\n",
      "    Starting var:.. head_mask = None\n",
      "    Starting var:.. use_cache = None\n",
      "    Starting var:.. encoder_outputs = {'last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0, grad>}\n",
      "    Starting var:.. kwargs = {}\n",
      "                    call      1305     def prepare_inputs_for_generation(\n",
      "                    line      1316         if past is not None:\n",
      "                    line      1317             decoder_input_ids = decoder_input_ids[:, -1:]\n",
      "    Modified var:.. decoder_input_ids = tensor<(2, 1), int64, cuda:0>\n",
      "                    line      1320             \"input_ids\": None,  # encoder_outputs is defined. input_ids not needed\n",
      "                    line      1321             \"encoder_outputs\": encoder_outputs,\n",
      "                    line      1322             \"past_key_values\": past,\n",
      "                    line      1323             \"decoder_input_ids\": decoder_input_ids,\n",
      "                    line      1324             \"attention_mask\": attention_mask,\n",
      "                    line      1325             \"head_mask\": head_mask,\n",
      "                    line      1326             \"use_cache\": use_cache,  # change this to avoid caching (presumably for debugging)\n",
      "                    line      1319         return {\n",
      "                    return    1319         return {\n",
      "    Return value:.. {'input_ids': None, 'encoder_outputs': {'last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0,...64, cuda:0>, 'attention_mask': tensor<(2, 6), int64, cuda:0>, 'head_mask': None, 'use_cache': None}\n",
      "Source path:... generation_utils.py\n",
      "                line      1732             outputs = self(\n",
      "                line      1733                 **model_inputs,\n",
      "                line      1734                 return_dict=True,\n",
      "                line      1735                 output_attentions=output_attentions,\n",
      "                line      1736                 output_hidden_states=output_hidden_states,\n",
      "                line      1732             outputs = self(\n",
      "    Source path:... module.py\n",
      "    Starting var:.. self = PegasusForConditionalGeneration(  (model): PegasusModel(    (shared): Embedding(96103, 1024, paddi...mentwise_affine=True)    )  )  (lm_head): Linear(in_features=1024, out_features=96103, bias=False))\n",
      "    Starting var:.. input = ()\n",
      "    Starting var:.. kwargs = {'input_ids': None, 'encoder_outputs': {'last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0,... 'use_cache': None, 'return_dict': True, 'output_attentions': False, 'output_hidden_states': False}\n",
      "                    call       715     def _call_impl(self, *input, **kwargs):\n",
      "                    line       716         for hook in itertools.chain(\n",
      "                    line       717                 _global_forward_pre_hooks.values(),\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                    line       718                 self._forward_pre_hooks.values()):\n",
      "                    line       716         for hook in itertools.chain(\n",
      "                    line       724         if torch._C._get_tracing_state():\n",
      "                    line       727             result = self.forward(*input, **kwargs)\n",
      "        Source path:... modeling_pegasus.py\n",
      "        Starting var:.. self = PegasusForConditionalGeneration(  (model): PegasusModel(    (shared): Embedding(96103, 1024, paddi...mentwise_affine=True)    )  )  (lm_head): Linear(in_features=1024, out_features=96103, bias=False))\n",
      "        Starting var:.. input_ids = None\n",
      "        Starting var:.. attention_mask = tensor<(2, 6), int64, cuda:0>\n",
      "        Starting var:.. decoder_input_ids = tensor<(2, 1), int64, cuda:0>\n",
      "        Starting var:.. decoder_attention_mask = None\n",
      "        Starting var:.. head_mask = None\n",
      "        Starting var:.. decoder_head_mask = None\n",
      "        Starting var:.. encoder_outputs = {'last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0, grad>}\n",
      "        Starting var:.. past_key_values = ((tensor<(2, 16, 9, 64), float32, cuda:0, grad>, tensor<(2, 16, 9, 64), float32, cuda:0, grad>, te...ad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>))\n",
      "        Starting var:.. inputs_embeds = None\n",
      "        Starting var:.. decoder_inputs_embeds = None\n",
      "        Starting var:.. labels = None\n",
      "        Starting var:.. use_cache = None\n",
      "        Starting var:.. output_attentions = False\n",
      "        Starting var:.. output_hidden_states = False\n",
      "        Starting var:.. return_dict = True\n",
      "                        call      1231     def forward(\n",
      "                        line      1258         return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
      "                        line      1260         if labels is not None:\n",
      "                        line      1266         outputs = self.model(\n",
      "                        line      1267             input_ids,\n",
      "                        line      1268             attention_mask=attention_mask,\n",
      "                        line      1269             decoder_input_ids=decoder_input_ids,\n",
      "                        line      1270             encoder_outputs=encoder_outputs,\n",
      "                        line      1271             decoder_attention_mask=decoder_attention_mask,\n",
      "                        line      1272             head_mask=head_mask,\n",
      "                        line      1273             decoder_head_mask=decoder_head_mask,\n",
      "                        line      1274             past_key_values=past_key_values,\n",
      "                        line      1275             inputs_embeds=inputs_embeds,\n",
      "                        line      1276             decoder_inputs_embeds=decoder_inputs_embeds,\n",
      "                        line      1277             use_cache=use_cache,\n",
      "                        line      1278             output_attentions=output_attentions,\n",
      "                        line      1279             output_hidden_states=output_hidden_states,\n",
      "                        line      1280             return_dict=return_dict,\n",
      "                        line      1266         outputs = self.model(\n",
      "        New var:....... outputs = {'last_hidden_state': tensor<(2, 1, 1024), float32, cuda:0, grad>, 'past_key_values': ((tensor<(2,...float32, cuda:0, grad>)), 'encoder_last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0, grad>}\n",
      "                        line      1282         lm_logits = self.lm_head(outputs[0]) + self.final_logits_bias\n",
      "        New var:....... lm_logits = tensor<(2, 1, 96103), float32, cuda:0, grad>\n",
      "                        line      1284         masked_lm_loss = None\n",
      "        New var:....... masked_lm_loss = None\n",
      "                        line      1285         if labels is not None:\n",
      "                        line      1289         if not return_dict:\n",
      "                        line      1293         return Seq2SeqLMOutput(\n",
      "                        line      1294             loss=masked_lm_loss,\n",
      "                        line      1295             logits=lm_logits,\n",
      "                        line      1296             past_key_values=outputs.past_key_values,\n",
      "                        line      1297             decoder_hidden_states=outputs.decoder_hidden_states,\n",
      "                        line      1298             decoder_attentions=outputs.decoder_attentions,\n",
      "                        line      1299             cross_attentions=outputs.cross_attentions,\n",
      "                        line      1300             encoder_last_hidden_state=outputs.encoder_last_hidden_state,\n",
      "                        line      1301             encoder_hidden_states=outputs.encoder_hidden_states,\n",
      "                        line      1302             encoder_attentions=outputs.encoder_attentions,\n",
      "                        line      1293         return Seq2SeqLMOutput(\n",
      "                        return    1293         return Seq2SeqLMOutput(\n",
      "        Return value:.. {'logits': tensor<(2, 1, 96103), float32, cuda:0, grad>, 'past_key_values': ((tensor<(2, 16, 10, 6...float32, cuda:0, grad>)), 'encoder_last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0, grad>}\n",
      "    Source path:... module.py\n",
      "    New var:....... result = {'logits': tensor<(2, 1, 96103), float32, cuda:0, grad>, 'past_key_values': ((tensor<(2, 16, 10, 6...float32, cuda:0, grad>)), 'encoder_last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0, grad>}\n",
      "                    line       728         for hook in itertools.chain(\n",
      "                    line       729                 _global_forward_hooks.values(),\n",
      "                    line       730                 self._forward_hooks.values()):\n",
      "                    line       728         for hook in itertools.chain(\n",
      "                    line       734         if (len(self._backward_hooks) > 0) or (len(_global_backward_hooks) > 0):\n",
      "                    line       749         return result\n",
      "                    return     749         return result\n",
      "    Return value:.. {'logits': tensor<(2, 1, 96103), float32, cuda:0, grad>, 'past_key_values': ((tensor<(2, 16, 10, 6...float32, cuda:0, grad>)), 'encoder_last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0, grad>}\n",
      "Source path:... generation_utils.py\n",
      "Modified var:.. outputs = {'logits': tensor<(2, 1, 96103), float32, cuda:0, grad>, 'past_key_values': ((tensor<(2, 16, 10, 6...float32, cuda:0, grad>)), 'encoder_last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0, grad>}\n",
      "                line      1738             next_token_logits = outputs.logits[:, -1, :]\n",
      "                line      1742             next_token_logits = self.adjust_logits_during_generation(\n",
      "                line      1743                 next_token_logits, cur_len=cur_len, max_length=max_length\n",
      "                line      1742             next_token_logits = self.adjust_logits_during_generation(\n",
      "    Starting var:.. self = PegasusForConditionalGeneration(  (model): PegasusModel(    (shared): Embedding(96103, 1024, paddi...mentwise_affine=True)    )  )  (lm_head): Linear(in_features=1024, out_features=96103, bias=False))\n",
      "    Starting var:.. logits = tensor<(2, 96103), float32, cuda:0, grad>\n",
      "    Starting var:.. kwargs = {'cur_len': 10, 'max_length': 60}\n",
      "                    call       373     def adjust_logits_during_generation(self, logits: torch.FloatTensor, **kwargs) -> torch.FloatTensor:\n",
      "                    line       378         return logits\n",
      "                    return     378         return logits\n",
      "    Return value:.. tensor<(2, 96103), float32, cuda:0, grad>\n",
      "                line      1746             next_token_scores = F.log_softmax(next_token_logits, dim=-1)  # (batch_size * num_beams, vocab_size)\n",
      "    Source path:... functional.py\n",
      "    Starting var:.. input = tensor<(2, 96103), float32, cuda:0, grad>\n",
      "    Starting var:.. dim = -1\n",
      "    Starting var:.. _stacklevel = 3\n",
      "    Starting var:.. dtype = None\n",
      "                    call      1581 def log_softmax(input, dim=None, _stacklevel=3, dtype=None):\n",
      "                    line      1598     if not torch.jit.is_scripting():\n",
      "        Source path:... _jit_internal.py\n",
      "                        call       750 def is_scripting():\n",
      "                        line       769     return False\n",
      "                        return     769     return False\n",
      "        Return value:.. False\n",
      "    Source path:... functional.py\n",
      "                    line      1599         if type(input) is not Tensor and has_torch_function((input,)):\n",
      "                    line      1602     if dim is None:\n",
      "                    line      1604     if dtype is None:\n",
      "                    line      1605         ret = input.log_softmax(dim)\n",
      "    New var:....... ret = tensor<(2, 96103), float32, cuda:0, grad>\n",
      "                    line      1608     return ret\n",
      "                    return    1608     return ret\n",
      "    Return value:.. tensor<(2, 96103), float32, cuda:0, grad>\n",
      "Source path:... generation_utils.py\n",
      "Modified var:.. next_token_scores = tensor<(2, 96103), float32, cuda:0, grad>\n",
      "                line      1748             next_token_scores = logits_processor(input_ids, next_token_scores)\n",
      "    Source path:... generation_logits_process.py\n",
      "    Starting var:.. self = [<transformers.generation_logits_process.MinLengthLogitsProcessor object>, <transformers.generation_logits_process.ForcedEOSTokenLogitsProcessor object>]\n",
      "    Starting var:.. input_ids = tensor<(2, 10), int64, cuda:0>\n",
      "    Starting var:.. scores = tensor<(2, 96103), float32, cuda:0, grad>\n",
      "    Starting var:.. kwargs = {}\n",
      "                    call        84     def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor, **kwargs) -> torch.FloatTensor:\n",
      "                    line        85         for processor in self:\n",
      "    New var:....... processor = <transformers.generation_logits_process.MinLengthLogitsProcessor object>\n",
      "                    line        86             function_args = inspect.signature(processor.__call__).parameters\n",
      "        Source path:... inspect.py\n",
      "        Starting var:.. obj = <bound method MinLengthLogitsProcessor.__call__ of <transformers.generation_logits_process.MinLengthLogitsProcessor object>>\n",
      "        Starting var:.. follow_wrapped = True\n",
      "                        call      3091 def signature(obj, *, follow_wrapped=True):\n",
      "                        line      3093     return Signature.from_callable(obj, follow_wrapped=follow_wrapped)\n",
      "                        return    3093     return Signature.from_callable(obj, follow_wrapped=follow_wrapped)\n",
      "        Return value:.. <Signature (input_ids: torch.LongTensor, scores: torch.FloatTensor) -> torch.FloatTensor>\n",
      "        Starting var:.. self = <Signature (input_ids: torch.LongTensor, scores: torch.FloatTensor) -> torch.FloatTensor>\n",
      "                        call      2846     def parameters(self):\n",
      "                        line      2847         return self._parameters\n",
      "                        return    2847         return self._parameters\n",
      "        Return value:.. mappingproxy(OrderedDict([('input_ids', <Parameter \"input_ids: torch.LongTensor\">), ('scores', <Parameter \"scores: torch.FloatTensor\">)]))\n",
      "    Source path:... generation_logits_process.py\n",
      "    New var:....... function_args = mappingproxy(OrderedDict([('input_ids', <Parameter \"input_ids: torch.LongTensor\">), ('scores', <Parameter \"scores: torch.FloatTensor\">)]))\n",
      "                    line        87             if len(function_args) > 2:\n",
      "                    line        93                 scores = processor(input_ids, scores)\n",
      "        Starting var:.. self = <transformers.generation_logits_process.MinLengthLogitsProcessor object>\n",
      "        Starting var:.. input_ids = tensor<(2, 10), int64, cuda:0>\n",
      "        Starting var:.. scores = tensor<(2, 96103), float32, cuda:0, grad>\n",
      "                        call       118     def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor) -> torch.FloatTensor:\n",
      "                        line       119         cur_len = input_ids.shape[-1]\n",
      "        New var:....... cur_len = 10\n",
      "                        line       120         if cur_len < self.min_length:\n",
      "                        line       122         return scores\n",
      "                        return     122         return scores\n",
      "        Return value:.. tensor<(2, 96103), float32, cuda:0, grad>\n",
      "                    line        85         for processor in self:\n",
      "    Modified var:.. processor = <transformers.generation_logits_process.ForcedEOSTokenLogitsProcessor object>\n",
      "                    line        86             function_args = inspect.signature(processor.__call__).parameters\n",
      "        Source path:... inspect.py\n",
      "        Starting var:.. obj = <bound method ForcedEOSTokenLogitsProcessor.__call__ of <transformers.generation_logits_process.ForcedEOSTokenLogitsProcessor object>>\n",
      "        Starting var:.. follow_wrapped = True\n",
      "                        call      3091 def signature(obj, *, follow_wrapped=True):\n",
      "                        line      3093     return Signature.from_callable(obj, follow_wrapped=follow_wrapped)\n",
      "                        return    3093     return Signature.from_callable(obj, follow_wrapped=follow_wrapped)\n",
      "        Return value:.. <Signature (input_ids: torch.LongTensor, scores: torch.FloatTensor) -> torch.FloatTensor>\n",
      "        Starting var:.. self = <Signature (input_ids: torch.LongTensor, scores: torch.FloatTensor) -> torch.FloatTensor>\n",
      "                        call      2846     def parameters(self):\n",
      "                        line      2847         return self._parameters\n",
      "                        return    2847         return self._parameters\n",
      "        Return value:.. mappingproxy(OrderedDict([('input_ids', <Parameter \"input_ids: torch.LongTensor\">), ('scores', <Parameter \"scores: torch.FloatTensor\">)]))\n",
      "    Source path:... generation_logits_process.py\n",
      "                    line        87             if len(function_args) > 2:\n",
      "                    line        93                 scores = processor(input_ids, scores)\n",
      "        Starting var:.. self = <transformers.generation_logits_process.ForcedEOSTokenLogitsProcessor object>\n",
      "        Starting var:.. input_ids = tensor<(2, 10), int64, cuda:0>\n",
      "        Starting var:.. scores = tensor<(2, 96103), float32, cuda:0, grad>\n",
      "                        call       571     def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor) -> torch.FloatTensor:\n",
      "                        line       572         cur_len = input_ids.shape[-1]\n",
      "        New var:....... cur_len = 10\n",
      "                        line       573         if cur_len == self.max_length - 1:\n",
      "                        line       577         return scores\n",
      "                        return     577         return scores\n",
      "        Return value:.. tensor<(2, 96103), float32, cuda:0, grad>\n",
      "                    line        85         for processor in self:\n",
      "                    line        94         return scores\n",
      "                    return      94         return scores\n",
      "    Return value:.. tensor<(2, 96103), float32, cuda:0, grad>\n",
      "Source path:... generation_utils.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                line      1749             next_token_scores = next_token_scores + beam_scores[:, None].expand_as(next_token_scores)\n",
      "                line      1752             if return_dict_in_generate:\n",
      "                line      1753                 if output_scores:\n",
      "                line      1754                     scores += (next_token_scores,)\n",
      "                line      1755                 if output_attentions:\n",
      "                line      1762                 if output_hidden_states:\n",
      "                line      1770             vocab_size = next_token_scores.shape[-1]\n",
      "                line      1771             next_token_scores = next_token_scores.view(batch_size, num_beams * vocab_size)\n",
      "Modified var:.. next_token_scores = tensor<(1, 192206), float32, cuda:0, grad>\n",
      "                line      1773             next_token_scores, next_tokens = torch.topk(\n",
      "                line      1774                 next_token_scores, 2 * num_beams, dim=1, largest=True, sorted=True\n",
      "                line      1773             next_token_scores, next_tokens = torch.topk(\n",
      "Modified var:.. next_token_scores = tensor<(1, 4), float32, cuda:0, grad>\n",
      "                line      1777             next_indices = next_tokens // vocab_size\n",
      "    Source path:... tensor.py\n",
      "    Starting var:.. args = (tensor<(1, 4), int64, cuda:0>, 96103)\n",
      "    Starting var:.. kwargs = {}\n",
      "    Starting var:.. f = <function Tensor.__floordiv__>\n",
      "    Starting var:.. wrapped = <function Tensor.__floordiv__>\n",
      "                    call        22     def wrapped(*args, **kwargs):\n",
      "                    line        23         from torch.overrides import has_torch_function, handle_torch_function\n",
      "    New var:....... has_torch_function = <function has_torch_function>\n",
      "    New var:....... handle_torch_function = <function handle_torch_function>\n",
      "                    line        24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "                        call        24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "                        line        24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "        New var:....... t = tensor<(1, 4), int64, cuda:0>\n",
      "                        return      24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "        Return value:.. True\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. t = tensor<(1, 4), int64, cuda:0>\n",
      "                        call        24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "                        line        24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "        Modified var:.. t = 96103\n",
      "                        return      24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "        Return value:.. False\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. t = 96103\n",
      "                        call        24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "                        exception   24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "        Exception:..... GeneratorExit\n",
      "                        return      24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "        Return value:.. None\n",
      "        Source path:... overrides.py\n",
      "        Starting var:.. relevant_args = (tensor<(1, 4), int64, cuda:0>, 96103)\n",
      "                        call      1070 def has_torch_function(relevant_args: Iterable[Any]) -> bool:\n",
      "                        line      1083     return _is_torch_function_enabled() and any(\n",
      "                        line      1087         for a in relevant_args\n",
      "                        line      1083     return _is_torch_function_enabled() and any(\n",
      "                        return    1083     return _is_torch_function_enabled() and any(\n",
      "        Return value:.. False\n",
      "    Source path:... tensor.py\n",
      "                    line        26         try:\n",
      "                    line        27             return f(*args, **kwargs)\n",
      "        Starting var:.. self = tensor<(1, 4), int64, cuda:0>\n",
      "        Starting var:.. other = 96103\n",
      "                        call       550     def __floordiv__(self, other):\n",
      "                        line       551         return torch.floor_divide(self, other)\n",
      "                        return     551         return torch.floor_divide(self, other)\n",
      "        Return value:.. tensor<(1, 4), int64, cuda:0>\n",
      "                    return      27             return f(*args, **kwargs)\n",
      "    Return value:.. tensor<(1, 4), int64, cuda:0>\n",
      "Source path:... generation_utils.py\n",
      "                line      1778             next_tokens = next_tokens % vocab_size\n",
      "                line      1781             beam_outputs = beam_scorer.process(\n",
      "                line      1782                 input_ids,\n",
      "                line      1783                 next_token_scores,\n",
      "                line      1784                 next_tokens,\n",
      "                line      1785                 next_indices,\n",
      "                line      1786                 pad_token_id=pad_token_id,\n",
      "                line      1787                 eos_token_id=eos_token_id,\n",
      "                line      1781             beam_outputs = beam_scorer.process(\n",
      "    Source path:... generation_beam_search.py\n",
      "    Starting var:.. self = <transformers.generation_beam_search.BeamSearchScorer object>\n",
      "    Starting var:.. input_ids = tensor<(2, 10), int64, cuda:0>\n",
      "    Starting var:.. next_scores = tensor<(1, 4), float32, cuda:0, grad>\n",
      "    Starting var:.. next_tokens = tensor<(1, 4), int64, cuda:0>\n",
      "    Starting var:.. next_indices = tensor<(1, 4), int64, cuda:0>\n",
      "    Starting var:.. pad_token_id = 0\n",
      "    Starting var:.. eos_token_id = 1\n",
      "                    call       199     def process(\n",
      "                    line       208         cur_len = input_ids.shape[-1]\n",
      "    New var:....... cur_len = 10\n",
      "                    line       209         batch_size = len(self._beam_hyps)\n",
      "    New var:....... batch_size = 1\n",
      "                    line       210         assert batch_size == (input_ids.shape[0] // self.group_size)\n",
      "                    line       212         device = input_ids.device\n",
      "    New var:....... device = device(type='cuda', index=0)\n",
      "                    line       213         next_beam_scores = torch.zeros((batch_size, self.group_size), dtype=next_scores.dtype, device=device)\n",
      "    New var:....... next_beam_scores = tensor<(1, 2), float32, cuda:0>\n",
      "                    line       214         next_beam_tokens = torch.zeros((batch_size, self.group_size), dtype=next_tokens.dtype, device=device)\n",
      "    New var:....... next_beam_tokens = tensor<(1, 2), int64, cuda:0>\n",
      "                    line       215         next_beam_indices = torch.zeros((batch_size, self.group_size), dtype=next_indices.dtype, device=device)\n",
      "    New var:....... next_beam_indices = tensor<(1, 2), int64, cuda:0>\n",
      "                    line       217         for batch_idx, beam_hyp in enumerate(self._beam_hyps):\n",
      "    New var:....... batch_idx = 0\n",
      "    New var:....... beam_hyp = <transformers.generation_beam_search.BeamHypotheses object>\n",
      "                    line       218             if self._done[batch_idx]:\n",
      "                    line       232             beam_idx = 0\n",
      "    New var:....... beam_idx = 0\n",
      "                    line       233             for beam_token_rank, (next_token, next_score, next_index) in enumerate(\n",
      "                    line       234                 zip(next_tokens[batch_idx], next_scores[batch_idx], next_indices[batch_idx])\n",
      "        Source path:... tensor.py\n",
      "        Starting var:.. self = tensor<(4,), int64, cuda:0>\n",
      "                        call       576     def __iter__(self):\n",
      "                        line       583         relevant_args = (self,)\n",
      "        New var:....... relevant_args = (tensor<(4,), int64, cuda:0>,)\n",
      "                        line       584         from torch.overrides import has_torch_function, handle_torch_function\n",
      "        New var:....... has_torch_function = <function has_torch_function>\n",
      "        New var:....... handle_torch_function = <function handle_torch_function>\n",
      "                        line       585         if type(self) is not Tensor and has_torch_function(relevant_args):\n",
      "                        line       587         if self.dim() == 0:\n",
      "                        line       589         if torch._C._get_tracing_state():\n",
      "                        line       594         return iter(self.unbind(0))\n",
      "                        return     594         return iter(self.unbind(0))\n",
      "        Return value:.. <tuple_iterator object>\n",
      "        Starting var:.. self = tensor<(4,), float32, cuda:0, grad>\n",
      "                        call       576     def __iter__(self):\n",
      "                        line       583         relevant_args = (self,)\n",
      "        New var:....... relevant_args = (tensor<(4,), float32, cuda:0, grad>,)\n",
      "                        line       584         from torch.overrides import has_torch_function, handle_torch_function\n",
      "        New var:....... has_torch_function = <function has_torch_function>\n",
      "        New var:....... handle_torch_function = <function handle_torch_function>\n",
      "                        line       585         if type(self) is not Tensor and has_torch_function(relevant_args):\n",
      "                        line       587         if self.dim() == 0:\n",
      "                        line       589         if torch._C._get_tracing_state():\n",
      "                        line       594         return iter(self.unbind(0))\n",
      "                        return     594         return iter(self.unbind(0))\n",
      "        Return value:.. <tuple_iterator object>\n",
      "        Starting var:.. self = tensor<(4,), int64, cuda:0>\n",
      "                        call       576     def __iter__(self):\n",
      "                        line       583         relevant_args = (self,)\n",
      "        New var:....... relevant_args = (tensor<(4,), int64, cuda:0>,)\n",
      "                        line       584         from torch.overrides import has_torch_function, handle_torch_function\n",
      "        New var:....... has_torch_function = <function has_torch_function>\n",
      "        New var:....... handle_torch_function = <function handle_torch_function>\n",
      "                        line       585         if type(self) is not Tensor and has_torch_function(relevant_args):\n",
      "                        line       587         if self.dim() == 0:\n",
      "                        line       589         if torch._C._get_tracing_state():\n",
      "                        line       594         return iter(self.unbind(0))\n",
      "                        return     594         return iter(self.unbind(0))\n",
      "        Return value:.. <tuple_iterator object>\n",
      "    Source path:... generation_beam_search.py\n",
      "                    line       233             for beam_token_rank, (next_token, next_score, next_index) in enumerate(\n",
      "    New var:....... beam_token_rank = 0\n",
      "    New var:....... next_token = tensor<(), int64, cuda:0>\n",
      "    New var:....... next_score = tensor<(), float32, cuda:0, grad>\n",
      "    New var:....... next_index = tensor<(), int64, cuda:0>\n",
      "                    line       236                 batch_beam_idx = batch_idx * self.group_size + next_index\n",
      "    New var:....... batch_beam_idx = tensor<(), int64, cuda:0>\n",
      "                    line       238                 if (eos_token_id is not None) and (next_token.item() == eos_token_id):\n",
      "                    line       249                     next_beam_scores[batch_idx, beam_idx] = next_score\n",
      "    Modified var:.. next_beam_scores = tensor<(1, 2), float32, cuda:0, grad>\n",
      "                    line       250                     next_beam_tokens[batch_idx, beam_idx] = next_token\n",
      "                    line       251                     next_beam_indices[batch_idx, beam_idx] = batch_beam_idx\n",
      "                    line       252                     beam_idx += 1\n",
      "    Modified var:.. beam_idx = 1\n",
      "                    line       255                 if beam_idx == self.group_size:\n",
      "                    line       233             for beam_token_rank, (next_token, next_score, next_index) in enumerate(\n",
      "    Modified var:.. beam_token_rank = 1\n",
      "                    line       236                 batch_beam_idx = batch_idx * self.group_size + next_index\n",
      "                    line       238                 if (eos_token_id is not None) and (next_token.item() == eos_token_id):\n",
      "                    line       249                     next_beam_scores[batch_idx, beam_idx] = next_score\n",
      "                    line       250                     next_beam_tokens[batch_idx, beam_idx] = next_token\n",
      "                    line       251                     next_beam_indices[batch_idx, beam_idx] = batch_beam_idx\n",
      "                    line       252                     beam_idx += 1\n",
      "    Modified var:.. beam_idx = 2\n",
      "                    line       255                 if beam_idx == self.group_size:\n",
      "                    line       256                     break\n",
      "                    line       258             if beam_idx < self.group_size:\n",
      "                    line       264             self._done[batch_idx] = self._done[batch_idx] or beam_hyp.is_done(\n",
      "                    line       265                 next_scores[batch_idx].max().item(), cur_len\n",
      "                    line       264             self._done[batch_idx] = self._done[batch_idx] or beam_hyp.is_done(\n",
      "        Starting var:.. self = <transformers.generation_beam_search.BeamHypotheses object>\n",
      "        Starting var:.. best_sum_logprobs = -8.913068771362305\n",
      "        Starting var:.. cur_len = 10\n",
      "                        call       371     def is_done(self, best_sum_logprobs: float, cur_len: int) -> bool:\n",
      "                        line       377         if len(self) < self.num_beams:\n",
      "                        line       378             return False\n",
      "                        return     378             return False\n",
      "        Return value:.. False\n",
      "                    line       217         for batch_idx, beam_hyp in enumerate(self._beam_hyps):\n",
      "                    line       268         return UserDict(\n",
      "                    line       270                 \"next_beam_scores\": next_beam_scores.view(-1),\n",
      "                    line       271                 \"next_beam_tokens\": next_beam_tokens.view(-1),\n",
      "                    line       272                 \"next_beam_indices\": next_beam_indices.view(-1),\n",
      "                    line       269             {\n",
      "                    line       268         return UserDict(\n",
      "        Source path:... __init__.py\n",
      "        Starting var:.. args = REPR FAILED\n",
      "        Starting var:.. kwargs = {}\n",
      "                        call       981     def __init__(*args, **kwargs):\n",
      "                        line       982         if not args:\n",
      "                        line       985         self, *args = args\n",
      "        Modified var:.. args = [{'next_beam_scores': tensor<(2,), float32, cuda:0, grad>, 'next_beam_tokens': tensor<(2,), int64, cuda:0>, 'next_beam_indices': tensor<(2,), int64, cuda:0>}]\n",
      "        New var:....... self = REPR FAILED\n",
      "                        line       986         if len(args) > 1:\n",
      "                        line       988         if args:\n",
      "                        line       989             dict = args[0]\n",
      "        New var:....... dict = {'next_beam_scores': tensor<(2,), float32, cuda:0, grad>, 'next_beam_tokens': tensor<(2,), int64, cuda:0>, 'next_beam_indices': tensor<(2,), int64, cuda:0>}\n",
      "                        line       997         self.data = {}\n",
      "        Modified var:.. self = {}\n",
      "                        line       998         if dict is not None:\n",
      "                        line       999             self.update(dict)\n",
      "        Modified var:.. self = {'next_beam_scores': tensor([ -8.9131, -10.3330], device='cuda:0', grad_fn=<ViewBackward>), 'next_...tokens': tensor([442, 112], device='cuda:0'), 'next_beam_indices': tensor([1, 0], device='cuda:0')}\n",
      "                        line      1000         if kwargs:\n",
      "                        return    1000         if kwargs:\n",
      "        Return value:.. None\n",
      "    Source path:... generation_beam_search.py\n",
      "                    return     268         return UserDict(\n",
      "    Return value:.. {'next_beam_scores': tensor([ -8.9131, -10.3330], device='cuda:0', grad_fn=<ViewBackward>), 'next_...tokens': tensor([442, 112], device='cuda:0'), 'next_beam_indices': tensor([1, 0], device='cuda:0')}\n",
      "Source path:... generation_utils.py\n",
      "Modified var:.. beam_outputs = {'next_beam_scores': tensor([ -8.9131, -10.3330], device='cuda:0', grad_fn=<ViewBackward>), 'next_...tokens': tensor([442, 112], device='cuda:0'), 'next_beam_indices': tensor([1, 0], device='cuda:0')}\n",
      "                line      1789             beam_scores = beam_outputs[\"next_beam_scores\"]\n",
      "    Source path:... __init__.py\n",
      "    Starting var:.. self = {'next_beam_scores': tensor([ -8.9131, -10.3330], device='cuda:0', grad_fn=<ViewBackward>), 'next_...tokens': tensor([442, 112], device='cuda:0'), 'next_beam_indices': tensor([1, 0], device='cuda:0')}\n",
      "    Starting var:.. key = 'next_beam_scores'\n",
      "                    call      1005     def __getitem__(self, key):\n",
      "                    line      1006         if key in self.data:\n",
      "                    line      1007             return self.data[key]\n",
      "                    return    1007             return self.data[key]\n",
      "    Return value:.. tensor<(2,), float32, cuda:0, grad>\n",
      "Source path:... generation_utils.py\n",
      "                line      1790             beam_next_tokens = beam_outputs[\"next_beam_tokens\"]\n",
      "    Source path:... __init__.py\n",
      "    Starting var:.. self = {'next_beam_scores': tensor([ -8.9131, -10.3330], device='cuda:0', grad_fn=<ViewBackward>), 'next_...tokens': tensor([442, 112], device='cuda:0'), 'next_beam_indices': tensor([1, 0], device='cuda:0')}\n",
      "    Starting var:.. key = 'next_beam_tokens'\n",
      "                    call      1005     def __getitem__(self, key):\n",
      "                    line      1006         if key in self.data:\n",
      "                    line      1007             return self.data[key]\n",
      "                    return    1007             return self.data[key]\n",
      "    Return value:.. tensor<(2,), int64, cuda:0>\n",
      "Source path:... generation_utils.py\n",
      "                line      1791             beam_idx = beam_outputs[\"next_beam_indices\"]\n",
      "    Source path:... __init__.py\n",
      "    Starting var:.. self = {'next_beam_scores': tensor([ -8.9131, -10.3330], device='cuda:0', grad_fn=<ViewBackward>), 'next_...tokens': tensor([442, 112], device='cuda:0'), 'next_beam_indices': tensor([1, 0], device='cuda:0')}\n",
      "    Starting var:.. key = 'next_beam_indices'\n",
      "                    call      1005     def __getitem__(self, key):\n",
      "                    line      1006         if key in self.data:\n",
      "                    line      1007             return self.data[key]\n",
      "                    return    1007             return self.data[key]\n",
      "    Return value:.. tensor<(2,), int64, cuda:0>\n",
      "Source path:... generation_utils.py\n",
      "                line      1793             input_ids = torch.cat([input_ids[beam_idx, :], beam_next_tokens.unsqueeze(-1)], dim=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Modified var:.. input_ids = tensor<(2, 11), int64, cuda:0>\n",
      "                line      1795             cur_len = cur_len + 1\n",
      "Modified var:.. cur_len = 11\n",
      "                line      1797             model_kwargs = self._update_model_kwargs_for_generation(\n",
      "                line      1798                 outputs, model_kwargs, is_encoder_decoder=self.config.is_encoder_decoder\n",
      "                line      1797             model_kwargs = self._update_model_kwargs_for_generation(\n",
      "    Starting var:.. outputs = {'logits': tensor<(2, 1, 96103), float32, cuda:0, grad>, 'past_key_values': ((tensor<(2, 16, 10, 6...float32, cuda:0, grad>)), 'encoder_last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0, grad>}\n",
      "    Starting var:.. model_kwargs = {'use_cache': None, 'attention_mask': tensor<(2, 6), int64, cuda:0>, 'encoder_outputs': {'last_hid...d>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>))}\n",
      "    Starting var:.. is_encoder_decoder = True\n",
      "                    call       511     def _update_model_kwargs_for_generation(\n",
      "                    line       515         if \"past_key_values\" in outputs:\n",
      "                    line       516             model_kwargs[\"past\"] = outputs.past_key_values\n",
      "                    line       525         if \"token_type_ids\" in model_kwargs:\n",
      "                    line       530         if not is_encoder_decoder:\n",
      "                    line       537         return model_kwargs\n",
      "                    return     537         return model_kwargs\n",
      "    Return value:.. {'use_cache': None, 'attention_mask': tensor<(2, 6), int64, cuda:0>, 'encoder_outputs': {'last_hid...d>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>))}\n",
      "                line      1800             if model_kwargs[\"past\"] is not None:\n",
      "                line      1801                 model_kwargs[\"past\"] = self._reorder_cache(model_kwargs[\"past\"], beam_idx)\n",
      "    Source path:... modeling_pegasus.py\n",
      "    Starting var:.. past = ((tensor<(2, 16, 10, 64), float32, cuda:0, grad>, tensor<(2, 16, 10, 64), float32, cuda:0, grad>, ...ad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>))\n",
      "    Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                    call      1333     def _reorder_cache(past, beam_idx):\n",
      "                    line      1334         reordered_past = ()\n",
      "    New var:....... reordered_past = ()\n",
      "                    line      1335         for layer_past in past:\n",
      "    New var:....... layer_past = (tensor<(2, 16, 10, 64), float32, cuda:0, grad>, tensor<(2, 16, 10, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>)\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 10, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 10, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 10, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 10, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 10, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "    Modified var:.. reordered_past = ((tensor<(2, 16, 10, 64), float32, cuda:0, grad>, tensor<(2, 16, 10, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>),)\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 10, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 10, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 10, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 10, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 10, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "    Modified var:.. reordered_past = ((tensor<(2, 16, 10, 64), float32, cuda:0, grad>, tensor<(2, 16, 10, 64), float32, cuda:0, grad>, ...ad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>))\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 10, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 10, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 10, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 10, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 10, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 10, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 10, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 10, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 10, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 10, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 10, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 10, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 10, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 10, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 10, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 10, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 10, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 10, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 10, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 10, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 10, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 10, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 10, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 10, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 10, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 10, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 10, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 10, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 10, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 10, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 10, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 10, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 10, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 10, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 10, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 10, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 10, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 10, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 10, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 10, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 10, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 10, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 10, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 10, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 10, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 10, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 10, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 10, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 10, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 10, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 10, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        Return value:.. tensor<(2, 16, 10, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 10, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 10, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 10, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 10, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 10, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 10, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 10, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 10, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 10, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 10, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 10, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 10, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 10, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 10, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 10, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 10, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 10, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 10, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1340         return reordered_past\n",
      "                    return    1340         return reordered_past\n",
      "    Return value:.. ((tensor<(2, 16, 10, 64), float32, cuda:0, grad>, tensor<(2, 16, 10, 64), float32, cuda:0, grad>, ...ad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>))\n",
      "Source path:... generation_utils.py\n",
      "                line      1803             if beam_scorer.is_done:\n",
      "    Source path:... generation_beam_search.py\n",
      "    Starting var:.. self = <transformers.generation_beam_search.BeamSearchScorer object>\n",
      "                    call       196     def is_done(self) -> bool:\n",
      "                    line       197         return self._done.all()\n",
      "                    return     197         return self._done.all()\n",
      "    Return value:.. tensor<(), bool, cuda:0>\n",
      "Source path:... generation_utils.py\n",
      "                line      1806             if stopping_criteria(input_ids, scores):\n",
      "    Source path:... generation_stopping_criteria.py\n",
      "    Starting var:.. self = [<transformers.generation_stopping_criteria.MaxLengthCriteria object>]\n",
      "    Starting var:.. input_ids = tensor<(2, 11), int64, cuda:0>\n",
      "    Starting var:.. scores = (tensor<(2, 96103), float32, cuda:0, grad>, tensor<(2, 96103), float32, cuda:0, grad>, tensor<(2, ...uda:0, grad>, tensor<(2, 96103), float32, cuda:0, grad>, tensor<(2, 96103), float32, cuda:0, grad>)\n",
      "    Starting var:.. kwargs = {}\n",
      "                    call        83     def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor, **kwargs) -> bool:\n",
      "                    line        84         return any(criteria(input_ids, scores) for criteria in self)\n",
      "        Starting var:.. .0 = <list_iterator object>\n",
      "        Starting var:.. input_ids = tensor<(2, 11), int64, cuda:0>\n",
      "        Starting var:.. scores = (tensor<(2, 96103), float32, cuda:0, grad>, tensor<(2, 96103), float32, cuda:0, grad>, tensor<(2, ...uda:0, grad>, tensor<(2, 96103), float32, cuda:0, grad>, tensor<(2, 96103), float32, cuda:0, grad>)\n",
      "                        call        84         return any(criteria(input_ids, scores) for criteria in self)\n",
      "                        line        84         return any(criteria(input_ids, scores) for criteria in self)\n",
      "        New var:....... criteria = <transformers.generation_stopping_criteria.MaxLengthCriteria object>\n",
      "                        return      84         return any(criteria(input_ids, scores) for criteria in self)\n",
      "        Return value:.. False\n",
      "        Starting var:.. .0 = <list_iterator object>\n",
      "        Starting var:.. criteria = <transformers.generation_stopping_criteria.MaxLengthCriteria object>\n",
      "        Starting var:.. input_ids = tensor<(2, 11), int64, cuda:0>\n",
      "        Starting var:.. scores = (tensor<(2, 96103), float32, cuda:0, grad>, tensor<(2, 96103), float32, cuda:0, grad>, tensor<(2, ...uda:0, grad>, tensor<(2, 96103), float32, cuda:0, grad>, tensor<(2, 96103), float32, cuda:0, grad>)\n",
      "                        call        84         return any(criteria(input_ids, scores) for criteria in self)\n",
      "                        line        84         return any(criteria(input_ids, scores) for criteria in self)\n",
      "                        return      84         return any(criteria(input_ids, scores) for criteria in self)\n",
      "        Return value:.. None\n",
      "                    return      84         return any(criteria(input_ids, scores) for criteria in self)\n",
      "    Return value:.. False\n",
      "Source path:... generation_utils.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                line      1729         while cur_len < max_length:\n",
      "                line      1730             model_inputs = self.prepare_inputs_for_generation(input_ids, **model_kwargs)\n",
      "    Source path:... modeling_pegasus.py\n",
      "    Starting var:.. self = PegasusForConditionalGeneration(  (model): PegasusModel(    (shared): Embedding(96103, 1024, paddi...mentwise_affine=True)    )  )  (lm_head): Linear(in_features=1024, out_features=96103, bias=False))\n",
      "    Starting var:.. decoder_input_ids = tensor<(2, 11), int64, cuda:0>\n",
      "    Starting var:.. past = ((tensor<(2, 16, 10, 64), float32, cuda:0, grad>, tensor<(2, 16, 10, 64), float32, cuda:0, grad>, ...ad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>))\n",
      "    Starting var:.. attention_mask = tensor<(2, 6), int64, cuda:0>\n",
      "    Starting var:.. head_mask = None\n",
      "    Starting var:.. use_cache = None\n",
      "    Starting var:.. encoder_outputs = {'last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0, grad>}\n",
      "    Starting var:.. kwargs = {}\n",
      "                    call      1305     def prepare_inputs_for_generation(\n",
      "                    line      1316         if past is not None:\n",
      "                    line      1317             decoder_input_ids = decoder_input_ids[:, -1:]\n",
      "    Modified var:.. decoder_input_ids = tensor<(2, 1), int64, cuda:0>\n",
      "                    line      1320             \"input_ids\": None,  # encoder_outputs is defined. input_ids not needed\n",
      "                    line      1321             \"encoder_outputs\": encoder_outputs,\n",
      "                    line      1322             \"past_key_values\": past,\n",
      "                    line      1323             \"decoder_input_ids\": decoder_input_ids,\n",
      "                    line      1324             \"attention_mask\": attention_mask,\n",
      "                    line      1325             \"head_mask\": head_mask,\n",
      "                    line      1326             \"use_cache\": use_cache,  # change this to avoid caching (presumably for debugging)\n",
      "                    line      1319         return {\n",
      "                    return    1319         return {\n",
      "    Return value:.. {'input_ids': None, 'encoder_outputs': {'last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0,...64, cuda:0>, 'attention_mask': tensor<(2, 6), int64, cuda:0>, 'head_mask': None, 'use_cache': None}\n",
      "Source path:... generation_utils.py\n",
      "                line      1732             outputs = self(\n",
      "                line      1733                 **model_inputs,\n",
      "                line      1734                 return_dict=True,\n",
      "                line      1735                 output_attentions=output_attentions,\n",
      "                line      1736                 output_hidden_states=output_hidden_states,\n",
      "                line      1732             outputs = self(\n",
      "    Source path:... module.py\n",
      "    Starting var:.. self = PegasusForConditionalGeneration(  (model): PegasusModel(    (shared): Embedding(96103, 1024, paddi...mentwise_affine=True)    )  )  (lm_head): Linear(in_features=1024, out_features=96103, bias=False))\n",
      "    Starting var:.. input = ()\n",
      "    Starting var:.. kwargs = {'input_ids': None, 'encoder_outputs': {'last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0,... 'use_cache': None, 'return_dict': True, 'output_attentions': False, 'output_hidden_states': False}\n",
      "                    call       715     def _call_impl(self, *input, **kwargs):\n",
      "                    line       716         for hook in itertools.chain(\n",
      "                    line       717                 _global_forward_pre_hooks.values(),\n",
      "                    line       718                 self._forward_pre_hooks.values()):\n",
      "                    line       716         for hook in itertools.chain(\n",
      "                    line       724         if torch._C._get_tracing_state():\n",
      "                    line       727             result = self.forward(*input, **kwargs)\n",
      "        Source path:... modeling_pegasus.py\n",
      "        Starting var:.. self = PegasusForConditionalGeneration(  (model): PegasusModel(    (shared): Embedding(96103, 1024, paddi...mentwise_affine=True)    )  )  (lm_head): Linear(in_features=1024, out_features=96103, bias=False))\n",
      "        Starting var:.. input_ids = None\n",
      "        Starting var:.. attention_mask = tensor<(2, 6), int64, cuda:0>\n",
      "        Starting var:.. decoder_input_ids = tensor<(2, 1), int64, cuda:0>\n",
      "        Starting var:.. decoder_attention_mask = None\n",
      "        Starting var:.. head_mask = None\n",
      "        Starting var:.. decoder_head_mask = None\n",
      "        Starting var:.. encoder_outputs = {'last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0, grad>}\n",
      "        Starting var:.. past_key_values = ((tensor<(2, 16, 10, 64), float32, cuda:0, grad>, tensor<(2, 16, 10, 64), float32, cuda:0, grad>, ...ad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>))\n",
      "        Starting var:.. inputs_embeds = None\n",
      "        Starting var:.. decoder_inputs_embeds = None\n",
      "        Starting var:.. labels = None\n",
      "        Starting var:.. use_cache = None\n",
      "        Starting var:.. output_attentions = False\n",
      "        Starting var:.. output_hidden_states = False\n",
      "        Starting var:.. return_dict = True\n",
      "                        call      1231     def forward(\n",
      "                        line      1258         return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
      "                        line      1260         if labels is not None:\n",
      "                        line      1266         outputs = self.model(\n",
      "                        line      1267             input_ids,\n",
      "                        line      1268             attention_mask=attention_mask,\n",
      "                        line      1269             decoder_input_ids=decoder_input_ids,\n",
      "                        line      1270             encoder_outputs=encoder_outputs,\n",
      "                        line      1271             decoder_attention_mask=decoder_attention_mask,\n",
      "                        line      1272             head_mask=head_mask,\n",
      "                        line      1273             decoder_head_mask=decoder_head_mask,\n",
      "                        line      1274             past_key_values=past_key_values,\n",
      "                        line      1275             inputs_embeds=inputs_embeds,\n",
      "                        line      1276             decoder_inputs_embeds=decoder_inputs_embeds,\n",
      "                        line      1277             use_cache=use_cache,\n",
      "                        line      1278             output_attentions=output_attentions,\n",
      "                        line      1279             output_hidden_states=output_hidden_states,\n",
      "                        line      1280             return_dict=return_dict,\n",
      "                        line      1266         outputs = self.model(\n",
      "        New var:....... outputs = {'last_hidden_state': tensor<(2, 1, 1024), float32, cuda:0, grad>, 'past_key_values': ((tensor<(2,...float32, cuda:0, grad>)), 'encoder_last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0, grad>}\n",
      "                        line      1282         lm_logits = self.lm_head(outputs[0]) + self.final_logits_bias\n",
      "        New var:....... lm_logits = tensor<(2, 1, 96103), float32, cuda:0, grad>\n",
      "                        line      1284         masked_lm_loss = None\n",
      "        New var:....... masked_lm_loss = None\n",
      "                        line      1285         if labels is not None:\n",
      "                        line      1289         if not return_dict:\n",
      "                        line      1293         return Seq2SeqLMOutput(\n",
      "                        line      1294             loss=masked_lm_loss,\n",
      "                        line      1295             logits=lm_logits,\n",
      "                        line      1296             past_key_values=outputs.past_key_values,\n",
      "                        line      1297             decoder_hidden_states=outputs.decoder_hidden_states,\n",
      "                        line      1298             decoder_attentions=outputs.decoder_attentions,\n",
      "                        line      1299             cross_attentions=outputs.cross_attentions,\n",
      "                        line      1300             encoder_last_hidden_state=outputs.encoder_last_hidden_state,\n",
      "                        line      1301             encoder_hidden_states=outputs.encoder_hidden_states,\n",
      "                        line      1302             encoder_attentions=outputs.encoder_attentions,\n",
      "                        line      1293         return Seq2SeqLMOutput(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                        return    1293         return Seq2SeqLMOutput(\n",
      "        Return value:.. {'logits': tensor<(2, 1, 96103), float32, cuda:0, grad>, 'past_key_values': ((tensor<(2, 16, 11, 6...float32, cuda:0, grad>)), 'encoder_last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0, grad>}\n",
      "    Source path:... module.py\n",
      "    New var:....... result = {'logits': tensor<(2, 1, 96103), float32, cuda:0, grad>, 'past_key_values': ((tensor<(2, 16, 11, 6...float32, cuda:0, grad>)), 'encoder_last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0, grad>}\n",
      "                    line       728         for hook in itertools.chain(\n",
      "                    line       729                 _global_forward_hooks.values(),\n",
      "                    line       730                 self._forward_hooks.values()):\n",
      "                    line       728         for hook in itertools.chain(\n",
      "                    line       734         if (len(self._backward_hooks) > 0) or (len(_global_backward_hooks) > 0):\n",
      "                    line       749         return result\n",
      "                    return     749         return result\n",
      "    Return value:.. {'logits': tensor<(2, 1, 96103), float32, cuda:0, grad>, 'past_key_values': ((tensor<(2, 16, 11, 6...float32, cuda:0, grad>)), 'encoder_last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0, grad>}\n",
      "Source path:... generation_utils.py\n",
      "Modified var:.. outputs = {'logits': tensor<(2, 1, 96103), float32, cuda:0, grad>, 'past_key_values': ((tensor<(2, 16, 11, 6...float32, cuda:0, grad>)), 'encoder_last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0, grad>}\n",
      "                line      1738             next_token_logits = outputs.logits[:, -1, :]\n",
      "                line      1742             next_token_logits = self.adjust_logits_during_generation(\n",
      "                line      1743                 next_token_logits, cur_len=cur_len, max_length=max_length\n",
      "                line      1742             next_token_logits = self.adjust_logits_during_generation(\n",
      "    Starting var:.. self = PegasusForConditionalGeneration(  (model): PegasusModel(    (shared): Embedding(96103, 1024, paddi...mentwise_affine=True)    )  )  (lm_head): Linear(in_features=1024, out_features=96103, bias=False))\n",
      "    Starting var:.. logits = tensor<(2, 96103), float32, cuda:0, grad>\n",
      "    Starting var:.. kwargs = {'cur_len': 11, 'max_length': 60}\n",
      "                    call       373     def adjust_logits_during_generation(self, logits: torch.FloatTensor, **kwargs) -> torch.FloatTensor:\n",
      "                    line       378         return logits\n",
      "                    return     378         return logits\n",
      "    Return value:.. tensor<(2, 96103), float32, cuda:0, grad>\n",
      "                line      1746             next_token_scores = F.log_softmax(next_token_logits, dim=-1)  # (batch_size * num_beams, vocab_size)\n",
      "    Source path:... functional.py\n",
      "    Starting var:.. input = tensor<(2, 96103), float32, cuda:0, grad>\n",
      "    Starting var:.. dim = -1\n",
      "    Starting var:.. _stacklevel = 3\n",
      "    Starting var:.. dtype = None\n",
      "                    call      1581 def log_softmax(input, dim=None, _stacklevel=3, dtype=None):\n",
      "                    line      1598     if not torch.jit.is_scripting():\n",
      "        Source path:... _jit_internal.py\n",
      "                        call       750 def is_scripting():\n",
      "                        line       769     return False\n",
      "                        return     769     return False\n",
      "        Return value:.. False\n",
      "    Source path:... functional.py\n",
      "                    line      1599         if type(input) is not Tensor and has_torch_function((input,)):\n",
      "                    line      1602     if dim is None:\n",
      "                    line      1604     if dtype is None:\n",
      "                    line      1605         ret = input.log_softmax(dim)\n",
      "    New var:....... ret = tensor<(2, 96103), float32, cuda:0, grad>\n",
      "                    line      1608     return ret\n",
      "                    return    1608     return ret\n",
      "    Return value:.. tensor<(2, 96103), float32, cuda:0, grad>\n",
      "Source path:... generation_utils.py\n",
      "Modified var:.. next_token_scores = tensor<(2, 96103), float32, cuda:0, grad>\n",
      "                line      1748             next_token_scores = logits_processor(input_ids, next_token_scores)\n",
      "    Source path:... generation_logits_process.py\n",
      "    Starting var:.. self = [<transformers.generation_logits_process.MinLengthLogitsProcessor object>, <transformers.generation_logits_process.ForcedEOSTokenLogitsProcessor object>]\n",
      "    Starting var:.. input_ids = tensor<(2, 11), int64, cuda:0>\n",
      "    Starting var:.. scores = tensor<(2, 96103), float32, cuda:0, grad>\n",
      "    Starting var:.. kwargs = {}\n",
      "                    call        84     def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor, **kwargs) -> torch.FloatTensor:\n",
      "                    line        85         for processor in self:\n",
      "    New var:....... processor = <transformers.generation_logits_process.MinLengthLogitsProcessor object>\n",
      "                    line        86             function_args = inspect.signature(processor.__call__).parameters\n",
      "        Source path:... inspect.py\n",
      "        Starting var:.. obj = <bound method MinLengthLogitsProcessor.__call__ of <transformers.generation_logits_process.MinLengthLogitsProcessor object>>\n",
      "        Starting var:.. follow_wrapped = True\n",
      "                        call      3091 def signature(obj, *, follow_wrapped=True):\n",
      "                        line      3093     return Signature.from_callable(obj, follow_wrapped=follow_wrapped)\n",
      "                        return    3093     return Signature.from_callable(obj, follow_wrapped=follow_wrapped)\n",
      "        Return value:.. <Signature (input_ids: torch.LongTensor, scores: torch.FloatTensor) -> torch.FloatTensor>\n",
      "        Starting var:.. self = <Signature (input_ids: torch.LongTensor, scores: torch.FloatTensor) -> torch.FloatTensor>\n",
      "                        call      2846     def parameters(self):\n",
      "                        line      2847         return self._parameters\n",
      "                        return    2847         return self._parameters\n",
      "        Return value:.. mappingproxy(OrderedDict([('input_ids', <Parameter \"input_ids: torch.LongTensor\">), ('scores', <Parameter \"scores: torch.FloatTensor\">)]))\n",
      "    Source path:... generation_logits_process.py\n",
      "    New var:....... function_args = mappingproxy(OrderedDict([('input_ids', <Parameter \"input_ids: torch.LongTensor\">), ('scores', <Parameter \"scores: torch.FloatTensor\">)]))\n",
      "                    line        87             if len(function_args) > 2:\n",
      "                    line        93                 scores = processor(input_ids, scores)\n",
      "        Starting var:.. self = <transformers.generation_logits_process.MinLengthLogitsProcessor object>\n",
      "        Starting var:.. input_ids = tensor<(2, 11), int64, cuda:0>\n",
      "        Starting var:.. scores = tensor<(2, 96103), float32, cuda:0, grad>\n",
      "                        call       118     def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor) -> torch.FloatTensor:\n",
      "                        line       119         cur_len = input_ids.shape[-1]\n",
      "        New var:....... cur_len = 11\n",
      "                        line       120         if cur_len < self.min_length:\n",
      "                        line       122         return scores\n",
      "                        return     122         return scores\n",
      "        Return value:.. tensor<(2, 96103), float32, cuda:0, grad>\n",
      "                    line        85         for processor in self:\n",
      "    Modified var:.. processor = <transformers.generation_logits_process.ForcedEOSTokenLogitsProcessor object>\n",
      "                    line        86             function_args = inspect.signature(processor.__call__).parameters\n",
      "        Source path:... inspect.py\n",
      "        Starting var:.. obj = <bound method ForcedEOSTokenLogitsProcessor.__call__ of <transformers.generation_logits_process.ForcedEOSTokenLogitsProcessor object>>\n",
      "        Starting var:.. follow_wrapped = True\n",
      "                        call      3091 def signature(obj, *, follow_wrapped=True):\n",
      "                        line      3093     return Signature.from_callable(obj, follow_wrapped=follow_wrapped)\n",
      "                        return    3093     return Signature.from_callable(obj, follow_wrapped=follow_wrapped)\n",
      "        Return value:.. <Signature (input_ids: torch.LongTensor, scores: torch.FloatTensor) -> torch.FloatTensor>\n",
      "        Starting var:.. self = <Signature (input_ids: torch.LongTensor, scores: torch.FloatTensor) -> torch.FloatTensor>\n",
      "                        call      2846     def parameters(self):\n",
      "                        line      2847         return self._parameters\n",
      "                        return    2847         return self._parameters\n",
      "        Return value:.. mappingproxy(OrderedDict([('input_ids', <Parameter \"input_ids: torch.LongTensor\">), ('scores', <Parameter \"scores: torch.FloatTensor\">)]))\n",
      "    Source path:... generation_logits_process.py\n",
      "                    line        87             if len(function_args) > 2:\n",
      "                    line        93                 scores = processor(input_ids, scores)\n",
      "        Starting var:.. self = <transformers.generation_logits_process.ForcedEOSTokenLogitsProcessor object>\n",
      "        Starting var:.. input_ids = tensor<(2, 11), int64, cuda:0>\n",
      "        Starting var:.. scores = tensor<(2, 96103), float32, cuda:0, grad>\n",
      "                        call       571     def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor) -> torch.FloatTensor:\n",
      "                        line       572         cur_len = input_ids.shape[-1]\n",
      "        New var:....... cur_len = 11\n",
      "                        line       573         if cur_len == self.max_length - 1:\n",
      "                        line       577         return scores\n",
      "                        return     577         return scores\n",
      "        Return value:.. tensor<(2, 96103), float32, cuda:0, grad>\n",
      "                    line        85         for processor in self:\n",
      "                    line        94         return scores\n",
      "                    return      94         return scores\n",
      "    Return value:.. tensor<(2, 96103), float32, cuda:0, grad>\n",
      "Source path:... generation_utils.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                line      1749             next_token_scores = next_token_scores + beam_scores[:, None].expand_as(next_token_scores)\n",
      "                line      1752             if return_dict_in_generate:\n",
      "                line      1753                 if output_scores:\n",
      "                line      1754                     scores += (next_token_scores,)\n",
      "                line      1755                 if output_attentions:\n",
      "                line      1762                 if output_hidden_states:\n",
      "                line      1770             vocab_size = next_token_scores.shape[-1]\n",
      "                line      1771             next_token_scores = next_token_scores.view(batch_size, num_beams * vocab_size)\n",
      "Modified var:.. next_token_scores = tensor<(1, 192206), float32, cuda:0, grad>\n",
      "                line      1773             next_token_scores, next_tokens = torch.topk(\n",
      "                line      1774                 next_token_scores, 2 * num_beams, dim=1, largest=True, sorted=True\n",
      "                line      1773             next_token_scores, next_tokens = torch.topk(\n",
      "Modified var:.. next_token_scores = tensor<(1, 4), float32, cuda:0, grad>\n",
      "                line      1777             next_indices = next_tokens // vocab_size\n",
      "    Source path:... tensor.py\n",
      "    Starting var:.. args = (tensor<(1, 4), int64, cuda:0>, 96103)\n",
      "    Starting var:.. kwargs = {}\n",
      "    Starting var:.. f = <function Tensor.__floordiv__>\n",
      "    Starting var:.. wrapped = <function Tensor.__floordiv__>\n",
      "                    call        22     def wrapped(*args, **kwargs):\n",
      "                    line        23         from torch.overrides import has_torch_function, handle_torch_function\n",
      "    New var:....... has_torch_function = <function has_torch_function>\n",
      "    New var:....... handle_torch_function = <function handle_torch_function>\n",
      "                    line        24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "                        call        24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "                        line        24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "        New var:....... t = tensor<(1, 4), int64, cuda:0>\n",
      "                        return      24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "        Return value:.. True\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. t = tensor<(1, 4), int64, cuda:0>\n",
      "                        call        24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "                        line        24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "        Modified var:.. t = 96103\n",
      "                        return      24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "        Return value:.. False\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. t = 96103\n",
      "                        call        24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "                        exception   24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "        Exception:..... GeneratorExit\n",
      "                        return      24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "        Return value:.. None\n",
      "        Source path:... overrides.py\n",
      "        Starting var:.. relevant_args = (tensor<(1, 4), int64, cuda:0>, 96103)\n",
      "                        call      1070 def has_torch_function(relevant_args: Iterable[Any]) -> bool:\n",
      "                        line      1083     return _is_torch_function_enabled() and any(\n",
      "                        line      1087         for a in relevant_args\n",
      "                        line      1083     return _is_torch_function_enabled() and any(\n",
      "                        return    1083     return _is_torch_function_enabled() and any(\n",
      "        Return value:.. False\n",
      "    Source path:... tensor.py\n",
      "                    line        26         try:\n",
      "                    line        27             return f(*args, **kwargs)\n",
      "        Starting var:.. self = tensor<(1, 4), int64, cuda:0>\n",
      "        Starting var:.. other = 96103\n",
      "                        call       550     def __floordiv__(self, other):\n",
      "                        line       551         return torch.floor_divide(self, other)\n",
      "                        return     551         return torch.floor_divide(self, other)\n",
      "        Return value:.. tensor<(1, 4), int64, cuda:0>\n",
      "                    return      27             return f(*args, **kwargs)\n",
      "    Return value:.. tensor<(1, 4), int64, cuda:0>\n",
      "Source path:... generation_utils.py\n",
      "                line      1778             next_tokens = next_tokens % vocab_size\n",
      "                line      1781             beam_outputs = beam_scorer.process(\n",
      "                line      1782                 input_ids,\n",
      "                line      1783                 next_token_scores,\n",
      "                line      1784                 next_tokens,\n",
      "                line      1785                 next_indices,\n",
      "                line      1786                 pad_token_id=pad_token_id,\n",
      "                line      1787                 eos_token_id=eos_token_id,\n",
      "                line      1781             beam_outputs = beam_scorer.process(\n",
      "    Source path:... generation_beam_search.py\n",
      "    Starting var:.. self = <transformers.generation_beam_search.BeamSearchScorer object>\n",
      "    Starting var:.. input_ids = tensor<(2, 11), int64, cuda:0>\n",
      "    Starting var:.. next_scores = tensor<(1, 4), float32, cuda:0, grad>\n",
      "    Starting var:.. next_tokens = tensor<(1, 4), int64, cuda:0>\n",
      "    Starting var:.. next_indices = tensor<(1, 4), int64, cuda:0>\n",
      "    Starting var:.. pad_token_id = 0\n",
      "    Starting var:.. eos_token_id = 1\n",
      "                    call       199     def process(\n",
      "                    line       208         cur_len = input_ids.shape[-1]\n",
      "    New var:....... cur_len = 11\n",
      "                    line       209         batch_size = len(self._beam_hyps)\n",
      "    New var:....... batch_size = 1\n",
      "                    line       210         assert batch_size == (input_ids.shape[0] // self.group_size)\n",
      "                    line       212         device = input_ids.device\n",
      "    New var:....... device = device(type='cuda', index=0)\n",
      "                    line       213         next_beam_scores = torch.zeros((batch_size, self.group_size), dtype=next_scores.dtype, device=device)\n",
      "    New var:....... next_beam_scores = tensor<(1, 2), float32, cuda:0>\n",
      "                    line       214         next_beam_tokens = torch.zeros((batch_size, self.group_size), dtype=next_tokens.dtype, device=device)\n",
      "    New var:....... next_beam_tokens = tensor<(1, 2), int64, cuda:0>\n",
      "                    line       215         next_beam_indices = torch.zeros((batch_size, self.group_size), dtype=next_indices.dtype, device=device)\n",
      "    New var:....... next_beam_indices = tensor<(1, 2), int64, cuda:0>\n",
      "                    line       217         for batch_idx, beam_hyp in enumerate(self._beam_hyps):\n",
      "    New var:....... batch_idx = 0\n",
      "    New var:....... beam_hyp = <transformers.generation_beam_search.BeamHypotheses object>\n",
      "                    line       218             if self._done[batch_idx]:\n",
      "                    line       232             beam_idx = 0\n",
      "    New var:....... beam_idx = 0\n",
      "                    line       233             for beam_token_rank, (next_token, next_score, next_index) in enumerate(\n",
      "                    line       234                 zip(next_tokens[batch_idx], next_scores[batch_idx], next_indices[batch_idx])\n",
      "        Source path:... tensor.py\n",
      "        Starting var:.. self = tensor<(4,), int64, cuda:0>\n",
      "                        call       576     def __iter__(self):\n",
      "                        line       583         relevant_args = (self,)\n",
      "        New var:....... relevant_args = (tensor<(4,), int64, cuda:0>,)\n",
      "                        line       584         from torch.overrides import has_torch_function, handle_torch_function\n",
      "        New var:....... has_torch_function = <function has_torch_function>\n",
      "        New var:....... handle_torch_function = <function handle_torch_function>\n",
      "                        line       585         if type(self) is not Tensor and has_torch_function(relevant_args):\n",
      "                        line       587         if self.dim() == 0:\n",
      "                        line       589         if torch._C._get_tracing_state():\n",
      "                        line       594         return iter(self.unbind(0))\n",
      "                        return     594         return iter(self.unbind(0))\n",
      "        Return value:.. <tuple_iterator object>\n",
      "        Starting var:.. self = tensor<(4,), float32, cuda:0, grad>\n",
      "                        call       576     def __iter__(self):\n",
      "                        line       583         relevant_args = (self,)\n",
      "        New var:....... relevant_args = (tensor<(4,), float32, cuda:0, grad>,)\n",
      "                        line       584         from torch.overrides import has_torch_function, handle_torch_function\n",
      "        New var:....... has_torch_function = <function has_torch_function>\n",
      "        New var:....... handle_torch_function = <function handle_torch_function>\n",
      "                        line       585         if type(self) is not Tensor and has_torch_function(relevant_args):\n",
      "                        line       587         if self.dim() == 0:\n",
      "                        line       589         if torch._C._get_tracing_state():\n",
      "                        line       594         return iter(self.unbind(0))\n",
      "                        return     594         return iter(self.unbind(0))\n",
      "        Return value:.. <tuple_iterator object>\n",
      "        Starting var:.. self = tensor<(4,), int64, cuda:0>\n",
      "                        call       576     def __iter__(self):\n",
      "                        line       583         relevant_args = (self,)\n",
      "        New var:....... relevant_args = (tensor<(4,), int64, cuda:0>,)\n",
      "                        line       584         from torch.overrides import has_torch_function, handle_torch_function\n",
      "        New var:....... has_torch_function = <function has_torch_function>\n",
      "        New var:....... handle_torch_function = <function handle_torch_function>\n",
      "                        line       585         if type(self) is not Tensor and has_torch_function(relevant_args):\n",
      "                        line       587         if self.dim() == 0:\n",
      "                        line       589         if torch._C._get_tracing_state():\n",
      "                        line       594         return iter(self.unbind(0))\n",
      "                        return     594         return iter(self.unbind(0))\n",
      "        Return value:.. <tuple_iterator object>\n",
      "    Source path:... generation_beam_search.py\n",
      "                    line       233             for beam_token_rank, (next_token, next_score, next_index) in enumerate(\n",
      "    New var:....... beam_token_rank = 0\n",
      "    New var:....... next_token = tensor<(), int64, cuda:0>\n",
      "    New var:....... next_score = tensor<(), float32, cuda:0, grad>\n",
      "    New var:....... next_index = tensor<(), int64, cuda:0>\n",
      "                    line       236                 batch_beam_idx = batch_idx * self.group_size + next_index\n",
      "    New var:....... batch_beam_idx = tensor<(), int64, cuda:0>\n",
      "                    line       238                 if (eos_token_id is not None) and (next_token.item() == eos_token_id):\n",
      "                    line       249                     next_beam_scores[batch_idx, beam_idx] = next_score\n",
      "    Modified var:.. next_beam_scores = tensor<(1, 2), float32, cuda:0, grad>\n",
      "                    line       250                     next_beam_tokens[batch_idx, beam_idx] = next_token\n",
      "                    line       251                     next_beam_indices[batch_idx, beam_idx] = batch_beam_idx\n",
      "                    line       252                     beam_idx += 1\n",
      "    Modified var:.. beam_idx = 1\n",
      "                    line       255                 if beam_idx == self.group_size:\n",
      "                    line       233             for beam_token_rank, (next_token, next_score, next_index) in enumerate(\n",
      "    Modified var:.. beam_token_rank = 1\n",
      "                    line       236                 batch_beam_idx = batch_idx * self.group_size + next_index\n",
      "                    line       238                 if (eos_token_id is not None) and (next_token.item() == eos_token_id):\n",
      "                    line       249                     next_beam_scores[batch_idx, beam_idx] = next_score\n",
      "                    line       250                     next_beam_tokens[batch_idx, beam_idx] = next_token\n",
      "                    line       251                     next_beam_indices[batch_idx, beam_idx] = batch_beam_idx\n",
      "                    line       252                     beam_idx += 1\n",
      "    Modified var:.. beam_idx = 2\n",
      "                    line       255                 if beam_idx == self.group_size:\n",
      "                    line       256                     break\n",
      "                    line       258             if beam_idx < self.group_size:\n",
      "                    line       264             self._done[batch_idx] = self._done[batch_idx] or beam_hyp.is_done(\n",
      "                    line       265                 next_scores[batch_idx].max().item(), cur_len\n",
      "                    line       264             self._done[batch_idx] = self._done[batch_idx] or beam_hyp.is_done(\n",
      "        Starting var:.. self = <transformers.generation_beam_search.BeamHypotheses object>\n",
      "        Starting var:.. best_sum_logprobs = -10.08659553527832\n",
      "        Starting var:.. cur_len = 11\n",
      "                        call       371     def is_done(self, best_sum_logprobs: float, cur_len: int) -> bool:\n",
      "                        line       377         if len(self) < self.num_beams:\n",
      "                        line       378             return False\n",
      "                        return     378             return False\n",
      "        Return value:.. False\n",
      "                    line       217         for batch_idx, beam_hyp in enumerate(self._beam_hyps):\n",
      "                    line       268         return UserDict(\n",
      "                    line       270                 \"next_beam_scores\": next_beam_scores.view(-1),\n",
      "                    line       271                 \"next_beam_tokens\": next_beam_tokens.view(-1),\n",
      "                    line       272                 \"next_beam_indices\": next_beam_indices.view(-1),\n",
      "                    line       269             {\n",
      "                    line       268         return UserDict(\n",
      "        Source path:... __init__.py\n",
      "        Starting var:.. args = REPR FAILED\n",
      "        Starting var:.. kwargs = {}\n",
      "                        call       981     def __init__(*args, **kwargs):\n",
      "                        line       982         if not args:\n",
      "                        line       985         self, *args = args\n",
      "        Modified var:.. args = [{'next_beam_scores': tensor<(2,), float32, cuda:0, grad>, 'next_beam_tokens': tensor<(2,), int64, cuda:0>, 'next_beam_indices': tensor<(2,), int64, cuda:0>}]\n",
      "        New var:....... self = REPR FAILED\n",
      "                        line       986         if len(args) > 1:\n",
      "                        line       988         if args:\n",
      "                        line       989             dict = args[0]\n",
      "        New var:....... dict = {'next_beam_scores': tensor<(2,), float32, cuda:0, grad>, 'next_beam_tokens': tensor<(2,), int64, cuda:0>, 'next_beam_indices': tensor<(2,), int64, cuda:0>}\n",
      "                        line       997         self.data = {}\n",
      "        Modified var:.. self = {}\n",
      "                        line       998         if dict is not None:\n",
      "                        line       999             self.update(dict)\n",
      "        Modified var:.. self = {'next_beam_scores': tensor([-10.0866, -10.4164], device='cuda:0', grad_fn=<ViewBackward>), 'next_...tokens': tensor([107, 117], device='cuda:0'), 'next_beam_indices': tensor([0, 0], device='cuda:0')}\n",
      "                        line      1000         if kwargs:\n",
      "                        return    1000         if kwargs:\n",
      "        Return value:.. None\n",
      "    Source path:... generation_beam_search.py\n",
      "                    return     268         return UserDict(\n",
      "    Return value:.. {'next_beam_scores': tensor([-10.0866, -10.4164], device='cuda:0', grad_fn=<ViewBackward>), 'next_...tokens': tensor([107, 117], device='cuda:0'), 'next_beam_indices': tensor([0, 0], device='cuda:0')}\n",
      "Source path:... generation_utils.py\n",
      "Modified var:.. beam_outputs = {'next_beam_scores': tensor([-10.0866, -10.4164], device='cuda:0', grad_fn=<ViewBackward>), 'next_...tokens': tensor([107, 117], device='cuda:0'), 'next_beam_indices': tensor([0, 0], device='cuda:0')}\n",
      "                line      1789             beam_scores = beam_outputs[\"next_beam_scores\"]\n",
      "    Source path:... __init__.py\n",
      "    Starting var:.. self = {'next_beam_scores': tensor([-10.0866, -10.4164], device='cuda:0', grad_fn=<ViewBackward>), 'next_...tokens': tensor([107, 117], device='cuda:0'), 'next_beam_indices': tensor([0, 0], device='cuda:0')}\n",
      "    Starting var:.. key = 'next_beam_scores'\n",
      "                    call      1005     def __getitem__(self, key):\n",
      "                    line      1006         if key in self.data:\n",
      "                    line      1007             return self.data[key]\n",
      "                    return    1007             return self.data[key]\n",
      "    Return value:.. tensor<(2,), float32, cuda:0, grad>\n",
      "Source path:... generation_utils.py\n",
      "                line      1790             beam_next_tokens = beam_outputs[\"next_beam_tokens\"]\n",
      "    Source path:... __init__.py\n",
      "    Starting var:.. self = {'next_beam_scores': tensor([-10.0866, -10.4164], device='cuda:0', grad_fn=<ViewBackward>), 'next_...tokens': tensor([107, 117], device='cuda:0'), 'next_beam_indices': tensor([0, 0], device='cuda:0')}\n",
      "    Starting var:.. key = 'next_beam_tokens'\n",
      "                    call      1005     def __getitem__(self, key):\n",
      "                    line      1006         if key in self.data:\n",
      "                    line      1007             return self.data[key]\n",
      "                    return    1007             return self.data[key]\n",
      "    Return value:.. tensor<(2,), int64, cuda:0>\n",
      "Source path:... generation_utils.py\n",
      "                line      1791             beam_idx = beam_outputs[\"next_beam_indices\"]\n",
      "    Source path:... __init__.py\n",
      "    Starting var:.. self = {'next_beam_scores': tensor([-10.0866, -10.4164], device='cuda:0', grad_fn=<ViewBackward>), 'next_...tokens': tensor([107, 117], device='cuda:0'), 'next_beam_indices': tensor([0, 0], device='cuda:0')}\n",
      "    Starting var:.. key = 'next_beam_indices'\n",
      "                    call      1005     def __getitem__(self, key):\n",
      "                    line      1006         if key in self.data:\n",
      "                    line      1007             return self.data[key]\n",
      "                    return    1007             return self.data[key]\n",
      "    Return value:.. tensor<(2,), int64, cuda:0>\n",
      "Source path:... generation_utils.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                line      1793             input_ids = torch.cat([input_ids[beam_idx, :], beam_next_tokens.unsqueeze(-1)], dim=-1)\n",
      "Modified var:.. input_ids = tensor<(2, 12), int64, cuda:0>\n",
      "                line      1795             cur_len = cur_len + 1\n",
      "Modified var:.. cur_len = 12\n",
      "                line      1797             model_kwargs = self._update_model_kwargs_for_generation(\n",
      "                line      1798                 outputs, model_kwargs, is_encoder_decoder=self.config.is_encoder_decoder\n",
      "                line      1797             model_kwargs = self._update_model_kwargs_for_generation(\n",
      "    Starting var:.. outputs = {'logits': tensor<(2, 1, 96103), float32, cuda:0, grad>, 'past_key_values': ((tensor<(2, 16, 11, 6...float32, cuda:0, grad>)), 'encoder_last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0, grad>}\n",
      "    Starting var:.. model_kwargs = {'use_cache': None, 'attention_mask': tensor<(2, 6), int64, cuda:0>, 'encoder_outputs': {'last_hid...d>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>))}\n",
      "    Starting var:.. is_encoder_decoder = True\n",
      "                    call       511     def _update_model_kwargs_for_generation(\n",
      "                    line       515         if \"past_key_values\" in outputs:\n",
      "                    line       516             model_kwargs[\"past\"] = outputs.past_key_values\n",
      "                    line       525         if \"token_type_ids\" in model_kwargs:\n",
      "                    line       530         if not is_encoder_decoder:\n",
      "                    line       537         return model_kwargs\n",
      "                    return     537         return model_kwargs\n",
      "    Return value:.. {'use_cache': None, 'attention_mask': tensor<(2, 6), int64, cuda:0>, 'encoder_outputs': {'last_hid...d>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>))}\n",
      "                line      1800             if model_kwargs[\"past\"] is not None:\n",
      "                line      1801                 model_kwargs[\"past\"] = self._reorder_cache(model_kwargs[\"past\"], beam_idx)\n",
      "    Source path:... modeling_pegasus.py\n",
      "    Starting var:.. past = ((tensor<(2, 16, 11, 64), float32, cuda:0, grad>, tensor<(2, 16, 11, 64), float32, cuda:0, grad>, ...ad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>))\n",
      "    Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                    call      1333     def _reorder_cache(past, beam_idx):\n",
      "                    line      1334         reordered_past = ()\n",
      "    New var:....... reordered_past = ()\n",
      "                    line      1335         for layer_past in past:\n",
      "    New var:....... layer_past = (tensor<(2, 16, 11, 64), float32, cuda:0, grad>, tensor<(2, 16, 11, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>)\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 11, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 11, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 11, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 11, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 11, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "    Modified var:.. reordered_past = ((tensor<(2, 16, 11, 64), float32, cuda:0, grad>, tensor<(2, 16, 11, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>),)\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 11, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 11, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 11, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 11, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 11, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "    Modified var:.. reordered_past = ((tensor<(2, 16, 11, 64), float32, cuda:0, grad>, tensor<(2, 16, 11, 64), float32, cuda:0, grad>, ...ad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>))\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 11, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 11, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 11, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 11, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 11, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 11, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 11, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 11, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 11, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 11, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 11, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 11, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 11, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 11, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 11, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 11, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 11, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 11, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 11, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 11, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 11, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 11, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 11, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 11, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 11, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 11, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 11, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 11, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 11, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 11, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 11, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 11, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 11, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 11, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 11, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 11, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 11, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 11, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 11, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 11, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 11, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 11, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 11, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 11, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 11, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 11, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 11, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 11, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 11, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 11, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 11, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 11, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 11, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 11, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 11, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 11, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 11, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 11, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 11, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 11, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 11, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 11, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 11, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 11, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 11, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 11, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 11, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 11, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 11, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 11, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1340         return reordered_past\n",
      "                    return    1340         return reordered_past\n",
      "    Return value:.. ((tensor<(2, 16, 11, 64), float32, cuda:0, grad>, tensor<(2, 16, 11, 64), float32, cuda:0, grad>, ...ad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>))\n",
      "Source path:... generation_utils.py\n",
      "                line      1803             if beam_scorer.is_done:\n",
      "    Source path:... generation_beam_search.py\n",
      "    Starting var:.. self = <transformers.generation_beam_search.BeamSearchScorer object>\n",
      "                    call       196     def is_done(self) -> bool:\n",
      "                    line       197         return self._done.all()\n",
      "                    return     197         return self._done.all()\n",
      "    Return value:.. tensor<(), bool, cuda:0>\n",
      "Source path:... generation_utils.py\n",
      "                line      1806             if stopping_criteria(input_ids, scores):\n",
      "    Source path:... generation_stopping_criteria.py\n",
      "    Starting var:.. self = [<transformers.generation_stopping_criteria.MaxLengthCriteria object>]\n",
      "    Starting var:.. input_ids = tensor<(2, 12), int64, cuda:0>\n",
      "    Starting var:.. scores = (tensor<(2, 96103), float32, cuda:0, grad>, tensor<(2, 96103), float32, cuda:0, grad>, tensor<(2, ...uda:0, grad>, tensor<(2, 96103), float32, cuda:0, grad>, tensor<(2, 96103), float32, cuda:0, grad>)\n",
      "    Starting var:.. kwargs = {}\n",
      "                    call        83     def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor, **kwargs) -> bool:\n",
      "                    line        84         return any(criteria(input_ids, scores) for criteria in self)\n",
      "        Starting var:.. .0 = <list_iterator object>\n",
      "        Starting var:.. input_ids = tensor<(2, 12), int64, cuda:0>\n",
      "        Starting var:.. scores = (tensor<(2, 96103), float32, cuda:0, grad>, tensor<(2, 96103), float32, cuda:0, grad>, tensor<(2, ...uda:0, grad>, tensor<(2, 96103), float32, cuda:0, grad>, tensor<(2, 96103), float32, cuda:0, grad>)\n",
      "                        call        84         return any(criteria(input_ids, scores) for criteria in self)\n",
      "                        line        84         return any(criteria(input_ids, scores) for criteria in self)\n",
      "        New var:....... criteria = <transformers.generation_stopping_criteria.MaxLengthCriteria object>\n",
      "                        return      84         return any(criteria(input_ids, scores) for criteria in self)\n",
      "        Return value:.. False\n",
      "        Starting var:.. .0 = <list_iterator object>\n",
      "        Starting var:.. criteria = <transformers.generation_stopping_criteria.MaxLengthCriteria object>\n",
      "        Starting var:.. input_ids = tensor<(2, 12), int64, cuda:0>\n",
      "        Starting var:.. scores = (tensor<(2, 96103), float32, cuda:0, grad>, tensor<(2, 96103), float32, cuda:0, grad>, tensor<(2, ...uda:0, grad>, tensor<(2, 96103), float32, cuda:0, grad>, tensor<(2, 96103), float32, cuda:0, grad>)\n",
      "                        call        84         return any(criteria(input_ids, scores) for criteria in self)\n",
      "                        line        84         return any(criteria(input_ids, scores) for criteria in self)\n",
      "                        return      84         return any(criteria(input_ids, scores) for criteria in self)\n",
      "        Return value:.. None\n",
      "                    return      84         return any(criteria(input_ids, scores) for criteria in self)\n",
      "    Return value:.. False\n",
      "Source path:... generation_utils.py\n",
      "                line      1729         while cur_len < max_length:\n",
      "                line      1730             model_inputs = self.prepare_inputs_for_generation(input_ids, **model_kwargs)\n",
      "    Source path:... modeling_pegasus.py\n",
      "    Starting var:.. self = PegasusForConditionalGeneration(  (model): PegasusModel(    (shared): Embedding(96103, 1024, paddi...mentwise_affine=True)    )  )  (lm_head): Linear(in_features=1024, out_features=96103, bias=False))\n",
      "    Starting var:.. decoder_input_ids = tensor<(2, 12), int64, cuda:0>\n",
      "    Starting var:.. past = ((tensor<(2, 16, 11, 64), float32, cuda:0, grad>, tensor<(2, 16, 11, 64), float32, cuda:0, grad>, ...ad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>))\n",
      "    Starting var:.. attention_mask = tensor<(2, 6), int64, cuda:0>\n",
      "    Starting var:.. head_mask = None\n",
      "    Starting var:.. use_cache = None\n",
      "    Starting var:.. encoder_outputs = {'last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0, grad>}\n",
      "    Starting var:.. kwargs = {}\n",
      "                    call      1305     def prepare_inputs_for_generation(\n",
      "                    line      1316         if past is not None:\n",
      "                    line      1317             decoder_input_ids = decoder_input_ids[:, -1:]\n",
      "    Modified var:.. decoder_input_ids = tensor<(2, 1), int64, cuda:0>\n",
      "                    line      1320             \"input_ids\": None,  # encoder_outputs is defined. input_ids not needed\n",
      "                    line      1321             \"encoder_outputs\": encoder_outputs,\n",
      "                    line      1322             \"past_key_values\": past,\n",
      "                    line      1323             \"decoder_input_ids\": decoder_input_ids,\n",
      "                    line      1324             \"attention_mask\": attention_mask,\n",
      "                    line      1325             \"head_mask\": head_mask,\n",
      "                    line      1326             \"use_cache\": use_cache,  # change this to avoid caching (presumably for debugging)\n",
      "                    line      1319         return {\n",
      "                    return    1319         return {\n",
      "    Return value:.. {'input_ids': None, 'encoder_outputs': {'last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0,...64, cuda:0>, 'attention_mask': tensor<(2, 6), int64, cuda:0>, 'head_mask': None, 'use_cache': None}\n",
      "Source path:... generation_utils.py\n",
      "                line      1732             outputs = self(\n",
      "                line      1733                 **model_inputs,\n",
      "                line      1734                 return_dict=True,\n",
      "                line      1735                 output_attentions=output_attentions,\n",
      "                line      1736                 output_hidden_states=output_hidden_states,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                line      1732             outputs = self(\n",
      "    Source path:... module.py\n",
      "    Starting var:.. self = PegasusForConditionalGeneration(  (model): PegasusModel(    (shared): Embedding(96103, 1024, paddi...mentwise_affine=True)    )  )  (lm_head): Linear(in_features=1024, out_features=96103, bias=False))\n",
      "    Starting var:.. input = ()\n",
      "    Starting var:.. kwargs = {'input_ids': None, 'encoder_outputs': {'last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0,... 'use_cache': None, 'return_dict': True, 'output_attentions': False, 'output_hidden_states': False}\n",
      "                    call       715     def _call_impl(self, *input, **kwargs):\n",
      "                    line       716         for hook in itertools.chain(\n",
      "                    line       717                 _global_forward_pre_hooks.values(),\n",
      "                    line       718                 self._forward_pre_hooks.values()):\n",
      "                    line       716         for hook in itertools.chain(\n",
      "                    line       724         if torch._C._get_tracing_state():\n",
      "                    line       727             result = self.forward(*input, **kwargs)\n",
      "        Source path:... modeling_pegasus.py\n",
      "        Starting var:.. self = PegasusForConditionalGeneration(  (model): PegasusModel(    (shared): Embedding(96103, 1024, paddi...mentwise_affine=True)    )  )  (lm_head): Linear(in_features=1024, out_features=96103, bias=False))\n",
      "        Starting var:.. input_ids = None\n",
      "        Starting var:.. attention_mask = tensor<(2, 6), int64, cuda:0>\n",
      "        Starting var:.. decoder_input_ids = tensor<(2, 1), int64, cuda:0>\n",
      "        Starting var:.. decoder_attention_mask = None\n",
      "        Starting var:.. head_mask = None\n",
      "        Starting var:.. decoder_head_mask = None\n",
      "        Starting var:.. encoder_outputs = {'last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0, grad>}\n",
      "        Starting var:.. past_key_values = ((tensor<(2, 16, 11, 64), float32, cuda:0, grad>, tensor<(2, 16, 11, 64), float32, cuda:0, grad>, ...ad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>))\n",
      "        Starting var:.. inputs_embeds = None\n",
      "        Starting var:.. decoder_inputs_embeds = None\n",
      "        Starting var:.. labels = None\n",
      "        Starting var:.. use_cache = None\n",
      "        Starting var:.. output_attentions = False\n",
      "        Starting var:.. output_hidden_states = False\n",
      "        Starting var:.. return_dict = True\n",
      "                        call      1231     def forward(\n",
      "                        line      1258         return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
      "                        line      1260         if labels is not None:\n",
      "                        line      1266         outputs = self.model(\n",
      "                        line      1267             input_ids,\n",
      "                        line      1268             attention_mask=attention_mask,\n",
      "                        line      1269             decoder_input_ids=decoder_input_ids,\n",
      "                        line      1270             encoder_outputs=encoder_outputs,\n",
      "                        line      1271             decoder_attention_mask=decoder_attention_mask,\n",
      "                        line      1272             head_mask=head_mask,\n",
      "                        line      1273             decoder_head_mask=decoder_head_mask,\n",
      "                        line      1274             past_key_values=past_key_values,\n",
      "                        line      1275             inputs_embeds=inputs_embeds,\n",
      "                        line      1276             decoder_inputs_embeds=decoder_inputs_embeds,\n",
      "                        line      1277             use_cache=use_cache,\n",
      "                        line      1278             output_attentions=output_attentions,\n",
      "                        line      1279             output_hidden_states=output_hidden_states,\n",
      "                        line      1280             return_dict=return_dict,\n",
      "                        line      1266         outputs = self.model(\n",
      "        New var:....... outputs = {'last_hidden_state': tensor<(2, 1, 1024), float32, cuda:0, grad>, 'past_key_values': ((tensor<(2,...float32, cuda:0, grad>)), 'encoder_last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0, grad>}\n",
      "                        line      1282         lm_logits = self.lm_head(outputs[0]) + self.final_logits_bias\n",
      "        New var:....... lm_logits = tensor<(2, 1, 96103), float32, cuda:0, grad>\n",
      "                        line      1284         masked_lm_loss = None\n",
      "        New var:....... masked_lm_loss = None\n",
      "                        line      1285         if labels is not None:\n",
      "                        line      1289         if not return_dict:\n",
      "                        line      1293         return Seq2SeqLMOutput(\n",
      "                        line      1294             loss=masked_lm_loss,\n",
      "                        line      1295             logits=lm_logits,\n",
      "                        line      1296             past_key_values=outputs.past_key_values,\n",
      "                        line      1297             decoder_hidden_states=outputs.decoder_hidden_states,\n",
      "                        line      1298             decoder_attentions=outputs.decoder_attentions,\n",
      "                        line      1299             cross_attentions=outputs.cross_attentions,\n",
      "                        line      1300             encoder_last_hidden_state=outputs.encoder_last_hidden_state,\n",
      "                        line      1301             encoder_hidden_states=outputs.encoder_hidden_states,\n",
      "                        line      1302             encoder_attentions=outputs.encoder_attentions,\n",
      "                        line      1293         return Seq2SeqLMOutput(\n",
      "                        return    1293         return Seq2SeqLMOutput(\n",
      "        Return value:.. {'logits': tensor<(2, 1, 96103), float32, cuda:0, grad>, 'past_key_values': ((tensor<(2, 16, 12, 6...float32, cuda:0, grad>)), 'encoder_last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0, grad>}\n",
      "    Source path:... module.py\n",
      "    New var:....... result = {'logits': tensor<(2, 1, 96103), float32, cuda:0, grad>, 'past_key_values': ((tensor<(2, 16, 12, 6...float32, cuda:0, grad>)), 'encoder_last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0, grad>}\n",
      "                    line       728         for hook in itertools.chain(\n",
      "                    line       729                 _global_forward_hooks.values(),\n",
      "                    line       730                 self._forward_hooks.values()):\n",
      "                    line       728         for hook in itertools.chain(\n",
      "                    line       734         if (len(self._backward_hooks) > 0) or (len(_global_backward_hooks) > 0):\n",
      "                    line       749         return result\n",
      "                    return     749         return result\n",
      "    Return value:.. {'logits': tensor<(2, 1, 96103), float32, cuda:0, grad>, 'past_key_values': ((tensor<(2, 16, 12, 6...float32, cuda:0, grad>)), 'encoder_last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0, grad>}\n",
      "Source path:... generation_utils.py\n",
      "Modified var:.. outputs = {'logits': tensor<(2, 1, 96103), float32, cuda:0, grad>, 'past_key_values': ((tensor<(2, 16, 12, 6...float32, cuda:0, grad>)), 'encoder_last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0, grad>}\n",
      "                line      1738             next_token_logits = outputs.logits[:, -1, :]\n",
      "                line      1742             next_token_logits = self.adjust_logits_during_generation(\n",
      "                line      1743                 next_token_logits, cur_len=cur_len, max_length=max_length\n",
      "                line      1742             next_token_logits = self.adjust_logits_during_generation(\n",
      "    Starting var:.. self = PegasusForConditionalGeneration(  (model): PegasusModel(    (shared): Embedding(96103, 1024, paddi...mentwise_affine=True)    )  )  (lm_head): Linear(in_features=1024, out_features=96103, bias=False))\n",
      "    Starting var:.. logits = tensor<(2, 96103), float32, cuda:0, grad>\n",
      "    Starting var:.. kwargs = {'cur_len': 12, 'max_length': 60}\n",
      "                    call       373     def adjust_logits_during_generation(self, logits: torch.FloatTensor, **kwargs) -> torch.FloatTensor:\n",
      "                    line       378         return logits\n",
      "                    return     378         return logits\n",
      "    Return value:.. tensor<(2, 96103), float32, cuda:0, grad>\n",
      "                line      1746             next_token_scores = F.log_softmax(next_token_logits, dim=-1)  # (batch_size * num_beams, vocab_size)\n",
      "    Source path:... functional.py\n",
      "    Starting var:.. input = tensor<(2, 96103), float32, cuda:0, grad>\n",
      "    Starting var:.. dim = -1\n",
      "    Starting var:.. _stacklevel = 3\n",
      "    Starting var:.. dtype = None\n",
      "                    call      1581 def log_softmax(input, dim=None, _stacklevel=3, dtype=None):\n",
      "                    line      1598     if not torch.jit.is_scripting():\n",
      "        Source path:... _jit_internal.py\n",
      "                        call       750 def is_scripting():\n",
      "                        line       769     return False\n",
      "                        return     769     return False\n",
      "        Return value:.. False\n",
      "    Source path:... functional.py\n",
      "                    line      1599         if type(input) is not Tensor and has_torch_function((input,)):\n",
      "                    line      1602     if dim is None:\n",
      "                    line      1604     if dtype is None:\n",
      "                    line      1605         ret = input.log_softmax(dim)\n",
      "    New var:....... ret = tensor<(2, 96103), float32, cuda:0, grad>\n",
      "                    line      1608     return ret\n",
      "                    return    1608     return ret\n",
      "    Return value:.. tensor<(2, 96103), float32, cuda:0, grad>\n",
      "Source path:... generation_utils.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Modified var:.. next_token_scores = tensor<(2, 96103), float32, cuda:0, grad>\n",
      "                line      1748             next_token_scores = logits_processor(input_ids, next_token_scores)\n",
      "    Source path:... generation_logits_process.py\n",
      "    Starting var:.. self = [<transformers.generation_logits_process.MinLengthLogitsProcessor object>, <transformers.generation_logits_process.ForcedEOSTokenLogitsProcessor object>]\n",
      "    Starting var:.. input_ids = tensor<(2, 12), int64, cuda:0>\n",
      "    Starting var:.. scores = tensor<(2, 96103), float32, cuda:0, grad>\n",
      "    Starting var:.. kwargs = {}\n",
      "                    call        84     def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor, **kwargs) -> torch.FloatTensor:\n",
      "                    line        85         for processor in self:\n",
      "    New var:....... processor = <transformers.generation_logits_process.MinLengthLogitsProcessor object>\n",
      "                    line        86             function_args = inspect.signature(processor.__call__).parameters\n",
      "        Source path:... inspect.py\n",
      "        Starting var:.. obj = <bound method MinLengthLogitsProcessor.__call__ of <transformers.generation_logits_process.MinLengthLogitsProcessor object>>\n",
      "        Starting var:.. follow_wrapped = True\n",
      "                        call      3091 def signature(obj, *, follow_wrapped=True):\n",
      "                        line      3093     return Signature.from_callable(obj, follow_wrapped=follow_wrapped)\n",
      "                        return    3093     return Signature.from_callable(obj, follow_wrapped=follow_wrapped)\n",
      "        Return value:.. <Signature (input_ids: torch.LongTensor, scores: torch.FloatTensor) -> torch.FloatTensor>\n",
      "        Starting var:.. self = <Signature (input_ids: torch.LongTensor, scores: torch.FloatTensor) -> torch.FloatTensor>\n",
      "                        call      2846     def parameters(self):\n",
      "                        line      2847         return self._parameters\n",
      "                        return    2847         return self._parameters\n",
      "        Return value:.. mappingproxy(OrderedDict([('input_ids', <Parameter \"input_ids: torch.LongTensor\">), ('scores', <Parameter \"scores: torch.FloatTensor\">)]))\n",
      "    Source path:... generation_logits_process.py\n",
      "    New var:....... function_args = mappingproxy(OrderedDict([('input_ids', <Parameter \"input_ids: torch.LongTensor\">), ('scores', <Parameter \"scores: torch.FloatTensor\">)]))\n",
      "                    line        87             if len(function_args) > 2:\n",
      "                    line        93                 scores = processor(input_ids, scores)\n",
      "        Starting var:.. self = <transformers.generation_logits_process.MinLengthLogitsProcessor object>\n",
      "        Starting var:.. input_ids = tensor<(2, 12), int64, cuda:0>\n",
      "        Starting var:.. scores = tensor<(2, 96103), float32, cuda:0, grad>\n",
      "                        call       118     def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor) -> torch.FloatTensor:\n",
      "                        line       119         cur_len = input_ids.shape[-1]\n",
      "        New var:....... cur_len = 12\n",
      "                        line       120         if cur_len < self.min_length:\n",
      "                        line       122         return scores\n",
      "                        return     122         return scores\n",
      "        Return value:.. tensor<(2, 96103), float32, cuda:0, grad>\n",
      "                    line        85         for processor in self:\n",
      "    Modified var:.. processor = <transformers.generation_logits_process.ForcedEOSTokenLogitsProcessor object>\n",
      "                    line        86             function_args = inspect.signature(processor.__call__).parameters\n",
      "        Source path:... inspect.py\n",
      "        Starting var:.. obj = <bound method ForcedEOSTokenLogitsProcessor.__call__ of <transformers.generation_logits_process.ForcedEOSTokenLogitsProcessor object>>\n",
      "        Starting var:.. follow_wrapped = True\n",
      "                        call      3091 def signature(obj, *, follow_wrapped=True):\n",
      "                        line      3093     return Signature.from_callable(obj, follow_wrapped=follow_wrapped)\n",
      "                        return    3093     return Signature.from_callable(obj, follow_wrapped=follow_wrapped)\n",
      "        Return value:.. <Signature (input_ids: torch.LongTensor, scores: torch.FloatTensor) -> torch.FloatTensor>\n",
      "        Starting var:.. self = <Signature (input_ids: torch.LongTensor, scores: torch.FloatTensor) -> torch.FloatTensor>\n",
      "                        call      2846     def parameters(self):\n",
      "                        line      2847         return self._parameters\n",
      "                        return    2847         return self._parameters\n",
      "        Return value:.. mappingproxy(OrderedDict([('input_ids', <Parameter \"input_ids: torch.LongTensor\">), ('scores', <Parameter \"scores: torch.FloatTensor\">)]))\n",
      "    Source path:... generation_logits_process.py\n",
      "                    line        87             if len(function_args) > 2:\n",
      "                    line        93                 scores = processor(input_ids, scores)\n",
      "        Starting var:.. self = <transformers.generation_logits_process.ForcedEOSTokenLogitsProcessor object>\n",
      "        Starting var:.. input_ids = tensor<(2, 12), int64, cuda:0>\n",
      "        Starting var:.. scores = tensor<(2, 96103), float32, cuda:0, grad>\n",
      "                        call       571     def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor) -> torch.FloatTensor:\n",
      "                        line       572         cur_len = input_ids.shape[-1]\n",
      "        New var:....... cur_len = 12\n",
      "                        line       573         if cur_len == self.max_length - 1:\n",
      "                        line       577         return scores\n",
      "                        return     577         return scores\n",
      "        Return value:.. tensor<(2, 96103), float32, cuda:0, grad>\n",
      "                    line        85         for processor in self:\n",
      "                    line        94         return scores\n",
      "                    return      94         return scores\n",
      "    Return value:.. tensor<(2, 96103), float32, cuda:0, grad>\n",
      "Source path:... generation_utils.py\n",
      "                line      1749             next_token_scores = next_token_scores + beam_scores[:, None].expand_as(next_token_scores)\n",
      "                line      1752             if return_dict_in_generate:\n",
      "                line      1753                 if output_scores:\n",
      "                line      1754                     scores += (next_token_scores,)\n",
      "                line      1755                 if output_attentions:\n",
      "                line      1762                 if output_hidden_states:\n",
      "                line      1770             vocab_size = next_token_scores.shape[-1]\n",
      "                line      1771             next_token_scores = next_token_scores.view(batch_size, num_beams * vocab_size)\n",
      "Modified var:.. next_token_scores = tensor<(1, 192206), float32, cuda:0, grad>\n",
      "                line      1773             next_token_scores, next_tokens = torch.topk(\n",
      "                line      1774                 next_token_scores, 2 * num_beams, dim=1, largest=True, sorted=True\n",
      "                line      1773             next_token_scores, next_tokens = torch.topk(\n",
      "Modified var:.. next_token_scores = tensor<(1, 4), float32, cuda:0, grad>\n",
      "                line      1777             next_indices = next_tokens // vocab_size\n",
      "    Source path:... tensor.py\n",
      "    Starting var:.. args = (tensor<(1, 4), int64, cuda:0>, 96103)\n",
      "    Starting var:.. kwargs = {}\n",
      "    Starting var:.. f = <function Tensor.__floordiv__>\n",
      "    Starting var:.. wrapped = <function Tensor.__floordiv__>\n",
      "                    call        22     def wrapped(*args, **kwargs):\n",
      "                    line        23         from torch.overrides import has_torch_function, handle_torch_function\n",
      "    New var:....... has_torch_function = <function has_torch_function>\n",
      "    New var:....... handle_torch_function = <function handle_torch_function>\n",
      "                    line        24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "                        call        24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "                        line        24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "        New var:....... t = tensor<(1, 4), int64, cuda:0>\n",
      "                        return      24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "        Return value:.. True\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. t = tensor<(1, 4), int64, cuda:0>\n",
      "                        call        24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "                        line        24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "        Modified var:.. t = 96103\n",
      "                        return      24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "        Return value:.. False\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. t = 96103\n",
      "                        call        24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "                        exception   24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "        Exception:..... GeneratorExit\n",
      "                        return      24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "        Return value:.. None\n",
      "        Source path:... overrides.py\n",
      "        Starting var:.. relevant_args = (tensor<(1, 4), int64, cuda:0>, 96103)\n",
      "                        call      1070 def has_torch_function(relevant_args: Iterable[Any]) -> bool:\n",
      "                        line      1083     return _is_torch_function_enabled() and any(\n",
      "                        line      1087         for a in relevant_args\n",
      "                        line      1083     return _is_torch_function_enabled() and any(\n",
      "                        return    1083     return _is_torch_function_enabled() and any(\n",
      "        Return value:.. False\n",
      "    Source path:... tensor.py\n",
      "                    line        26         try:\n",
      "                    line        27             return f(*args, **kwargs)\n",
      "        Starting var:.. self = tensor<(1, 4), int64, cuda:0>\n",
      "        Starting var:.. other = 96103\n",
      "                        call       550     def __floordiv__(self, other):\n",
      "                        line       551         return torch.floor_divide(self, other)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                        return     551         return torch.floor_divide(self, other)\n",
      "        Return value:.. tensor<(1, 4), int64, cuda:0>\n",
      "                    return      27             return f(*args, **kwargs)\n",
      "    Return value:.. tensor<(1, 4), int64, cuda:0>\n",
      "Source path:... generation_utils.py\n",
      "                line      1778             next_tokens = next_tokens % vocab_size\n",
      "                line      1781             beam_outputs = beam_scorer.process(\n",
      "                line      1782                 input_ids,\n",
      "                line      1783                 next_token_scores,\n",
      "                line      1784                 next_tokens,\n",
      "                line      1785                 next_indices,\n",
      "                line      1786                 pad_token_id=pad_token_id,\n",
      "                line      1787                 eos_token_id=eos_token_id,\n",
      "                line      1781             beam_outputs = beam_scorer.process(\n",
      "    Source path:... generation_beam_search.py\n",
      "    Starting var:.. self = <transformers.generation_beam_search.BeamSearchScorer object>\n",
      "    Starting var:.. input_ids = tensor<(2, 12), int64, cuda:0>\n",
      "    Starting var:.. next_scores = tensor<(1, 4), float32, cuda:0, grad>\n",
      "    Starting var:.. next_tokens = tensor<(1, 4), int64, cuda:0>\n",
      "    Starting var:.. next_indices = tensor<(1, 4), int64, cuda:0>\n",
      "    Starting var:.. pad_token_id = 0\n",
      "    Starting var:.. eos_token_id = 1\n",
      "                    call       199     def process(\n",
      "                    line       208         cur_len = input_ids.shape[-1]\n",
      "    New var:....... cur_len = 12\n",
      "                    line       209         batch_size = len(self._beam_hyps)\n",
      "    New var:....... batch_size = 1\n",
      "                    line       210         assert batch_size == (input_ids.shape[0] // self.group_size)\n",
      "                    line       212         device = input_ids.device\n",
      "    New var:....... device = device(type='cuda', index=0)\n",
      "                    line       213         next_beam_scores = torch.zeros((batch_size, self.group_size), dtype=next_scores.dtype, device=device)\n",
      "    New var:....... next_beam_scores = tensor<(1, 2), float32, cuda:0>\n",
      "                    line       214         next_beam_tokens = torch.zeros((batch_size, self.group_size), dtype=next_tokens.dtype, device=device)\n",
      "    New var:....... next_beam_tokens = tensor<(1, 2), int64, cuda:0>\n",
      "                    line       215         next_beam_indices = torch.zeros((batch_size, self.group_size), dtype=next_indices.dtype, device=device)\n",
      "    New var:....... next_beam_indices = tensor<(1, 2), int64, cuda:0>\n",
      "                    line       217         for batch_idx, beam_hyp in enumerate(self._beam_hyps):\n",
      "    New var:....... batch_idx = 0\n",
      "    New var:....... beam_hyp = <transformers.generation_beam_search.BeamHypotheses object>\n",
      "                    line       218             if self._done[batch_idx]:\n",
      "                    line       232             beam_idx = 0\n",
      "    New var:....... beam_idx = 0\n",
      "                    line       233             for beam_token_rank, (next_token, next_score, next_index) in enumerate(\n",
      "                    line       234                 zip(next_tokens[batch_idx], next_scores[batch_idx], next_indices[batch_idx])\n",
      "        Source path:... tensor.py\n",
      "        Starting var:.. self = tensor<(4,), int64, cuda:0>\n",
      "                        call       576     def __iter__(self):\n",
      "                        line       583         relevant_args = (self,)\n",
      "        New var:....... relevant_args = (tensor<(4,), int64, cuda:0>,)\n",
      "                        line       584         from torch.overrides import has_torch_function, handle_torch_function\n",
      "        New var:....... has_torch_function = <function has_torch_function>\n",
      "        New var:....... handle_torch_function = <function handle_torch_function>\n",
      "                        line       585         if type(self) is not Tensor and has_torch_function(relevant_args):\n",
      "                        line       587         if self.dim() == 0:\n",
      "                        line       589         if torch._C._get_tracing_state():\n",
      "                        line       594         return iter(self.unbind(0))\n",
      "                        return     594         return iter(self.unbind(0))\n",
      "        Return value:.. <tuple_iterator object>\n",
      "        Starting var:.. self = tensor<(4,), float32, cuda:0, grad>\n",
      "                        call       576     def __iter__(self):\n",
      "                        line       583         relevant_args = (self,)\n",
      "        New var:....... relevant_args = (tensor<(4,), float32, cuda:0, grad>,)\n",
      "                        line       584         from torch.overrides import has_torch_function, handle_torch_function\n",
      "        New var:....... has_torch_function = <function has_torch_function>\n",
      "        New var:....... handle_torch_function = <function handle_torch_function>\n",
      "                        line       585         if type(self) is not Tensor and has_torch_function(relevant_args):\n",
      "                        line       587         if self.dim() == 0:\n",
      "                        line       589         if torch._C._get_tracing_state():\n",
      "                        line       594         return iter(self.unbind(0))\n",
      "                        return     594         return iter(self.unbind(0))\n",
      "        Return value:.. <tuple_iterator object>\n",
      "        Starting var:.. self = tensor<(4,), int64, cuda:0>\n",
      "                        call       576     def __iter__(self):\n",
      "                        line       583         relevant_args = (self,)\n",
      "        New var:....... relevant_args = (tensor<(4,), int64, cuda:0>,)\n",
      "                        line       584         from torch.overrides import has_torch_function, handle_torch_function\n",
      "        New var:....... has_torch_function = <function has_torch_function>\n",
      "        New var:....... handle_torch_function = <function handle_torch_function>\n",
      "                        line       585         if type(self) is not Tensor and has_torch_function(relevant_args):\n",
      "                        line       587         if self.dim() == 0:\n",
      "                        line       589         if torch._C._get_tracing_state():\n",
      "                        line       594         return iter(self.unbind(0))\n",
      "                        return     594         return iter(self.unbind(0))\n",
      "        Return value:.. <tuple_iterator object>\n",
      "    Source path:... generation_beam_search.py\n",
      "                    line       233             for beam_token_rank, (next_token, next_score, next_index) in enumerate(\n",
      "    New var:....... beam_token_rank = 0\n",
      "    New var:....... next_token = tensor<(), int64, cuda:0>\n",
      "    New var:....... next_score = tensor<(), float32, cuda:0, grad>\n",
      "    New var:....... next_index = tensor<(), int64, cuda:0>\n",
      "                    line       236                 batch_beam_idx = batch_idx * self.group_size + next_index\n",
      "    New var:....... batch_beam_idx = tensor<(), int64, cuda:0>\n",
      "                    line       238                 if (eos_token_id is not None) and (next_token.item() == eos_token_id):\n",
      "                    line       240                     is_beam_token_worse_than_top_num_beams = beam_token_rank >= self.group_size\n",
      "    New var:....... is_beam_token_worse_than_top_num_beams = False\n",
      "                    line       241                     if is_beam_token_worse_than_top_num_beams:\n",
      "                    line       243                     beam_hyp.add(\n",
      "                    line       244                         input_ids[batch_beam_idx].clone(),\n",
      "                    line       245                         next_score.item(),\n",
      "                    line       243                     beam_hyp.add(\n",
      "        Starting var:.. self = <transformers.generation_beam_search.BeamHypotheses object>\n",
      "        Starting var:.. hyp = tensor<(12,), int64, cuda:0>\n",
      "        Starting var:.. sum_logprobs = -10.187658309936523\n",
      "                        call       357     def add(self, hyp: torch.LongTensor, sum_logprobs: float):\n",
      "                        line       361         score = sum_logprobs / (hyp.shape[-1] ** self.length_penalty)\n",
      "        New var:....... score = -0.8489715258280436\n",
      "                        line       362         if len(self) < self.num_beams or score > self.worst_score:\n",
      "                        line       363             self.beams.append((score, hyp))\n",
      "                        line       364             if len(self) > self.num_beams:\n",
      "                        line       369                 self.worst_score = min(score, self.worst_score)\n",
      "                        return     369                 self.worst_score = min(score, self.worst_score)\n",
      "        Return value:.. None\n",
      "                    line       255                 if beam_idx == self.group_size:\n",
      "                    line       233             for beam_token_rank, (next_token, next_score, next_index) in enumerate(\n",
      "    Modified var:.. beam_token_rank = 1\n",
      "                    line       236                 batch_beam_idx = batch_idx * self.group_size + next_index\n",
      "                    line       238                 if (eos_token_id is not None) and (next_token.item() == eos_token_id):\n",
      "                    line       249                     next_beam_scores[batch_idx, beam_idx] = next_score\n",
      "    Modified var:.. next_beam_scores = tensor<(1, 2), float32, cuda:0, grad>\n",
      "                    line       250                     next_beam_tokens[batch_idx, beam_idx] = next_token\n",
      "                    line       251                     next_beam_indices[batch_idx, beam_idx] = batch_beam_idx\n",
      "                    line       252                     beam_idx += 1\n",
      "    Modified var:.. beam_idx = 1\n",
      "                    line       255                 if beam_idx == self.group_size:\n",
      "                    line       233             for beam_token_rank, (next_token, next_score, next_index) in enumerate(\n",
      "    Modified var:.. beam_token_rank = 2\n",
      "                    line       236                 batch_beam_idx = batch_idx * self.group_size + next_index\n",
      "                    line       238                 if (eos_token_id is not None) and (next_token.item() == eos_token_id):\n",
      "                    line       240                     is_beam_token_worse_than_top_num_beams = beam_token_rank >= self.group_size\n",
      "    Modified var:.. is_beam_token_worse_than_top_num_beams = True\n",
      "                    line       241                     if is_beam_token_worse_than_top_num_beams:\n",
      "                    line       242                         continue\n",
      "                    line       233             for beam_token_rank, (next_token, next_score, next_index) in enumerate(\n",
      "    Modified var:.. beam_token_rank = 3\n",
      "                    line       236                 batch_beam_idx = batch_idx * self.group_size + next_index\n",
      "                    line       238                 if (eos_token_id is not None) and (next_token.item() == eos_token_id):\n",
      "                    line       249                     next_beam_scores[batch_idx, beam_idx] = next_score\n",
      "                    line       250                     next_beam_tokens[batch_idx, beam_idx] = next_token\n",
      "                    line       251                     next_beam_indices[batch_idx, beam_idx] = batch_beam_idx\n",
      "                    line       252                     beam_idx += 1\n",
      "    Modified var:.. beam_idx = 2\n",
      "                    line       255                 if beam_idx == self.group_size:\n",
      "                    line       256                     break\n",
      "                    line       258             if beam_idx < self.group_size:\n",
      "                    line       264             self._done[batch_idx] = self._done[batch_idx] or beam_hyp.is_done(\n",
      "                    line       265                 next_scores[batch_idx].max().item(), cur_len\n",
      "                    line       264             self._done[batch_idx] = self._done[batch_idx] or beam_hyp.is_done(\n",
      "        Starting var:.. self = <transformers.generation_beam_search.BeamHypotheses object>\n",
      "        Starting var:.. best_sum_logprobs = -10.187658309936523\n",
      "        Starting var:.. cur_len = 12\n",
      "                        call       371     def is_done(self, best_sum_logprobs: float, cur_len: int) -> bool:\n",
      "                        line       377         if len(self) < self.num_beams:\n",
      "                        line       379         elif self.early_stopping:\n",
      "                        line       382             cur_score = best_sum_logprobs / cur_len ** self.length_penalty\n",
      "        New var:....... cur_score = -0.8489715258280436\n",
      "                        line       383             ret = self.worst_score >= cur_score\n",
      "        New var:....... ret = True\n",
      "                        line       384             return ret\n",
      "                        return     384             return ret\n",
      "        Return value:.. True\n",
      "                    line       217         for batch_idx, beam_hyp in enumerate(self._beam_hyps):\n",
      "                    line       268         return UserDict(\n",
      "                    line       270                 \"next_beam_scores\": next_beam_scores.view(-1),\n",
      "                    line       271                 \"next_beam_tokens\": next_beam_tokens.view(-1),\n",
      "                    line       272                 \"next_beam_indices\": next_beam_indices.view(-1),\n",
      "                    line       269             {\n",
      "                    line       268         return UserDict(\n",
      "        Source path:... __init__.py\n",
      "        Starting var:.. args = REPR FAILED\n",
      "        Starting var:.. kwargs = {}\n",
      "                        call       981     def __init__(*args, **kwargs):\n",
      "                        line       982         if not args:\n",
      "                        line       985         self, *args = args\n",
      "        Modified var:.. args = [{'next_beam_scores': tensor<(2,), float32, cuda:0, grad>, 'next_beam_tokens': tensor<(2,), int64, cuda:0>, 'next_beam_indices': tensor<(2,), int64, cuda:0>}]\n",
      "        New var:....... self = REPR FAILED\n",
      "                        line       986         if len(args) > 1:\n",
      "                        line       988         if args:\n",
      "                        line       989             dict = args[0]\n",
      "        New var:....... dict = {'next_beam_scores': tensor<(2,), float32, cuda:0, grad>, 'next_beam_tokens': tensor<(2,), int64, cuda:0>, 'next_beam_indices': tensor<(2,), int64, cuda:0>}\n",
      "                        line       997         self.data = {}\n",
      "        Modified var:.. self = {}\n",
      "                        line       998         if dict is not None:\n",
      "                        line       999             self.update(dict)\n",
      "        Modified var:.. self = {'next_beam_scores': tensor([-11.9152, -13.0620], device='cuda:0', grad_fn=<ViewBackward>), 'next_...kens': tensor([3227,  107], device='cuda:0'), 'next_beam_indices': tensor([1, 1], device='cuda:0')}\n",
      "                        line      1000         if kwargs:\n",
      "                        return    1000         if kwargs:\n",
      "        Return value:.. None\n",
      "    Source path:... generation_beam_search.py\n",
      "                    return     268         return UserDict(\n",
      "    Return value:.. {'next_beam_scores': tensor([-11.9152, -13.0620], device='cuda:0', grad_fn=<ViewBackward>), 'next_...kens': tensor([3227,  107], device='cuda:0'), 'next_beam_indices': tensor([1, 1], device='cuda:0')}\n",
      "Source path:... generation_utils.py\n",
      "Modified var:.. beam_outputs = {'next_beam_scores': tensor([-11.9152, -13.0620], device='cuda:0', grad_fn=<ViewBackward>), 'next_...kens': tensor([3227,  107], device='cuda:0'), 'next_beam_indices': tensor([1, 1], device='cuda:0')}\n",
      "                line      1789             beam_scores = beam_outputs[\"next_beam_scores\"]\n",
      "    Source path:... __init__.py\n",
      "    Starting var:.. self = {'next_beam_scores': tensor([-11.9152, -13.0620], device='cuda:0', grad_fn=<ViewBackward>), 'next_...kens': tensor([3227,  107], device='cuda:0'), 'next_beam_indices': tensor([1, 1], device='cuda:0')}\n",
      "    Starting var:.. key = 'next_beam_scores'\n",
      "                    call      1005     def __getitem__(self, key):\n",
      "                    line      1006         if key in self.data:\n",
      "                    line      1007             return self.data[key]\n",
      "                    return    1007             return self.data[key]\n",
      "    Return value:.. tensor<(2,), float32, cuda:0, grad>\n",
      "Source path:... generation_utils.py\n",
      "                line      1790             beam_next_tokens = beam_outputs[\"next_beam_tokens\"]\n",
      "    Source path:... __init__.py\n",
      "    Starting var:.. self = {'next_beam_scores': tensor([-11.9152, -13.0620], device='cuda:0', grad_fn=<ViewBackward>), 'next_...kens': tensor([3227,  107], device='cuda:0'), 'next_beam_indices': tensor([1, 1], device='cuda:0')}\n",
      "    Starting var:.. key = 'next_beam_tokens'\n",
      "                    call      1005     def __getitem__(self, key):\n",
      "                    line      1006         if key in self.data:\n",
      "                    line      1007             return self.data[key]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                    return    1007             return self.data[key]\n",
      "    Return value:.. tensor<(2,), int64, cuda:0>\n",
      "Source path:... generation_utils.py\n",
      "                line      1791             beam_idx = beam_outputs[\"next_beam_indices\"]\n",
      "    Source path:... __init__.py\n",
      "    Starting var:.. self = {'next_beam_scores': tensor([-11.9152, -13.0620], device='cuda:0', grad_fn=<ViewBackward>), 'next_...kens': tensor([3227,  107], device='cuda:0'), 'next_beam_indices': tensor([1, 1], device='cuda:0')}\n",
      "    Starting var:.. key = 'next_beam_indices'\n",
      "                    call      1005     def __getitem__(self, key):\n",
      "                    line      1006         if key in self.data:\n",
      "                    line      1007             return self.data[key]\n",
      "                    return    1007             return self.data[key]\n",
      "    Return value:.. tensor<(2,), int64, cuda:0>\n",
      "Source path:... generation_utils.py\n",
      "                line      1793             input_ids = torch.cat([input_ids[beam_idx, :], beam_next_tokens.unsqueeze(-1)], dim=-1)\n",
      "Modified var:.. input_ids = tensor<(2, 13), int64, cuda:0>\n",
      "                line      1795             cur_len = cur_len + 1\n",
      "Modified var:.. cur_len = 13\n",
      "                line      1797             model_kwargs = self._update_model_kwargs_for_generation(\n",
      "                line      1798                 outputs, model_kwargs, is_encoder_decoder=self.config.is_encoder_decoder\n",
      "                line      1797             model_kwargs = self._update_model_kwargs_for_generation(\n",
      "    Starting var:.. outputs = {'logits': tensor<(2, 1, 96103), float32, cuda:0, grad>, 'past_key_values': ((tensor<(2, 16, 12, 6...float32, cuda:0, grad>)), 'encoder_last_hidden_state': tensor<(2, 6, 1024), float32, cuda:0, grad>}\n",
      "    Starting var:.. model_kwargs = {'use_cache': None, 'attention_mask': tensor<(2, 6), int64, cuda:0>, 'encoder_outputs': {'last_hid...d>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>))}\n",
      "    Starting var:.. is_encoder_decoder = True\n",
      "                    call       511     def _update_model_kwargs_for_generation(\n",
      "                    line       515         if \"past_key_values\" in outputs:\n",
      "                    line       516             model_kwargs[\"past\"] = outputs.past_key_values\n",
      "                    line       525         if \"token_type_ids\" in model_kwargs:\n",
      "                    line       530         if not is_encoder_decoder:\n",
      "                    line       537         return model_kwargs\n",
      "                    return     537         return model_kwargs\n",
      "    Return value:.. {'use_cache': None, 'attention_mask': tensor<(2, 6), int64, cuda:0>, 'encoder_outputs': {'last_hid...d>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>))}\n",
      "                line      1800             if model_kwargs[\"past\"] is not None:\n",
      "                line      1801                 model_kwargs[\"past\"] = self._reorder_cache(model_kwargs[\"past\"], beam_idx)\n",
      "    Source path:... modeling_pegasus.py\n",
      "    Starting var:.. past = ((tensor<(2, 16, 12, 64), float32, cuda:0, grad>, tensor<(2, 16, 12, 64), float32, cuda:0, grad>, ...ad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>))\n",
      "    Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                    call      1333     def _reorder_cache(past, beam_idx):\n",
      "                    line      1334         reordered_past = ()\n",
      "    New var:....... reordered_past = ()\n",
      "                    line      1335         for layer_past in past:\n",
      "    New var:....... layer_past = (tensor<(2, 16, 12, 64), float32, cuda:0, grad>, tensor<(2, 16, 12, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>)\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 12, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 12, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 12, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 12, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 12, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "    Modified var:.. reordered_past = ((tensor<(2, 16, 12, 64), float32, cuda:0, grad>, tensor<(2, 16, 12, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>),)\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 12, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 12, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 12, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 12, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 12, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "    Modified var:.. reordered_past = ((tensor<(2, 16, 12, 64), float32, cuda:0, grad>, tensor<(2, 16, 12, 64), float32, cuda:0, grad>, ...ad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>))\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 12, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 12, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 12, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 12, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 12, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 12, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 12, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 12, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 12, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 12, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 12, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 12, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 12, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 12, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 12, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 12, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 12, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 12, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 12, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 12, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 12, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 12, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 12, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 12, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 12, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 12, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 12, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 12, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 12, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 12, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 12, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 12, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 12, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 12, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 12, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 12, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 12, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 12, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 12, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 12, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 12, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 12, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 12, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 12, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 12, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 12, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 12, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 12, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 12, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 12, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 12, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 12, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 12, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 12, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 12, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 12, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 12, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 12, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 12, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 12, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 12, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 12, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 12, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 12, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 12, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        New var:....... past_state = tensor<(2, 16, 12, 64), float32, cuda:0, grad>\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 12, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 12, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. tensor<(2, 16, 12, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. .0 = <tuple_iterator object>\n",
      "        Starting var:.. past_state = tensor<(2, 16, 12, 64), float32, cuda:0, grad>\n",
      "        Starting var:.. beam_idx = tensor<(2,), int64, cuda:0>\n",
      "                        call      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        line      1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "                        return    1338                 tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
      "        Return value:.. None\n",
      "                    line      1337             reordered_past += (\n",
      "                    line      1335         for layer_past in past:\n",
      "                    line      1340         return reordered_past\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                    return    1340         return reordered_past\n",
      "    Return value:.. ((tensor<(2, 16, 12, 64), float32, cuda:0, grad>, tensor<(2, 16, 12, 64), float32, cuda:0, grad>, ...ad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>, tensor<(2, 16, 6, 64), float32, cuda:0, grad>))\n",
      "Source path:... generation_utils.py\n",
      "                line      1803             if beam_scorer.is_done:\n",
      "    Source path:... generation_beam_search.py\n",
      "    Starting var:.. self = <transformers.generation_beam_search.BeamSearchScorer object>\n",
      "                    call       196     def is_done(self) -> bool:\n",
      "                    line       197         return self._done.all()\n",
      "                    return     197         return self._done.all()\n",
      "    Return value:.. tensor<(), bool, cuda:0>\n",
      "Source path:... generation_utils.py\n",
      "                line      1804                 break\n",
      "                line      1809         sequence_outputs = beam_scorer.finalize(\n",
      "                line      1810             input_ids, beam_scores, next_tokens, next_indices, pad_token_id=pad_token_id, eos_token_id=eos_token_id\n",
      "                line      1809         sequence_outputs = beam_scorer.finalize(\n",
      "    Source path:... generation_beam_search.py\n",
      "    Starting var:.. self = <transformers.generation_beam_search.BeamSearchScorer object>\n",
      "    Starting var:.. input_ids = tensor<(2, 13), int64, cuda:0>\n",
      "    Starting var:.. final_beam_scores = tensor<(2,), float32, cuda:0, grad>\n",
      "    Starting var:.. final_beam_tokens = tensor<(1, 4), int64, cuda:0>\n",
      "    Starting var:.. final_beam_indices = tensor<(1, 4), int64, cuda:0>\n",
      "    Starting var:.. pad_token_id = 0\n",
      "    Starting var:.. eos_token_id = 1\n",
      "                    call       276     def finalize(\n",
      "                    line       285         batch_size = len(self._beam_hyps)\n",
      "    New var:....... batch_size = 1\n",
      "                    line       288         for batch_idx, beam_hyp in enumerate(self._beam_hyps):\n",
      "    New var:....... batch_idx = 0\n",
      "    New var:....... beam_hyp = <transformers.generation_beam_search.BeamHypotheses object>\n",
      "                    line       289             if self._done[batch_idx]:\n",
      "                    line       290                 continue\n",
      "                    line       288         for batch_idx, beam_hyp in enumerate(self._beam_hyps):\n",
      "                    line       301         sent_lengths = input_ids.new(batch_size * self.num_beam_hyps_to_keep)\n",
      "    New var:....... sent_lengths = tensor<(1,), int64, cuda:0>\n",
      "                    line       302         best = []\n",
      "    New var:....... best = []\n",
      "                    line       303         best_scores = torch.zeros(batch_size * self.num_beam_hyps_to_keep, device=self.device, dtype=torch.float32)\n",
      "    New var:....... best_scores = tensor<(1,), float32, cuda:0>\n",
      "                    line       306         for i, beam_hyp in enumerate(self._beam_hyps):\n",
      "    New var:....... i = 0\n",
      "                    line       307             sorted_hyps = sorted(beam_hyp.beams, key=lambda x: x[0])\n",
      "        Starting var:.. x = (-0.37353289127349854, tensor<(6,), int64, cuda:0>)\n",
      "                        call       307             sorted_hyps = sorted(beam_hyp.beams, key=lambda x: x[0])\n",
      "                        line       307             sorted_hyps = sorted(beam_hyp.beams, key=lambda x: x[0])\n",
      "                        return     307             sorted_hyps = sorted(beam_hyp.beams, key=lambda x: x[0])\n",
      "        Return value:.. -0.37353289127349854\n",
      "        Starting var:.. x = (-0.8489715258280436, tensor<(12,), int64, cuda:0>)\n",
      "                        call       307             sorted_hyps = sorted(beam_hyp.beams, key=lambda x: x[0])\n",
      "                        line       307             sorted_hyps = sorted(beam_hyp.beams, key=lambda x: x[0])\n",
      "                        return     307             sorted_hyps = sorted(beam_hyp.beams, key=lambda x: x[0])\n",
      "        Return value:.. -0.8489715258280436\n",
      "    New var:....... sorted_hyps = [(-0.8489715258280436, tensor<(12,), int64, cuda:0>), (-0.37353289127349854, tensor<(6,), int64, cuda:0>)]\n",
      "                    line       308             for j in range(self.num_beam_hyps_to_keep):\n",
      "    New var:....... j = 0\n",
      "                    line       309                 best_hyp_tuple = sorted_hyps.pop()\n",
      "    Modified var:.. sorted_hyps = [(-0.8489715258280436, tensor<(12,), int64, cuda:0>)]\n",
      "    New var:....... best_hyp_tuple = (-0.37353289127349854, tensor<(6,), int64, cuda:0>)\n",
      "                    line       310                 best_score = best_hyp_tuple[0]\n",
      "    New var:....... best_score = -0.37353289127349854\n",
      "                    line       311                 best_hyp = best_hyp_tuple[1]\n",
      "    New var:....... best_hyp = tensor<(6,), int64, cuda:0>\n",
      "                    line       312                 sent_lengths[self.num_beam_hyps_to_keep * i + j] = len(best_hyp)\n",
      "        Source path:... tensor.py\n",
      "        Starting var:.. self = tensor<(6,), int64, cuda:0>\n",
      "                        call       567     def __len__(self):\n",
      "                        line       568         relevant_args = (self,)\n",
      "        New var:....... relevant_args = (tensor<(6,), int64, cuda:0>,)\n",
      "                        line       569         from torch.overrides import has_torch_function, handle_torch_function\n",
      "        New var:....... has_torch_function = <function has_torch_function>\n",
      "        New var:....... handle_torch_function = <function handle_torch_function>\n",
      "                        line       570         if type(self) is not Tensor and has_torch_function(relevant_args):\n",
      "                        line       572         if self.dim() == 0:\n",
      "                        line       574         return self.shape[0]\n",
      "                        return     574         return self.shape[0]\n",
      "        Return value:.. 6\n",
      "    Source path:... generation_beam_search.py\n",
      "                    line       315                 best.append(best_hyp)\n",
      "    Modified var:.. best = [tensor<(6,), int64, cuda:0>]\n",
      "                    line       316                 best_scores[i * self.num_beam_hyps_to_keep + j] = best_score\n",
      "                    line       308             for j in range(self.num_beam_hyps_to_keep):\n",
      "                    line       306         for i, beam_hyp in enumerate(self._beam_hyps):\n",
      "                    line       319         sent_max_len = min(sent_lengths.max().item() + 1, self.max_length)\n",
      "    New var:....... sent_max_len = 7\n",
      "                    line       320         decoded: torch.LongTensor = input_ids.new(batch_size * self.num_beam_hyps_to_keep, sent_max_len)\n",
      "    New var:....... decoded = tensor<(1, 7), int64, cuda:0>\n",
      "                    line       322         if sent_lengths.min().item() != sent_lengths.max().item():\n",
      "                    line       327         for i, hypo in enumerate(best):\n",
      "    New var:....... hypo = tensor<(6,), int64, cuda:0>\n",
      "                    line       328             decoded[i, : sent_lengths[i]] = hypo\n",
      "                    line       329             if sent_lengths[i] < self.max_length:\n",
      "        Source path:... tensor.py\n",
      "        Starting var:.. args = (tensor<(), int64, cuda:0>, 60)\n",
      "        Starting var:.. kwargs = {}\n",
      "        Starting var:.. f = <method 'lt' of 'torch._C._TensorBase' objects>\n",
      "        Starting var:.. wrapped = <function _TensorBase.lt>\n",
      "                        call        22     def wrapped(*args, **kwargs):\n",
      "                        line        23         from torch.overrides import has_torch_function, handle_torch_function\n",
      "        New var:....... has_torch_function = <function has_torch_function>\n",
      "        New var:....... handle_torch_function = <function handle_torch_function>\n",
      "                        line        24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):\n",
      "                        line        26         try:\n",
      "                        line        27             return f(*args, **kwargs)\n",
      "                        return      27             return f(*args, **kwargs)\n",
      "        Return value:.. tensor<(), bool, cuda:0>\n",
      "    Source path:... generation_beam_search.py\n",
      "                    line       330                 decoded[i, sent_lengths[i]] = eos_token_id\n",
      "                    line       327         for i, hypo in enumerate(best):\n",
      "                    line       331         return UserDict(\n",
      "                    line       333                 \"sequences\": decoded,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                    line       334                 \"sequence_scores\": best_scores,\n",
      "                    line       332             {\n",
      "                    line       331         return UserDict(\n",
      "        Source path:... __init__.py\n",
      "        Starting var:.. args = REPR FAILED\n",
      "        Starting var:.. kwargs = {}\n",
      "                        call       981     def __init__(*args, **kwargs):\n",
      "                        line       982         if not args:\n",
      "                        line       985         self, *args = args\n",
      "        Modified var:.. args = [{'sequences': tensor<(1, 7), int64, cuda:0>, 'sequence_scores': tensor<(1,), float32, cuda:0>}]\n",
      "        New var:....... self = REPR FAILED\n",
      "                        line       986         if len(args) > 1:\n",
      "                        line       988         if args:\n",
      "                        line       989             dict = args[0]\n",
      "        New var:....... dict = {'sequences': tensor<(1, 7), int64, cuda:0>, 'sequence_scores': tensor<(1,), float32, cuda:0>}\n",
      "                        line       997         self.data = {}\n",
      "        Modified var:.. self = {}\n",
      "                        line       998         if dict is not None:\n",
      "                        line       999             self.update(dict)\n",
      "        Modified var:.. self = {'sequences': tensor([[   0, 3227,  117,  161,  442,  107,    1]], device='cuda:0'), 'sequence_scores': tensor([-0.3735], device='cuda:0')}\n",
      "                        line      1000         if kwargs:\n",
      "                        return    1000         if kwargs:\n",
      "        Return value:.. None\n",
      "    Source path:... generation_beam_search.py\n",
      "                    return     331         return UserDict(\n",
      "    Return value:.. {'sequences': tensor([[   0, 3227,  117,  161,  442,  107,    1]], device='cuda:0'), 'sequence_scores': tensor([-0.3735], device='cuda:0')}\n",
      "Source path:... generation_utils.py\n",
      "New var:....... sequence_outputs = {'sequences': tensor([[   0, 3227,  117,  161,  442,  107,    1]], device='cuda:0'), 'sequence_scores': tensor([-0.3735], device='cuda:0')}\n",
      "                line      1813         if return_dict_in_generate:\n",
      "                line      1814             if not output_scores:\n",
      "                line      1816             if self.config.is_encoder_decoder:\n",
      "                line      1817                 return BeamSearchEncoderDecoderOutput(\n",
      "                line      1818                     sequences=sequence_outputs[\"sequences\"],\n",
      "    Source path:... __init__.py\n",
      "    Starting var:.. self = {'sequences': tensor([[   0, 3227,  117,  161,  442,  107,    1]], device='cuda:0'), 'sequence_scores': tensor([-0.3735], device='cuda:0')}\n",
      "    Starting var:.. key = 'sequences'\n",
      "                    call      1005     def __getitem__(self, key):\n",
      "                    line      1006         if key in self.data:\n",
      "                    line      1007             return self.data[key]\n",
      "                    return    1007             return self.data[key]\n",
      "    Return value:.. tensor<(1, 7), int64, cuda:0>\n",
      "Source path:... generation_utils.py\n",
      "                line      1819                     sequences_scores=sequence_outputs[\"sequence_scores\"],\n",
      "    Source path:... __init__.py\n",
      "    Starting var:.. self = {'sequences': tensor([[   0, 3227,  117,  161,  442,  107,    1]], device='cuda:0'), 'sequence_scores': tensor([-0.3735], device='cuda:0')}\n",
      "    Starting var:.. key = 'sequence_scores'\n",
      "                    call      1005     def __getitem__(self, key):\n",
      "                    line      1006         if key in self.data:\n",
      "                    line      1007             return self.data[key]\n",
      "                    return    1007             return self.data[key]\n",
      "    Return value:.. tensor<(1,), float32, cuda:0>\n",
      "Source path:... generation_utils.py\n",
      "                line      1820                     scores=scores,\n",
      "                line      1821                     encoder_attentions=encoder_attentions,\n",
      "                line      1822                     encoder_hidden_states=encoder_hidden_states,\n",
      "                line      1823                     decoder_attentions=decoder_attentions,\n",
      "                line      1824                     cross_attentions=cross_attentions,\n",
      "                line      1825                     decoder_hidden_states=decoder_hidden_states,\n",
      "                line      1817                 return BeamSearchEncoderDecoderOutput(\n",
      "    Source path:... <string>\n",
      "    Starting var:.. self = {}\n",
      "    Starting var:.. sequences = tensor<(1, 7), int64, cuda:0>\n",
      "    Starting var:.. sequences_scores = tensor<(1,), float32, cuda:0>\n",
      "    Starting var:.. scores = (tensor<(2, 96103), float32, cuda:0, grad>, tensor<(2, 96103), float32, cuda:0, grad>, tensor<(2, ...uda:0, grad>, tensor<(2, 96103), float32, cuda:0, grad>, tensor<(2, 96103), float32, cuda:0, grad>)\n",
      "    Starting var:.. encoder_attentions = None\n",
      "    Starting var:.. encoder_hidden_states = None\n",
      "    Starting var:.. decoder_attentions = None\n",
      "    Starting var:.. cross_attentions = None\n",
      "    Starting var:.. decoder_hidden_states = None\n",
      "                    call         2 # Copyright 2020 The Google AI Language Team Authors, Facebook AI Research authors and The HuggingFace Inc. team.\n",
      "                    line         3 # Copyright (c) 2020, NVIDIA CORPORATION.  All rights reserved.\n",
      "        Source path:... file_utils.py\n",
      "        Starting var:.. self = {}\n",
      "        Starting var:.. name = 'sequences'\n",
      "        Starting var:.. value = tensor<(1, 7), int64, cuda:0>\n",
      "        Starting var:.. __class__ = <class 'transformers.file_utils.ModelOutput'>\n",
      "                        call      1620     def __setattr__(self, name, value):\n",
      "                        line      1621         if name in self.keys() and value is not None:\n",
      "                        line      1624         super().__setattr__(name, value)\n",
      "                        return    1624         super().__setattr__(name, value)\n",
      "        Return value:.. None\n",
      "    Source path:... <string>\n",
      "                    line         4 #\n",
      "        Source path:... file_utils.py\n",
      "        Starting var:.. self = {}\n",
      "        Starting var:.. name = 'sequences_scores'\n",
      "        Starting var:.. value = tensor<(1,), float32, cuda:0>\n",
      "        Starting var:.. __class__ = <class 'transformers.file_utils.ModelOutput'>\n",
      "                        call      1620     def __setattr__(self, name, value):\n",
      "                        line      1621         if name in self.keys() and value is not None:\n",
      "                        line      1624         super().__setattr__(name, value)\n",
      "                        return    1624         super().__setattr__(name, value)\n",
      "        Return value:.. None\n",
      "    Source path:... <string>\n",
      "                    line         5 # Licensed under the Apache License, Version 2.0 (the \"License\");\n",
      "        Source path:... file_utils.py\n",
      "        Starting var:.. self = {}\n",
      "        Starting var:.. name = 'scores'\n",
      "        Starting var:.. value = (tensor<(2, 96103), float32, cuda:0, grad>, tensor<(2, 96103), float32, cuda:0, grad>, tensor<(2, ...uda:0, grad>, tensor<(2, 96103), float32, cuda:0, grad>, tensor<(2, 96103), float32, cuda:0, grad>)\n",
      "        Starting var:.. __class__ = <class 'transformers.file_utils.ModelOutput'>\n",
      "                        call      1620     def __setattr__(self, name, value):\n",
      "                        line      1621         if name in self.keys() and value is not None:\n",
      "                        line      1624         super().__setattr__(name, value)\n",
      "                        return    1624         super().__setattr__(name, value)\n",
      "        Return value:.. None\n",
      "    Source path:... <string>\n",
      "                    line         6 # you may not use this file except in compliance with the License.\n",
      "        Source path:... file_utils.py\n",
      "        Starting var:.. self = {}\n",
      "        Starting var:.. name = 'encoder_attentions'\n",
      "        Starting var:.. value = None\n",
      "        Starting var:.. __class__ = <class 'transformers.file_utils.ModelOutput'>\n",
      "                        call      1620     def __setattr__(self, name, value):\n",
      "                        line      1621         if name in self.keys() and value is not None:\n",
      "                        line      1624         super().__setattr__(name, value)\n",
      "                        return    1624         super().__setattr__(name, value)\n",
      "        Return value:.. None\n",
      "    Source path:... <string>\n",
      "                    line         7 # You may obtain a copy of the License at\n",
      "        Source path:... file_utils.py\n",
      "        Starting var:.. self = {}\n",
      "        Starting var:.. name = 'encoder_hidden_states'\n",
      "        Starting var:.. value = None\n",
      "        Starting var:.. __class__ = <class 'transformers.file_utils.ModelOutput'>\n",
      "                        call      1620     def __setattr__(self, name, value):\n",
      "                        line      1621         if name in self.keys() and value is not None:\n",
      "                        line      1624         super().__setattr__(name, value)\n",
      "                        return    1624         super().__setattr__(name, value)\n",
      "        Return value:.. None\n",
      "    Source path:... <string>\n",
      "                    line         8 #\n",
      "        Source path:... file_utils.py\n",
      "        Starting var:.. self = {}\n",
      "        Starting var:.. name = 'decoder_attentions'\n",
      "        Starting var:.. value = None\n",
      "        Starting var:.. __class__ = <class 'transformers.file_utils.ModelOutput'>\n",
      "                        call      1620     def __setattr__(self, name, value):\n",
      "                        line      1621         if name in self.keys() and value is not None:\n",
      "                        line      1624         super().__setattr__(name, value)\n",
      "                        return    1624         super().__setattr__(name, value)\n",
      "        Return value:.. None\n",
      "    Source path:... <string>\n",
      "                    line         9 #     http://www.apache.org/licenses/LICENSE-2.0\n",
      "        Source path:... file_utils.py\n",
      "        Starting var:.. self = {}\n",
      "        Starting var:.. name = 'cross_attentions'\n",
      "        Starting var:.. value = None\n",
      "        Starting var:.. __class__ = <class 'transformers.file_utils.ModelOutput'>\n",
      "                        call      1620     def __setattr__(self, name, value):\n",
      "                        line      1621         if name in self.keys() and value is not None:\n",
      "                        line      1624         super().__setattr__(name, value)\n",
      "                        return    1624         super().__setattr__(name, value)\n",
      "        Return value:.. None\n",
      "    Source path:... <string>\n",
      "                    line        10 #\n",
      "        Source path:... file_utils.py\n",
      "        Starting var:.. self = {}\n",
      "        Starting var:.. name = 'decoder_hidden_states'\n",
      "        Starting var:.. value = None\n",
      "        Starting var:.. __class__ = <class 'transformers.file_utils.ModelOutput'>\n",
      "                        call      1620     def __setattr__(self, name, value):\n",
      "                        line      1621         if name in self.keys() and value is not None:\n",
      "                        line      1624         super().__setattr__(name, value)\n",
      "                        return    1624         super().__setattr__(name, value)\n",
      "        Return value:.. None\n",
      "    Source path:... <string>\n",
      "                    line        11 # Unless required by applicable law or agreed to in writing, software\n",
      "        Source path:... file_utils.py\n",
      "        Starting var:.. self = {}\n",
      "                        call      1561     def __post_init__(self):\n",
      "                        line      1562         class_fields = fields(self)\n",
      "        New var:....... class_fields = (Field(name='sequences',type=<class 'torch.LongTensor'>,default=None,default_factory=<dataclasses....E object>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),_field_type=_FIELD))\n",
      "                        line      1565         assert len(class_fields), f\"{self.__class__.__name__} has no fields.\"\n",
      "                        line      1566         assert all(\n",
      "                        line      1567             field.default is None for field in class_fields[1:]\n",
      "                        line      1566         assert all(\n",
      "                        line      1570         first_field = getattr(self, class_fields[0].name)\n",
      "        New var:....... first_field = tensor<(1, 7), int64, cuda:0>\n",
      "                        line      1571         other_fields_are_none = all(getattr(self, field.name) is None for field in class_fields[1:])\n",
      "        New var:....... other_fields_are_none = False\n",
      "                        line      1573         if other_fields_are_none and not is_tensor(first_field):\n",
      "                        line      1596             for field in class_fields:\n",
      "        New var:....... field = Field(name='sequences',type=<class 'torch.LongTensor'>,default=None,default_factory=<dataclasses._...PE object>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),_field_type=_FIELD)\n",
      "                        line      1597                 v = getattr(self, field.name)\n",
      "        New var:....... v = tensor<(1, 7), int64, cuda:0>\n",
      "                        line      1598                 if v is not None:\n",
      "                        line      1599                     self[field.name] = v\n",
      "        Modified var:.. self = {'sequences': tensor<(1, 7), int64, cuda:0>}\n",
      "                        line      1596             for field in class_fields:\n",
      "        Modified var:.. field = Field(name='sequences_scores',type=typing.Union[torch.FloatTensor, NoneType],default=None,default_...PE object>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),_field_type=_FIELD)\n",
      "                        line      1597                 v = getattr(self, field.name)\n",
      "        Modified var:.. v = tensor<(1,), float32, cuda:0>\n",
      "                        line      1598                 if v is not None:\n",
      "                        line      1599                     self[field.name] = v\n",
      "        Modified var:.. self = {'sequences': tensor<(1, 7), int64, cuda:0>, 'sequences_scores': tensor<(1,), float32, cuda:0>}\n",
      "                        line      1596             for field in class_fields:\n",
      "        Modified var:.. field = Field(name='scores',type=typing.Union[typing.Tuple[torch.FloatTensor], NoneType],default=None,defa...PE object>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),_field_type=_FIELD)\n",
      "                        line      1597                 v = getattr(self, field.name)\n",
      "        Modified var:.. v = (tensor<(2, 96103), float32, cuda:0, grad>, tensor<(2, 96103), float32, cuda:0, grad>, tensor<(2, ...uda:0, grad>, tensor<(2, 96103), float32, cuda:0, grad>, tensor<(2, 96103), float32, cuda:0, grad>)\n",
      "                        line      1598                 if v is not None:\n",
      "                        line      1599                     self[field.name] = v\n",
      "        Modified var:.. self = {'sequences': tensor<(1, 7), int64, cuda:0>, 'sequences_scores': tensor<(1,), float32, cuda:0>, 's...da:0, grad>, tensor<(2, 96103), float32, cuda:0, grad>, tensor<(2, 96103), float32, cuda:0, grad>)}\n",
      "                        line      1596             for field in class_fields:\n",
      "        Modified var:.. field = Field(name='encoder_attentions',type=typing.Union[typing.Tuple[torch.FloatTensor], NoneType],defau...PE object>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),_field_type=_FIELD)\n",
      "                        line      1597                 v = getattr(self, field.name)\n",
      "        Modified var:.. v = None\n",
      "                        line      1598                 if v is not None:\n",
      "                        line      1596             for field in class_fields:\n",
      "        Modified var:.. field = Field(name='encoder_hidden_states',type=typing.Union[typing.Tuple[torch.FloatTensor], NoneType],de...PE object>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),_field_type=_FIELD)\n",
      "                        line      1597                 v = getattr(self, field.name)\n",
      "                        line      1598                 if v is not None:\n",
      "                        line      1596             for field in class_fields:\n",
      "        Modified var:.. field = Field(name='decoder_attentions',type=typing.Union[typing.Tuple[typing.Tuple[torch.FloatTensor]], N...PE object>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),_field_type=_FIELD)\n",
      "                        line      1597                 v = getattr(self, field.name)\n",
      "                        line      1598                 if v is not None:\n",
      "                        line      1596             for field in class_fields:\n",
      "        Modified var:.. field = Field(name='cross_attentions',type=typing.Union[typing.Tuple[typing.Tuple[torch.FloatTensor]], Non...PE object>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),_field_type=_FIELD)\n",
      "                        line      1597                 v = getattr(self, field.name)\n",
      "                        line      1598                 if v is not None:\n",
      "                        line      1596             for field in class_fields:\n",
      "        Modified var:.. field = Field(name='decoder_hidden_states',type=typing.Union[typing.Tuple[typing.Tuple[torch.FloatTensor]]...PE object>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),_field_type=_FIELD)\n",
      "                        line      1597                 v = getattr(self, field.name)\n",
      "                        line      1598                 if v is not None:\n",
      "                        line      1596             for field in class_fields:\n",
      "                        return    1596             for field in class_fields:\n",
      "        Return value:.. None\n",
      "    Source path:... <string>\n",
      "    Modified var:.. self = {'sequences': tensor<(1, 7), int64, cuda:0>, 'sequences_scores': tensor<(1,), float32, cuda:0>, 's...da:0, grad>, tensor<(2, 96103), float32, cuda:0, grad>, tensor<(2, 96103), float32, cuda:0, grad>)}\n",
      "                    return      11 # Unless required by applicable law or agreed to in writing, software\n",
      "    Return value:.. None\n",
      "Source path:... generation_utils.py\n",
      "                return    1817                 return BeamSearchEncoderDecoderOutput(\n",
      "Return value:.. {'sequences': tensor<(1, 7), int64, cuda:0>, 'sequences_scores': tensor<(1,), float32, cuda:0>, 's...da:0, grad>, tensor<(2, 96103), float32, cuda:0, grad>, tensor<(2, 96103), float32, cuda:0, grad>)}\n",
      "Elapsed time: 00:00:44.895727\n"
     ]
    }
   ],
   "source": [
    "input_text=\"hello my name is Tom\"\n",
    "num_return_sequences=1\n",
    "num_beams=2\n",
    "return_probs=True\n",
    "batch = pp_tokenizer(input_text, truncation=True, padding='longest', return_tensors=\"pt\").to(device)\n",
    "generated = pp_model.generate2(**batch, return_dict_in_generate=True, output_scores=True,\n",
    "                              num_return_sequences=num_return_sequences,\n",
    "                                num_beams=num_beams,\n",
    "                                num_beam_groups=1,\n",
    "                                diversity_penalty=0,\n",
    "                                temperature=1.5, \n",
    "                              length_penalty=1)\n",
    "\n",
    "# Score: score = sum_logprobs / (hyp.shape[-1] ** self.length_penalty)\n",
    "# gradient gets removed (i think) by the line \n",
    "# beam_hyp.add(\n",
    "#   input_ids[batch_beam_idx].clone(),\n",
    "#   next_score.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.max(\n",
      "values=tensor([-2.2412, -4.3012], device='cuda:0', grad_fn=<MaxBackward0>),\n",
      "indices=tensor([  1, 125], device='cuda:0'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-0.3070, -0.5892], device='cuda:0', grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=generated['scores'][5]\n",
    "print(x.max(1))\n",
    "x.max(1).values / (len(generated['scores']) ** 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.5.0'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformers.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-10.1877, -11.9152], device='cuda:0', grad_fn=<MaxBackward0>)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁Tom', '▁is', '▁my', '▁name', '.']\n",
      "[3227, 117, 161, 442, 107, 1]\n"
     ]
    }
   ],
   "source": [
    "tgt_text = pp_tokenizer.batch_decode(generated.sequences, skip_special_tokens=True)\n",
    "print(pp_tokenizer.tokenize(tgt_text[0]))\n",
    "print(pp_tokenizer.encode(tgt_text[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BeamSearchEncoderDecoderOutput(sequences=tensor([[   0, 3227,  117,  161,  442,  107,    1]], device='cuda:0'), sequences_scores=tensor([-0.5345], device='cuda:0'), scores=(tensor([[-1.3439e+01, -7.4424e+00, -1.3252e+01,  ..., -1.3211e+01,\n",
       "         -1.4638e+01, -1.3537e+01],\n",
       "        [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "         -1.0000e+09, -1.0000e+09]], device='cuda:0', grad_fn=<AddBackward0>), tensor([[-15.5012,  -9.3269, -15.3885,  ..., -15.2806, -16.5083, -15.2270],\n",
       "        [-15.4444, -12.1908, -14.3813,  ..., -15.8672, -15.1434, -17.1512]],\n",
       "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[-16.5940,  -9.6609, -16.3711,  ..., -16.8337, -17.5857, -18.3755],\n",
       "        [-17.1933, -14.4977, -17.3700,  ..., -16.0694, -18.6977, -20.8976]],\n",
       "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[-16.4108, -10.8331, -16.1417,  ..., -17.0277, -19.3644, -19.6051],\n",
       "        [-16.7516, -13.8706, -16.3067,  ..., -18.6184, -19.7848, -18.4986]],\n",
       "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[-15.1181,  -4.0021, -15.1088,  ..., -14.8143, -17.1200, -16.4294],\n",
       "        [-17.0799,  -8.7235, -17.2435,  ..., -16.9944, -18.6935, -17.6231]],\n",
       "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[-15.8145,  -2.2412, -15.9799,  ..., -15.8631, -15.9474, -15.7329],\n",
       "        [-17.1781,  -9.9892, -17.4299,  ..., -17.7495, -18.4152, -18.9498]],\n",
       "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[-17.7951, -12.8669, -17.5973,  ..., -17.8044, -17.7813, -20.3570],\n",
       "        [-21.8533, -18.2705, -21.7452,  ..., -22.5638, -23.0072, -23.9783]],\n",
       "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[-18.8066, -14.4911, -19.1018,  ..., -17.4928, -20.1688, -21.1021],\n",
       "        [-20.1733, -11.6720, -19.5005,  ..., -20.3499, -22.2123, -23.1372]],\n",
       "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[-18.5903, -11.0614, -17.9596,  ..., -18.4252, -20.4403, -22.0225],\n",
       "        [-22.5761, -19.3569, -22.4808,  ..., -23.3218, -24.9530, -24.8354]],\n",
       "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[-21.1511, -12.4512, -21.2865,  ..., -20.5096, -22.2291, -20.8949],\n",
       "        [-23.2880, -17.8568, -22.8372,  ..., -23.9645, -25.3855, -27.1204]],\n",
       "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[-21.5622, -11.5183, -21.1957,  ..., -20.9271, -22.6352, -23.1086],\n",
       "        [-25.7294, -17.1983, -23.9045,  ..., -28.7667, -27.9310, -23.2960]],\n",
       "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[-23.8061, -10.1877, -23.9268,  ..., -23.8773, -23.8718, -23.7802],\n",
       "        [-22.5766, -12.9709, -22.5671,  ..., -23.4863, -23.3790, -22.2032]],\n",
       "       device='cuda:0', grad_fn=<AddBackward0>)), encoder_attentions=None, encoder_hidden_states=None, decoder_attentions=None, cross_attentions=None, decoder_hidden_states=None)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([-10.1877, -11.9152], device='cuda:0', grad_fn=<MaxBackward0>),\n",
       "indices=tensor([   1, 3227], device='cuda:0'))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4965853037914095"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(-7e-01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BeamSearchEncoderDecoderOutput(sequences=tensor([[  0, 600, 442, 117, 112, 208, 107,   1]], device='cuda:0'), sequences_scores=tensor([-0.7592], device='cuda:0'), scores=(tensor([[-1.3111e+01, -7.3406e+00, -1.2861e+01,  ..., -1.1740e+01,\n",
       "         -1.4253e+01, -1.4704e+01],\n",
       "        [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "         -1.0000e+09, -1.0000e+09]], device='cuda:0', grad_fn=<AddBackward0>), tensor([[-16.4262, -13.5976, -16.2702,  ..., -16.8354, -18.7062, -18.8218],\n",
       "        [-15.1518, -11.4697, -14.6758,  ..., -17.2132, -16.4186, -17.0657]],\n",
       "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[-14.4046,  -8.1447, -14.3312,  ..., -13.1408, -14.7156, -16.0423],\n",
       "        [-16.8748, -10.4540, -16.4042,  ..., -18.1801, -20.0519, -18.0784]],\n",
       "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[-13.6286,  -7.3730, -13.5444,  ..., -17.7188, -14.8766, -14.5535],\n",
       "        [-19.3907, -12.9705, -19.0755,  ..., -18.0790, -20.3148, -20.5254]],\n",
       "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[-13.8037,  -6.2306, -13.5897,  ..., -13.5254, -14.6855, -14.6925],\n",
       "        [-19.0522, -11.2394, -18.7212,  ..., -18.1934, -19.1359, -19.4110]],\n",
       "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[-15.5325,  -4.0283, -15.7884,  ..., -15.2176, -17.1408, -15.3182],\n",
       "        [-17.6072,  -6.6679, -17.9966,  ..., -17.3745, -19.2237, -16.7076]],\n",
       "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[-16.8730,  -3.6011, -17.3682,  ..., -16.4137, -17.7808, -16.9634],\n",
       "        [-17.2629,  -8.5726, -18.0556,  ..., -16.2124, -18.1173, -17.5850]],\n",
       "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[-17.8938, -10.5418, -17.7939,  ..., -18.1626, -18.2853, -20.2212],\n",
       "        [-21.1158, -11.9903, -21.7874,  ..., -21.5642, -23.7897, -24.5016]],\n",
       "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[-19.0096, -10.2241, -18.9750,  ..., -20.8422, -23.0351, -23.1777],\n",
       "        [-17.9479, -11.3632, -18.3507,  ..., -16.4217, -18.9476, -19.4932]],\n",
       "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[-20.5099, -10.3764, -20.5305,  ..., -19.7903, -23.9965, -23.9639],\n",
       "        [-20.1006, -10.4982, -20.1158,  ..., -19.0608, -23.5525, -21.6893]],\n",
       "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[-21.4107,  -9.4184, -21.4097,  ..., -22.5307, -22.9288, -21.7403],\n",
       "        [-22.1086, -15.4044, -21.8313,  ..., -21.4147, -24.9675, -22.8598]],\n",
       "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[-22.6035,  -8.9826, -22.8311,  ..., -21.6836, -22.9211, -21.7193],\n",
       "        [-24.7492, -12.4753, -24.9278,  ..., -26.4672, -27.6568, -25.8758]],\n",
       "       device='cuda:0', grad_fn=<AddBackward0>)), encoder_attentions=None, encoder_hidden_states=None, decoder_attentions=None, cross_attentions=None, decoder_hidden_states=None)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "AutoTokenizer,\n",
    "AutoModelForCausalLM,\n",
    "LogitsProcessorList,\n",
    "MinLengthLogitsProcessor,\n",
    ")\n",
    "logits_processor = LogitsProcessorList([\n",
    "    MinLengthLogitsProcessor(15, eos_token_id=pp_model.config.eos_token_id),\n",
    "])\n",
    "decoder_start_token_id = pp_model.config.bos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def create_paraphrase_dataset(batch, cname_input, cname_output, num_beams=32,\n",
    "                              num_return_sequences=32): \n",
    "    \"\"\"Create paraphrases for each example in the batch. Then repeat the other fields \n",
    "        so that the resulting datase has the same length as the number of paraphrases. \n",
    "        Key assumption is \n",
    "        that the same number of paraphrases is created for each example.\n",
    "        batch: a dict of examples used by the `map` function from the dataset\n",
    "        cname_input: What column to create paraphrases of \n",
    "        cname_output: What to call the column of paraphrases\n",
    "        other parameters - passed to get_paraphrases. \"\"\"\n",
    "    \n",
    "    # Generate paraphrases. \n",
    "    # This can be later extended to add diversity or so on. \n",
    "    #set_trace()\n",
    "    pp_l,probs = get_paraphrases(batch[cname_input], num_beams=num_beams,\n",
    "        num_return_sequences=num_return_sequences)\n",
    "    \n",
    "    # To return paraphrases as a list of lists for batch input (not done here but might need later)\n",
    "    #     split_into_sublists = lambda l,n: [l[i:i + n] for i in range(0, len(l), n)]\n",
    "    #     pp_l = split_into_sublists(pp_l, n_seed_seqs)\n",
    "    batch[cname_output] = pp_l \n",
    "    batch[\"probs\"] = probs.to('cpu').numpy()\n",
    "    \n",
    "    # Repeat each entry in all other columns `num_return_sequences` times so they are the same length\n",
    "    # as the paraphrase column\n",
    "    # Only works if the same number of paraphrases is generated for each phrase. \n",
    "    # Else try something like \n",
    "        # for o in zip(*batch.values()):\n",
    "        #     d = dict(zip(batch.keys(), o))\n",
    "        #     get_paraphrases(batch[cname_input],num_return_sequences=n_seed_seqs,num_beams=n_seed_seqs)\n",
    "        #     for k,v in d.items(): \n",
    "        #       return_d[k] += v if k == 'text' else [v for o in range(n_paraphrases)]\n",
    "        # return return_d\n",
    "    return_d = defaultdict(list) \n",
    "    repeat_each_item_n_times = lambda l,n: [o for o in l for i in range(n)]\n",
    "    for k in batch.keys(): \n",
    "        if   k == cname_output: return_d[k] = batch[cname_output]\n",
    "        elif k == \"probs\"     : return_d[k] = batch[\"probs\"]\n",
    "        else:                   return_d[k] = repeat_each_item_n_times(batch[k], num_return_sequences)\n",
    "    return return_d "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Generate paraphrase dataset\n",
    "num_beams = 10\n",
    "num_return_sequences = 3\n",
    "cname_input = 'text' # which text column to paraphrase\n",
    "cname_output= cname_input + '_pp'\n",
    "date = '20210825'\n",
    "fname = path_cache + '_rt_train'+ date + '_' + str(num_return_sequences)\n",
    "if os.path.exists(fname):  \n",
    "    ds_pp = datasets.load_from_disk(fname)\n",
    "else:\n",
    "    ds_pp = train.shard(200, 0, contiguous=True)\n",
    "    # Have to call with batched=True\n",
    "    # Need to set a batch size otherwise will run out of memory on the GPU card. \n",
    "    # 64 seems to work well \n",
    "    ds_pp = ds_pp.map(\n",
    "        lambda x: create_paraphrase_dataset(x, \n",
    "            num_beams=num_beams, num_return_sequences=num_return_sequences,\n",
    "            cname_input=cname_input, cname_output=cname_output),\n",
    "        batched=True, batch_size=4) \n",
    "    ds_pp.save_to_disk(fname)\n",
    "    gc.collect(); torch.cuda.empty_cache() # free up most of the GPU memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def get_vm_scores(ds_pp, cname_orig, cname_pp, cname_label='label', \n",
    "                  use_metric=False, monitor=False): \n",
    "    \"\"\"Get victim model preds+probs for the paraphrase dataset.\n",
    "    \"\"\"\n",
    "    assert vm_model.training == False  # checks that model is in eval mode \n",
    "    if use_metric: \n",
    "        metric_d = {}\n",
    "        metric_d['orig'],metric_d['pp'] = load_metric('accuracy'),load_metric('accuracy')\n",
    "    orig_probs_l,pp_probs_l = [],[]\n",
    "    if monitor: monitor = Monitor(2)  # track GPU usage and memory\n",
    "    \n",
    "    def get_vm_preds(x): \n",
    "        \"\"\"Get predictions for a vector x (here a vector of documents/text). \n",
    "        Works for a sentiment-analysis dataset (needs to be adjusted for NLI tasks)\"\"\"\n",
    "        inputs = vm_tokenizer(x, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "        inputs.to(device)\n",
    "        outputs = vm_model(**inputs, labels=labels)\n",
    "        probs = outputs.logits.softmax(1).cpu()\n",
    "        preds = probs.argmax(1)\n",
    "        return probs, preds\n",
    "       \n",
    "    print(\"Getting victim model predictions for both original and paraphrased text.\")\n",
    "    dl = DataLoader(ds_pp, batch_size=batch_size, shuffle=False, \n",
    "                    num_workers=n_wkrs, pin_memory=True)\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(dl): \n",
    "            if i % 50 == 0 : print(\"Now processing batch\", i, \"out of\", len(dl))\n",
    "            labels,orig,pp = data['label'].to(device),data[cname_orig],data[cname_pp]\n",
    "            orig_probs, orig_preds = get_vm_preds(orig)            \n",
    "            pp_probs,   pp_preds   = get_vm_preds(pp)    \n",
    "            orig_probs_l.append(orig_probs); pp_probs_l.append(pp_probs)\n",
    "            if use_metric: \n",
    "                metric_d['orig'].add_batch(predictions=orig_preds, references=labels)\n",
    "                metric_d['pp'].add_batch(  predictions=pp_preds,   references=labels)\n",
    "    if monitor: monitor.stop()\n",
    "    def list2tensor(l): return torch.cat(l)\n",
    "    orig_probs_t,pp_probs_t = list2tensor(orig_probs_l),list2tensor(pp_probs_l)\n",
    "    if use_metric: return orig_probs_t, pp_probs_t, metric_d\n",
    "    else:          return orig_probs_t, pp_probs_t, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "cname_orig = cname_input\n",
    "cname_pp = cname_output\n",
    "cname_label = 'label'\n",
    "print_metric = True\n",
    "fname = path_cache + 'results_df_'+ date + \"_\" + str(num_return_sequences) + \".csv\"\n",
    "if os.path.exists(fname):    results_df = pd.read_csv(fname)\n",
    "else: \n",
    "    #sim_score_t = generate_sim_scores()\n",
    "    orig_probs_t,pp_probs_t,metric_d = get_vm_scores(ds_pp, cname_orig, \n",
    "                                                     cname_pp, cname_label,\n",
    "                                                     monitor=True, use_metric=print_metric)\n",
    "    if print_metric: \n",
    "        print(\"orig vm accuracy:\",       metric_d['orig'].compute())\n",
    "        print(\"paraphrase vm accuracy:\", metric_d['pp'].compute())\n",
    "    vm_orig_scores  = torch.tensor([r[idx] for idx,r in zip(ds_pp[cname_label], orig_probs_t)])\n",
    "    vm_pp_scores    = torch.tensor([r[idx] for idx,r in zip(ds_pp[cname_label], pp_probs_t)])\n",
    "    results_df = pd.DataFrame({\n",
    "                  cname_orig: ds_pp[cname_orig],\n",
    "                  cname_pp: ds_pp[cname_pp],\n",
    "   #               'sim_score': sim_score_t,\n",
    "                  'label_true': ds_pp[cname_label], \n",
    "                  'label_vm_orig': orig_probs_t.argmax(1),\n",
    "                  'label_vm_pp': pp_probs_t.argmax(1),\n",
    "                  'vm_orig_truelabel': vm_orig_scores,             \n",
    "                  'vm_pp_truelabel': vm_pp_scores,\n",
    "                  'vm_truelabel_change': vm_orig_scores - vm_pp_scores,\n",
    "                  'vm_orig_class0': orig_probs_t[:,0], \n",
    "                  'vm_orig_class1': orig_probs_t[:,1], \n",
    "                  'vm_pp_class0': pp_probs_t[:,0], \n",
    "                  'vm_pp_class1': pp_probs_t[:,1], \n",
    "                  })\n",
    "#    results_df['vm_truelabel_change_X_sim_score'] = results_df['vm_truelabel_change'] * results_df['sim_score']\n",
    "    results_df.to_csv(fname, index_label = 'idx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training loop pseudocode\n",
    "\n",
    "The REINFORCE estimator is $$ \\nabla_\\theta J(\\theta) \\approx \\sum_{s=1}^S  R(x,x'_s) \\nabla \\log p(x'_s|x,\\theta)$$\n",
    "\n",
    "**Non-batched version (one example), stochastic gradient descent**  \n",
    "Inputs: train, n_pp=1, vm, ppm, $\\alpha = 5e^{-5}$ (saw this rate for $\\alpha$ somewhere  \n",
    "Set eval_mode=true for vm, eval_mode = false for ppm  \n",
    "Freeze all layers of ppm except last 6  \n",
    "Shuffle traning dataset  \n",
    "\n",
    "Loop: take one row from train\n",
    "* generate large UNIVERSE list of paraphrases `pp_l` (e.g. 128) from 'text' column using ppm\n",
    "* extract sequence scores from this list to get a vector of probabilities `pp_probs`\n",
    "* take `log` of `pp_probs` and store in `pp_logprobs`\n",
    "* pick S paraphrases from `pp_l` to get `pp_s`. \n",
    "* Take the corresponding entries from `pp_logprobs`. Get gradient of each entry by looking at .grad attribute. Sum them up and store in a variable `gradsum` \n",
    "* for each `pp` (i.e. $x'_s$) in `pp_s`:\n",
    "    * get reward using `reward_fn_onepp(x, pp)`. $r=R(x,x'_s) = f(x)_y - f(x'_s)_y + \\lambda SS(x, x'_s)$\n",
    "* Sum up these rewards to get `rewardsum` and add to `gradsum` to get `nablaJ`\n",
    "* Update parameters of paraphrase model with $\\theta_{t+1} = \\theta_t + \\alpha \\nabla_\\theta J(\\theta)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "batch_size = 1\n",
    "alpha = 5e-5\n",
    "n_pp = 1\n",
    "pp_l_sz = 64\n",
    "S = 20\n",
    "# Paraphrase settings\n",
    "num_beams = pp_l_sz\n",
    "num_beam_groups = 1\n",
    "diversity_penalty = 0.\n",
    "temperature = 1.5\n",
    "### Setup\n",
    "vm_model.eval()\n",
    "pp_model.train()\n",
    "train_small = train.shard(100, 0, contiguous=True)  # small training set for testing purposes\n",
    "train_small_dl = DataLoader(train_small, batch_size=batch_size, \n",
    "                            shuffle=True, num_workers=n_wkrs)\n",
    "dl = train_small_dl\n",
    "## Layer freezing \n",
    "# Unfreeze last 2 layers of the base model decoder\n",
    "# Not sure if decoder layer norm should be unfrozen or not, but it appears after the\n",
    "#   other parameters in the module ordering, so let's include it for now\n",
    "# Also unfreeze the linear head.  This isn't stored in the base model but rather tacked on top\n",
    "#   and will be fine-tuned for summarisation. \n",
    "layer_list = ['decoder.layers.14', 'decoder.layers.15', 'decoder.layer_norm'] \n",
    "for i, (name,param) in enumerate(pp_model.base_model.named_parameters()): \n",
    "    if np.any([o in name for o in layer_list]):   param.requires_grad = True\n",
    "    else:                                         param.requires_grad = False\n",
    "for param in pp_model.lm_head.parameters():       param.requires_grad = True\n",
    "# For some reason this seems to be excluded\n",
    "for param in pp_model.base_model.shared.parameters(): param.requires_grad=False \n",
    "### For checking the grad status of the layers\n",
    "# for i, (name, param) in enumerate(pp_model.base_model.named_parameters()): print(i, name, param.requires_grad)\n",
    "# for i, (name, param) in enumerate(pp_model.lm_head.named_parameters()):    print(i, name, param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 out of 86\n",
      "> \u001b[0;32m<ipython-input-30-b95c66eb06e5>\u001b[0m(7)\u001b[0;36mget_paraphrases\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m      5 \u001b[0;31m    else we return just a list of pp's. \"\"\"\n",
      "\u001b[0m\u001b[0;32m      6 \u001b[0;31m    \u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m----> 7 \u001b[0;31m    \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpp_tokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'longest'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      8 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      9 \u001b[0;31m    translated = pp_model.generate2(**batch, num_beams=num_beams, \n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m<ipython-input-30-b95c66eb06e5>\u001b[0m(9)\u001b[0;36mget_paraphrases\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m      7 \u001b[0;31m    \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpp_tokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'longest'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      8 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m----> 9 \u001b[0;31m    translated = pp_model.generate2(**batch, num_beams=num_beams, \n",
      "\u001b[0m\u001b[0;32m     10 \u001b[0;31m        \u001b[0mnum_return_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_return_sequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtemperature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     11 \u001b[0;31m        \u001b[0mnum_beam_groups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_beam_groups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiversity_penalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdiversity_penalty\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m<ipython-input-30-b95c66eb06e5>\u001b[0m(10)\u001b[0;36mget_paraphrases\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m      8 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      9 \u001b[0;31m    translated = pp_model.generate2(**batch, num_beams=num_beams, \n",
      "\u001b[0m\u001b[0;32m---> 10 \u001b[0;31m        \u001b[0mnum_return_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_return_sequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtemperature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     11 \u001b[0;31m        \u001b[0mnum_beam_groups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_beam_groups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiversity_penalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdiversity_penalty\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     12 \u001b[0;31m        \u001b[0mreturn_dict_in_generate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_scores\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> \n",
      "> \u001b[0;32m<ipython-input-30-b95c66eb06e5>\u001b[0m(11)\u001b[0;36mget_paraphrases\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m      9 \u001b[0;31m    translated = pp_model.generate2(**batch, num_beams=num_beams, \n",
      "\u001b[0m\u001b[0;32m     10 \u001b[0;31m        \u001b[0mnum_return_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_return_sequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtemperature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 11 \u001b[0;31m        \u001b[0mnum_beam_groups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_beam_groups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiversity_penalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdiversity_penalty\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     12 \u001b[0;31m        \u001b[0mreturn_dict_in_generate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_scores\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     13 \u001b[0;31m    )\n",
      "\u001b[0m\n",
      "ipdb> \n",
      "> \u001b[0;32m<ipython-input-30-b95c66eb06e5>\u001b[0m(12)\u001b[0;36mget_paraphrases\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     10 \u001b[0;31m        \u001b[0mnum_return_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_return_sequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtemperature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     11 \u001b[0;31m        \u001b[0mnum_beam_groups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_beam_groups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiversity_penalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdiversity_penalty\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 12 \u001b[0;31m        \u001b[0mreturn_dict_in_generate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_scores\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     13 \u001b[0;31m    )\n",
      "\u001b[0m\u001b[0;32m     14 \u001b[0;31m    \u001b[0;31m# Sequence scores won't add to 1 across the generated paraphrases, so here we normalise them.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> \n",
      "> \u001b[0;32m<ipython-input-30-b95c66eb06e5>\u001b[0m(9)\u001b[0;36mget_paraphrases\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m      7 \u001b[0;31m    \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpp_tokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'longest'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      8 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m----> 9 \u001b[0;31m    translated = pp_model.generate2(**batch, num_beams=num_beams, \n",
      "\u001b[0m\u001b[0;32m     10 \u001b[0;31m        \u001b[0mnum_return_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_return_sequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtemperature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     11 \u001b[0;31m        \u001b[0mnum_beam_groups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_beam_groups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiversity_penalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdiversity_penalty\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> \n",
      "> \u001b[0;32m<ipython-input-30-b95c66eb06e5>\u001b[0m(16)\u001b[0;36mget_paraphrases\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     14 \u001b[0;31m    \u001b[0;31m# Sequence scores won't add to 1 across the generated paraphrases, so here we normalise them.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     15 \u001b[0;31m    \u001b[0;31m# We also need to take exp for them to work.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 16 \u001b[0;31m    \u001b[0mseq_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranslated\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequences_scores\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranslated\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequences_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     17 \u001b[0;31m    \u001b[0mtgt_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpp_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranslated\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     18 \u001b[0;31m    \u001b[0;32mif\u001b[0m \u001b[0mreturn_probs\u001b[0m\u001b[0;34m:\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mtgt_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_probs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> translated\n",
      "BeamSearchEncoderDecoderOutput(sequences=tensor([[   0,  398,  126,  ...,    0,    0,    0],\n",
      "        [   0,  398,  126,  ...,    0,    0,    0],\n",
      "        [   0,  398,  126,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [   0,  398,  126,  ...,    0,    0,    0],\n",
      "        [   0,  398,  126,  ...,    0,    0,    0],\n",
      "        [   0,  398,  126,  ..., 1645,  107,    1]], device='cuda:0'), sequences_scores=tensor([-1.0977, -1.1258, -1.1276, -1.1318, -1.1334, -1.1465, -1.1466, -1.1472,\n",
      "        -1.1528, -1.1530, -1.1549, -1.1556, -1.1588, -1.1599, -1.1605, -1.1626,\n",
      "        -1.1636, -1.1675, -1.1680, -1.1688, -1.1739, -1.1778, -1.1788, -1.1799,\n",
      "        -1.1802, -1.1804, -1.1817, -1.1862, -1.1868, -1.1875, -1.1901, -1.1963,\n",
      "        -1.1964, -1.1968, -1.1971, -1.1994, -1.2024, -1.2038, -1.2101, -1.2133,\n",
      "        -1.2138, -1.2143, -1.2145, -1.2154, -1.2174, -1.2185, -1.2201, -1.2213,\n",
      "        -1.2226, -1.2243, -1.2325, -1.2331, -1.2344, -1.2349, -1.2378, -1.2397,\n",
      "        -1.2412, -1.2413, -1.2414, -1.2415, -1.2437, -1.2470, -1.2477, -1.2488],\n",
      "       device='cuda:0'), scores=(tensor([[-1.3150e+01, -1.0775e+01, -1.3008e+01,  ..., -1.5826e+01,\n",
      "         -1.4548e+01, -1.3874e+01],\n",
      "        [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
      "         -1.0000e+09, -1.0000e+09],\n",
      "        [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
      "         -1.0000e+09, -1.0000e+09],\n",
      "        ...,\n",
      "        [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
      "         -1.0000e+09, -1.0000e+09],\n",
      "        [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
      "         -1.0000e+09, -1.0000e+09],\n",
      "        [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
      "         -1.0000e+09, -1.0000e+09]], device='cuda:0', grad_fn=<AddBackward0>), tensor([[-15.5589, -14.4239, -14.7609,  ..., -20.6249, -14.9298, -19.0487],\n",
      "        [-15.2942, -14.4140, -14.6236,  ..., -18.2064, -17.2438, -15.0161],\n",
      "        [-15.6772, -13.3665, -15.6077,  ..., -19.9398, -15.6245, -16.4424],\n",
      "        ...,\n",
      "        [-21.9152, -22.5853, -22.0627,  ..., -23.7152, -23.6725, -22.2512],\n",
      "        [-20.6113, -17.9430, -19.8752,  ..., -25.4483, -18.9932, -21.5735],\n",
      "        [-22.7716, -20.7431, -21.8850,  ..., -25.0319, -23.3937, -26.3446]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[-16.4601, -13.9366, -15.5713,  ..., -19.3258, -16.6169, -17.5690],\n",
      "        [-17.1475, -16.1101, -17.1907,  ..., -21.5710, -19.1920, -17.4470],\n",
      "        [-18.2632, -17.4910, -18.0196,  ..., -20.2599, -20.6171, -22.8239],\n",
      "        ...,\n",
      "        [-20.8741, -18.6191, -20.4356,  ..., -24.4780, -21.2642, -24.5100],\n",
      "        [-21.2125, -18.2266, -21.1500,  ..., -20.7593, -23.6967, -21.1769],\n",
      "        [-19.5662, -14.1880, -19.1022,  ..., -22.7785, -20.1849, -22.3005]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[-17.3108, -14.8472, -17.2408,  ..., -19.6597, -17.3629, -18.8586],\n",
      "        [-17.4788, -13.2435, -16.9401,  ..., -19.2103, -18.1464, -18.1092],\n",
      "        [-19.1075, -18.2431, -18.3218,  ..., -23.4106, -19.0408, -19.8322],\n",
      "        ...,\n",
      "        [-21.4089, -20.9613, -20.5338,  ..., -24.2985, -22.3343, -21.5512],\n",
      "        [-21.7786, -21.6290, -21.2065,  ..., -24.7707, -22.2967, -23.9033],\n",
      "        [-20.6269, -16.3659, -20.9881,  ..., -21.7899, -21.2798, -22.8024]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[-17.2019, -14.3449, -17.2242,  ..., -20.9230, -17.7209, -18.0461],\n",
      "        [-18.7212, -17.3915, -19.0912,  ..., -19.8633, -21.3094, -17.7078],\n",
      "        [-18.3772, -17.4199, -17.9111,  ..., -19.9991, -20.4132, -20.9167],\n",
      "        ...,\n",
      "        [-22.8425, -20.1401, -22.8223,  ..., -24.8852, -24.8288, -21.5243],\n",
      "        [-21.4981, -21.9901, -21.2981,  ..., -23.3701, -23.6013, -22.7206],\n",
      "        [-21.6017, -20.8501, -21.0611,  ..., -24.6251, -22.9586, -24.7634]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[-18.4377, -16.6221, -17.7710,  ..., -19.8911, -20.1482, -20.0015],\n",
      "        [-20.0609, -16.9226, -19.3276,  ..., -23.6441, -20.8425, -22.4605],\n",
      "        [-18.3966, -16.1159, -18.2242,  ..., -20.4923, -18.5946, -18.2563],\n",
      "        ...,\n",
      "        [-21.7924, -19.0513, -21.0239,  ..., -24.7983, -22.1640, -25.6564],\n",
      "        [-22.5173, -18.1145, -21.6667,  ..., -23.6535, -23.8139, -25.2835],\n",
      "        [-22.4721, -18.8856, -22.2071,  ..., -22.2600, -23.7206, -21.5511]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[-19.0671, -15.4572, -18.8838,  ..., -21.7729, -19.4174, -20.7510],\n",
      "        [-19.2936, -17.1668, -18.8880,  ..., -20.9599, -21.0446, -19.2201],\n",
      "        [-19.3036, -16.7288, -18.9214,  ..., -24.5685, -17.9289, -20.4784],\n",
      "        ...,\n",
      "        [-21.9480, -20.6931, -21.3181,  ..., -24.5566, -22.3719, -21.5951],\n",
      "        [-22.1085, -21.7778, -21.3518,  ..., -25.5708, -20.6735, -28.3420],\n",
      "        [-22.5784, -20.7754, -22.2998,  ..., -26.3650, -23.7221, -21.3678]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[-18.5799, -16.0510, -18.7631,  ..., -22.5215, -19.1355, -20.1728],\n",
      "        [-20.8067, -18.2225, -19.7011,  ..., -23.2347, -20.7948, -20.2456],\n",
      "        [-20.8783, -20.6261, -19.7623,  ..., -24.8794, -21.6791, -23.8074],\n",
      "        ...,\n",
      "        [-22.8315, -21.3857, -22.3960,  ..., -24.0856, -24.7065, -21.6042],\n",
      "        [-23.5058, -20.8293, -23.1548,  ..., -27.6003, -23.9555, -26.0023],\n",
      "        [-22.7671, -20.4168, -21.8903,  ..., -24.1013, -26.0702, -23.3775]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[-19.3351, -16.7604, -18.8718,  ..., -22.5834, -19.0179, -20.0555],\n",
      "        [-20.7069, -19.2143, -20.3160,  ..., -21.6270, -21.7435, -21.5682],\n",
      "        [-21.5970, -18.6741, -20.4582,  ..., -23.6926, -22.8532, -22.0447],\n",
      "        ...,\n",
      "        [-23.8462, -20.9999, -22.5064,  ..., -25.4906, -25.1223, -25.7962],\n",
      "        [-23.6078, -20.7811, -23.5311,  ..., -25.7667, -25.0419, -24.4871],\n",
      "        [-23.1204, -20.4217, -22.5693,  ..., -25.9273, -23.4075, -24.0786]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[-21.8654, -18.6686, -21.3645,  ..., -25.8223, -22.9154, -26.0779],\n",
      "        [-21.3960, -16.8696, -21.1992,  ..., -22.4537, -20.9612, -21.5414],\n",
      "        [-21.8444, -18.5073, -22.0156,  ..., -22.8657, -23.7075, -20.0071],\n",
      "        ...,\n",
      "        [-24.1461, -20.5035, -23.4859,  ..., -24.1276, -26.5453, -27.9147],\n",
      "        [-24.5698, -21.5089, -24.8668,  ..., -27.3832, -26.9485, -24.7493],\n",
      "        [-25.2024, -24.1082, -24.2966,  ..., -30.6977, -26.5431, -24.3141]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[-20.3011, -17.8084, -19.9235,  ..., -19.9378, -21.6833, -21.4491],\n",
      "        [-21.4080, -17.1586, -21.5441,  ..., -23.0345, -22.8190, -19.6351],\n",
      "        [-20.6879, -18.9366, -20.0096,  ..., -22.4110, -22.6820, -21.4668],\n",
      "        ...,\n",
      "        [-23.8625, -22.6806, -23.2406,  ..., -28.6940, -25.2146, -25.4751],\n",
      "        [-24.7039, -23.3533, -24.0890,  ..., -29.1564, -25.2136, -26.2882],\n",
      "        [-25.4753, -26.4380, -25.3740,  ..., -30.9096, -27.2012, -26.3691]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[-22.9481, -20.4473, -22.6515,  ..., -25.4876, -23.6487, -22.1908],\n",
      "        [-21.6427, -18.6190, -22.0504,  ..., -23.8813, -22.6047, -22.7775],\n",
      "        [-22.3901, -21.0511, -21.7633,  ..., -23.7179, -22.5159, -23.5873],\n",
      "        ...,\n",
      "        [-24.9155, -20.6059, -24.8764,  ..., -27.2352, -25.5928, -25.9219],\n",
      "        [-25.6860, -24.2222, -25.0534,  ..., -29.3467, -27.3133, -23.2389],\n",
      "        [-24.9243, -21.7846, -24.9206,  ..., -27.7271, -25.1639, -22.5196]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[-23.6485, -19.5961, -22.6286,  ..., -25.3248, -24.8046, -24.3264],\n",
      "        [-21.9012, -18.6294, -22.1046,  ..., -25.2030, -21.2632, -23.3180],\n",
      "        [-22.6549, -18.0530, -21.3913,  ..., -26.0186, -23.2350, -23.1181],\n",
      "        ...,\n",
      "        [-26.2193, -24.2859, -25.8914,  ..., -26.9682, -26.7978, -26.5710],\n",
      "        [-25.2285, -21.1841, -25.3006,  ..., -28.3289, -24.8222, -24.7124],\n",
      "        [-25.9269, -24.0894, -25.3481,  ..., -28.8348, -27.4217, -24.5582]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[-23.1217, -17.9832, -22.4198,  ..., -24.0839, -21.1905, -24.3884],\n",
      "        [-23.7239, -20.0050, -23.3665,  ..., -27.8283, -24.2781, -26.4791],\n",
      "        [-23.9326, -20.3312, -23.7167,  ..., -27.4875, -24.4497, -26.3418],\n",
      "        ...,\n",
      "        [-25.8504, -21.7727, -25.3692,  ..., -26.1636, -26.9883, -26.6976],\n",
      "        [-27.0945, -23.0715, -27.4623,  ..., -29.2324, -26.9853, -30.3963],\n",
      "        [-26.1305, -21.7490, -26.0360,  ..., -31.0908, -26.7700, -25.6170]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[-22.1572, -16.9191, -22.0862,  ..., -24.6969, -22.9178, -23.0855],\n",
      "        [-23.3495, -19.4168, -23.5615,  ..., -25.0546, -25.0157, -21.7256],\n",
      "        [-23.8063, -19.8732, -23.8317,  ..., -23.8873, -25.1568, -24.2557],\n",
      "        ...,\n",
      "        [-26.9306, -25.2776, -25.9303,  ..., -31.3111, -28.2576, -26.6603],\n",
      "        [-27.6614, -22.7591, -27.3749,  ..., -27.5433, -29.7903, -27.3446],\n",
      "        [-26.8809, -23.7006, -26.7260,  ..., -28.7447, -28.5380, -26.0160]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[-23.9346, -19.1105, -23.4830,  ..., -27.4302, -24.0362, -21.6287],\n",
      "        [-24.3917, -22.1924, -23.8657,  ..., -28.5479, -26.7277, -25.6785],\n",
      "        [-24.2733, -19.5058, -23.9201,  ..., -25.7954, -26.8594, -22.9858],\n",
      "        ...,\n",
      "        [-25.7387, -22.8427, -25.0834,  ..., -30.0731, -26.6947, -27.5717],\n",
      "        [-27.2010, -22.4570, -27.8185,  ..., -29.9887, -28.3847, -26.1537],\n",
      "        [-26.6232, -20.4733, -26.1247,  ..., -28.9939, -27.4120, -27.2862]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[-23.9159, -19.0431, -23.7110,  ..., -24.5854, -26.2026, -22.9756],\n",
      "        [-24.3992, -18.9832, -24.1600,  ..., -26.8851, -24.1549, -25.3433],\n",
      "        [-25.5025, -21.7399, -24.9835,  ..., -29.1679, -27.3987, -27.9738],\n",
      "        ...,\n",
      "        [-26.4977, -19.0970, -26.4015,  ..., -27.7399, -27.4694, -26.0167],\n",
      "        [-25.7106, -18.2318, -26.1317,  ..., -27.9068, -26.7391, -25.5079],\n",
      "        [-27.9311, -24.9198, -26.6274,  ..., -27.9846, -28.6606, -30.2134]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[-25.1434, -22.0825, -24.6413,  ..., -25.9934, -27.4266, -23.7164],\n",
      "        [-25.4515, -21.6897, -24.6613,  ..., -28.6760, -26.0415, -27.2406],\n",
      "        [-25.3007, -17.3536, -25.1936,  ..., -26.1454, -26.0315, -25.5135],\n",
      "        ...,\n",
      "        [-27.8168, -24.2092, -27.2952,  ..., -34.5401, -31.1018, -29.0061],\n",
      "        [-27.5504, -24.5338, -27.0796,  ..., -32.6227, -28.4645, -26.7484],\n",
      "        [-27.0780, -23.6325, -26.7221,  ..., -30.7758, -26.7929, -29.8245]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[-25.0905, -22.4561, -24.6624,  ..., -29.2002, -26.3367, -27.5567],\n",
      "        [-25.3481, -17.4475, -25.1625,  ..., -27.5092, -26.4548, -24.8649],\n",
      "        [-26.1575, -22.6640, -25.7874,  ..., -31.3004, -28.2637, -27.5255],\n",
      "        ...,\n",
      "        [-28.6632, -24.2911, -27.8728,  ..., -32.3037, -30.1438, -30.7354],\n",
      "        [-27.9643, -22.8776, -27.9810,  ..., -30.9421, -29.0290, -28.1727],\n",
      "        [-27.2704, -20.1480, -27.2329,  ..., -27.9616, -28.0952, -26.1790]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[-26.1460, -24.8348, -25.6320,  ..., -29.3625, -26.3539, -28.5844],\n",
      "        [-27.4727, -25.5236, -26.6546,  ..., -31.6624, -28.4116, -28.8076],\n",
      "        [-26.1130, -19.2016, -26.1855,  ..., -27.9100, -27.1897, -25.5983],\n",
      "        ...,\n",
      "        [-28.6327, -14.8787, -29.1369,  ..., -29.6715, -29.8432, -28.0775],\n",
      "        [-28.6603, -23.3786, -28.5988,  ..., -29.5857, -29.1327, -30.3050],\n",
      "        [-29.4257, -26.6932, -29.8950,  ..., -32.3590, -32.0340, -29.7280]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[-26.7716, -22.9906, -27.4361,  ..., -29.3094, -27.7098, -26.9190],\n",
      "        [-26.6822, -23.6901, -26.0420,  ..., -30.6622, -27.7454, -26.6651],\n",
      "        [-28.2654, -25.3264, -27.3515,  ..., -34.4527, -30.4623, -30.8448],\n",
      "        ...,\n",
      "        [-29.4599, -25.6644, -28.8857,  ..., -33.6668, -30.3105, -30.2590],\n",
      "        [-29.3827, -25.7948, -29.3902,  ..., -34.3693, -32.2414, -29.6804],\n",
      "        [-29.6917, -26.7964, -28.8337,  ..., -33.1040, -30.3439, -30.7816]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[-27.5711, -25.6328, -26.6056,  ..., -32.2644, -29.1254, -27.8840],\n",
      "        [-27.0030, -24.5103, -26.0327,  ..., -33.1603, -28.8884, -28.4239],\n",
      "        [-28.0298, -23.9683, -27.7466,  ..., -29.7685, -29.4683, -28.8730],\n",
      "        ...,\n",
      "        [-30.1483, -15.9793, -30.3997,  ..., -31.1331, -32.0265, -30.2860],\n",
      "        [-29.9531, -25.6107, -29.9712,  ..., -32.0801, -31.5552, -29.9695],\n",
      "        [-30.4444, -26.7021, -29.7321,  ..., -31.3722, -32.1088, -29.6667]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[-27.5047, -25.6254, -27.5016,  ..., -33.6702, -29.3696, -27.9482],\n",
      "        [-28.0330, -24.9929, -27.6233,  ..., -35.9015, -31.9331, -28.2845],\n",
      "        [-27.7689, -22.9708, -27.0459,  ..., -34.6029, -31.8874, -31.4259],\n",
      "        ...,\n",
      "        [-30.8209, -26.7243, -30.4613,  ..., -37.3930, -33.9812, -31.8579],\n",
      "        [-31.4301, -27.6511, -30.8728,  ..., -41.3760, -37.1769, -35.5109],\n",
      "        [-31.7680, -27.3723, -31.1767,  ..., -34.7572, -31.8151, -31.9477]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[-28.0281, -22.8152, -28.4553,  ..., -30.6299, -28.9705, -26.9184],\n",
      "        [-29.2087, -25.1240, -28.3533,  ..., -35.5827, -34.6404, -31.9296],\n",
      "        [-28.6604, -25.2411, -28.2360,  ..., -34.7977, -34.9905, -31.3982],\n",
      "        ...,\n",
      "        [-30.1903, -23.9516, -29.2255,  ..., -34.7172, -33.6676, -31.3165],\n",
      "        [-31.3196, -25.8600, -32.0585,  ..., -36.3978, -33.6917, -31.3285],\n",
      "        [-29.7622, -24.8845, -29.4530,  ..., -33.5653, -29.6812, -29.9573]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[-28.2016, -23.1226, -28.3217,  ..., -29.7362, -28.2268, -28.6732],\n",
      "        [-29.2772, -23.7687, -29.0806,  ..., -32.4186, -30.5580, -27.8546],\n",
      "        [-28.9017, -23.0879, -28.7454,  ..., -31.1753, -29.9970, -27.7155],\n",
      "        ...,\n",
      "        [-31.7712, -26.7689, -31.3174,  ..., -39.5910, -35.1678, -36.1186],\n",
      "        [-30.7971, -26.7451, -31.3592,  ..., -34.3343, -32.1315, -30.7901],\n",
      "        [-30.4584, -23.8092, -29.4265,  ..., -35.2847, -34.0294, -30.8079]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[-28.9502, -24.1105, -29.0885,  ..., -34.6239, -34.1768, -29.6643],\n",
      "        [-29.1664, -23.5062, -29.3854,  ..., -31.2329, -30.1628, -30.7198],\n",
      "        [-29.9046, -23.3065, -30.3963,  ..., -34.1520, -31.8778, -31.5170],\n",
      "        ...,\n",
      "        [-32.1792, -25.0028, -30.6216,  ..., -36.9270, -37.2174, -33.0166],\n",
      "        [-31.5712, -29.4905, -31.2596,  ..., -38.5435, -34.5780, -33.7748],\n",
      "        [-32.0360, -24.3879, -30.4757,  ..., -39.6212, -35.6802, -34.0540]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[-30.2611, -25.0425, -30.2920,  ..., -32.7364, -31.2083, -31.7037],\n",
      "        [-30.7936, -25.1299, -31.0330,  ..., -35.6706, -32.4644, -34.0554],\n",
      "        [-30.1110, -16.2380, -30.4654,  ..., -30.5758, -30.6592, -30.4879],\n",
      "        ...,\n",
      "        [-32.4688, -18.7292, -32.9886,  ..., -34.1042, -34.5765, -32.5005],\n",
      "        [-30.9314, -25.2661, -30.8630,  ..., -34.9116, -31.8464, -33.1766],\n",
      "        [-35.5366, -29.1771, -34.8332,  ..., -39.0512, -36.4429, -41.6866]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[-30.0737, -24.0344, -29.6043,  ..., -35.0957, -31.2904, -33.0221],\n",
      "        [-29.0715, -19.6608, -29.7871,  ..., -31.6871, -31.5979, -31.7110],\n",
      "        [-29.4695, -19.5092, -29.6338,  ..., -31.0894, -31.3662, -31.7302],\n",
      "        ...,\n",
      "        [-32.0964, -22.6077, -32.5027,  ..., -34.0446, -33.9772, -34.3486],\n",
      "        [-33.1866, -24.7980, -33.5888,  ..., -39.6480, -36.9227, -35.6416],\n",
      "        [-32.5372, -22.8834, -33.2288,  ..., -34.7424, -33.7958, -35.2654]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[-29.3962, -19.8957, -30.2391,  ..., -32.1469, -32.3339, -31.0471],\n",
      "        [-30.8217, -24.2014, -30.7022,  ..., -35.0537, -32.4396, -34.6715],\n",
      "        [-29.8977, -16.9648, -30.1824,  ..., -30.7238, -30.7336, -29.9331],\n",
      "        ...,\n",
      "        [-33.8002, -29.1073, -34.2250,  ..., -38.7936, -36.6321, -35.9535],\n",
      "        [-34.3514, -29.2025, -33.8561,  ..., -38.3762, -35.5460, -42.2228],\n",
      "        [-33.6552, -26.2474, -33.7245,  ..., -37.0668, -34.8985, -35.9777]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[-29.7151, -16.6793, -30.0486,  ..., -30.0347, -30.0390, -30.1237],\n",
      "        [-29.9557, -20.2918, -30.3968,  ..., -30.7111, -30.7522, -31.2755],\n",
      "        [-30.7491, -20.6985, -31.3026,  ..., -33.5425, -33.0600, -33.3618],\n",
      "        ...,\n",
      "        [-33.0070, -23.1750, -33.4191,  ..., -35.9361, -35.2050, -35.0376],\n",
      "        [-32.6274, -26.5734, -32.3762,  ..., -36.6924, -34.1361, -35.2398],\n",
      "        [-33.3735, -24.5888, -33.5524,  ..., -36.8693, -35.1805, -35.6366]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[-31.2821, -24.6380, -31.1837,  ..., -36.5628, -32.7028, -34.0573],\n",
      "        [-31.2484, -17.6800, -31.4570,  ..., -31.4275, -31.7715, -31.5368],\n",
      "        [-32.1523, -26.0755, -31.8596,  ..., -36.8331, -34.3582, -33.6011],\n",
      "        ...,\n",
      "        [-33.7332, -25.1724, -33.9653,  ..., -35.5337, -34.8360, -35.9655],\n",
      "        [-35.9323, -30.1155, -34.7706,  ..., -42.3157, -38.6999, -42.1016],\n",
      "        [-34.2913, -20.9166, -34.5071,  ..., -34.5937, -34.8234, -34.4270]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[-31.0846, -22.6012, -31.7588,  ..., -33.1158, -33.8427, -33.9813],\n",
      "        [-30.8265, -21.1086, -31.2488,  ..., -32.9374, -33.0459, -32.4722],\n",
      "        [-31.1873, -22.6113, -31.4914,  ..., -33.4257, -32.6784, -32.7610],\n",
      "        ...,\n",
      "        [-34.3970, -27.7316, -34.2380,  ..., -38.5912, -36.7549, -37.1445],\n",
      "        [-35.3199, -28.0988, -35.1809,  ..., -37.6211, -36.8104, -38.2404],\n",
      "        [-34.0100, -28.5151, -33.9040,  ..., -36.9620, -34.6383, -34.5025]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[-32.0530, -18.4621, -32.1852,  ..., -31.9668, -32.5383, -32.1783],\n",
      "        [-31.9437, -18.5597, -32.3901,  ..., -33.1700, -33.3766, -32.3366],\n",
      "        [-31.8317, -21.8301, -32.3572,  ..., -34.8084, -34.3079, -33.3125],\n",
      "        ...,\n",
      "        [-35.2897, -21.7513, -35.5793,  ..., -34.7700, -35.4464, -35.4903],\n",
      "        [-36.3172, -28.4991, -35.8400,  ..., -42.3259, -39.8944, -42.9029],\n",
      "        [-36.5684, -30.1976, -36.2223,  ..., -39.8877, -36.8089, -42.7613]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[-32.4932, -18.9385, -32.7599,  ..., -32.8264, -33.1794, -32.4579],\n",
      "        [-32.2876, -23.0131, -32.6799,  ..., -33.6431, -33.8597, -34.0789],\n",
      "        [-32.7536, -19.7157, -32.7719,  ..., -32.8551, -33.0497, -33.6439],\n",
      "        ...,\n",
      "        [-36.6517, -29.7483, -36.3466,  ..., -41.0372, -39.6285, -41.2446],\n",
      "        [-36.4915, -22.7466, -36.8105,  ..., -36.9726, -36.9005, -36.8005],\n",
      "        [-38.2109, -32.6825, -37.3412,  ..., -43.0610, -39.6389, -45.6586]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[-33.0877, -19.8185, -33.4089,  ..., -33.3898, -33.6792, -33.4543],\n",
      "        [-33.8895, -20.4009, -34.2970,  ..., -34.7022, -34.6881, -34.2496],\n",
      "        [-34.2110, -20.3899, -34.3913,  ..., -33.9642, -34.3294, -34.4746],\n",
      "        ...,\n",
      "        [-36.8350, -23.3608, -37.1968,  ..., -36.9412, -36.9356, -37.2043],\n",
      "        [-35.9770, -30.8949, -35.9190,  ..., -40.3630, -37.2400, -38.4726],\n",
      "        [-36.6381, -26.5616, -37.4356,  ..., -38.5485, -38.2666, -36.9956]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[-35.6853, -29.7469, -35.9386,  ..., -40.1058, -38.3459, -36.8380],\n",
      "        [-34.6687, -20.8774, -34.9487,  ..., -35.3347, -35.2295, -35.1631],\n",
      "        [-34.6168, -24.5402, -35.1994,  ..., -36.8614, -36.0818, -35.0409],\n",
      "        ...,\n",
      "        [-39.4166, -32.2710, -38.7502,  ..., -42.1671, -40.7335, -44.4550],\n",
      "        [-39.2038, -32.3560, -38.4556,  ..., -42.4688, -39.8189, -44.0275],\n",
      "        [-38.8445, -31.0094, -38.8425,  ..., -42.0488, -39.4078, -45.6804]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[-34.2462, -28.5178, -34.1837,  ..., -37.8328, -34.0744, -36.4677],\n",
      "        [-35.4433, -21.6327, -35.8190,  ..., -36.0327, -35.6908, -35.5319],\n",
      "        [-34.8650, -24.4542, -35.4126,  ..., -37.3412, -35.9133, -35.0133],\n",
      "        ...,\n",
      "        [-37.3314, -30.9030, -37.3722,  ..., -41.5422, -39.5385, -38.2581],\n",
      "        [-38.5866, -24.9076, -38.7783,  ..., -38.8178, -38.7253, -39.1566],\n",
      "        [-40.5150, -33.6659, -39.6530,  ..., -44.1377, -40.7444, -47.9845]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[-37.5044, -30.5568, -36.9897,  ..., -41.0261, -37.3736, -43.5076],\n",
      "        [-35.7759, -30.2778, -35.7164,  ..., -40.2038, -38.7223, -35.5210],\n",
      "        [-35.7064, -21.9639, -36.1994,  ..., -36.0000, -36.4585, -36.2682],\n",
      "        ...,\n",
      "        [-40.6393, -32.6096, -39.7030,  ..., -43.6313, -43.2282, -45.6069],\n",
      "        [-38.8180, -27.9001, -39.3942,  ..., -41.2503, -40.2026, -39.8298],\n",
      "        [-38.6188, -29.0995, -39.6516,  ..., -40.4202, -38.8376, -38.7979]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[-35.0435, -25.1155, -35.3653,  ..., -37.1683, -35.9822, -34.9154],\n",
      "        [-34.9678, -28.5160, -35.1851,  ..., -38.3439, -36.3743, -36.6394],\n",
      "        [-36.6450, -30.6827, -36.3697,  ..., -39.6564, -37.9869, -39.3237],\n",
      "        ...,\n",
      "        [-40.1079, -30.2916, -40.7606,  ..., -43.2555, -40.7013, -43.4194],\n",
      "        [-40.3079, -29.0161, -40.8637,  ..., -43.1192, -41.4342, -41.3411],\n",
      "        [-40.4809, -27.0745, -40.7195,  ..., -41.1193, -41.1592, -40.3560]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[-35.9477, -22.0891, -36.1898,  ..., -36.3158, -35.9863, -36.5427],\n",
      "        [-37.1547, -23.7127, -37.4041,  ..., -37.8836, -37.4100, -37.8900],\n",
      "        [-38.7686, -33.4660, -38.1639,  ..., -41.5578, -40.0748, -45.9437],\n",
      "        ...,\n",
      "        [-41.6104, -35.3727, -41.5301,  ..., -45.3042, -43.3388, -43.2350],\n",
      "        [-43.6574, -35.5657, -42.8177,  ..., -44.8702, -44.2693, -47.3693],\n",
      "        [-41.6300, -35.7097, -41.3404,  ..., -46.7513, -43.4836, -41.4484]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[-37.9267, -27.2692, -38.4083,  ..., -40.0358, -39.0920, -37.6724],\n",
      "        [-38.3183, -27.8180, -38.7622,  ..., -40.3965, -39.1130, -37.8970],\n",
      "        [-38.2873, -25.0149, -38.3255,  ..., -39.0856, -38.7238, -38.5807],\n",
      "        ...,\n",
      "        [-42.9150, -31.6660, -43.0727,  ..., -44.6013, -43.0596, -42.2230],\n",
      "        [-43.0310, -38.3908, -42.6833,  ..., -47.4162, -45.2705, -44.0455],\n",
      "        [-45.4650, -40.1025, -45.4678,  ..., -52.9132, -47.8592, -47.9286]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[-37.6334, -24.3486, -37.9979,  ..., -38.4907, -37.9803, -37.4510],\n",
      "        [-38.4804, -24.8362, -38.8136,  ..., -38.6856, -38.3884, -38.3805],\n",
      "        [-38.8598, -25.2989, -39.0058,  ..., -38.7760, -39.1750, -39.3069],\n",
      "        ...,\n",
      "        [-44.6849, -38.5342, -44.4288,  ..., -50.3835, -47.5824, -45.8354],\n",
      "        [-45.0098, -38.6664, -43.9815,  ..., -50.2715, -49.0332, -49.5419],\n",
      "        [-45.9057, -37.6256, -45.1272,  ..., -46.5876, -47.2028, -47.0325]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[-47.3066, -35.7723, -46.5091,  ..., -48.5282, -49.2258, -51.1491],\n",
      "        [-42.6602, -29.1553, -42.9260,  ..., -43.0973, -42.6175, -42.0231],\n",
      "        [-42.7377, -29.1874, -42.9238,  ..., -43.6217, -42.8619, -42.9002],\n",
      "        ...,\n",
      "        [-46.3878, -33.8667, -46.8312,  ..., -48.3901, -47.2018, -47.4585],\n",
      "        [-45.6219, -36.8776, -45.5204,  ..., -48.3777, -44.9747, -46.0324],\n",
      "        [-48.7721, -42.5636, -48.3180,  ..., -53.6130, -51.6483, -51.2037]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)), encoder_attentions=None, encoder_hidden_states=None, decoder_attentions=None, cross_attentions=None, decoder_hidden_states=None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ipdb> n\n",
      "> \u001b[0;32m<ipython-input-30-b95c66eb06e5>\u001b[0m(17)\u001b[0;36mget_paraphrases\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     15 \u001b[0;31m    \u001b[0;31m# We also need to take exp for them to work.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     16 \u001b[0;31m    \u001b[0mseq_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranslated\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequences_scores\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranslated\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequences_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 17 \u001b[0;31m    \u001b[0mtgt_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpp_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranslated\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     18 \u001b[0;31m    \u001b[0;32mif\u001b[0m \u001b[0mreturn_probs\u001b[0m\u001b[0;34m:\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mtgt_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_probs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     19 \u001b[0;31m    \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m              \u001b[0;32mreturn\u001b[0m \u001b[0mtgt_text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> seq_probs\n",
      "tensor([0.0172, 0.0167, 0.0167, 0.0166, 0.0166, 0.0164, 0.0164, 0.0163, 0.0163,\n",
      "        0.0163, 0.0162, 0.0162, 0.0162, 0.0161, 0.0161, 0.0161, 0.0161, 0.0160,\n",
      "        0.0160, 0.0160, 0.0159, 0.0159, 0.0158, 0.0158, 0.0158, 0.0158, 0.0158,\n",
      "        0.0157, 0.0157, 0.0157, 0.0157, 0.0156, 0.0156, 0.0156, 0.0156, 0.0155,\n",
      "        0.0155, 0.0154, 0.0153, 0.0153, 0.0153, 0.0153, 0.0153, 0.0153, 0.0152,\n",
      "        0.0152, 0.0152, 0.0152, 0.0152, 0.0151, 0.0150, 0.0150, 0.0150, 0.0150,\n",
      "        0.0149, 0.0149, 0.0149, 0.0149, 0.0149, 0.0149, 0.0148, 0.0148, 0.0148,\n",
      "        0.0148], device='cuda:0')\n",
      "ipdb> translated.sequences_scores\n",
      "tensor([-1.0977, -1.1258, -1.1276, -1.1318, -1.1334, -1.1465, -1.1466, -1.1472,\n",
      "        -1.1528, -1.1530, -1.1549, -1.1556, -1.1588, -1.1599, -1.1605, -1.1626,\n",
      "        -1.1636, -1.1675, -1.1680, -1.1688, -1.1739, -1.1778, -1.1788, -1.1799,\n",
      "        -1.1802, -1.1804, -1.1817, -1.1862, -1.1868, -1.1875, -1.1901, -1.1963,\n",
      "        -1.1964, -1.1968, -1.1971, -1.1994, -1.2024, -1.2038, -1.2101, -1.2133,\n",
      "        -1.2138, -1.2143, -1.2145, -1.2154, -1.2174, -1.2185, -1.2201, -1.2213,\n",
      "        -1.2226, -1.2243, -1.2325, -1.2331, -1.2344, -1.2349, -1.2378, -1.2397,\n",
      "        -1.2412, -1.2413, -1.2414, -1.2415, -1.2437, -1.2470, -1.2477, -1.2488],\n",
      "       device='cuda:0')\n",
      "ipdb> translated\n",
      "BeamSearchEncoderDecoderOutput(sequences=tensor([[   0,  398,  126,  ...,    0,    0,    0],\n",
      "        [   0,  398,  126,  ...,    0,    0,    0],\n",
      "        [   0,  398,  126,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [   0,  398,  126,  ...,    0,    0,    0],\n",
      "        [   0,  398,  126,  ...,    0,    0,    0],\n",
      "        [   0,  398,  126,  ..., 1645,  107,    1]], device='cuda:0'), sequences_scores=tensor([-1.0977, -1.1258, -1.1276, -1.1318, -1.1334, -1.1465, -1.1466, -1.1472,\n",
      "        -1.1528, -1.1530, -1.1549, -1.1556, -1.1588, -1.1599, -1.1605, -1.1626,\n",
      "        -1.1636, -1.1675, -1.1680, -1.1688, -1.1739, -1.1778, -1.1788, -1.1799,\n",
      "        -1.1802, -1.1804, -1.1817, -1.1862, -1.1868, -1.1875, -1.1901, -1.1963,\n",
      "        -1.1964, -1.1968, -1.1971, -1.1994, -1.2024, -1.2038, -1.2101, -1.2133,\n",
      "        -1.2138, -1.2143, -1.2145, -1.2154, -1.2174, -1.2185, -1.2201, -1.2213,\n",
      "        -1.2226, -1.2243, -1.2325, -1.2331, -1.2344, -1.2349, -1.2378, -1.2397,\n",
      "        -1.2412, -1.2413, -1.2414, -1.2415, -1.2437, -1.2470, -1.2477, -1.2488],\n",
      "       device='cuda:0'), scores=(tensor([[-1.3150e+01, -1.0775e+01, -1.3008e+01,  ..., -1.5826e+01,\n",
      "         -1.4548e+01, -1.3874e+01],\n",
      "        [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
      "         -1.0000e+09, -1.0000e+09],\n",
      "        [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
      "         -1.0000e+09, -1.0000e+09],\n",
      "        ...,\n",
      "        [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
      "         -1.0000e+09, -1.0000e+09],\n",
      "        [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
      "         -1.0000e+09, -1.0000e+09],\n",
      "        [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
      "         -1.0000e+09, -1.0000e+09]], device='cuda:0', grad_fn=<AddBackward0>), tensor([[-15.5589, -14.4239, -14.7609,  ..., -20.6249, -14.9298, -19.0487],\n",
      "        [-15.2942, -14.4140, -14.6236,  ..., -18.2064, -17.2438, -15.0161],\n",
      "        [-15.6772, -13.3665, -15.6077,  ..., -19.9398, -15.6245, -16.4424],\n",
      "        ...,\n",
      "        [-21.9152, -22.5853, -22.0627,  ..., -23.7152, -23.6725, -22.2512],\n",
      "        [-20.6113, -17.9430, -19.8752,  ..., -25.4483, -18.9932, -21.5735],\n",
      "        [-22.7716, -20.7431, -21.8850,  ..., -25.0319, -23.3937, -26.3446]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[-16.4601, -13.9366, -15.5713,  ..., -19.3258, -16.6169, -17.5690],\n",
      "        [-17.1475, -16.1101, -17.1907,  ..., -21.5710, -19.1920, -17.4470],\n",
      "        [-18.2632, -17.4910, -18.0196,  ..., -20.2599, -20.6171, -22.8239],\n",
      "        ...,\n",
      "        [-20.8741, -18.6191, -20.4356,  ..., -24.4780, -21.2642, -24.5100],\n",
      "        [-21.2125, -18.2266, -21.1500,  ..., -20.7593, -23.6967, -21.1769],\n",
      "        [-19.5662, -14.1880, -19.1022,  ..., -22.7785, -20.1849, -22.3005]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[-17.3108, -14.8472, -17.2408,  ..., -19.6597, -17.3629, -18.8586],\n",
      "        [-17.4788, -13.2435, -16.9401,  ..., -19.2103, -18.1464, -18.1092],\n",
      "        [-19.1075, -18.2431, -18.3218,  ..., -23.4106, -19.0408, -19.8322],\n",
      "        ...,\n",
      "        [-21.4089, -20.9613, -20.5338,  ..., -24.2985, -22.3343, -21.5512],\n",
      "        [-21.7786, -21.6290, -21.2065,  ..., -24.7707, -22.2967, -23.9033],\n",
      "        [-20.6269, -16.3659, -20.9881,  ..., -21.7899, -21.2798, -22.8024]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[-17.2019, -14.3449, -17.2242,  ..., -20.9230, -17.7209, -18.0461],\n",
      "        [-18.7212, -17.3915, -19.0912,  ..., -19.8633, -21.3094, -17.7078],\n",
      "        [-18.3772, -17.4199, -17.9111,  ..., -19.9991, -20.4132, -20.9167],\n",
      "        ...,\n",
      "        [-22.8425, -20.1401, -22.8223,  ..., -24.8852, -24.8288, -21.5243],\n",
      "        [-21.4981, -21.9901, -21.2981,  ..., -23.3701, -23.6013, -22.7206],\n",
      "        [-21.6017, -20.8501, -21.0611,  ..., -24.6251, -22.9586, -24.7634]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[-18.4377, -16.6221, -17.7710,  ..., -19.8911, -20.1482, -20.0015],\n",
      "        [-20.0609, -16.9226, -19.3276,  ..., -23.6441, -20.8425, -22.4605],\n",
      "        [-18.3966, -16.1159, -18.2242,  ..., -20.4923, -18.5946, -18.2563],\n",
      "        ...,\n",
      "        [-21.7924, -19.0513, -21.0239,  ..., -24.7983, -22.1640, -25.6564],\n",
      "        [-22.5173, -18.1145, -21.6667,  ..., -23.6535, -23.8139, -25.2835],\n",
      "        [-22.4721, -18.8856, -22.2071,  ..., -22.2600, -23.7206, -21.5511]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[-19.0671, -15.4572, -18.8838,  ..., -21.7729, -19.4174, -20.7510],\n",
      "        [-19.2936, -17.1668, -18.8880,  ..., -20.9599, -21.0446, -19.2201],\n",
      "        [-19.3036, -16.7288, -18.9214,  ..., -24.5685, -17.9289, -20.4784],\n",
      "        ...,\n",
      "        [-21.9480, -20.6931, -21.3181,  ..., -24.5566, -22.3719, -21.5951],\n",
      "        [-22.1085, -21.7778, -21.3518,  ..., -25.5708, -20.6735, -28.3420],\n",
      "        [-22.5784, -20.7754, -22.2998,  ..., -26.3650, -23.7221, -21.3678]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[-18.5799, -16.0510, -18.7631,  ..., -22.5215, -19.1355, -20.1728],\n",
      "        [-20.8067, -18.2225, -19.7011,  ..., -23.2347, -20.7948, -20.2456],\n",
      "        [-20.8783, -20.6261, -19.7623,  ..., -24.8794, -21.6791, -23.8074],\n",
      "        ...,\n",
      "        [-22.8315, -21.3857, -22.3960,  ..., -24.0856, -24.7065, -21.6042],\n",
      "        [-23.5058, -20.8293, -23.1548,  ..., -27.6003, -23.9555, -26.0023],\n",
      "        [-22.7671, -20.4168, -21.8903,  ..., -24.1013, -26.0702, -23.3775]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[-19.3351, -16.7604, -18.8718,  ..., -22.5834, -19.0179, -20.0555],\n",
      "        [-20.7069, -19.2143, -20.3160,  ..., -21.6270, -21.7435, -21.5682],\n",
      "        [-21.5970, -18.6741, -20.4582,  ..., -23.6926, -22.8532, -22.0447],\n",
      "        ...,\n",
      "        [-23.8462, -20.9999, -22.5064,  ..., -25.4906, -25.1223, -25.7962],\n",
      "        [-23.6078, -20.7811, -23.5311,  ..., -25.7667, -25.0419, -24.4871],\n",
      "        [-23.1204, -20.4217, -22.5693,  ..., -25.9273, -23.4075, -24.0786]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[-21.8654, -18.6686, -21.3645,  ..., -25.8223, -22.9154, -26.0779],\n",
      "        [-21.3960, -16.8696, -21.1992,  ..., -22.4537, -20.9612, -21.5414],\n",
      "        [-21.8444, -18.5073, -22.0156,  ..., -22.8657, -23.7075, -20.0071],\n",
      "        ...,\n",
      "        [-24.1461, -20.5035, -23.4859,  ..., -24.1276, -26.5453, -27.9147],\n",
      "        [-24.5698, -21.5089, -24.8668,  ..., -27.3832, -26.9485, -24.7493],\n",
      "        [-25.2024, -24.1082, -24.2966,  ..., -30.6977, -26.5431, -24.3141]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[-20.3011, -17.8084, -19.9235,  ..., -19.9378, -21.6833, -21.4491],\n",
      "        [-21.4080, -17.1586, -21.5441,  ..., -23.0345, -22.8190, -19.6351],\n",
      "        [-20.6879, -18.9366, -20.0096,  ..., -22.4110, -22.6820, -21.4668],\n",
      "        ...,\n",
      "        [-23.8625, -22.6806, -23.2406,  ..., -28.6940, -25.2146, -25.4751],\n",
      "        [-24.7039, -23.3533, -24.0890,  ..., -29.1564, -25.2136, -26.2882],\n",
      "        [-25.4753, -26.4380, -25.3740,  ..., -30.9096, -27.2012, -26.3691]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[-22.9481, -20.4473, -22.6515,  ..., -25.4876, -23.6487, -22.1908],\n",
      "        [-21.6427, -18.6190, -22.0504,  ..., -23.8813, -22.6047, -22.7775],\n",
      "        [-22.3901, -21.0511, -21.7633,  ..., -23.7179, -22.5159, -23.5873],\n",
      "        ...,\n",
      "        [-24.9155, -20.6059, -24.8764,  ..., -27.2352, -25.5928, -25.9219],\n",
      "        [-25.6860, -24.2222, -25.0534,  ..., -29.3467, -27.3133, -23.2389],\n",
      "        [-24.9243, -21.7846, -24.9206,  ..., -27.7271, -25.1639, -22.5196]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[-23.6485, -19.5961, -22.6286,  ..., -25.3248, -24.8046, -24.3264],\n",
      "        [-21.9012, -18.6294, -22.1046,  ..., -25.2030, -21.2632, -23.3180],\n",
      "        [-22.6549, -18.0530, -21.3913,  ..., -26.0186, -23.2350, -23.1181],\n",
      "        ...,\n",
      "        [-26.2193, -24.2859, -25.8914,  ..., -26.9682, -26.7978, -26.5710],\n",
      "        [-25.2285, -21.1841, -25.3006,  ..., -28.3289, -24.8222, -24.7124],\n",
      "        [-25.9269, -24.0894, -25.3481,  ..., -28.8348, -27.4217, -24.5582]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[-23.1217, -17.9832, -22.4198,  ..., -24.0839, -21.1905, -24.3884],\n",
      "        [-23.7239, -20.0050, -23.3665,  ..., -27.8283, -24.2781, -26.4791],\n",
      "        [-23.9326, -20.3312, -23.7167,  ..., -27.4875, -24.4497, -26.3418],\n",
      "        ...,\n",
      "        [-25.8504, -21.7727, -25.3692,  ..., -26.1636, -26.9883, -26.6976],\n",
      "        [-27.0945, -23.0715, -27.4623,  ..., -29.2324, -26.9853, -30.3963],\n",
      "        [-26.1305, -21.7490, -26.0360,  ..., -31.0908, -26.7700, -25.6170]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[-22.1572, -16.9191, -22.0862,  ..., -24.6969, -22.9178, -23.0855],\n",
      "        [-23.3495, -19.4168, -23.5615,  ..., -25.0546, -25.0157, -21.7256],\n",
      "        [-23.8063, -19.8732, -23.8317,  ..., -23.8873, -25.1568, -24.2557],\n",
      "        ...,\n",
      "        [-26.9306, -25.2776, -25.9303,  ..., -31.3111, -28.2576, -26.6603],\n",
      "        [-27.6614, -22.7591, -27.3749,  ..., -27.5433, -29.7903, -27.3446],\n",
      "        [-26.8809, -23.7006, -26.7260,  ..., -28.7447, -28.5380, -26.0160]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[-23.9346, -19.1105, -23.4830,  ..., -27.4302, -24.0362, -21.6287],\n",
      "        [-24.3917, -22.1924, -23.8657,  ..., -28.5479, -26.7277, -25.6785],\n",
      "        [-24.2733, -19.5058, -23.9201,  ..., -25.7954, -26.8594, -22.9858],\n",
      "        ...,\n",
      "        [-25.7387, -22.8427, -25.0834,  ..., -30.0731, -26.6947, -27.5717],\n",
      "        [-27.2010, -22.4570, -27.8185,  ..., -29.9887, -28.3847, -26.1537],\n",
      "        [-26.6232, -20.4733, -26.1247,  ..., -28.9939, -27.4120, -27.2862]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[-23.9159, -19.0431, -23.7110,  ..., -24.5854, -26.2026, -22.9756],\n",
      "        [-24.3992, -18.9832, -24.1600,  ..., -26.8851, -24.1549, -25.3433],\n",
      "        [-25.5025, -21.7399, -24.9835,  ..., -29.1679, -27.3987, -27.9738],\n",
      "        ...,\n",
      "        [-26.4977, -19.0970, -26.4015,  ..., -27.7399, -27.4694, -26.0167],\n",
      "        [-25.7106, -18.2318, -26.1317,  ..., -27.9068, -26.7391, -25.5079],\n",
      "        [-27.9311, -24.9198, -26.6274,  ..., -27.9846, -28.6606, -30.2134]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[-25.1434, -22.0825, -24.6413,  ..., -25.9934, -27.4266, -23.7164],\n",
      "        [-25.4515, -21.6897, -24.6613,  ..., -28.6760, -26.0415, -27.2406],\n",
      "        [-25.3007, -17.3536, -25.1936,  ..., -26.1454, -26.0315, -25.5135],\n",
      "        ...,\n",
      "        [-27.8168, -24.2092, -27.2952,  ..., -34.5401, -31.1018, -29.0061],\n",
      "        [-27.5504, -24.5338, -27.0796,  ..., -32.6227, -28.4645, -26.7484],\n",
      "        [-27.0780, -23.6325, -26.7221,  ..., -30.7758, -26.7929, -29.8245]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[-25.0905, -22.4561, -24.6624,  ..., -29.2002, -26.3367, -27.5567],\n",
      "        [-25.3481, -17.4475, -25.1625,  ..., -27.5092, -26.4548, -24.8649],\n",
      "        [-26.1575, -22.6640, -25.7874,  ..., -31.3004, -28.2637, -27.5255],\n",
      "        ...,\n",
      "        [-28.6632, -24.2911, -27.8728,  ..., -32.3037, -30.1438, -30.7354],\n",
      "        [-27.9643, -22.8776, -27.9810,  ..., -30.9421, -29.0290, -28.1727],\n",
      "        [-27.2704, -20.1480, -27.2329,  ..., -27.9616, -28.0952, -26.1790]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[-26.1460, -24.8348, -25.6320,  ..., -29.3625, -26.3539, -28.5844],\n",
      "        [-27.4727, -25.5236, -26.6546,  ..., -31.6624, -28.4116, -28.8076],\n",
      "        [-26.1130, -19.2016, -26.1855,  ..., -27.9100, -27.1897, -25.5983],\n",
      "        ...,\n",
      "        [-28.6327, -14.8787, -29.1369,  ..., -29.6715, -29.8432, -28.0775],\n",
      "        [-28.6603, -23.3786, -28.5988,  ..., -29.5857, -29.1327, -30.3050],\n",
      "        [-29.4257, -26.6932, -29.8950,  ..., -32.3590, -32.0340, -29.7280]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[-26.7716, -22.9906, -27.4361,  ..., -29.3094, -27.7098, -26.9190],\n",
      "        [-26.6822, -23.6901, -26.0420,  ..., -30.6622, -27.7454, -26.6651],\n",
      "        [-28.2654, -25.3264, -27.3515,  ..., -34.4527, -30.4623, -30.8448],\n",
      "        ...,\n",
      "        [-29.4599, -25.6644, -28.8857,  ..., -33.6668, -30.3105, -30.2590],\n",
      "        [-29.3827, -25.7948, -29.3902,  ..., -34.3693, -32.2414, -29.6804],\n",
      "        [-29.6917, -26.7964, -28.8337,  ..., -33.1040, -30.3439, -30.7816]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[-27.5711, -25.6328, -26.6056,  ..., -32.2644, -29.1254, -27.8840],\n",
      "        [-27.0030, -24.5103, -26.0327,  ..., -33.1603, -28.8884, -28.4239],\n",
      "        [-28.0298, -23.9683, -27.7466,  ..., -29.7685, -29.4683, -28.8730],\n",
      "        ...,\n",
      "        [-30.1483, -15.9793, -30.3997,  ..., -31.1331, -32.0265, -30.2860],\n",
      "        [-29.9531, -25.6107, -29.9712,  ..., -32.0801, -31.5552, -29.9695],\n",
      "        [-30.4444, -26.7021, -29.7321,  ..., -31.3722, -32.1088, -29.6667]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[-27.5047, -25.6254, -27.5016,  ..., -33.6702, -29.3696, -27.9482],\n",
      "        [-28.0330, -24.9929, -27.6233,  ..., -35.9015, -31.9331, -28.2845],\n",
      "        [-27.7689, -22.9708, -27.0459,  ..., -34.6029, -31.8874, -31.4259],\n",
      "        ...,\n",
      "        [-30.8209, -26.7243, -30.4613,  ..., -37.3930, -33.9812, -31.8579],\n",
      "        [-31.4301, -27.6511, -30.8728,  ..., -41.3760, -37.1769, -35.5109],\n",
      "        [-31.7680, -27.3723, -31.1767,  ..., -34.7572, -31.8151, -31.9477]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[-28.0281, -22.8152, -28.4553,  ..., -30.6299, -28.9705, -26.9184],\n",
      "        [-29.2087, -25.1240, -28.3533,  ..., -35.5827, -34.6404, -31.9296],\n",
      "        [-28.6604, -25.2411, -28.2360,  ..., -34.7977, -34.9905, -31.3982],\n",
      "        ...,\n",
      "        [-30.1903, -23.9516, -29.2255,  ..., -34.7172, -33.6676, -31.3165],\n",
      "        [-31.3196, -25.8600, -32.0585,  ..., -36.3978, -33.6917, -31.3285],\n",
      "        [-29.7622, -24.8845, -29.4530,  ..., -33.5653, -29.6812, -29.9573]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[-28.2016, -23.1226, -28.3217,  ..., -29.7362, -28.2268, -28.6732],\n",
      "        [-29.2772, -23.7687, -29.0806,  ..., -32.4186, -30.5580, -27.8546],\n",
      "        [-28.9017, -23.0879, -28.7454,  ..., -31.1753, -29.9970, -27.7155],\n",
      "        ...,\n",
      "        [-31.7712, -26.7689, -31.3174,  ..., -39.5910, -35.1678, -36.1186],\n",
      "        [-30.7971, -26.7451, -31.3592,  ..., -34.3343, -32.1315, -30.7901],\n",
      "        [-30.4584, -23.8092, -29.4265,  ..., -35.2847, -34.0294, -30.8079]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[-28.9502, -24.1105, -29.0885,  ..., -34.6239, -34.1768, -29.6643],\n",
      "        [-29.1664, -23.5062, -29.3854,  ..., -31.2329, -30.1628, -30.7198],\n",
      "        [-29.9046, -23.3065, -30.3963,  ..., -34.1520, -31.8778, -31.5170],\n",
      "        ...,\n",
      "        [-32.1792, -25.0028, -30.6216,  ..., -36.9270, -37.2174, -33.0166],\n",
      "        [-31.5712, -29.4905, -31.2596,  ..., -38.5435, -34.5780, -33.7748],\n",
      "        [-32.0360, -24.3879, -30.4757,  ..., -39.6212, -35.6802, -34.0540]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[-30.2611, -25.0425, -30.2920,  ..., -32.7364, -31.2083, -31.7037],\n",
      "        [-30.7936, -25.1299, -31.0330,  ..., -35.6706, -32.4644, -34.0554],\n",
      "        [-30.1110, -16.2380, -30.4654,  ..., -30.5758, -30.6592, -30.4879],\n",
      "        ...,\n",
      "        [-32.4688, -18.7292, -32.9886,  ..., -34.1042, -34.5765, -32.5005],\n",
      "        [-30.9314, -25.2661, -30.8630,  ..., -34.9116, -31.8464, -33.1766],\n",
      "        [-35.5366, -29.1771, -34.8332,  ..., -39.0512, -36.4429, -41.6866]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[-30.0737, -24.0344, -29.6043,  ..., -35.0957, -31.2904, -33.0221],\n",
      "        [-29.0715, -19.6608, -29.7871,  ..., -31.6871, -31.5979, -31.7110],\n",
      "        [-29.4695, -19.5092, -29.6338,  ..., -31.0894, -31.3662, -31.7302],\n",
      "        ...,\n",
      "        [-32.0964, -22.6077, -32.5027,  ..., -34.0446, -33.9772, -34.3486],\n",
      "        [-33.1866, -24.7980, -33.5888,  ..., -39.6480, -36.9227, -35.6416],\n",
      "        [-32.5372, -22.8834, -33.2288,  ..., -34.7424, -33.7958, -35.2654]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[-29.3962, -19.8957, -30.2391,  ..., -32.1469, -32.3339, -31.0471],\n",
      "        [-30.8217, -24.2014, -30.7022,  ..., -35.0537, -32.4396, -34.6715],\n",
      "        [-29.8977, -16.9648, -30.1824,  ..., -30.7238, -30.7336, -29.9331],\n",
      "        ...,\n",
      "        [-33.8002, -29.1073, -34.2250,  ..., -38.7936, -36.6321, -35.9535],\n",
      "        [-34.3514, -29.2025, -33.8561,  ..., -38.3762, -35.5460, -42.2228],\n",
      "        [-33.6552, -26.2474, -33.7245,  ..., -37.0668, -34.8985, -35.9777]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[-29.7151, -16.6793, -30.0486,  ..., -30.0347, -30.0390, -30.1237],\n",
      "        [-29.9557, -20.2918, -30.3968,  ..., -30.7111, -30.7522, -31.2755],\n",
      "        [-30.7491, -20.6985, -31.3026,  ..., -33.5425, -33.0600, -33.3618],\n",
      "        ...,\n",
      "        [-33.0070, -23.1750, -33.4191,  ..., -35.9361, -35.2050, -35.0376],\n",
      "        [-32.6274, -26.5734, -32.3762,  ..., -36.6924, -34.1361, -35.2398],\n",
      "        [-33.3735, -24.5888, -33.5524,  ..., -36.8693, -35.1805, -35.6366]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[-31.2821, -24.6380, -31.1837,  ..., -36.5628, -32.7028, -34.0573],\n",
      "        [-31.2484, -17.6800, -31.4570,  ..., -31.4275, -31.7715, -31.5368],\n",
      "        [-32.1523, -26.0755, -31.8596,  ..., -36.8331, -34.3582, -33.6011],\n",
      "        ...,\n",
      "        [-33.7332, -25.1724, -33.9653,  ..., -35.5337, -34.8360, -35.9655],\n",
      "        [-35.9323, -30.1155, -34.7706,  ..., -42.3157, -38.6999, -42.1016],\n",
      "        [-34.2913, -20.9166, -34.5071,  ..., -34.5937, -34.8234, -34.4270]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[-31.0846, -22.6012, -31.7588,  ..., -33.1158, -33.8427, -33.9813],\n",
      "        [-30.8265, -21.1086, -31.2488,  ..., -32.9374, -33.0459, -32.4722],\n",
      "        [-31.1873, -22.6113, -31.4914,  ..., -33.4257, -32.6784, -32.7610],\n",
      "        ...,\n",
      "        [-34.3970, -27.7316, -34.2380,  ..., -38.5912, -36.7549, -37.1445],\n",
      "        [-35.3199, -28.0988, -35.1809,  ..., -37.6211, -36.8104, -38.2404],\n",
      "        [-34.0100, -28.5151, -33.9040,  ..., -36.9620, -34.6383, -34.5025]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[-32.0530, -18.4621, -32.1852,  ..., -31.9668, -32.5383, -32.1783],\n",
      "        [-31.9437, -18.5597, -32.3901,  ..., -33.1700, -33.3766, -32.3366],\n",
      "        [-31.8317, -21.8301, -32.3572,  ..., -34.8084, -34.3079, -33.3125],\n",
      "        ...,\n",
      "        [-35.2897, -21.7513, -35.5793,  ..., -34.7700, -35.4464, -35.4903],\n",
      "        [-36.3172, -28.4991, -35.8400,  ..., -42.3259, -39.8944, -42.9029],\n",
      "        [-36.5684, -30.1976, -36.2223,  ..., -39.8877, -36.8089, -42.7613]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[-32.4932, -18.9385, -32.7599,  ..., -32.8264, -33.1794, -32.4579],\n",
      "        [-32.2876, -23.0131, -32.6799,  ..., -33.6431, -33.8597, -34.0789],\n",
      "        [-32.7536, -19.7157, -32.7719,  ..., -32.8551, -33.0497, -33.6439],\n",
      "        ...,\n",
      "        [-36.6517, -29.7483, -36.3466,  ..., -41.0372, -39.6285, -41.2446],\n",
      "        [-36.4915, -22.7466, -36.8105,  ..., -36.9726, -36.9005, -36.8005],\n",
      "        [-38.2109, -32.6825, -37.3412,  ..., -43.0610, -39.6389, -45.6586]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[-33.0877, -19.8185, -33.4089,  ..., -33.3898, -33.6792, -33.4543],\n",
      "        [-33.8895, -20.4009, -34.2970,  ..., -34.7022, -34.6881, -34.2496],\n",
      "        [-34.2110, -20.3899, -34.3913,  ..., -33.9642, -34.3294, -34.4746],\n",
      "        ...,\n",
      "        [-36.8350, -23.3608, -37.1968,  ..., -36.9412, -36.9356, -37.2043],\n",
      "        [-35.9770, -30.8949, -35.9190,  ..., -40.3630, -37.2400, -38.4726],\n",
      "        [-36.6381, -26.5616, -37.4356,  ..., -38.5485, -38.2666, -36.9956]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[-35.6853, -29.7469, -35.9386,  ..., -40.1058, -38.3459, -36.8380],\n",
      "        [-34.6687, -20.8774, -34.9487,  ..., -35.3347, -35.2295, -35.1631],\n",
      "        [-34.6168, -24.5402, -35.1994,  ..., -36.8614, -36.0818, -35.0409],\n",
      "        ...,\n",
      "        [-39.4166, -32.2710, -38.7502,  ..., -42.1671, -40.7335, -44.4550],\n",
      "        [-39.2038, -32.3560, -38.4556,  ..., -42.4688, -39.8189, -44.0275],\n",
      "        [-38.8445, -31.0094, -38.8425,  ..., -42.0488, -39.4078, -45.6804]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[-34.2462, -28.5178, -34.1837,  ..., -37.8328, -34.0744, -36.4677],\n",
      "        [-35.4433, -21.6327, -35.8190,  ..., -36.0327, -35.6908, -35.5319],\n",
      "        [-34.8650, -24.4542, -35.4126,  ..., -37.3412, -35.9133, -35.0133],\n",
      "        ...,\n",
      "        [-37.3314, -30.9030, -37.3722,  ..., -41.5422, -39.5385, -38.2581],\n",
      "        [-38.5866, -24.9076, -38.7783,  ..., -38.8178, -38.7253, -39.1566],\n",
      "        [-40.5150, -33.6659, -39.6530,  ..., -44.1377, -40.7444, -47.9845]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[-37.5044, -30.5568, -36.9897,  ..., -41.0261, -37.3736, -43.5076],\n",
      "        [-35.7759, -30.2778, -35.7164,  ..., -40.2038, -38.7223, -35.5210],\n",
      "        [-35.7064, -21.9639, -36.1994,  ..., -36.0000, -36.4585, -36.2682],\n",
      "        ...,\n",
      "        [-40.6393, -32.6096, -39.7030,  ..., -43.6313, -43.2282, -45.6069],\n",
      "        [-38.8180, -27.9001, -39.3942,  ..., -41.2503, -40.2026, -39.8298],\n",
      "        [-38.6188, -29.0995, -39.6516,  ..., -40.4202, -38.8376, -38.7979]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[-35.0435, -25.1155, -35.3653,  ..., -37.1683, -35.9822, -34.9154],\n",
      "        [-34.9678, -28.5160, -35.1851,  ..., -38.3439, -36.3743, -36.6394],\n",
      "        [-36.6450, -30.6827, -36.3697,  ..., -39.6564, -37.9869, -39.3237],\n",
      "        ...,\n",
      "        [-40.1079, -30.2916, -40.7606,  ..., -43.2555, -40.7013, -43.4194],\n",
      "        [-40.3079, -29.0161, -40.8637,  ..., -43.1192, -41.4342, -41.3411],\n",
      "        [-40.4809, -27.0745, -40.7195,  ..., -41.1193, -41.1592, -40.3560]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[-35.9477, -22.0891, -36.1898,  ..., -36.3158, -35.9863, -36.5427],\n",
      "        [-37.1547, -23.7127, -37.4041,  ..., -37.8836, -37.4100, -37.8900],\n",
      "        [-38.7686, -33.4660, -38.1639,  ..., -41.5578, -40.0748, -45.9437],\n",
      "        ...,\n",
      "        [-41.6104, -35.3727, -41.5301,  ..., -45.3042, -43.3388, -43.2350],\n",
      "        [-43.6574, -35.5657, -42.8177,  ..., -44.8702, -44.2693, -47.3693],\n",
      "        [-41.6300, -35.7097, -41.3404,  ..., -46.7513, -43.4836, -41.4484]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[-37.9267, -27.2692, -38.4083,  ..., -40.0358, -39.0920, -37.6724],\n",
      "        [-38.3183, -27.8180, -38.7622,  ..., -40.3965, -39.1130, -37.8970],\n",
      "        [-38.2873, -25.0149, -38.3255,  ..., -39.0856, -38.7238, -38.5807],\n",
      "        ...,\n",
      "        [-42.9150, -31.6660, -43.0727,  ..., -44.6013, -43.0596, -42.2230],\n",
      "        [-43.0310, -38.3908, -42.6833,  ..., -47.4162, -45.2705, -44.0455],\n",
      "        [-45.4650, -40.1025, -45.4678,  ..., -52.9132, -47.8592, -47.9286]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[-37.6334, -24.3486, -37.9979,  ..., -38.4907, -37.9803, -37.4510],\n",
      "        [-38.4804, -24.8362, -38.8136,  ..., -38.6856, -38.3884, -38.3805],\n",
      "        [-38.8598, -25.2989, -39.0058,  ..., -38.7760, -39.1750, -39.3069],\n",
      "        ...,\n",
      "        [-44.6849, -38.5342, -44.4288,  ..., -50.3835, -47.5824, -45.8354],\n",
      "        [-45.0098, -38.6664, -43.9815,  ..., -50.2715, -49.0332, -49.5419],\n",
      "        [-45.9057, -37.6256, -45.1272,  ..., -46.5876, -47.2028, -47.0325]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[-47.3066, -35.7723, -46.5091,  ..., -48.5282, -49.2258, -51.1491],\n",
      "        [-42.6602, -29.1553, -42.9260,  ..., -43.0973, -42.6175, -42.0231],\n",
      "        [-42.7377, -29.1874, -42.9238,  ..., -43.6217, -42.8619, -42.9002],\n",
      "        ...,\n",
      "        [-46.3878, -33.8667, -46.8312,  ..., -48.3901, -47.2018, -47.4585],\n",
      "        [-45.6219, -36.8776, -45.5204,  ..., -48.3777, -44.9747, -46.0324],\n",
      "        [-48.7721, -42.5636, -48.3180,  ..., -53.6130, -51.6483, -51.2037]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)), encoder_attentions=None, encoder_hidden_states=None, decoder_attentions=None, cross_attentions=None, decoder_hidden_states=None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ipdb> q\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-462e4fd4ffd5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# generate paraphrases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     pp_l,pp_probs = get_paraphrases(text, num_return_sequences=pp_l_sz, num_beams=num_beams,\n\u001b[0m\u001b[1;32m      6\u001b[0m                 \u001b[0mnum_beam_groups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_beam_groups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiversity_penalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdiversity_penalty\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                 temperature=temperature, return_probs=True)\n",
      "\u001b[0;32m<ipython-input-30-b95c66eb06e5>\u001b[0m in \u001b[0;36mget_paraphrases\u001b[0;34m(input_text, num_return_sequences, num_beams, return_probs, num_beam_groups, diversity_penalty, temperature)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# We also need to take exp for them to work.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mseq_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranslated\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequences_scores\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranslated\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequences_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mtgt_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpp_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranslated\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_probs\u001b[0m\u001b[0;34m:\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mtgt_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_probs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m              \u001b[0;32mreturn\u001b[0m \u001b[0mtgt_text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-30-b95c66eb06e5>\u001b[0m in \u001b[0;36mget_paraphrases\u001b[0;34m(input_text, num_return_sequences, num_beams, return_probs, num_beam_groups, diversity_penalty, temperature)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# We also need to take exp for them to work.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mseq_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranslated\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequences_scores\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranslated\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequences_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mtgt_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpp_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranslated\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_probs\u001b[0m\u001b[0;34m:\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mtgt_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_probs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m              \u001b[0;32mreturn\u001b[0m \u001b[0mtgt_text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Programs/miniconda/envs/nlp_env/lib/python3.8/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;31m# None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'line'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Programs/miniconda/envs/nlp_env/lib/python3.8/bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i, data in enumerate(dl): \n",
    "    if i % 10 == 0 : print(i, \"out of\", len(dl))\n",
    "    label,text = data['label'].to(device),data[\"text\"]\n",
    "    # generate paraphrases\n",
    "    pp_l,pp_probs = get_paraphrases(text, num_return_sequences=pp_l_sz, num_beams=num_beams,\n",
    "                num_beam_groups=num_beam_groups, diversity_penalty=diversity_penalty,\n",
    "                temperature=temperature, return_probs=True)\n",
    "    pp_logprobs = torch.log(pp_probs)\n",
    "    if i ==0: break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = undecorated(undecorated(generate1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{'input_text': [\"this is the best american movie about troubled teens since 1998's whatever .\"], 'num_return_sequences': 64, 'num_beams': 64, 'return_probs': True, \n",
    " 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_probs.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "??pp_model.base_model.__repr__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,mod in enumerate(pp_model.base_model.named_modules()): \n",
    "    print(i,mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x =mod[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(x.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_logprobs.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pp_model.generate.__closure__[0].cell_contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.cell_contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "??pp_model.greedy_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x= pp_model.generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "??x.__self__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "??undecorated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?train_small_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward_fn_onepp(x): \n",
    "    pass\n",
    "    \n",
    "    \n",
    "def reward_fn_onerow(x): \n",
    "    \"\"\"x is one row of a pandas df\"\"\"\n",
    "    text,pp,lbl_change = x['text'],x['text_pp'],x['vm_truelabel_change']\n",
    "    return lbl_change\n",
    "\n",
    "def reward_fn_batch(): \n",
    "    pass \n",
    "\n",
    "def loss_fn(): \n",
    "    pass "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
