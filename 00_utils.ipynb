{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains useful functions for the rest of the scripts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import torch, numpy as np, pandas as pd, time, GPUtil, wandb, os, sys, shutil, subprocess, argparse\n",
    "from timeit import default_timer as timer\n",
    "from threading import Thread\n",
    "import logging\n",
    "logger = logging.getLogger(\"travis_attack.utils\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "import torch\n",
    "import time \n",
    "from nbdev.test import test_fail\n",
    "#from nbdev import show_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "def set_seed(seed):\n",
    "    \"\"\"Sets all seeds for the session\"\"\"\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    np.random.seed(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "def set_session_options(): \n",
    "    \"\"\"Sets some useful options for the sesson\"\"\"\n",
    "    os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"  # set to false if not working\n",
    "    os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"run\"  # some value to stop the error from coming up \n",
    "    pd.set_option(\"display.max_colwidth\", 400)\n",
    "    pd.options.mode.chained_assignment = None \n",
    "    # stop truncation of tables in wandb dashboard\n",
    "    wandb.Table.MAX_ARTIFACT_ROWS = 1000000\n",
    "    wandb.Table.MAX_ROWS = 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def setup_logging(cfg, disable_other_loggers=True): \n",
    "    \"\"\"taken from this recipe from the logging cookbook: \n",
    "    https://docs.python.org/3/howto/logging-cookbook.html#logging-to-multiple-destinations \"\"\"\n",
    "    logging.basicConfig(level=logging.DEBUG,\n",
    "                        format='%(asctime)s %(name)-12s %(levelname)-8s %(message)s',\n",
    "                        datefmt='%m-%d %H:%M',\n",
    "                        filename=cfg.path_logfile,\n",
    "                        filemode='w')\n",
    "    # define a Handler which writes INFO messages or higher to the sys.stderr\n",
    "    console = logging.StreamHandler()\n",
    "    console.setLevel(logging.INFO)\n",
    "    formatter = logging.Formatter('%(name)-12s: %(levelname)-8s %(message)s') # set a format which is simpler for console use\n",
    "    console.setFormatter(formatter)  # tell the handler to use this format\n",
    "    logging.getLogger('').addHandler(console)  # add the handler to the root logger\n",
    "    \n",
    "    if disable_other_loggers:\n",
    "        allowed_modules = [\"travis_attack\", \"wandb\"]  #  \"sentence_transformers\", \"transformers\", \"datasets\" \n",
    "        logger.debug(f\"Disabling all loggers except those from the following libraries: {allowed_modules}\")\n",
    "        for log_name, log_obj in logging.Logger.manager.loggerDict.items():\n",
    "            if not any(mod in log_name for mod in allowed_modules):\n",
    "                log_obj.disabled = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "def setup_parser(): \n",
    "    \"\"\"Set up command line options\"\"\"\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--lr\", type=float)\n",
    "    parser.add_argument(\"--kl_coef\", type=float)\n",
    "    parser.add_argument(\"--ref_logp_coef\", type=float)\n",
    "    parser.add_argument(\"--acc_steps\", type=int)\n",
    "    parser.add_argument(\"--seed\", type=int)\n",
    "    parser.add_argument(\"--n_train_epochs\", type=int)\n",
    "    parser.add_argument(\"--batch_size_train\", type=int)\n",
    "    parser.add_argument(\"--batch_size_eval\", type=int)\n",
    "    \n",
    "    parser.add_argument(\"--temperature\", type=float)\n",
    "    parser.add_argument(\"--top_p\", type=float)\n",
    "    parser.add_argument(\"--length_penalty\", type=float)\n",
    "    parser.add_argument(\"--repetition_penalty\", type=float)\n",
    "\n",
    "    parser.add_argument(\"--reward_fn\")\n",
    "    parser.add_argument(\"--dataset_name\")\n",
    "    parser.add_argument(\"--sampling_strategy\")\n",
    "    parser.add_argument(\"--reward_penalty_type\")\n",
    "\n",
    "    \n",
    "    #parser.add_argument('args', nargs=argparse.REMAINDER)  # activate to put keywords in kwargs.\n",
    "    return parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class timecode:\n",
    "    \"\"\"This class is used for timing code\"\"\"\n",
    "    def __enter__(self):\n",
    "        self.t0 = timer()\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, type, value, traceback):\n",
    "        self.t = timer() - self.t0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a `with timecode() as time_variable` block to time the code in context. The time is stored in the `.t` attribute of whatever variable you call `time_variable`. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with timecode() as t: \n",
    "    time.sleep(0.5)\n",
    "print(t.t)\n",
    "\n",
    "with timecode() as t: \n",
    "    x = [0,1,2,3,4]\n",
    "    y = [o+1 for o in x]\n",
    "print(t.t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def print_device_info(): \n",
    "    \"\"\"\n",
    "    Prints some statistics around versions and the GPU's available for\n",
    "    the host machine\n",
    "    \"\"\"\n",
    "    import torch\n",
    "    import sys\n",
    "    print(\"######## Diagnostics and version information ######## \")\n",
    "    print('__Python VERSION:', sys.version)\n",
    "    print('__pyTorch VERSION:', torch.__version__)\n",
    "    print('__CUDA VERSION', )\n",
    "    from subprocess import call\n",
    "    # call([\"nvcc\", \"--version\"]) does not work\n",
    "    #! nvcc --version\n",
    "    print('__CUDNN VERSION:', torch.backends.cudnn.version())\n",
    "    print('__Number CUDA Devices:', torch.cuda.device_count())\n",
    "    print('__Devices')\n",
    "    call([\"nvidia-smi\", \"--format=csv\", \"--query-gpu=index,name,driver_version,memory.total,memory.used,memory.free\"])\n",
    "    print('Active CUDA Device: GPU', torch.cuda.current_device())\n",
    "    print ('Available devices ', torch.cuda.device_count())\n",
    "    print(\"Device name:\", torch.cuda.get_device_name())\n",
    "    print ('Current cuda device ', torch.cuda.current_device())\n",
    "    print(\"#################################################################\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export    \n",
    "def dump_tensors(gpu_only=True):\n",
    "    \"\"\"Prints a list of the Tensors being tracked by the garbage collector. \n",
    "    Useful when running into an out of memory error on the GPU. \"\"\"\n",
    "    import gc\n",
    "    total_size = 0\n",
    "    for obj in gc.get_objects():\n",
    "        try:\n",
    "            if torch.is_tensor(obj):\n",
    "                if not gpu_only or obj.is_cuda:\n",
    "                    print(\"%s:%s%s %s\" % (type(obj).__name__, \n",
    "                                            \" GPU\" if obj.is_cuda else \"\",\n",
    "                                            \" pinned\" if obj.is_pinned else \"\",\n",
    "                                            pretty_size(obj.size())))\n",
    "                    total_size += obj.numel()\n",
    "            elif hasattr(obj, \"data\") and torch.is_tensor(obj.data):\n",
    "                if not gpu_only or obj.is_cuda:\n",
    "                    print(\"%s â†’ %s:%s%s%s%s %s\" % (type(obj).__name__, \n",
    "                                                    type(obj.data).__name__, \n",
    "                                                    \" GPU\" if obj.is_cuda else \"\",\n",
    "                                                    \" pinned\" if obj.data.is_pinned else \"\",\n",
    "                                                    \" grad\" if obj.requires_grad else \"\", \n",
    "                                                    \" volatile\" if obj.volatile else \"\",\n",
    "                                                    pretty_size(obj.data.size())))\n",
    "                    total_size += obj.data.numel()\n",
    "        except Exception as e:\n",
    "            pass        \n",
    "    print(\"Total size:\", total_size)   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export      \n",
    "class Monitor(Thread):\n",
    "    \"\"\"Use this to check that you are using the GPU during your pytorch functions and to track memory usage \n",
    "    of the GPU's as well.\"\"\" \n",
    "    def __init__(self, delay):\n",
    "        super(Monitor, self).__init__()\n",
    "        self.stopped = False\n",
    "        self.delay = delay # Time between calls to GPUtil\n",
    "        self.start()\n",
    "\n",
    "    def run(self):\n",
    "        while not self.stopped:\n",
    "            GPUtil.showUtilization()\n",
    "            time.sleep(self.delay)\n",
    "\n",
    "    def stop(self):\n",
    "        self.stopped = True\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def show_gpu(msg):\n",
    "    \"\"\"\n",
    "    ref: https://github.com/huggingface/transformers/issues/1742#issue-518262673\n",
    "    put in logger.info()\n",
    "    \"\"\"\n",
    "    def query(field):\n",
    "        return(subprocess.check_output(\n",
    "            ['nvidia-smi', f'--query-gpu={field}',\n",
    "                '--format=csv,nounits,noheader'], \n",
    "            encoding='utf-8'))\n",
    "    def to_int(result):\n",
    "        return int(result.strip().split('\\n')[0])\n",
    "    \n",
    "    used = to_int(query('memory.used'))\n",
    "    total = to_int(query('memory.total'))\n",
    "    pct = used/total\n",
    "    return f\"{msg} {100*pct:2.1f}% ({used} out of {total})\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Misc utils "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def round_t(t, dp=2):\n",
    "    \"\"\"Return rounded tensors for easy viewing. t is a tensor, dp=decimal places\"\"\"\n",
    "    if t.device.type == \"cuda\": t=t.cpu()\n",
    "    return t.detach().numpy().round(dp)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round_t(torch.rand((10,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def merge_dicts(d1, d2): \n",
    "    \"\"\"Merge the two dicts and return the result. Check first that there is no key overlap.\"\"\"\n",
    "    assert set(d1.keys()).isdisjoint(d2.keys())\n",
    "    return {**d1, **d2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = dict(a=1, b=2)\n",
    "d2 = dict(g=1, c=3)\n",
    "merge_dicts(d1, d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = dict(a=1, b=2)\n",
    "d2 = dict(a=1, c=3)\n",
    "test_fail(merge_dicts, args = (d1,d2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you merge two dicts and then remove keys from one, the merged results still has all the keys. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dict(a=\"a\", b=\"b\", c=\"c\", d=\"d\")\n",
    "d2 = dict(e=\"e\", f=\"f\")\n",
    "d3 = merge_dicts(d2, d)\n",
    "delkeys = [\"b\", \"d\"]\n",
    "for k in delkeys:  d.pop(k, None)\n",
    "print(d)\n",
    "print(d2)\n",
    "print(d3)\n",
    "assert len(d3) == 4 + 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "def display_all(df):\n",
    "    with pd.option_context(\"display.max_rows\", 1000): \n",
    "        with pd.option_context(\"display.max_columns\", 1000): \n",
    "            with pd.option_context(\"max_colwidth\", 480):\n",
    "                display(df)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def unpack_nested_lists_in_df(df, scalar_cols=[]):\n",
    "    \"\"\"Take a df where we have lists stored in the cells and convert it to many rows. \n",
    "    Put all columns without lists stored in the cells into `scalar_cols`.\"\"\"\n",
    "    return df.set_index(scalar_cols).apply(pd.Series.explode).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tests: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \n",
    "x1 = torch.tensor([1,2,3], device = device).cpu().tolist()\n",
    "x2 = torch.tensor([4,5,6], device = device).cpu().tolist()\n",
    "y1 = torch.tensor([1,4,3], device = device).cpu().tolist()\n",
    "y2 = torch.tensor([4,5,6], device = device).cpu().tolist()\n",
    "z1 = 1\n",
    "z2 = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case where we have mixed scalars (z) and columns with nested lists of same length (x,y)\n",
    "l = list()\n",
    "l.append({\"x\":x1, \"y\":y1, \"z\":z1})\n",
    "l.append({\"x\":x2, \"y\":y2, \"z\":z2})\n",
    "print(l)\n",
    "df = pd.DataFrame(l)\n",
    "print(df)\n",
    "unpack_nested_lists_in_df(df, scalar_cols=['z'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case with columns of nested lists of mixed length across rows (but same in a given row) (x,y)\n",
    "x2a = torch.tensor([4,5], device = device).cpu().tolist()\n",
    "y2a = torch.tensor([4,5], device = device).cpu().tolist()\n",
    "l = list()\n",
    "l.append({\"x\":x1, \"y\":y1, \"z\":z1})\n",
    "l.append({\"x\":x2a, \"y\":y2a, \"z\":z2})\n",
    "print(l)\n",
    "print(df)\n",
    "df = pd.DataFrame(l)\n",
    "unpack_nested_lists_in_df(df, scalar_cols=['z'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case where x and y don't have same list sizes in a given row. Should fail\n",
    "y1b = torch.tensor([1,4], device = device).cpu().tolist()\n",
    "y2b = torch.tensor([4,5], device = device).cpu().tolist()\n",
    "l = list()\n",
    "l.append({\"x\":x1, \"y\":y1b, \"z\":z1})\n",
    "l.append({\"x\":x2, \"y\":y2b, \"z\":z2})\n",
    "print(l)\n",
    "df = pd.DataFrame(l)\n",
    "print(df)\n",
    "test_fail(unpack_nested_lists_in_df, args=(df, ['z']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case with multiple scalar columns\n",
    "a1 = 4\n",
    "a2 = 6\n",
    "l = list()\n",
    "l.append({\"x\":x1, \"y\":y1, \"z\":z1, \"a\": a1})\n",
    "l.append({\"x\":x2, \"y\":y2, \"z\":z2, \"a\": a2})\n",
    "print(l)\n",
    "df = pd.DataFrame(l)\n",
    "print(df)\n",
    "unpack_nested_lists_in_df(df, scalar_cols=['z', 'a'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def append_df_to_csv(df, path):\n",
    "    \"\"\"Checks columns and other stuff before appending\"\"\"\n",
    "    import os\n",
    "    if not os.path.isfile(path):   df.to_csv(path, mode='a', index=False)  # create with header if not exists\n",
    "    elif len(df.columns) != len(pd.read_csv(path, nrows=1).columns):\n",
    "        raise Exception(\"Columns do not match. Dataframe has \" + str(len(df.columns)) + \" columns. CSV file has \" + str(len(pd.read_csv(path, nrows=1).columns)) + \" columns.\")\n",
    "    elif not (df.columns == pd.read_csv(path, nrows=1).columns).all():\n",
    "        raise Exception(\"Columns and column order of dataframe and csv file do not match.\")\n",
    "    else:\n",
    "        df.to_csv(path, mode='a', index=False, header=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def robust_rmtree(path, logger=None, max_retries=6):\n",
    "    \"\"\"Robustly tries to delete paths.\n",
    "    Retries several times (with increasing delays) if an OSError\n",
    "    occurs.  If the final attempt fails, the Exception is propagated\n",
    "    to the caller.\n",
    "    \"\"\"\n",
    "    dt = 1\n",
    "    for i in range(max_retries):\n",
    "        try:\n",
    "            shutil.rmtree(path)\n",
    "            return\n",
    "        except OSError:\n",
    "            if logger:\n",
    "                logger.info('Unable to remove path: %s' % path)\n",
    "                logger.info('Retrying after %d seconds' % dt)\n",
    "            time.sleep(dt)\n",
    "            dt *= 2\n",
    "\n",
    "    # Final attempt, pass any Exceptions up to caller.\n",
    "    shutil.rmtree(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def test_pp_model(text, pp_tokenizer, pp_model): \n",
    "    \"\"\"Get some paraphrases for a bit of text\"\"\"\n",
    "    print(\"ORIGINAL\\n\",text)\n",
    "    num_beams = 10\n",
    "    num_return_sequences = 10\n",
    "    batch = pp_tokenizer([text], return_tensors='pt', max_length=60, truncation=True)\n",
    "    translated = pp_model.generate(**batch, num_beams=num_beams, num_return_sequences=num_return_sequences, length_penalty=1)\n",
    "    tgt_text = pp_tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
    "    return tgt_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wandb utils \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def start_wandb_run(cfg, log_code=True): \n",
    "    \"\"\"Start wandb run, set up paths, update cfg, create dir for model artifacts if needed,\"\"\"\n",
    "    run = wandb.init(project=cfg.wandb['project'], entity=cfg.wandb['entity'], \n",
    "                          config=vars(cfg), mode=cfg.wandb['mode'],\n",
    "                          notes=cfg.wandb['run_notes'], save_code=log_code)\n",
    "    if log_code: run.log_code(\".\")\n",
    "    cfg.run_name,cfg.run_id = run.name, run.id\n",
    "    cfg.path_run = f\"{cfg.path_checkpoints}{run.name}/\"\n",
    "    if not os.path.exists(cfg.path_run): os.makedirs(cfg.path_run, exist_ok=True)\n",
    "    return run, cfg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def resume_wandb_run(cfg): \n",
    "    run = wandb.init(project=\"travis_attack\", entity=\"uts_nlp\", config=vars(cfg),\n",
    "                     resume='must', id=cfg.run_id , mode=cfg.wandb['mode'])\n",
    "    return run "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def table2df(table):\n",
    "    \"\"\"Convert wandb table to pandas dataframe\"\"\"\n",
    "    return pd.DataFrame(data=table.data, columns=table.columns)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_utils.ipynb.\n",
      "Converted 02_tests.ipynb.\n",
      "Converted 03_config.ipynb.\n",
      "Converted 07_models.ipynb.\n",
      "Converted 10_data.ipynb.\n",
      "Converted 20_trainer.ipynb.\n",
      "Converted 25_insights.ipynb.\n",
      "Converted baselines.ipynb.\n",
      "Converted baselines_analysis.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted run.ipynb.\n",
      "Converted show_examples.ipynb.\n",
      "Converted test_pp_model.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
