{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains useful functions for the rest of the scripts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import torch, numpy as np, pandas as pd, time, GPUtil, wandb, logging, os, sys, shutil\n",
    "from timeit import default_timer as timer\n",
    "from threading import Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "import torch\n",
    "import time \n",
    "from nbdev.test import test_fail\n",
    "#from nbdev import show_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "def set_seed(seed):\n",
    "    \"\"\"Sets all seeds for the session\"\"\"\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    np.random.seed(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "def set_session_options(): \n",
    "    \"\"\"Sets some useful options for the sesson\"\"\"\n",
    "    os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"  # set to false if not working\n",
    "    pd.set_option(\"display.max_colwidth\", 400)\n",
    "    # stop truncation of tables in wandb dashboard\n",
    "    wandb.Table.MAX_ARTIFACT_ROWS = 1000000\n",
    "    wandb.Table.MAX_ROWS = 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "def prepare_logger(): \n",
    "    \"\"\"Set logging level and config + return logger\"\"\"\n",
    "    logging.basicConfig(format='%(message)s', stream=sys.stdout) # stdout while we are doing stdout to file piping\n",
    "    logger = logging.getLogger(\"main_logger\")\n",
    "    logger.setLevel(logging.INFO)\n",
    "    return logger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class timecode:\n",
    "    \"\"\"This class is used for timing code\"\"\"\n",
    "    def __enter__(self):\n",
    "        self.t0 = timer()\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, type, value, traceback):\n",
    "        self.t = timer() - self.t0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a `with timecode() as time_variable` block to time the code in context. The time is stored in the `.t` attribute of whatever variable you call `time_variable`. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0011097937822342\n",
      "2.682209014892578e-06\n"
     ]
    }
   ],
   "source": [
    "with timecode() as t: \n",
    "    time.sleep(1)\n",
    "print(t.t)\n",
    "\n",
    "with timecode() as t: \n",
    "    x = [0,1,2,3,4]\n",
    "    y = [o+1 for o in x]\n",
    "print(t.t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def print_device_info(): \n",
    "    \"\"\"\n",
    "    Prints some statistics around versions and the GPU's available for\n",
    "    the host machine\n",
    "    \"\"\"\n",
    "    import torch\n",
    "    import sys\n",
    "    print(\"######## Diagnostics and version information ######## \")\n",
    "    print('__Python VERSION:', sys.version)\n",
    "    print('__pyTorch VERSION:', torch.__version__)\n",
    "    print('__CUDA VERSION', )\n",
    "    from subprocess import call\n",
    "    # call([\"nvcc\", \"--version\"]) does not work\n",
    "    #! nvcc --version\n",
    "    print('__CUDNN VERSION:', torch.backends.cudnn.version())\n",
    "    print('__Number CUDA Devices:', torch.cuda.device_count())\n",
    "    print('__Devices')\n",
    "    call([\"nvidia-smi\", \"--format=csv\", \"--query-gpu=index,name,driver_version,memory.total,memory.used,memory.free\"])\n",
    "    print('Active CUDA Device: GPU', torch.cuda.current_device())\n",
    "    print ('Available devices ', torch.cuda.device_count())\n",
    "    print(\"Device name:\", torch.cuda.get_device_name())\n",
    "    print ('Current cuda device ', torch.cuda.current_device())\n",
    "    print(\"#################################################################\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export    \n",
    "def dump_tensors(gpu_only=True):\n",
    "    \"\"\"Prints a list of the Tensors being tracked by the garbage collector. \n",
    "    Useful when running into an out of memory error on the GPU. \"\"\"\n",
    "    import gc\n",
    "    total_size = 0\n",
    "    for obj in gc.get_objects():\n",
    "        try:\n",
    "            if torch.is_tensor(obj):\n",
    "                if not gpu_only or obj.is_cuda:\n",
    "                    print(\"%s:%s%s %s\" % (type(obj).__name__, \n",
    "                                            \" GPU\" if obj.is_cuda else \"\",\n",
    "                                            \" pinned\" if obj.is_pinned else \"\",\n",
    "                                            pretty_size(obj.size())))\n",
    "                    total_size += obj.numel()\n",
    "            elif hasattr(obj, \"data\") and torch.is_tensor(obj.data):\n",
    "                if not gpu_only or obj.is_cuda:\n",
    "                    print(\"%s â†’ %s:%s%s%s%s %s\" % (type(obj).__name__, \n",
    "                                                    type(obj.data).__name__, \n",
    "                                                    \" GPU\" if obj.is_cuda else \"\",\n",
    "                                                    \" pinned\" if obj.data.is_pinned else \"\",\n",
    "                                                    \" grad\" if obj.requires_grad else \"\", \n",
    "                                                    \" volatile\" if obj.volatile else \"\",\n",
    "                                                    pretty_size(obj.data.size())))\n",
    "                    total_size += obj.data.numel()\n",
    "        except Exception as e:\n",
    "            pass        \n",
    "    print(\"Total size:\", total_size)   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export      \n",
    "class Monitor(Thread):\n",
    "    \"\"\"Use this to check that you are using the GPU during your pytorch functions and to track memory usage \n",
    "    of the GPU's as well.\"\"\" \n",
    "    def __init__(self, delay):\n",
    "        super(Monitor, self).__init__()\n",
    "        self.stopped = False\n",
    "        self.delay = delay # Time between calls to GPUtil\n",
    "        self.start()\n",
    "\n",
    "    def run(self):\n",
    "        while not self.stopped:\n",
    "            GPUtil.showUtilization()\n",
    "            time.sleep(self.delay)\n",
    "\n",
    "    def stop(self):\n",
    "        self.stopped = True\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def show_gpu(msg):\n",
    "    \"\"\"\n",
    "    ref: https://github.com/huggingface/transformers/issues/1742#issue-518262673\n",
    "    put in logger.info()\n",
    "    \"\"\"\n",
    "    import subprocess\n",
    "    def query(field):\n",
    "        return(subprocess.check_output(\n",
    "            ['nvidia-smi', f'--query-gpu={field}',\n",
    "                '--format=csv,nounits,noheader'], \n",
    "            encoding='utf-8'))\n",
    "    def to_int(result):\n",
    "        return int(result.strip().split('\\n')[0])\n",
    "    \n",
    "    used = to_int(query('memory.used'))\n",
    "    total = to_int(query('memory.total'))\n",
    "    pct = used/total\n",
    "    return f\"{msg} {100*pct:2.1f}% ({used} out of {total})\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Misc utils "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def round_t(t, dp=2):\n",
    "    \"\"\"Return rounded tensors for easy viewing. t is a tensor, dp=decimal places\"\"\"\n",
    "    if t.device.type == \"cuda\": t=t.cpu()\n",
    "    return t.detach().numpy().round(dp)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.78, 0.44],\n",
       "       [0.45, 0.63],\n",
       "       [0.29, 0.23],\n",
       "       [0.44, 0.14],\n",
       "       [0.34, 0.98],\n",
       "       [0.74, 0.73],\n",
       "       [0.8 , 0.53],\n",
       "       [0.03, 0.62],\n",
       "       [0.08, 0.98],\n",
       "       [0.02, 0.61]], dtype=float32)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round_t(torch.rand((10,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def merge_dicts(d1, d2): \n",
    "    \"\"\"Merge the two dicts and return the result. Check first that there is no key overlap.\"\"\"\n",
    "    assert set(d1.keys()).isdisjoint(d2.keys())\n",
    "    return {**d1, **d2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 1, 'b': 2, 'g': 1, 'c': 3}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1 = dict(a=1, b=2)\n",
    "d2 = dict(g=1, c=3)\n",
    "merge_dicts(d1, d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = dict(a=1, b=2)\n",
    "d2 = dict(a=1, c=3)\n",
    "test_fail(merge_dicts, args = (d1,d2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you merge two dicts and then remove keys from one, the merged results still has all the keys. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 'a', 'c': 'c'}\n",
      "{'e': 'e', 'f': 'f'}\n",
      "{'e': 'e', 'f': 'f', 'a': 'a', 'b': 'b', 'c': 'c', 'd': 'd'}\n"
     ]
    }
   ],
   "source": [
    "d = dict(a=\"a\", b=\"b\", c=\"c\", d=\"d\")\n",
    "d2 = dict(e=\"e\", f=\"f\")\n",
    "d3 = merge_dicts(d2, d)\n",
    "delkeys = [\"b\", \"d\"]\n",
    "for k in delkeys:  d.pop(k, None)\n",
    "print(d)\n",
    "print(d2)\n",
    "print(d3)\n",
    "assert len(d3) == 4 + 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "def display_all(df):\n",
    "    with pd.option_context(\"display.max_rows\", 1000): \n",
    "        with pd.option_context(\"display.max_columns\", 1000): \n",
    "            with pd.option_context(\"max_colwidth\", 480):\n",
    "                display(df)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def unpack_nested_lists_in_df(df, scalar_cols=[]):\n",
    "    \"\"\"Take a df where we have lists stored in the cells and convert it to many rows. \n",
    "    Put all columns without lists stored in the cells into `scalar_cols`.\"\"\"\n",
    "    return df.set_index(scalar_cols).apply(pd.Series.explode).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tests: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \n",
    "x1 = torch.tensor([1,2,3], device = device).cpu().tolist()\n",
    "x2 = torch.tensor([4,5,6], device = device).cpu().tolist()\n",
    "y1 = torch.tensor([1,4,3], device = device).cpu().tolist()\n",
    "y2 = torch.tensor([4,5,6], device = device).cpu().tolist()\n",
    "z1 = 1\n",
    "z2 = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'x': [1, 2, 3], 'y': [1, 4, 3], 'z': 1}, {'x': [4, 5, 6], 'y': [4, 5, 6], 'z': 2}]\n",
      "           x          y  z\n",
      "0  [1, 2, 3]  [1, 4, 3]  1\n",
      "1  [4, 5, 6]  [4, 5, 6]  2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>z</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   z  x  y\n",
       "0  1  1  1\n",
       "1  1  2  4\n",
       "2  1  3  3\n",
       "3  2  4  4\n",
       "4  2  5  5\n",
       "5  2  6  6"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Case where we have mixed scalars (z) and columns with nested lists of same length (x,y)\n",
    "l = list()\n",
    "l.append({\"x\":x1, \"y\":y1, \"z\":z1})\n",
    "l.append({\"x\":x2, \"y\":y2, \"z\":z2})\n",
    "print(l)\n",
    "df = pd.DataFrame(l)\n",
    "print(df)\n",
    "unpack_nested_lists_in_df(df, scalar_cols=['z'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'x': [1, 2, 3], 'y': [1, 4, 3], 'z': 1}, {'x': [4, 5], 'y': [4, 5], 'z': 2}]\n",
      "           x          y  z\n",
      "0  [1, 2, 3]  [1, 4, 3]  1\n",
      "1  [4, 5, 6]  [4, 5, 6]  2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>z</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   z  x  y\n",
       "0  1  1  1\n",
       "1  1  2  4\n",
       "2  1  3  3\n",
       "3  2  4  4\n",
       "4  2  5  5"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Case with columns of nested lists of mixed length across rows (but same in a given row) (x,y)\n",
    "x2a = torch.tensor([4,5], device = device).cpu().tolist()\n",
    "y2a = torch.tensor([4,5], device = device).cpu().tolist()\n",
    "l = list()\n",
    "l.append({\"x\":x1, \"y\":y1, \"z\":z1})\n",
    "l.append({\"x\":x2a, \"y\":y2a, \"z\":z2})\n",
    "print(l)\n",
    "print(df)\n",
    "df = pd.DataFrame(l)\n",
    "unpack_nested_lists_in_df(df, scalar_cols=['z'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'x': [1, 2, 3], 'y': [1, 4], 'z': 1}, {'x': [4, 5, 6], 'y': [4, 5], 'z': 2}]\n",
      "           x       y  z\n",
      "0  [1, 2, 3]  [1, 4]  1\n",
      "1  [4, 5, 6]  [4, 5]  2\n"
     ]
    }
   ],
   "source": [
    "# Case where x and y don't have same list sizes in a given row. Should fail\n",
    "y1b = torch.tensor([1,4], device = device).cpu().tolist()\n",
    "y2b = torch.tensor([4,5], device = device).cpu().tolist()\n",
    "l = list()\n",
    "l.append({\"x\":x1, \"y\":y1b, \"z\":z1})\n",
    "l.append({\"x\":x2, \"y\":y2b, \"z\":z2})\n",
    "print(l)\n",
    "df = pd.DataFrame(l)\n",
    "print(df)\n",
    "test_fail(unpack_nested_lists_in_df, args=(df, ['z']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'x': [1, 2, 3], 'y': [1, 4, 3], 'z': 1, 'a': 4}, {'x': [4, 5, 6], 'y': [4, 5, 6], 'z': 2, 'a': 6}]\n",
      "           x          y  z  a\n",
      "0  [1, 2, 3]  [1, 4, 3]  1  4\n",
      "1  [4, 5, 6]  [4, 5, 6]  2  6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>z</th>\n",
       "      <th>a</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   z  a  x  y\n",
       "0  1  4  1  1\n",
       "1  1  4  2  4\n",
       "2  1  4  3  3\n",
       "3  2  6  4  4\n",
       "4  2  6  5  5\n",
       "5  2  6  6  6"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Case with multiple scalar columns\n",
    "a1 = 4\n",
    "a2 = 6\n",
    "l = list()\n",
    "l.append({\"x\":x1, \"y\":y1, \"z\":z1, \"a\": a1})\n",
    "l.append({\"x\":x2, \"y\":y2, \"z\":z2, \"a\": a2})\n",
    "print(l)\n",
    "df = pd.DataFrame(l)\n",
    "print(df)\n",
    "unpack_nested_lists_in_df(df, scalar_cols=['z', 'a'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def robust_rmtree(path, logger=None, max_retries=6):\n",
    "    \"\"\"Robustly tries to delete paths.\n",
    "    Retries several times (with increasing delays) if an OSError\n",
    "    occurs.  If the final attempt fails, the Exception is propagated\n",
    "    to the caller.\n",
    "    \"\"\"\n",
    "    dt = 1\n",
    "    for i in range(max_retries):\n",
    "        try:\n",
    "            shutil.rmtree(path)\n",
    "            return\n",
    "        except OSError:\n",
    "            if logger:\n",
    "                logger.info('Unable to remove path: %s' % path)\n",
    "                logger.info('Retrying after %d seconds' % dt)\n",
    "            time.sleep(dt)\n",
    "            dt *= 2\n",
    "\n",
    "    # Final attempt, pass any Exceptions up to caller.\n",
    "    shutil.rmtree(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wandb utils \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def table2df(table):\n",
    "    \"\"\"Convert wandb table to pandas dataframe\"\"\"\n",
    "    return pd.DataFrame(data=table.data, columns=table.columns)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_utils.ipynb.\n",
      "Converted 02_tests.ipynb.\n",
      "Converted 03_config.ipynb.\n",
      "Converted 07_models.ipynb.\n",
      "Converted 10_data.ipynb.\n",
      "Converted 20_trainer.ipynb.\n",
      "Converted 30_logging.ipynb.\n",
      "Converted 35_charts.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted run.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
