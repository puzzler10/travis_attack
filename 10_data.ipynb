{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import torch, random, pandas as pd, os, warnings, shutil, uuid\n",
    "from torch.utils.data import DataLoader, RandomSampler\n",
    "from datasets import load_dataset, load_from_disk, DatasetDict, ClassLabel\n",
    "from IPython.display import display, HTML\n",
    "from travis_attack.models import get_vm_probs\n",
    "from travis_attack.config import Config\n",
    "from travis_attack.utils import robust_rmtree, timecode\n",
    "from IPython.core.debugger import set_trace\n",
    "import logging\n",
    "logger = logging.getLogger(\"travis_attack.data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "import inspect\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ProcessedDataset: \n",
    "    \"\"\"Class that wraps a raw dataset (e.g. from huggingface datasets) and performs preprocessing on it.\"\"\"\n",
    "    def __init__(self, cfg, vm_tokenizer, vm_model, pp_tokenizer, sts_model,\n",
    "                 load_processed_from_file=True): \n",
    "        \"\"\"load_processed_from_file: set to true to load completed version from file, false will process the data. \"\"\"\n",
    "        self._cfg,self._vm_tokenizer,self._vm_model,self._pp_tokenizer,self._sts_model = cfg,vm_tokenizer,vm_model,pp_tokenizer,sts_model\n",
    "        shard_suffix = f\"_{self._cfg.n_shards}_shards\" if self._cfg.use_small_ds else \"\"\n",
    "        self.cache_path_raw = f\"{self._cfg.path_data_cache}{self._cfg.dataset_name}_raw{shard_suffix}\"\n",
    "        self.cache_path_tkn = f\"{self._cfg.path_data_cache}{self._cfg.dataset_name}_tkn{shard_suffix}\"\n",
    "        \n",
    "        logger.info(f\"Will load dataset {self._cfg.dataset_name} with use_small_ds set to {self._cfg.use_small_ds}\")\n",
    "        \n",
    "        if load_processed_from_file:\n",
    "            if os.path.exists(self.cache_path_raw) and os.path.exists(self.cache_path_tkn):\n",
    "                logger.info(\"Cache file found for processed dataset, so loading that dataset.\")\n",
    "                self.dsd_raw = load_from_disk(self.cache_path_raw) \n",
    "                self.dsd_tkn = load_from_disk(self.cache_path_tkn)\n",
    "                self._prep_dataloaders()\n",
    "            else: \n",
    "                warnings.warn(\"Cache file not found, so will now process the raw dataset.\")\n",
    "                self._preprocess_dataset() \n",
    "        else:   \n",
    "            self._preprocess_dataset() \n",
    "        self._update_cfg()\n",
    "        \n",
    "        logger.debug(f\"Dataset lengths: {self._cfg.ds_length}\")\n",
    "        logger.debug(f\"Total training epochs:{self._cfg.n_train_steps}\")\n",
    "        logger.debug(f\"Last batch size in each epoch is: {self._cfg.dl_leftover_batch_size}\")\n",
    "        logger.debug(f\"Dataloader batch sizes are: {self._cfg.dl_batch_sizes}\") \n",
    "            \n",
    "            \n",
    "    def _prep_dsd_simple(self): \n",
    "        \"\"\"Load the simple dataset and package it up in a DatasetDict (dsd) \n",
    "        with splits for train, valid, test.\"\"\"\n",
    "        dsd = DatasetDict()\n",
    "        for s in self._cfg.splits:  \n",
    "            dsd[s] = load_dataset('csv', \n",
    "                data_files=f\"{self._cfg.path_data}simple_dataset_{s}.csv\", keep_in_memory=False)['train']\n",
    "        return dsd\n",
    "        \n",
    "    def _prep_dsd_rotten_tomatoes(self):\n",
    "        \"\"\"Load the rotten tomatoes dataet and package it up in a DatasetDict (dsd) \n",
    "        with splits for train, valid, test.\"\"\"\n",
    "        dsd = load_dataset(\"rotten_tomatoes\")\n",
    "        dsd['valid'] = dsd.pop('validation')  # \"valid\" is easier than \"validation\" \n",
    "        # make sure that all datasets have the same number of labels as what the victim model predicts\n",
    "        for _,ds in dsd.items(): assert ds.features[self._cfg.label_cname].num_classes == self._cfg.vm_num_labels \n",
    "        return dsd \n",
    "    \n",
    "    def _prep_dsd_raw_snli(self): \n",
    "        ## For snli\n",
    "        # remove_minus1_labels = lambda x: x[label_cname] != -1\n",
    "        # ds_train = ds_train.filter(remove_minus1_labels)\n",
    "        # valid = valid.filter(remove_minus1_labels)\n",
    "        # test = test.filter(remove_minus1_labels)\n",
    "        raise NotImplementedError(\"SNLI not implemented yet.\")\n",
    "    \n",
    "    def _preprocess_dataset(self): \n",
    "        \"\"\"Add columns, tokenize, transform, prepare dataloaders, and do other preprocessing tasks.\"\"\"\n",
    "        if   self._cfg.dataset_name == \"simple\":          dsd = self._prep_dsd_simple()\n",
    "        elif self._cfg.dataset_name == \"rotten_tomatoes\": dsd = self._prep_dsd_rotten_tomatoes()\n",
    "        else: raise Exception(\"cfg.dataset_name must be either 'simple' or 'rotten_tomatoes'\")\n",
    "        dsd = dsd.map(self._add_idx, batched=True, with_indices=True)  # add idx column\n",
    "        if self._cfg.use_small_ds: dsd = self._shard_dsd(dsd)  # do after adding idx so it's consistent across runs\n",
    "        # add VM score & filter out misclassified examples.\n",
    "        # use a common variable dsd, add all columns, and later filter columns to get dsd_raw and dsd_tkn\n",
    "        dsd = dsd.map(self._add_vm_orig_score, batched=True)  \n",
    "        if self._cfg.remove_misclassified_examples:  dsd = dsd.filter(lambda x: x['orig_vm_predclass'] == x['label']) \n",
    "        dsd = dsd.map(self._add_sts_orig_embeddings, batched=True)  # add STS score \n",
    "        dsd = dsd.map(self._tokenize_fn,             batched=True)  # tokenize\n",
    "        dsd = dsd.map(self._add_n_tokens,            batched=True)  # add n_tokens\n",
    "        dsd = dsd.map(self._add_n_letters,           batched=True)  # add n_letters\n",
    "        if self._cfg.bucket_by_length: dsd = dsd.sort(\"n_tokens\", reverse=True)  # sort by n_tokens (high to low), useful for cuda memory caching\n",
    "        # Split dsd into dsd_raw and dsd_tkn\n",
    "        assert dsd.column_names['train'] == dsd.column_names['valid'] == dsd.column_names['test']\n",
    "        self.cnames_dsd_raw = ['idx', 'text', 'label']\n",
    "        self.cnames_dsd_tkn = [o for o in dsd.column_names['train'] if o != 'text'] \n",
    "        self.dsd_raw = dsd.remove_columns([o for o in  dsd['train'].column_names if o not in self.cnames_dsd_raw])\n",
    "        self.dsd_tkn = dsd.remove_columns([\"text\"])\n",
    "        for s in self._cfg.splits: assert len(self.dsd_raw[s]) == len(self.dsd_tkn[s])  # check ds has same number of elements in raw and tkn\n",
    "        self._cache_processed_ds()\n",
    "        self._prep_dataloaders()\n",
    "        \n",
    "    def _prep_dataloaders(self): \n",
    "        self.dld_raw = self._get_dataloaders_dict(self.dsd_raw, collate_fn=self._collate_fn_raw)  # dict of data loaders that serve raw text\n",
    "        self.dld_tkn = self._get_dataloaders_dict(self.dsd_tkn, collate_fn=self._collate_fn_tkn)  # dict of data loaders that serve tokenized text\n",
    "        \n",
    "    def _add_idx(self, batch, idx):\n",
    "        \"\"\"Add row numbers\"\"\"\n",
    "        batch['idx'] = idx \n",
    "        return batch   \n",
    "    \n",
    "    def _add_n_tokens(self, batch): \n",
    "        \"\"\"Add the number of tokens of the orig text \"\"\"\n",
    "        batch['n_tokens'] = [len(o) for o in batch['input_ids']]\n",
    "        return batch \n",
    "    \n",
    "    def _add_n_letters(self, batch): \n",
    "        batch['n_letters'] = [len(o) for o in batch['text']]\n",
    "        return batch\n",
    "    \n",
    "    def _add_sts_orig_embeddings(self, batch): \n",
    "        \"\"\"Add the sts embeddings of the orig text\"\"\"\n",
    "        batch['orig_sts_embeddings'] = self._sts_model.encode(batch[self._cfg.orig_cname], batch_size=64, convert_to_tensor=False)\n",
    "        return batch\n",
    "    \n",
    "    def _add_vm_orig_score(self, batch): \n",
    "        \"\"\"Add the vm score of the orig text\"\"\"\n",
    "        labels = torch.tensor(batch[self._cfg.label_cname], device=self._cfg.device)\n",
    "        orig_probs,orig_predclass = get_vm_probs(batch[self._cfg.orig_cname], self._cfg, self._vm_tokenizer,\n",
    "                                                 self._vm_model, return_predclass=True)\n",
    "        batch['orig_truelabel_probs'] = torch.gather(orig_probs,1, labels[:,None]).squeeze().cpu().tolist()\n",
    "        batch['orig_vm_predclass'] = orig_predclass.cpu().tolist()\n",
    "        return batch\n",
    "    \n",
    "    def _tokenize_fn(self, batch):  \n",
    "        \"\"\"Tokenize a batch of orig text using the paraphrase tokenizer.\"\"\"\n",
    "        return self._pp_tokenizer(batch[self._cfg.orig_cname], truncation=True, max_length=self._cfg.orig_max_length)  \n",
    "    \n",
    "    def _collate_fn_tkn(self, x): \n",
    "        \"\"\"Collate function used by the DataLoader that serves tokenized data. \n",
    "        x is a list (with length batch_size) of dicts. Keys should be the same across dicts.\n",
    "        I guess an error is raised if not. \"\"\"\n",
    "        # check all keys are the same in the list. the assert is quick (~1e-5 seconds)\n",
    "        for o in x: assert set(o) == set(x[0])\n",
    "        d = dict()\n",
    "        for k in x[0].keys():  d[k] = [o[k] for o in x]\n",
    "        return self._pp_tokenizer.pad(d, pad_to_multiple_of=self._cfg.orig_padding_multiple, return_tensors=\"pt\")\n",
    "\n",
    "    def _collate_fn_raw(self, x): \n",
    "        \"\"\"Collate function used by the DataLoader that serves raw data. x is a list of data.\"\"\"\n",
    "        d = dict()\n",
    "        for o in x: assert set(o) == set(x[0])  # check all keys are the same in list\n",
    "        for k in x[0].keys(): d[k] = [o[k] for o in x]\n",
    "        return d \n",
    "\n",
    "    def _get_sampler(self, ds): \n",
    "        \"\"\"Returns a RandomSampler. Used so we can keep the same shuffle order across multiple data loaders.\n",
    "        Used when self._cfg.shuffle_train = True\"\"\"\n",
    "        g = torch.Generator()\n",
    "        g.manual_seed(seed)\n",
    "        return RandomSampler(ds, generator=g)\n",
    "    \n",
    "    def _shard_dsd(self, dsd):\n",
    "        \"\"\"Replaces dsd with a smaller shard of itself.\"\"\"\n",
    "        for k,v in dsd.items():  \n",
    "            dsd[k] = v.shard(self._cfg.n_shards, 0, contiguous=self._cfg.shard_contiguous)\n",
    "        return dsd\n",
    "        \n",
    "    def _get_dataloaders_dict(self, dsd, collate_fn): \n",
    "        \"\"\"Prepare a dict of dataloaders for train, valid and test\"\"\"\n",
    "        if self._cfg.bucket_by_length and self._cfg.shuffle_train:  raise Exception(\"Can only do one of bucket by length or shuffle\")\n",
    "        d = dict()\n",
    "        for split, ds in dsd.items(): \n",
    "            if self._cfg.shuffle_train:\n",
    "                if split == \"train\": \n",
    "                    sampler = self.get_sampler(ds)\n",
    "                    d[split] =  DataLoader(ds, batch_size=self._cfg.batch_size_train, \n",
    "                                           sampler=sampler, collate_fn=collate_fn, \n",
    "                                           num_workers=self._cfg.n_wkrs, pin_memory=self._cfg.pin_memory) \n",
    "                else: \n",
    "                    d[split] =  DataLoader(ds, batch_size=self._cfg.batch_size_eval, \n",
    "                                           shuffle=False, collate_fn=collate_fn, \n",
    "                                           num_workers=self._cfg.n_wkrs, pin_memory=self._cfg.pin_memory) \n",
    "            if self._cfg.bucket_by_length: \n",
    "                batch_size = self._cfg.batch_size_train if split == \"train\" else self._cfg.batch_size_eval\n",
    "                d[split] =  DataLoader(ds, batch_size=batch_size, shuffle=False, collate_fn=collate_fn, \n",
    "                                       num_workers=self._cfg.n_wkrs, pin_memory=self._cfg.pin_memory) \n",
    "\n",
    "        # Add eval dataloader for train: same as train but bigger batch size and explicitly no shuffling.\n",
    "        d['train_eval'] = DataLoader(dsd['train'], batch_size=self._cfg.batch_size_eval, shuffle=False,\n",
    "                                    collate_fn=collate_fn, \n",
    "                                     num_workers=self._cfg.n_wkrs, pin_memory=self._cfg.pin_memory) \n",
    "        return d \n",
    "    \n",
    "    def _update_cfg(self): \n",
    "        self._cfg.ds_length,self._cfg.dl_n_batches,self._cfg.dl_leftover_batch_size,self._cfg.dl_batch_sizes = dict(),dict(),dict(),dict()\n",
    "        def get_dl_batch_sizes(batch_size, dl_n_batches): \n",
    "            if self._cfg.dl_leftover_batch_size[k] == 0: \n",
    "                return [batch_size for i in range(dl_n_batches)]\n",
    "            else: \n",
    "                l = [batch_size for i in range(dl_n_batches - 1)]\n",
    "                l.append(self._cfg.dl_leftover_batch_size[k])\n",
    "                return l\n",
    "                \n",
    "        for k,v in self.dsd_raw.items(): self._cfg.ds_length[k] = len(v)   # Dataset lengths\n",
    "        for k,v in self.dld_raw.items(): \n",
    "            self._cfg.dl_n_batches[k] = len(v)   # Dataloader lengths \n",
    "            # Dataloader last batch size and list of batch sizes\n",
    "            ds_k = \"train\" if k == \"train_eval\" else k \n",
    "            if k == \"train\": \n",
    "                self._cfg.dl_leftover_batch_size[k] = self._cfg.ds_length[ds_k] % self._cfg.batch_size_train\n",
    "                self._cfg.dl_batch_sizes[k]     = get_dl_batch_sizes(self._cfg.batch_size_train, self._cfg.dl_n_batches[k])\n",
    "            else: \n",
    "                self._cfg.dl_leftover_batch_size[k] = self._cfg.ds_length[ds_k] % self._cfg.batch_size_eval\n",
    "                self._cfg.dl_batch_sizes[k]     = get_dl_batch_sizes(self._cfg.batch_size_eval, self._cfg.dl_n_batches[k])\n",
    "            \n",
    "        # Total number of training steps\n",
    "        self._cfg.n_train_steps = self._cfg.n_train_epochs * self._cfg.dl_n_batches['train']\n",
    "    \n",
    "    def _cache_processed_ds(self):\n",
    "        def _reset_dir(path): \n",
    "            if os.path.exists(path) and os.path.isdir(path):    \n",
    "                # So deleting the old files sometimes throws errors because of race conditions, I think \n",
    "                # so as a workaround we will just move files to old directories and then periodicallly clean them. \n",
    "                #                robust_rmtree(path, logger=None, max_retries=6)  \n",
    "                path_old_files = f\"{self._cfg.path_data_cache}old_files/\"\n",
    "                os.makedirs(path_old_files, exist_ok=True)\n",
    "                shutil.move(path, f\"{path_old_files}{uuid.uuid4().hex}\") \n",
    "            os.makedirs(path, exist_ok=True)\n",
    "        _reset_dir(self.cache_path_raw)\n",
    "        _reset_dir(self.cache_path_tkn)\n",
    "        self.dsd_raw.save_to_disk(dataset_dict_path = self.cache_path_raw)\n",
    "        self.dsd_tkn.save_to_disk(dataset_dict_path = self.cache_path_tkn)\n",
    "        \n",
    "    def show_random_elements(self, ds, num_examples=10):\n",
    "        \"\"\"Print some elements in a nice format so you can take a look at them. \n",
    "        Split is one of 'train', 'test', 'valid'. \n",
    "        Use for a dataset `ds` from the `dataset` package.  \"\"\"\n",
    "        assert num_examples <= len(ds), \"Can't pick more elements than there are in the dataset.\"\n",
    "        picks = []\n",
    "        for _ in range(num_examples):\n",
    "            pick = random.randint(0, len(ds)-1)\n",
    "            while pick in picks:\n",
    "                pick = random.randint(0, len(ds)-1)\n",
    "            picks.append(pick)\n",
    "        df = pd.DataFrame(ds[picks])\n",
    "        for column, typ in ds.features.items():\n",
    "            if isinstance(typ, ClassLabel):\n",
    "                df[column] = df[column].transform(lambda i: typ.names[i])\n",
    "        display(HTML(df.to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basics "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have defined a class `ProcessedDataset` that will load and preprocess a dataset. But before processing the dataset you must load both the config object and all models/tokenizers, so we do this first. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from travis_attack.models import prepare_models\n",
    "cfg = Config()\n",
    "vm_tokenizer, vm_model, pp_tokenizer, pp_model, sts_model, cfg = prepare_models(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently there are two choices for dataset: \n",
    "\n",
    "* `simple`, a dataset of simple sentences with four elements each in the train, test and valid splits\n",
    "* `rotten_tomatoes`, a dataset of movie reviews scraped from the Rotten Tomatoes site. \n",
    "\n",
    "The dataset is specified by the config class. There are two ways to do this. \n",
    "\n",
    "1. Edit the `self.dataset_name` variable in the Config class to either `simple` or `rotten_tomatoes`. An error will be thrown if the name is not one of these two. This is the best way to use when doing runs.   \n",
    "2. Use the `adjust_dataset_...` methods of the config class: e.g. `cfg = cfg.adjust_dataset_for_rotten_tomatoes_dataset() = Config()`. This is easiest for automated testing so we will do this here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the config is specified and loaded, create an object of class `ProcessedDataset` by passing the config, models and tokenizers as variables. This will do all preprocessing automatically in creating the object (the preprocessing code is in the `__init__()` function of the class.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-b253756c445fb811\n",
      "Reusing dataset csv (/data/tproth/.cache/huggingface/datasets/csv/default-b253756c445fb811/0.0.0/6b9057d9e23d9d8a2f05b985917a0da84d70c5dae3d22ddd8a3f22fb01c69d9e)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eee3dda4a8bc41a5b92822f85cb2c7d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-c802946231f72062\n",
      "Reusing dataset csv (/data/tproth/.cache/huggingface/datasets/csv/default-c802946231f72062/0.0.0/6b9057d9e23d9d8a2f05b985917a0da84d70c5dae3d22ddd8a3f22fb01c69d9e)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1ae94dabc9e4f9ab1717d1c3ac33fef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-43a49c5188c42e69\n",
      "Reusing dataset csv (/data/tproth/.cache/huggingface/datasets/csv/default-43a49c5188c42e69/0.0.0/6b9057d9e23d9d8a2f05b985917a0da84d70c5dae3d22ddd8a3f22fb01c69d9e)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e150f74fae3841ab91f5ecfdf2a50830",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ec7b57b173841eea5b694de8b39be08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae0d71948de6412dacd756715fa285e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe39dfcf308c4bd5a1be2237c7529c84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43849cd503714094930bf781ae9b67ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f0b4d18ca974530867965144e50fdc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d1a949722b84ea5851ecb2d32c9806f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5b3ac3e924a46ab89d288c7e32774c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ced4cd37850c4b5e8dcf73c1a504815c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e0383a880fa4fd5b169495d40dd63d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bf8e7237e8f4429b14602c2a172ef2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8548603e9e0a4bbebdec3e9878208c77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ca978ef5ce540e58b100bfca0fca24e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be02d2c52c3e4ce7bda7932e08cebed2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a40651dc91434b36a4dfe2a482e226a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51701eb5711e4f438707a7ef23b59465",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "860befb72dbe4081a952a736c89025b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3680b753103c44c68be374949940f269",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cb04a35c08d46ccaafa1d7fe5885e36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2db45f3cb494da89ad27723e89fa67c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb8fccb6b29048c8a6237ee93d2f2ba4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b3b64fc16ca460f87ba5a59f0f8dd3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d9180c533f54efaae128f03acaa0768",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Flattening the indices:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3205c0e967334dfeaf53b5439d2e1fa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Flattening the indices:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b71fc6619e89433b84047c62ca00a849",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Flattening the indices:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b86cb2d7cb34d36b0e5b67131c91b94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Flattening the indices:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c62c0428929470bba125a71e75fdda7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Flattening the indices:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "190734f2981c40a2b1af8473e442d662",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Flattening the indices:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cfg_simple = cfg.adjust_config_for_simple_dataset()\n",
    "ds = ProcessedDataset(cfg_simple, vm_tokenizer, vm_model, pp_tokenizer, sts_model, \n",
    "                      load_processed_from_file=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to use the small dataset adjust the config before creating the `ProcessedDataset` object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset rotten_tomatoes_movie_review (/data/tproth/.cache/huggingface/datasets/rotten_tomatoes_movie_review/default/1.0.0/40d411e45a6ce3484deed7cc15b82a53dad9a72aafd9f86f8f227134bec5ca46)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8cc7538745a43bfafcbb5b31bf70e9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "468eed6407cc4d80a10d8aca4179300a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28d7753738954945ba348b8bc3af1a35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee89609671af402eb174d4e1d2ff0460",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be0d6075d6d74386966e2b22d437fa72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a14a9d2eb5e4ce4a31748dc3a98afe1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f25aff9bcf67466c8d23217180142343",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8e581cda88145a1bd79230ca2bf3142",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2434d6c09d0b41308c22c831d1fbee14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7a2ef5c3280449aa55edc163ac79249",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cae7340c86b94e0bb9405c2799eb242e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "566857099fd8492faed14eb218baa702",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89acc5d2788b415699627fab0381b151",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c68d82da54d4bf288d899bd82640075",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5611c9fae8642c4bb2b5740fd0d3923",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bed00771c2644d1b3fbd734a94a3901",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3781a17db71348f4a3801608b1904ad7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f82b7e90a924ab3ae83914e000351f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e803bb6e44904843991d9d27dcfd57ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f64aa04cea94c68a3503a53a2e9e146",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02c955f41b3647fcaf2e1f19106a4efb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7407951ad4de41f09b71cee569a22358",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f195dec93ad44adc969a0b387225ce98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Flattening the indices:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1be6197cb19046c18c688685a70e3676",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Flattening the indices:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee2bc2a0828247e49457ce6bcecc62a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Flattening the indices:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "800efcaf5d5d447cb644086001834d8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Flattening the indices:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49f07d206aaf4ff7a9af2858838e808c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Flattening the indices:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7fee2f536244f3cadf6632773717f1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Flattening the indices:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cfg_rt_small_ds = cfg.adjust_config_for_rotten_tomatoes_dataset().small_ds()\n",
    "ds = ProcessedDataset(cfg_rt_small_ds, vm_tokenizer, vm_model, pp_tokenizer, sts_model,\n",
    "                      load_processed_from_file=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can access raw data with `ds.dsd_raw` and processed data with the `ds.dsd_tkn`. (The dsd here stands for \"DatasetDict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 154\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 18\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 16\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.dsd_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'idx', 'orig_truelabel_probs', 'orig_vm_predclass', 'orig_sts_embeddings', 'input_ids', 'attention_mask', 'n_tokens', 'n_letters'],\n",
       "        num_rows: 154\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['label', 'idx', 'orig_truelabel_probs', 'orig_vm_predclass', 'orig_sts_embeddings', 'input_ids', 'attention_mask', 'n_tokens', 'n_letters'],\n",
       "        num_rows: 18\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['label', 'idx', 'orig_truelabel_probs', 'orig_vm_predclass', 'orig_sts_embeddings', 'input_ids', 'attention_mask', 'n_tokens', 'n_letters'],\n",
       "        num_rows: 16\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.dsd_tkn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can access elements by indexing: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['berling and bÃ©art . . . continue to impress , and isabelle huppert . . . again shows uncanny skill in getting under the skin of her characters .',\n",
       "  \"i'm not sure which will take longer to heal : the welt on johnny knoxville's stomach from a riot-control projectile or my own tortured psyche .\"],\n",
       " 'label': [1, 0],\n",
       " 'idx': [400, 750]}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.dsd_raw['valid'][0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': [1, 0],\n",
       " 'idx': [400, 750],\n",
       " 'orig_truelabel_probs': [0.9531264901161194, 0.8985466957092285],\n",
       " 'orig_vm_predclass': [1, 0],\n",
       " 'orig_sts_embeddings': [[0.10162420570850372,\n",
       "   -0.15061667561531067,\n",
       "   -0.02832075022161007,\n",
       "   0.18470776081085205,\n",
       "   -0.144411101937294,\n",
       "   -0.02936149388551712,\n",
       "   0.3306199908256531,\n",
       "   0.07828425616025925,\n",
       "   -0.030337156727910042,\n",
       "   -0.14721500873565674,\n",
       "   0.23712067306041718,\n",
       "   -0.288776159286499,\n",
       "   -0.07359367609024048,\n",
       "   -0.28062987327575684,\n",
       "   0.04253583401441574,\n",
       "   0.07229325920343399,\n",
       "   0.15865543484687805,\n",
       "   0.22507694363594055,\n",
       "   -0.143656387925148,\n",
       "   -0.08837874233722687,\n",
       "   -0.3990294337272644,\n",
       "   -0.023890824988484383,\n",
       "   0.05965694040060043,\n",
       "   0.1094372570514679,\n",
       "   0.11948876827955246,\n",
       "   -0.30829957127571106,\n",
       "   -0.10492965579032898,\n",
       "   0.1315850019454956,\n",
       "   0.11578385531902313,\n",
       "   -0.45641112327575684,\n",
       "   -0.06523998081684113,\n",
       "   -0.08991163969039917,\n",
       "   -0.30539849400520325,\n",
       "   0.14492005109786987,\n",
       "   -0.2655504047870636,\n",
       "   0.1472175568342209,\n",
       "   -0.044842615723609924,\n",
       "   0.03951779007911682,\n",
       "   0.09245096892118454,\n",
       "   -0.3786919116973877,\n",
       "   -0.2955397367477417,\n",
       "   -0.041304439306259155,\n",
       "   -0.1722501665353775,\n",
       "   -0.05433393642306328,\n",
       "   0.003626302583143115,\n",
       "   -0.2684785723686218,\n",
       "   -0.11951649934053421,\n",
       "   -0.05911079794168472,\n",
       "   -0.2790667414665222,\n",
       "   -0.012160307727754116,\n",
       "   -0.09533562511205673,\n",
       "   -0.21570149064064026,\n",
       "   -0.2709865868091583,\n",
       "   -0.18893659114837646,\n",
       "   -0.11295003443956375,\n",
       "   -0.11568070203065872,\n",
       "   0.1467294543981552,\n",
       "   0.3096033036708832,\n",
       "   0.020093543455004692,\n",
       "   -0.13192272186279297,\n",
       "   0.13189753890037537,\n",
       "   0.20289602875709534,\n",
       "   -0.2745835781097412,\n",
       "   0.16350142657756805,\n",
       "   -0.10308562219142914,\n",
       "   -0.3670356273651123,\n",
       "   0.09816203266382217,\n",
       "   0.028201866894960403,\n",
       "   -0.06978487223386765,\n",
       "   0.15091370046138763,\n",
       "   0.1291765421628952,\n",
       "   0.011518839746713638,\n",
       "   0.27867648005485535,\n",
       "   -0.04272485896945,\n",
       "   0.29007092118263245,\n",
       "   0.31105583906173706,\n",
       "   0.1264265775680542,\n",
       "   0.17793968319892883,\n",
       "   -0.021006278693675995,\n",
       "   -0.07266954332590103,\n",
       "   -0.034061845391988754,\n",
       "   -0.06548726558685303,\n",
       "   0.15889210999011993,\n",
       "   0.10364654660224915,\n",
       "   0.2298266589641571,\n",
       "   -0.024399474263191223,\n",
       "   0.07520630210638046,\n",
       "   -0.16561615467071533,\n",
       "   0.03798902407288551,\n",
       "   0.0658748596906662,\n",
       "   0.09225508570671082,\n",
       "   0.10162342339754105,\n",
       "   0.0797513946890831,\n",
       "   0.2020944505929947,\n",
       "   0.13337412476539612,\n",
       "   -0.08311817795038223,\n",
       "   0.028267746791243553,\n",
       "   0.0019306871108710766,\n",
       "   -0.18033476173877716,\n",
       "   0.4007144868373871,\n",
       "   0.06740424036979675,\n",
       "   -0.008436129428446293,\n",
       "   -0.09976471960544586,\n",
       "   0.1546136885881424,\n",
       "   0.17959466576576233,\n",
       "   -0.19455529749393463,\n",
       "   0.4597214460372925,\n",
       "   -0.35939088463783264,\n",
       "   -0.09204742312431335,\n",
       "   -0.08142368495464325,\n",
       "   -0.26208534836769104,\n",
       "   -0.11228547245264053,\n",
       "   -0.248759463429451,\n",
       "   -0.18218427896499634,\n",
       "   -0.0020329647231847048,\n",
       "   0.16565372049808502,\n",
       "   -0.13226035237312317,\n",
       "   0.3230060935020447,\n",
       "   -0.014961478300392628,\n",
       "   -0.12003511190414429,\n",
       "   0.22422918677330017,\n",
       "   0.2421308010816574,\n",
       "   -0.16248175501823425,\n",
       "   -0.27595725655555725,\n",
       "   0.15969549119472504,\n",
       "   -0.13724026083946228,\n",
       "   0.06641535460948944,\n",
       "   -0.02996237576007843,\n",
       "   0.13072793185710907,\n",
       "   0.2775281071662903,\n",
       "   -0.0011341552017256618,\n",
       "   0.29327553510665894,\n",
       "   0.15133295953273773,\n",
       "   0.061434555798769,\n",
       "   -0.13145257532596588,\n",
       "   0.01072451751679182,\n",
       "   0.050697945058345795,\n",
       "   0.09117259830236435,\n",
       "   -0.3120841681957245,\n",
       "   -0.1297130584716797,\n",
       "   -0.2336122840642929,\n",
       "   0.09729835391044617,\n",
       "   0.03790696710348129,\n",
       "   -0.04768779128789902,\n",
       "   0.15826745331287384,\n",
       "   0.10517674684524536,\n",
       "   -0.22587835788726807,\n",
       "   0.32683953642845154,\n",
       "   -0.005764065310359001,\n",
       "   0.18519988656044006,\n",
       "   -0.2957790195941925,\n",
       "   -0.16283084452152252,\n",
       "   -0.006460170261561871,\n",
       "   0.06792714446783066,\n",
       "   -0.039994075894355774,\n",
       "   0.042625363916158676,\n",
       "   -0.06213407963514328,\n",
       "   0.017908167093992233,\n",
       "   -0.03958365321159363,\n",
       "   0.056915830820798874,\n",
       "   -0.057802464812994,\n",
       "   0.40855616331100464,\n",
       "   -0.1339474320411682,\n",
       "   -0.31962350010871887,\n",
       "   0.1711355447769165,\n",
       "   -0.020919740200042725,\n",
       "   0.26181915402412415,\n",
       "   0.3262142539024353,\n",
       "   -0.05342373996973038,\n",
       "   0.08415433764457703,\n",
       "   0.007236942183226347,\n",
       "   -0.0627862736582756,\n",
       "   -0.13988059759140015,\n",
       "   -0.021862436085939407,\n",
       "   0.03895248472690582,\n",
       "   -0.05438562110066414,\n",
       "   -0.22705739736557007,\n",
       "   -0.05772858485579491,\n",
       "   0.16604356467723846,\n",
       "   0.1991817206144333,\n",
       "   0.2730175852775574,\n",
       "   0.3556148409843445,\n",
       "   0.10660091787576675,\n",
       "   0.05397717282176018,\n",
       "   -0.30889925360679626,\n",
       "   -0.227083221077919,\n",
       "   0.28050491213798523,\n",
       "   0.01929512433707714,\n",
       "   0.1630212664604187,\n",
       "   0.07770583778619766,\n",
       "   0.08997148275375366,\n",
       "   -0.22683210670948029,\n",
       "   -0.11283860355615616,\n",
       "   0.10844297707080841,\n",
       "   0.25137457251548767,\n",
       "   -0.06345345824956894,\n",
       "   0.04609433561563492,\n",
       "   0.05251634120941162,\n",
       "   -0.32669928669929504,\n",
       "   0.07633143663406372,\n",
       "   -0.2616399824619293,\n",
       "   -0.23149441182613373,\n",
       "   -0.12353762239217758,\n",
       "   -0.16350321471691132,\n",
       "   0.15215399861335754,\n",
       "   -0.04077831655740738,\n",
       "   -0.025365373119711876,\n",
       "   -0.024380745366215706,\n",
       "   0.1292121410369873,\n",
       "   -0.02832568995654583,\n",
       "   -0.15566225349903107,\n",
       "   -0.28087154030799866,\n",
       "   -0.10462173074483871,\n",
       "   -0.07080148905515671,\n",
       "   -0.06846734881401062,\n",
       "   -0.27884575724601746,\n",
       "   0.3368644118309021,\n",
       "   -0.052021872252225876,\n",
       "   0.23579517006874084,\n",
       "   0.07179871201515198,\n",
       "   -0.07933103293180466,\n",
       "   -0.3223845362663269,\n",
       "   -0.063166543841362,\n",
       "   -0.3994535505771637,\n",
       "   0.14044895768165588,\n",
       "   -0.0954185351729393,\n",
       "   -0.10373937338590622,\n",
       "   -0.0017018214566633105,\n",
       "   -0.3959083557128906,\n",
       "   -0.5588034987449646,\n",
       "   -0.10679729282855988,\n",
       "   0.07462307810783386,\n",
       "   0.027308933436870575,\n",
       "   -0.1181473433971405,\n",
       "   -0.20307351648807526,\n",
       "   -0.18280290067195892,\n",
       "   0.01331978291273117,\n",
       "   -0.182404026389122,\n",
       "   -0.28639551997184753,\n",
       "   -0.2918660342693329,\n",
       "   0.3747044503688812,\n",
       "   0.05691724643111229,\n",
       "   0.15528562664985657,\n",
       "   0.03322841227054596,\n",
       "   0.20016692578792572,\n",
       "   -0.030091866850852966,\n",
       "   -0.09301898628473282,\n",
       "   -0.037826135754585266,\n",
       "   0.06080195680260658,\n",
       "   0.7586633563041687,\n",
       "   0.12945149838924408,\n",
       "   -0.0946769118309021,\n",
       "   -0.1849745810031891,\n",
       "   0.10328011214733124,\n",
       "   0.05588601902127266,\n",
       "   0.4135621190071106,\n",
       "   -0.1369520127773285,\n",
       "   -0.014780078083276749,\n",
       "   0.050900090485811234,\n",
       "   0.3510362505912781,\n",
       "   0.07683676481246948,\n",
       "   0.1978016346693039,\n",
       "   -0.1160915195941925,\n",
       "   -0.046550288796424866,\n",
       "   0.16200712323188782,\n",
       "   -0.07564600557088852,\n",
       "   0.10143600404262543,\n",
       "   0.20319896936416626,\n",
       "   -0.14116887748241425,\n",
       "   0.0891922116279602,\n",
       "   0.1449897140264511,\n",
       "   0.39288678765296936,\n",
       "   -0.034492332488298416,\n",
       "   -0.2071201652288437,\n",
       "   0.2378983497619629,\n",
       "   -0.24807894229888916,\n",
       "   -0.08711923658847809,\n",
       "   -0.054588038474321365,\n",
       "   -0.2057398557662964,\n",
       "   -0.06459912657737732,\n",
       "   0.24307109415531158,\n",
       "   -0.23495127260684967,\n",
       "   0.053291067481040955,\n",
       "   -0.013819989748299122,\n",
       "   0.023064732551574707,\n",
       "   0.0025883973576128483,\n",
       "   -0.14632436633110046,\n",
       "   0.023461202159523964,\n",
       "   0.13823102414608002,\n",
       "   0.05042317137122154,\n",
       "   -0.1902385801076889,\n",
       "   -0.11717958003282547,\n",
       "   -0.18621300160884857,\n",
       "   -0.1278408020734787,\n",
       "   -0.05949309095740318,\n",
       "   -0.14524130523204803,\n",
       "   -0.06680045276880264,\n",
       "   0.194358229637146,\n",
       "   -0.42915335297584534,\n",
       "   0.18488365411758423,\n",
       "   0.11793637275695801,\n",
       "   0.0033794078044593334,\n",
       "   0.0843629390001297,\n",
       "   -0.03769106790423393,\n",
       "   0.046999040991067886,\n",
       "   -0.10291524231433868,\n",
       "   -0.13739439845085144,\n",
       "   -0.034174516797065735,\n",
       "   0.39816758036613464,\n",
       "   0.18848764896392822,\n",
       "   -0.049102455377578735,\n",
       "   0.011572221294045448,\n",
       "   -0.048235345631837845,\n",
       "   0.002288384363055229,\n",
       "   0.05001160502433777,\n",
       "   0.33441248536109924,\n",
       "   0.19467946887016296,\n",
       "   0.06088314205408096,\n",
       "   0.07261280715465546,\n",
       "   -0.3148270547389984,\n",
       "   -0.0359155498445034,\n",
       "   -0.16183581948280334,\n",
       "   -0.261409193277359,\n",
       "   -0.12423204630613327,\n",
       "   0.04785231500864029,\n",
       "   0.05811602249741554,\n",
       "   -0.09967387467622757,\n",
       "   0.09860579669475555,\n",
       "   -0.04982154443860054,\n",
       "   0.11713521182537079,\n",
       "   -0.1186194121837616,\n",
       "   0.22512467205524445,\n",
       "   -0.00939498282968998,\n",
       "   -0.11631686985492706,\n",
       "   0.20855972170829773,\n",
       "   0.3099546730518341,\n",
       "   0.1674901247024536,\n",
       "   0.2716306746006012,\n",
       "   -0.12640003859996796,\n",
       "   -0.10126357525587082,\n",
       "   -0.02440587803721428,\n",
       "   0.10700931400060654,\n",
       "   -0.11380191147327423,\n",
       "   -0.3867582380771637,\n",
       "   -0.3894975781440735,\n",
       "   0.18154901266098022,\n",
       "   -0.2495223730802536,\n",
       "   -0.0700039193034172,\n",
       "   -0.04545808210968971,\n",
       "   0.24908949434757233,\n",
       "   0.21154382824897766,\n",
       "   0.008861334063112736,\n",
       "   0.026780186221003532,\n",
       "   -0.0720832496881485,\n",
       "   0.21488861739635468,\n",
       "   0.22174789011478424,\n",
       "   0.0849585309624672,\n",
       "   0.12557652592658997,\n",
       "   0.09810133278369904,\n",
       "   0.31019526720046997,\n",
       "   0.021294964477419853,\n",
       "   -0.1987060010433197,\n",
       "   0.15128248929977417,\n",
       "   0.056247275322675705,\n",
       "   0.0323132760822773,\n",
       "   -0.06833306699991226,\n",
       "   0.08540847152471542,\n",
       "   -0.03572315350174904,\n",
       "   0.01696014031767845,\n",
       "   0.13657023012638092,\n",
       "   0.1515538990497589,\n",
       "   0.03314238041639328,\n",
       "   0.054176751524209976,\n",
       "   0.03264039382338524,\n",
       "   -0.24998225271701813,\n",
       "   0.030678045004606247,\n",
       "   0.19788335263729095,\n",
       "   0.1369750052690506,\n",
       "   -0.20179134607315063,\n",
       "   0.25246384739875793,\n",
       "   0.07789178937673569,\n",
       "   0.002181057119742036,\n",
       "   0.07624503970146179,\n",
       "   0.27734610438346863],\n",
       "  [-0.04943045973777771,\n",
       "   -0.13852399587631226,\n",
       "   0.10275880992412567,\n",
       "   0.09161150455474854,\n",
       "   0.1544291228055954,\n",
       "   0.1317816823720932,\n",
       "   -0.15991587936878204,\n",
       "   0.10065166652202606,\n",
       "   0.08826592564582825,\n",
       "   -0.21027380228042603,\n",
       "   0.051606543362140656,\n",
       "   0.23786285519599915,\n",
       "   0.25900447368621826,\n",
       "   0.04953916743397713,\n",
       "   -0.0976845845580101,\n",
       "   -0.055581483989953995,\n",
       "   0.09812244772911072,\n",
       "   0.04494871571660042,\n",
       "   -0.18276308476924896,\n",
       "   0.21401239931583405,\n",
       "   -0.5241497159004211,\n",
       "   0.18526901304721832,\n",
       "   0.19978167116641998,\n",
       "   0.04047496244311333,\n",
       "   -0.1573326289653778,\n",
       "   -0.02534630335867405,\n",
       "   -0.04208940267562866,\n",
       "   -0.04265511408448219,\n",
       "   -0.09408576041460037,\n",
       "   -0.1382148712873459,\n",
       "   -0.024179544299840927,\n",
       "   -0.3726431131362915,\n",
       "   -0.27662086486816406,\n",
       "   -0.10778167843818665,\n",
       "   0.2276206910610199,\n",
       "   0.04805929958820343,\n",
       "   0.02950209565460682,\n",
       "   0.5797379016876221,\n",
       "   0.07750672847032547,\n",
       "   -0.1140674352645874,\n",
       "   0.08875007927417755,\n",
       "   0.12368199229240417,\n",
       "   -0.1120656356215477,\n",
       "   0.07099978625774384,\n",
       "   0.31605538725852966,\n",
       "   -0.014240577816963196,\n",
       "   0.1501733362674713,\n",
       "   -0.3296676278114319,\n",
       "   -0.27644848823547363,\n",
       "   0.15928681194782257,\n",
       "   -0.0702049657702446,\n",
       "   0.1502365916967392,\n",
       "   0.164701908826828,\n",
       "   0.08071962743997574,\n",
       "   0.11071237176656723,\n",
       "   0.06440407037734985,\n",
       "   -0.2930458188056946,\n",
       "   0.18912316858768463,\n",
       "   -0.09310777485370636,\n",
       "   0.23761770129203796,\n",
       "   -0.025612913072109222,\n",
       "   -0.02043636329472065,\n",
       "   -0.21958063542842865,\n",
       "   -0.020464332774281502,\n",
       "   0.19861124455928802,\n",
       "   -0.5861010551452637,\n",
       "   -0.004562572576105595,\n",
       "   -0.14379610121250153,\n",
       "   0.23262271285057068,\n",
       "   0.6464654803276062,\n",
       "   0.06404292583465576,\n",
       "   0.07561646401882172,\n",
       "   -0.17164726555347443,\n",
       "   -0.2774145007133484,\n",
       "   -0.07341466844081879,\n",
       "   -0.06310192495584488,\n",
       "   -0.07741332799196243,\n",
       "   0.08654654026031494,\n",
       "   0.16036762297153473,\n",
       "   -0.16013573110103607,\n",
       "   0.30613866448402405,\n",
       "   0.0530259869992733,\n",
       "   0.020146971568465233,\n",
       "   -0.2061411738395691,\n",
       "   -0.38712620735168457,\n",
       "   -0.008615870960056782,\n",
       "   -0.01695665530860424,\n",
       "   0.13259628415107727,\n",
       "   -0.1020965501666069,\n",
       "   -0.08045586198568344,\n",
       "   0.1289198398590088,\n",
       "   0.055268991738557816,\n",
       "   0.5387978553771973,\n",
       "   0.03611309081315994,\n",
       "   0.23890918493270874,\n",
       "   0.2003883719444275,\n",
       "   -0.28506073355674744,\n",
       "   0.33524763584136963,\n",
       "   -0.30401521921157837,\n",
       "   0.10532358288764954,\n",
       "   -0.03241916373372078,\n",
       "   -0.3048737943172455,\n",
       "   -0.23490600287914276,\n",
       "   -0.20289427042007446,\n",
       "   0.25306469202041626,\n",
       "   0.07313738763332367,\n",
       "   0.08895611017942429,\n",
       "   -0.18723547458648682,\n",
       "   -0.16306784749031067,\n",
       "   0.07545583695173264,\n",
       "   0.1353868693113327,\n",
       "   0.10827914625406265,\n",
       "   -0.040717486292123795,\n",
       "   0.04855018109083176,\n",
       "   0.3728392720222473,\n",
       "   0.11408451944589615,\n",
       "   0.10098927468061447,\n",
       "   -0.03960295394062996,\n",
       "   -0.3918899893760681,\n",
       "   0.10854905098676682,\n",
       "   0.04001818597316742,\n",
       "   -0.3960278034210205,\n",
       "   -0.003670476609840989,\n",
       "   -0.19962331652641296,\n",
       "   -0.1654239445924759,\n",
       "   -0.003624727949500084,\n",
       "   -0.056863442063331604,\n",
       "   0.0966358408331871,\n",
       "   0.1756976842880249,\n",
       "   -0.034549396485090256,\n",
       "   0.057992786169052124,\n",
       "   0.17022350430488586,\n",
       "   0.32430386543273926,\n",
       "   0.114195317029953,\n",
       "   -0.029835624620318413,\n",
       "   0.16663230955600739,\n",
       "   0.06881628185510635,\n",
       "   0.2057124674320221,\n",
       "   0.07955899834632874,\n",
       "   -0.13945749402046204,\n",
       "   -0.060774367302656174,\n",
       "   0.219375342130661,\n",
       "   -0.5840176343917847,\n",
       "   -0.04427669569849968,\n",
       "   -0.13369153439998627,\n",
       "   -0.06558743864297867,\n",
       "   0.19083061814308167,\n",
       "   -0.32918503880500793,\n",
       "   -0.045105233788490295,\n",
       "   0.11514171957969666,\n",
       "   -0.30375558137893677,\n",
       "   0.009747699834406376,\n",
       "   0.005843212362378836,\n",
       "   0.22384527325630188,\n",
       "   -0.13796661794185638,\n",
       "   -0.06146703287959099,\n",
       "   -0.35502415895462036,\n",
       "   -0.08002030104398727,\n",
       "   -0.25957611203193665,\n",
       "   0.5278834104537964,\n",
       "   -0.061575084924697876,\n",
       "   -0.05237756669521332,\n",
       "   0.011651192791759968,\n",
       "   -0.10794946551322937,\n",
       "   0.17748472094535828,\n",
       "   -0.03516782075166702,\n",
       "   0.034887298941612244,\n",
       "   -0.12885062396526337,\n",
       "   0.2460929900407791,\n",
       "   0.1939871907234192,\n",
       "   -0.2531720995903015,\n",
       "   -0.20683826506137848,\n",
       "   0.08734358847141266,\n",
       "   -0.03879080340266228,\n",
       "   -0.31890174746513367,\n",
       "   0.14679518342018127,\n",
       "   -0.15452593564987183,\n",
       "   -0.11643967032432556,\n",
       "   0.1736983358860016,\n",
       "   0.3180089294910431,\n",
       "   0.22206325829029083,\n",
       "   -0.21917082369327545,\n",
       "   -0.2050030380487442,\n",
       "   0.09211806207895279,\n",
       "   -0.050193194299936295,\n",
       "   -0.05728798359632492,\n",
       "   0.5130828619003296,\n",
       "   0.14619432389736176,\n",
       "   0.016278952360153198,\n",
       "   -0.10614242404699326,\n",
       "   0.13540448248386383,\n",
       "   -0.05964970216155052,\n",
       "   0.14380277693271637,\n",
       "   0.17907121777534485,\n",
       "   0.008375143632292747,\n",
       "   -0.03512287884950638,\n",
       "   -0.16277168691158295,\n",
       "   0.008802413940429688,\n",
       "   -0.169563889503479,\n",
       "   0.23782816529273987,\n",
       "   -0.10530007630586624,\n",
       "   -0.25562039017677307,\n",
       "   0.1447320580482483,\n",
       "   -0.249654620885849,\n",
       "   0.20609432458877563,\n",
       "   0.04766374081373215,\n",
       "   -0.03042485937476158,\n",
       "   -0.34539711475372314,\n",
       "   -0.027387216687202454,\n",
       "   -0.004330961499363184,\n",
       "   -0.15093277394771576,\n",
       "   0.16960732638835907,\n",
       "   0.3440720736980438,\n",
       "   -0.05961198732256889,\n",
       "   -0.06646332889795303,\n",
       "   -0.022599395364522934,\n",
       "   -0.00481927115470171,\n",
       "   0.26524627208709717,\n",
       "   0.01991901360452175,\n",
       "   -0.07051273435354233,\n",
       "   0.11688220500946045,\n",
       "   -0.024803411215543747,\n",
       "   0.15502913296222687,\n",
       "   -0.35491272807121277,\n",
       "   0.032276831567287445,\n",
       "   0.01596538908779621,\n",
       "   0.10856819152832031,\n",
       "   0.26419365406036377,\n",
       "   0.226031094789505,\n",
       "   -0.32235801219940186,\n",
       "   -0.12821011245250702,\n",
       "   0.4291054606437683,\n",
       "   -0.026892680674791336,\n",
       "   0.02408178709447384,\n",
       "   -0.035891465842723846,\n",
       "   -0.06776315718889236,\n",
       "   -0.29292425513267517,\n",
       "   -0.1812058985233307,\n",
       "   0.1185477152466774,\n",
       "   0.10821227729320526,\n",
       "   -0.3973696529865265,\n",
       "   -0.22965435683727264,\n",
       "   0.004805231001228094,\n",
       "   -0.06040269136428833,\n",
       "   0.15705664455890656,\n",
       "   -0.007801872678101063,\n",
       "   -0.12118248641490936,\n",
       "   -0.029307691380381584,\n",
       "   0.06223117932677269,\n",
       "   0.5146416425704956,\n",
       "   0.16321010887622833,\n",
       "   -0.22255489230155945,\n",
       "   -0.14887316524982452,\n",
       "   0.12178973108530045,\n",
       "   0.008739353157579899,\n",
       "   0.4040840268135071,\n",
       "   -0.3008124530315399,\n",
       "   0.10166537016630173,\n",
       "   0.04810849204659462,\n",
       "   0.14321818947792053,\n",
       "   -0.08138824254274368,\n",
       "   -0.07086440920829773,\n",
       "   0.08098987489938736,\n",
       "   -0.1793324202299118,\n",
       "   0.12838011980056763,\n",
       "   -0.14738471806049347,\n",
       "   -0.09150251001119614,\n",
       "   0.2838256061077118,\n",
       "   0.5254113078117371,\n",
       "   -0.0077126664109528065,\n",
       "   -0.0492367222905159,\n",
       "   -0.384215772151947,\n",
       "   0.19909654557704926,\n",
       "   0.013729853555560112,\n",
       "   0.23301394283771515,\n",
       "   -0.19866465032100677,\n",
       "   -0.3854683041572571,\n",
       "   0.07163845002651215,\n",
       "   0.1294645369052887,\n",
       "   -0.0381501205265522,\n",
       "   0.2198815643787384,\n",
       "   -0.3984532356262207,\n",
       "   0.1562640517950058,\n",
       "   0.0448455773293972,\n",
       "   0.12349334359169006,\n",
       "   0.04974376782774925,\n",
       "   -0.25215134024620056,\n",
       "   -0.10595399886369705,\n",
       "   0.02246915176510811,\n",
       "   0.1396755427122116,\n",
       "   -0.010026900097727776,\n",
       "   -0.04911923035979271,\n",
       "   -0.21496868133544922,\n",
       "   0.0361613854765892,\n",
       "   -0.11666775494813919,\n",
       "   -0.0639164075255394,\n",
       "   -0.01916561648249626,\n",
       "   -0.04970518872141838,\n",
       "   0.1379029005765915,\n",
       "   0.37653082609176636,\n",
       "   0.28675034642219543,\n",
       "   -0.016574783250689507,\n",
       "   0.00016270214109681547,\n",
       "   0.008361401967704296,\n",
       "   -0.19077646732330322,\n",
       "   -0.10182920098304749,\n",
       "   -0.14073117077350616,\n",
       "   -0.06621962040662766,\n",
       "   0.3115283250808716,\n",
       "   0.1661100685596466,\n",
       "   0.003424146445468068,\n",
       "   -0.01182794850319624,\n",
       "   -0.26961183547973633,\n",
       "   0.055040549486875534,\n",
       "   0.09279441833496094,\n",
       "   -0.478782057762146,\n",
       "   -0.31217625737190247,\n",
       "   -0.2655084431171417,\n",
       "   0.07218936085700989,\n",
       "   -0.524439811706543,\n",
       "   0.23371686041355133,\n",
       "   0.23322036862373352,\n",
       "   -0.18191072344779968,\n",
       "   0.11602067202329636,\n",
       "   0.1057429388165474,\n",
       "   0.5593655109405518,\n",
       "   0.05095742642879486,\n",
       "   0.019900448620319366,\n",
       "   0.08908859640359879,\n",
       "   0.2724286615848541,\n",
       "   -0.17568854987621307,\n",
       "   0.35859450697898865,\n",
       "   0.23206540942192078,\n",
       "   -0.18830682337284088,\n",
       "   -0.11418380588293076,\n",
       "   -0.04269058257341385,\n",
       "   -0.37103986740112305,\n",
       "   -0.3094482123851776,\n",
       "   -0.11967667192220688,\n",
       "   -0.27670818567276,\n",
       "   -0.018685782328248024,\n",
       "   0.05175786092877388,\n",
       "   0.34751051664352417,\n",
       "   -0.054217781871557236,\n",
       "   -0.0526111014187336,\n",
       "   -0.03572491928935051,\n",
       "   0.02526790089905262,\n",
       "   -0.16155505180358887,\n",
       "   -0.25244104862213135,\n",
       "   -0.17010892927646637,\n",
       "   0.1091722697019577,\n",
       "   -0.11001961678266525,\n",
       "   -0.3668206036090851,\n",
       "   0.3028756082057953,\n",
       "   0.07461721450090408,\n",
       "   -0.2881872355937958,\n",
       "   0.29371264576911926,\n",
       "   0.1429644674062729,\n",
       "   0.4976820945739746,\n",
       "   -0.2216663360595703,\n",
       "   0.04601815715432167,\n",
       "   0.14528092741966248,\n",
       "   0.08511350303888321,\n",
       "   0.40792137384414673,\n",
       "   -0.037774357944726944,\n",
       "   0.04765035957098007,\n",
       "   -0.16928741335868835,\n",
       "   0.03440367802977562,\n",
       "   -0.30012306571006775,\n",
       "   -0.14011961221694946,\n",
       "   0.23072989284992218,\n",
       "   0.20373329520225525,\n",
       "   -0.024453867226839066,\n",
       "   -0.1416102796792984,\n",
       "   0.2862122058868408,\n",
       "   -0.04242418706417084,\n",
       "   -0.07788196951150894,\n",
       "   0.33071938157081604,\n",
       "   -0.15423941612243652,\n",
       "   -0.19745837152004242,\n",
       "   0.179616779088974,\n",
       "   -0.14918743073940277,\n",
       "   -0.04762958362698555,\n",
       "   -0.42619577050209045]],\n",
       " 'input_ids': [[129,\n",
       "   73177,\n",
       "   111,\n",
       "   110,\n",
       "   47567,\n",
       "   3904,\n",
       "   110,\n",
       "   107,\n",
       "   110,\n",
       "   107,\n",
       "   110,\n",
       "   107,\n",
       "   801,\n",
       "   112,\n",
       "   11356,\n",
       "   110,\n",
       "   108,\n",
       "   111,\n",
       "   117,\n",
       "   65534,\n",
       "   5124,\n",
       "   31816,\n",
       "   144,\n",
       "   110,\n",
       "   107,\n",
       "   110,\n",
       "   107,\n",
       "   110,\n",
       "   107,\n",
       "   435,\n",
       "   939,\n",
       "   39411,\n",
       "   3016,\n",
       "   115,\n",
       "   509,\n",
       "   365,\n",
       "   109,\n",
       "   769,\n",
       "   113,\n",
       "   215,\n",
       "   1918,\n",
       "   110,\n",
       "   107,\n",
       "   1],\n",
       "  [532,\n",
       "   131,\n",
       "   208,\n",
       "   146,\n",
       "   334,\n",
       "   162,\n",
       "   138,\n",
       "   248,\n",
       "   895,\n",
       "   112,\n",
       "   7321,\n",
       "   110,\n",
       "   151,\n",
       "   109,\n",
       "   63646,\n",
       "   124,\n",
       "   25171,\n",
       "   6059,\n",
       "   4817,\n",
       "   36351,\n",
       "   2620,\n",
       "   131,\n",
       "   116,\n",
       "   5566,\n",
       "   135,\n",
       "   114,\n",
       "   25302,\n",
       "   121,\n",
       "   13300,\n",
       "   44817,\n",
       "   132,\n",
       "   161,\n",
       "   282,\n",
       "   33533,\n",
       "   29442,\n",
       "   110,\n",
       "   107,\n",
       "   1]],\n",
       " 'attention_mask': [[1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1],\n",
       "  [1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1]],\n",
       " 'n_tokens': [44, 38],\n",
       " 'n_letters': [144, 143]}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.dsd_tkn['valid'][0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternately you can look at some random elements of a dataset with the `ds.show_random_elements()` method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the affectionate loopiness that once seemed congenital to demme's perspective has a tough time emerging from between the badly dated cutesy-pie mystery scenario and the newfangled hollywood post-production effects .</td>\n",
       "      <td>neg</td>\n",
       "      <td>6150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a battle between bug-eye theatre and dead-eye matinee .</td>\n",
       "      <td>neg</td>\n",
       "      <td>6400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>it is a comedy that's not very funny and an action movie that is not very thrilling ( and an uneasy alliance , at that ) .</td>\n",
       "      <td>neg</td>\n",
       "      <td>6450</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds.show_random_elements(ds.dsd_raw['train'], num_examples=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>idx</th>\n",
       "      <th>orig_truelabel_probs</th>\n",
       "      <th>orig_vm_predclass</th>\n",
       "      <th>orig_sts_embeddings</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>n_tokens</th>\n",
       "      <th>n_letters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neg</td>\n",
       "      <td>5900</td>\n",
       "      <td>0.812017</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.26082396507263184, 0.16894088685512543, -0.000696819624863565, 0.42390045523643494, 0.12588629126548767, -0.2456263303756714, 0.25331953167915344, -0.10000850260257721, -0.07515019178390503, -0.02511535957455635, 0.03716929629445076, -0.1675442010164261, 0.21177415549755096, 0.10612250864505768, -0.11261694133281708, 0.018164006993174553, 0.08856771141290665, -0.0724453255534172, -0.4939577579498291, 0.15241022408008575, 0.16478994488716125, 0.30741605162620544, 0.19510920345783234, -0.04479996860027313, 0.16139273345470428, -0.10825827717781067, -0.02531084045767784, -0.34616410732269287, -0.07442427426576614, -0.15140996873378754, 0.05133926495909691, -0.49399861693382263, -0.27262526750564575, -0.12282334268093109, 0.14226046204566956, 0.2190028727054596, 0.08068602532148361, 0.23904889822006226, 0.07611984759569168, -0.2089087814092636, -0.07901982218027115, 0.37364712357521057, -0.11654812097549438, 0.11241912841796875, -0.16392573714256287, -0.2552502155303955, -0.04766825586557388, -0.14634528756141663, -0.02990572713315487, -0.1224118322134018, -0.28583237528800964, -0.05020933970808983, 0.08913134038448334, -0.13715822994709015, 0.12391725927591324, -0.1633434295654297, 0.29116320610046387, 0.30185750126838684, -0.2698788046836853, 0.22278627753257751, 0.02050643600523472, 0.17432183027267456, 0.25925225019454956, -0.0584811270236969, 0.16076985001564026, -0.3483920991420746, -0.04350963607430458, 0.12565301358699799, 0.0007046845857985318, 0.7770388126373291, 0.14977848529815674, -0.3200789988040924, -0.11471429467201233, 0.1588069200515747, 0.2392265349626541, 0.06355749815702438, -0.11811453104019165, 0.017058227211236954, 0.1150524839758873, 0.015598387457430363, 0.23242153227329254, -0.08645912259817123, 0.37758150696754456, 0.18046456575393677, -0.29646632075309753, -0.17986299097537994, -0.017268827185034752, -0.1653253436088562, -0.07298078387975693, -0.14704126119613647, -0.08836515247821808, -0.2627905309200287, 0.11998080462217331, 0.11300908774137497, 0.20445899665355682, 0.12975050508975983, -0.13014553487300873, 0.1109667420387268, -0.2775782644748688, 0.04304569587111473, ...]</td>\n",
       "      <td>[16478, 415, 131, 116, 6796, 112, 21024, 119, 115, 8704, 110, 108, 47011, 61377, 1759, 117, 19965, 110, 107, 1]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>20</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neg</td>\n",
       "      <td>6550</td>\n",
       "      <td>0.560361</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.28279241919517517, -0.10911419987678528, 0.185452401638031, -0.31022754311561584, 0.2721474766731262, 0.143635094165802, 0.1588427573442459, 0.07887238264083862, -0.07462634146213531, -0.04302912577986717, 0.19168832898139954, 0.12744538486003876, 0.03302061930298805, 0.35184308886528015, 0.02633996494114399, -0.12195242941379547, 0.2733384966850281, -0.02968870848417282, 0.2663077116012573, 0.033906809985637665, 0.014440209604799747, 0.02836601994931698, 0.3171355128288269, 0.17385075986385345, -0.09732065349817276, -0.2866568863391876, 0.17569024860858917, -0.004056242294609547, -0.11474941670894623, -0.38688334822654724, 0.010693566873669624, 0.08699995279312134, 0.1914653778076172, -0.07150154560804367, -0.11033782362937927, -0.035256337374448776, 0.3646480143070221, -0.07560033351182938, 0.10404468327760696, -0.15902841091156006, -0.18942876160144806, -0.0454980842769146, 0.07817275822162628, -0.11899391561746597, -0.021510759368538857, -0.2692556381225586, 0.07824939489364624, -0.23629973828792572, -0.06936605274677277, -0.2710849642753601, 0.015071428380906582, 0.1451604962348938, -0.08288583159446716, -0.007211702410131693, 0.09828613698482513, -0.18080736696720123, 0.1366795301437378, -0.08440432697534561, 0.07456615567207336, -0.09058354794979095, -0.36064258217811584, -0.12619048357009888, 0.03774487227201462, -0.33537110686302185, 0.23234142363071442, -0.15576718747615814, -0.21634942293167114, -0.6222754716873169, 0.014109872281551361, -0.1254936158657074, -0.07818818837404251, 0.0686282068490982, 0.1632554680109024, 0.03296481445431709, 0.05164318159222603, -0.0860288068652153, 0.10972880572080612, 0.05365408584475517, 0.013793966732919216, -0.15731367468833923, -0.30272218585014343, -0.21046552062034607, 0.3018110990524292, -0.06533841788768768, -0.35051441192626953, -0.3832939565181732, -0.06097899377346039, 0.08307389169931412, -0.17937450110912323, 0.3539979159832001, -0.29797446727752686, 0.2458031326532364, 0.3172275125980377, 0.2503081262111664, -0.0986585021018982, -0.25740835070610046, 0.11290610581636429, -0.01475759968161583, -0.3525673449039459, 0.19793599843978882, ...]</td>\n",
       "      <td>[3721, 1121, 117, 288, 109, 209, 474, 120, 131, 116, 1092, 2190, 115, 2453, 2092, 110, 108, 114, 896, 141, 109, 1348, 121, 14787, 12103, 1772, 3021, 8805, 143, 51265, 110, 158, 120, 2841, 130, 610, 372, 587, 113, 109, 4508, 5088, 113, 52182, 51167, 115, 109, 450, 121, 11513, 47414, 415, 278, 110, 107, 1]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>56</td>\n",
       "      <td>230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pos</td>\n",
       "      <td>950</td>\n",
       "      <td>0.894819</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.1295185387134552, 0.08725076913833618, 0.16249580681324005, 0.09270603209733963, -0.05479922890663147, -0.4042092561721802, 0.044919490814208984, -0.015336044132709503, -0.05520963668823242, -0.1714986115694046, 0.13645341992378235, -0.21943482756614685, -0.01515096053481102, -0.1524168848991394, -0.021992869675159454, -0.1730937957763672, 0.4978390336036682, -0.39657658338546753, -0.06187061592936516, 0.11838138103485107, 0.0286897923797369, -0.09177327156066895, -0.11579828709363937, 0.0384468212723732, 0.27413299679756165, -0.08362582325935364, -0.33973729610443115, 0.289218008518219, -0.34868723154067993, 0.010074760764837265, 0.41043534874916077, 0.2695227265357971, -0.47849276661872864, 0.02920924872159958, 0.17637252807617188, 0.02537361904978752, 0.25593501329421997, -0.2687920928001404, 0.19637033343315125, 0.10471389442682266, 0.5327776670455933, 0.26942288875579834, 0.09989957511425018, 0.0004130508750677109, -0.22754546999931335, -0.16906039416790009, 0.1634337306022644, -0.46608710289001465, -0.26222971081733704, 0.03476766496896744, 0.020135406404733658, 0.16166219115257263, -0.11212167143821716, 0.0611935555934906, 0.1479577124118805, -0.35471445322036743, -0.14004448056221008, -0.2564741373062134, -0.34316256642341614, -0.32408127188682556, 0.12188054621219635, -0.09297027438879013, 0.07313328981399536, -0.019537940621376038, -0.11266116797924042, -0.49935227632522583, -0.5597988963127136, 0.057982150465250015, 0.30742019414901733, -0.04193183407187462, 0.0877077728509903, 0.11447340250015259, 0.32417207956314087, 0.15870186686515808, -0.13938716053962708, 0.20942211151123047, 0.16791647672653198, -0.40716519951820374, -0.47167089581489563, -0.10710559040307999, -0.06997077912092209, -0.1667996644973755, -0.3509700298309326, -0.18834857642650604, -0.059045568108558655, -0.02201288379728794, 0.10729056596755981, -0.11800283938646317, 0.17891091108322144, 0.17431680858135223, -0.21734818816184998, 0.3496575355529785, 0.34084752202033997, 0.1076493114233017, 0.3619900345802307, -0.01222921907901764, 0.14957047998905182, -0.015920229256153107, 0.03864670917391777, 0.060621462762355804, ...]</td>\n",
       "      <td>[14729, 113, 1316, 218, 129, 332, 154, 197, 372, 22245, 113, 85810, 19425, 110, 108, 155, 126, 131, 116, 309, 848, 6028, 110, 107, 1]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>25</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds.show_random_elements(ds.dsd_tkn['train'], num_examples=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing DataLoaders "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can access dataloaders for the raw text in `ds.dsd_raw` with `ds.dld_raw`, and for the tokenised text in `ds.dsd_tkn` with `ds_dld_tkn`. Both of these are dictionaries of dataloaders with keys `['train', 'valid', 'test', 'train_eval]`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloader dict has keys: dict_keys(['train', 'test', 'valid', 'train_eval'])\n",
      "dict_keys(['text', 'label', 'idx'])\n",
      "dict_keys(['label', 'idx', 'orig_truelabel_probs', 'orig_vm_predclass', 'orig_sts_embeddings', 'input_ids', 'attention_mask', 'n_tokens', 'n_letters'])\n",
      "Tokenised input is of shape: torch.Size([4, 56])\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataloader dict has keys:\", ds.dld_raw.keys())\n",
    "batch_raw = next(iter(ds.dld_raw['train']))\n",
    "batch_tkn = next(iter(ds.dld_tkn['train']))\n",
    "print(batch_raw.keys())\n",
    "print(batch_tkn.keys())\n",
    "print(\"Tokenised input is of shape:\", batch_tkn['input_ids'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#hide\n",
    "## Export "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_utils.ipynb.\n",
      "Converted 02_tests.ipynb.\n",
      "Converted 03_config.ipynb.\n",
      "Converted 07_models.ipynb.\n",
      "Converted 10_data.ipynb.\n",
      "Converted 20_trainer.ipynb.\n",
      "Converted 25_insights.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted run.ipynb.\n",
      "Converted show_examples.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
