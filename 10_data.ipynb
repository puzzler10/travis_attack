{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, load_metric, load_from_disk, DatasetDict\n",
    "import torch\n",
    "from travis_attack.trainer import get_vm_probs\n",
    "from travis_attack.config import Config\n",
    "from fastcore.meta import delegates\n",
    "\n",
    "# dev\n",
    "import inspect\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class _BaseDataset(): \n",
    "    \"\"\"Common functionality between datasets. \n",
    "    Base class that wraps a huggingface dataset.\"\"\"\n",
    "    def __init__(self, cfg): \n",
    "        self.cfg = cfg\n",
    "        \n",
    "    def preprocess_dataset(self): \n",
    "        dsd = self.dsd_raw.map(self._add_idx, batched=True, with_indices=True)\n",
    "        if self.cfg.use_small_ds: dsd = self.prep_small_ds(dsd)  # do after adding idx so it's consistent across runs\n",
    "        dsd = dsd.map(self._get_vm_orig_score, batched=True)\n",
    "        if self.cfg.remove_misclassified_examples: dsd = dsd.filter(lambda x: x['orig_vm_predclass'] == x['label'])\n",
    "        dsd = dsd.map(self._get_sts_orig_embeddings, batched=True)\n",
    "        dsd = dsd.map(self.tokenize_fn,             batched=True) \n",
    "        dsd = dsd.map(self.add_n_tokens,            batched=True)\n",
    "        if bucket_by_length: dsd = dsd.sort(\"n_tokens\", reverse=True)\n",
    "        self.dld_raw = get_dataloaders_dict(dsd, collate_fn=collate_fn_raw) \n",
    "        self.dld_tkn = get_dataloaders_dict(dsd, collate_fn=collate_fn_tkn)\n",
    "        \n",
    "    def _add_idx(self, x, idx):\n",
    "        \"\"\"Add row numbers\"\"\"\n",
    "        x['idx'] = idx; \n",
    "        return x   \n",
    "    \n",
    "    def _add_n_tokens(self, x): \n",
    "        \"\"\"Add the number of tokens of the \"text\" field\"\"\"\n",
    "        x['n_tokens'] = [len(o) for o in x['input_ids']]\n",
    "        return x \n",
    "    \n",
    "    def _get_sts_orig_embeddings(self, sts_model, batch): \n",
    "        batch['orig_sts_embeddings'] = sts_model.encode(batch['text'], batch_size=64, convert_to_tensor=False)\n",
    "        return batch\n",
    "    \n",
    "    def _get_vm_orig_score(self, batch): \n",
    "        labels = torch.tensor(batch['label'], device=self.cfg.device)\n",
    "        orig_probs,orig_predclass = get_vm_probs(text = batch[self.cfg.orig_cname], return_predclass=True)\n",
    "        batch['orig_truelabel_probs'] = torch.gather(orig_probs,1, labels[:,None]).squeeze().cpu().tolist()\n",
    "        batch['orig_vm_predclass'] = orig_predclass.cpu().tolist()\n",
    "        return batch\n",
    "    \n",
    "    def tokenize_fn(self, x):  \n",
    "        return pp_tokenizer(x['text'], truncation=True, max_length=max_length)  \n",
    "    \n",
    "    def collate_fn_tkn(self, x): \n",
    "        d = dict()\n",
    "        for k in ['idx', 'attention_mask', 'input_ids', 'label', 'orig_truelabel_probs', 'orig_sts_embeddings']: \n",
    "            d[k] = [o[k] for o in x]\n",
    "        return pp_tokenizer.pad(d, pad_to_multiple_of=padding_multiple, return_tensors=\"pt\")\n",
    "\n",
    "    def collate_fn_raw(self, x): \n",
    "        d = dict()\n",
    "        for k in ['text', 'idx']: \n",
    "            d[k] = [o[k] for o in x]\n",
    "        return d \n",
    "\n",
    "    def _get_sampler(self, ds): \n",
    "        \"\"\"Returns a RandomSampler.\n",
    "        Used so we can keep the same shuffle order across multiple data loaders.\"\"\"\n",
    "        g = torch.Generator()\n",
    "        g.manual_seed(seed)\n",
    "        return RandomSampler(ds, generator=g)\n",
    "    \n",
    "    def prep_small_ds(self, ds_dict):\n",
    "        \"\"\"Replaces datasets with a sharded version of themselves.\"\"\"\n",
    "        for k,v in ds_dict.items():  \n",
    "            ds_dict[k] = v.shard(self.cfg.n_shards, 0, contiguous=self.cfg.shard_contiguous)\n",
    "        return ds_dict\n",
    "    \n",
    "    def show_random_elements(self, dataset, num_examples=10):\n",
    "        \"\"\"Print some elements in a nice format so you can take a look at them. Use for a dataset from the `datasets` package.  \"\"\"\n",
    "        import datasets\n",
    "        import random\n",
    "        import pandas as pd\n",
    "        from IPython.display import display, HTML\n",
    "\n",
    "        assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
    "        picks = []\n",
    "        for _ in range(num_examples):\n",
    "            pick = random.randint(0, len(dataset)-1)\n",
    "            while pick in picks:\n",
    "                pick = random.randint(0, len(dataset)-1)\n",
    "            picks.append(pick)\n",
    "\n",
    "        df = pd.DataFrame(dataset[picks])\n",
    "        for column, typ in dataset.features.items():\n",
    "            if isinstance(typ, datasets.ClassLabel):\n",
    "                df[column] = df[column].transform(lambda i: typ.names[i])\n",
    "        display(HTML(df.to_html()))\n",
    "        \n",
    "    def get_dataloaders_dict(self, ds_dict, collate_fn): \n",
    "        if bucket_by_length and shuffle_train:  raise Exception(\"Can only do one of bucket by length or shuffle\")\n",
    "        d = dict()\n",
    "        for split, ds in ds_dict.items(): \n",
    "            if shuffle_train:\n",
    "                if split == \"train\": \n",
    "                    sampler = get_sampler(ds)\n",
    "                    d[split] =  DataLoader(ds, batch_size=batch_size_train, sampler=sampler, collate_fn=collate_fn, \n",
    "                                           num_workers=n_wkrs, pin_memory=pin_memory) \n",
    "                else: \n",
    "                    d[split] =  DataLoader(ds, batch_size=batch_size_eval, shuffle=False, collate_fn=collate_fn, \n",
    "                                           num_workers=n_wkrs, pin_memory=pin_memory) \n",
    "            if bucket_by_length: \n",
    "                batch_size = batch_size_train if split == \"train\" else batch_size_eval\n",
    "                d[split] =  DataLoader(ds, batch_size=batch_size, shuffle=False, collate_fn=collate_fn, \n",
    "                                       num_workers=n_wkrs, pin_memory=pin_memory) \n",
    "\n",
    "        # Add eval dataloader for train \n",
    "        d['train_eval'] = DataLoader(ds_dict['train'], batch_size=batch_size_eval, shuffle=False,\n",
    "                                    collate_fn=collate_fn, num_workers=n_wkrs, pin_memory=pin_memory) \n",
    "        return d \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rotten Tomatoes dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "#@delegates()\n",
    "class RottenTomatoesDataset(_BaseDataset): \n",
    "    def __init__(self, cfg): \n",
    "        super().__init__(cfg)\n",
    "        self.prep_dsd_raw()\n",
    "        self.preprocess_dataset()\n",
    "        \n",
    "   \n",
    "    def prep_dsd_raw(self):\n",
    "        \"\"\"Load raw data and package it up in a DatasetDict (dsd) with splits for train, valid, test.\"\"\"\n",
    "        self.dsd_raw = load_dataset(\"rotten_tomatoes\")\n",
    "        self.dsd_raw['valid'] = self.dsd_raw.pop('validation')  # \"valid\" is easier than \"validation\"\n",
    "        for _,ds in self.dsd_raw.items():\n",
    "            # make sure that all datasets have the same number of labels as what the victim model predicts\n",
    "            assert ds.features[self.cfg.label_cname].num_classes == self.cfg.vm_num_labels \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class SimpleDatasetWrapper(_BaseDataset): \n",
    "    def __init__(self, path_data, splits): \n",
    "        super().__init__()\n",
    "        dsd_raw = DatasetDict()\n",
    "        for s in splits:  \n",
    "            dsd_raw[s] = load_dataset('csv', data_files=f\"{path_data}simple_dataset_{s}.csv\")['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset rotten_tomatoes_movie_review (/data/tproth/.cache/huggingface/datasets/rotten_tomatoes_movie_review/default/1.0.0/e06abb624abab47e1a64608fdfe65a913f5a68c66118408032644a3285208fb5)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "818e8d2d14734ee89c1cbd1218783f7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cfg = Config().rotten_tomatoes_dataset()\n",
    "cfg.vm_num_labels = 2  # replace this with code that determines it later\n",
    "\n",
    "\n",
    "# load vm \n",
    "# load sts model \n",
    "\n",
    "\n",
    "ds = RottenTomatoesDataset(cfg=cfg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 8530\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 1066\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 1066\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.dsd_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Signature (cfg)>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inspect.signature(RottenTomatoesDataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SNLI dataset (not implemented )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SNLIDatasetWrapper(_DatasetWrapper): \n",
    "    def __init__(): \n",
    "        super().__init__()\n",
    "        pass\n",
    "        ## For snli\n",
    "        # remove_minus1_labels = lambda x: x[label_cname] != -1\n",
    "        # ds_train = ds_train.filter(remove_minus1_labels)\n",
    "        # valid = valid.filter(remove_minus1_labels)\n",
    "        # test = test.filter(remove_minus1_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions that add new fields to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute VM and STS scores for a text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions used to prepare dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Misc functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
