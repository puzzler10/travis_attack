---

title: Preparing data


keywords: fastai
sidebar: home_sidebar



nb_path: "10_data.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: 10_data.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Classes">Classes<a class="anchor-link" href="#Classes"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Base-class">Base class<a class="anchor-link" href="#Base-class"> </a></h3>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="ProcessedDataset" class="doc_header"><code>class</code> <code>ProcessedDataset</code><a href="https://github.com/puzzler10/travis_attack/tree/main/travis_attack/data.py#L14" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>ProcessedDataset</code>(<strong><code>cfg</code></strong>, <strong><code>vm_tokenizer</code></strong>, <strong><code>pp_tokenizer</code></strong>, <strong><code>vm_model</code></strong>, <strong><code>sts_model</code></strong>)</p>
</blockquote>
<p>Class that wraps a raw dataset (e.g. from huggingface datasets) and performs preprocessing on it.</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Usage">Usage<a class="anchor-link" href="#Usage"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Basics">Basics<a class="anchor-link" href="#Basics"> </a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Here we have defined a class <a href="/travis_attack/data.html#ProcessedDataset"><code>ProcessedDataset</code></a> that will load and preprocess a dataset. But before processing the dataset you must load both the config object and all models/tokenizers, so we do this first.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">travis_attack.models</span> <span class="kn">import</span> <span class="n">prepare_models</span>
<span class="n">cfg</span> <span class="o">=</span> <span class="n">Config</span><span class="p">()</span>
<span class="n">vm_tokenizer</span><span class="p">,</span> <span class="n">vm_model</span><span class="p">,</span> <span class="n">pp_tokenizer</span><span class="p">,</span> <span class="n">pp_model</span><span class="p">,</span> <span class="n">sts_model</span><span class="p">,</span> <span class="n">cfg</span> <span class="o">=</span> <span class="n">prepare_models</span><span class="p">(</span><span class="n">cfg</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Currently there are two choices for dataset:</p>
<ul>
<li><code>simple</code>, a dataset of simple sentences with four elements each in the train, test and valid splits</li>
<li><code>rotten_tomatoes</code>, a dataset of movie reviews scraped from the Rotten Tomatoes site. </li>
</ul>
<p>The dataset is specified by the config class. There are two ways to do this.</p>
<ol>
<li>Edit the <code>self.dataset_name</code> variable in the Config class to either <code>simple</code> or <code>rotten_tomatoes</code>. An error will be thrown if the name is not one of these two. This is the best way to use when doing runs.   </li>
<li>Use the <code>adjust_dataset_...</code> methods of the config class: e.g. <code>cfg = cfg.adjust_dataset_for_rotten_tomatoes_dataset() = Config()</code>. This is easiest for automated testing so we will do this here. </li>
</ol>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Once the config is specified and loaded, create an object of class <a href="/travis_attack/data.html#ProcessedDataset"><code>ProcessedDataset</code></a> by passing the config, models and tokenizers as variables. This will do all preprocessing automatically in creating the object (the preprocessing code is in the <code>__init__()</code> function of the class.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">cfg_simple</span> <span class="o">=</span> <span class="n">cfg</span><span class="o">.</span><span class="n">adjust_config_for_simple_dataset</span><span class="p">()</span>
<span class="n">ds</span> <span class="o">=</span> <span class="n">ProcessedDataset</span><span class="p">(</span><span class="n">cfg_simple</span><span class="p">,</span>  <span class="n">vm_tokenizer</span><span class="p">,</span> <span class="n">pp_tokenizer</span><span class="p">,</span> <span class="n">vm_model</span><span class="p">,</span> <span class="n">sts_model</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>Using custom data configuration default-b253756c445fb811
Reusing dataset csv (/data/tproth/.cache/huggingface/datasets/csv/default-b253756c445fb811/0.0.0/bf68a4c4aefa545d0712b2fcbb1b327f905bbe2f6425fbc5e8c25234acb9e14a)
Using custom data configuration default-c802946231f72062
Reusing dataset csv (/data/tproth/.cache/huggingface/datasets/csv/default-c802946231f72062/0.0.0/bf68a4c4aefa545d0712b2fcbb1b327f905bbe2f6425fbc5e8c25234acb9e14a)
Using custom data configuration default-43a49c5188c42e69
Reusing dataset csv (/data/tproth/.cache/huggingface/datasets/csv/default-43a49c5188c42e69/0.0.0/bf68a4c4aefa545d0712b2fcbb1b327f905bbe2f6425fbc5e8c25234acb9e14a)
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>If you want to use the small dataset adjust the config before creating the <a href="/travis_attack/data.html#ProcessedDataset"><code>ProcessedDataset</code></a> object.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">cfg_rt_small_ds</span> <span class="o">=</span> <span class="n">cfg</span><span class="o">.</span><span class="n">adjust_config_for_rotten_tomatoes_dataset</span><span class="p">()</span>
<span class="n">ds</span> <span class="o">=</span> <span class="n">ProcessedDataset</span><span class="p">(</span><span class="n">cfg_rt_small_ds</span><span class="p">,</span>  <span class="n">vm_tokenizer</span><span class="p">,</span> <span class="n">pp_tokenizer</span><span class="p">,</span> <span class="n">vm_model</span><span class="p">,</span> <span class="n">sts_model</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>Using custom data configuration default
Reusing dataset rotten_tomatoes_movie_review (/data/tproth/.cache/huggingface/datasets/rotten_tomatoes_movie_review/default/1.0.0/e06abb624abab47e1a64608fdfe65a913f5a68c66118408032644a3285208fb5)
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Accessing-datasets">Accessing datasets<a class="anchor-link" href="#Accessing-datasets"> </a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>You can access raw data with <code>ds.dsd_raw</code> and processed data with the <code>ds.dsd_tkn</code>. (The dsd here stands for "DatasetDict")</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">ds</span><span class="o">.</span><span class="n">dsd_raw</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>DatasetDict({
    train: Dataset({
        features: [&#39;text&#39;, &#39;label&#39;],
        num_rows: 8530
    })
    test: Dataset({
        features: [&#39;text&#39;, &#39;label&#39;],
        num_rows: 1066
    })
    valid: Dataset({
        features: [&#39;text&#39;, &#39;label&#39;],
        num_rows: 1066
    })
})</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">ds</span><span class="o">.</span><span class="n">dsd_tkn</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>DatasetDict({
    train: Dataset({
        features: [&#39;attention_mask&#39;, &#39;idx&#39;, &#39;input_ids&#39;, &#39;label&#39;, &#39;n_tokens&#39;, &#39;orig_sts_embeddings&#39;, &#39;orig_truelabel_probs&#39;, &#39;orig_vm_predclass&#39;, &#39;text&#39;],
        num_rows: 7443
    })
    test: Dataset({
        features: [&#39;attention_mask&#39;, &#39;idx&#39;, &#39;input_ids&#39;, &#39;label&#39;, &#39;n_tokens&#39;, &#39;orig_sts_embeddings&#39;, &#39;orig_truelabel_probs&#39;, &#39;orig_vm_predclass&#39;, &#39;text&#39;],
        num_rows: 889
    })
    valid: Dataset({
        features: [&#39;attention_mask&#39;, &#39;idx&#39;, &#39;input_ids&#39;, &#39;label&#39;, &#39;n_tokens&#39;, &#39;orig_sts_embeddings&#39;, &#39;orig_truelabel_probs&#39;, &#39;orig_vm_predclass&#39;, &#39;text&#39;],
        num_rows: 895
    })
})</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>You can access elements by indexing:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">ds</span><span class="o">.</span><span class="n">dsd_raw</span><span class="p">[</span><span class="s1">&#39;valid&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">:</span><span class="mi">2</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>{&#39;text&#39;: [&#39;compassionately explores the seemingly irreconcilable situation between conservative christian parents and their estranged gay and lesbian children .&#39;,
  &#39;the soundtrack alone is worth the price of admission .&#39;],
 &#39;label&#39;: [1, 1]}</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">ds</span><span class="o">.</span><span class="n">dsd_tkn</span><span class="p">[</span><span class="s1">&#39;valid&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">:</span><span class="mi">2</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>{&#39;attention_mask&#39;: [[1,
   1,
   1,
   1,
   1,
   1,
   1,
   1,
   1,
   1,
   1,
   1,
   1,
   1,
   1,
   1,
   1,
   1,
   1,
   1,
   1,
   1,
   1,
   1,
   1,
   1,
   1,
   1,
   1,
   1,
   1,
   1,
   1,
   1,
   1,
   1,
   1,
   1,
   1,
   1,
   1,
   1,
   1,
   1,
   1,
   1,
   1,
   1,
   1,
   1,
   1,
   1,
   1,
   1,
   1,
   1,
   1,
   1,
   1,
   1,
   1],
  [1,
   1,
   1,
   1,
   1,
   1,
   1,
   1,
   1,
   1,
   1,
   1,
   1,
   1,
   1,
   1,
   1,
   1,
   1,
   1,
   1,
   1,
   1,
   1,
   1,
   1,
   1,
   1,
   1,
   1,
   1,
   1,
   1,
   1,
   1,
   1,
   1,
   1,
   1,
   1,
   1,
   1,
   1,
   1,
   1,
   1,
   1,
   1,
   1,
   1,
   1,
   1,
   1,
   1,
   1,
   1,
   1,
   1,
   1,
   1,
   1]],
 &#39;idx&#39;: [1028, 407],
 &#39;input_ids&#39;: [[0,
   627,
   1569,
   18,
   934,
   23485,
   283,
   31,
   1782,
   320,
   295,
   219,
   6195,
   4626,
   859,
   1236,
   922,
   5810,
   859,
   2084,
   605,
   354,
   816,
   10,
   6740,
   12,
   1116,
   12,
   627,
   12,
   25581,
   3795,
   4783,
   1440,
   5251,
   7468,
   8,
   2494,
   11875,
   1504,
   5853,
   18857,
   4842,
   11,
   10,
   10861,
   29478,
   117,
   25031,
   5179,
   1722,
   14102,
   12111,
   2792,
   74,
   655,
   860,
   7,
   1331,
   479,
   2],
  [0,
   113,
   15,
   2510,
   27785,
   22,
   351,
   75,
   28,
   2325,
   11,
   5,
   16259,
   37254,
   9,
   5,
   275,
   9,
   5,
   3514,
   1671,
   28777,
   7906,
   53,
   24,
   16,
   10,
   1086,
   319,
   9,
   1531,
   8,
   47,
   120,
   7,
   192,
   5,
   65,
   9,
   5,
   232,
   18,
   275,
   5552,
   2156,
   385,
   35947,
   10,
   4467,
   257,
   718,
   2156,
   33,
   10,
   17840,
   9,
   10,
   205,
   86,
   479,
   2]],
 &#39;label&#39;: [0, 1],
 &#39;n_tokens&#39;: [61, 61],
 &#39;orig_sts_embeddings&#39;: [[-0.18457703292369843,
   -0.09812847524881363,
   -0.04049499332904816,
   0.28171661496162415,
   0.19172710180282593,
   0.14890596270561218,
   0.2062542736530304,
   0.06248242035508156,
   -0.044895756989717484,
   -0.052304767072200775,
   0.24804383516311646,
   0.13039831817150116,
   -0.12390138953924179,
   0.14384429156780243,
   -0.04497780650854111,
   0.18519248068332672,
   0.21535024046897888,
   0.09016167372465134,
   0.02530963532626629,
   0.4318044185638428,
   0.10253333300352097,
   -0.13705001771450043,
   0.4013608694076538,
   0.22692105174064636,
   0.03863525390625,
   -0.10345681756734848,
   -0.04417723789811134,
   -0.024858441203832626,
   -0.23282280564308167,
   -0.3662370443344116,
   -0.23374857008457184,
   -0.09960643202066422,
   -0.18434108793735504,
   0.3328252136707306,
   0.08697742968797684,
   0.31542420387268066,
   0.09706789255142212,
   -0.0336151160299778,
   0.17330105602741241,
   -0.16610732674598694,
   -0.10631045699119568,
   0.29835572838783264,
   -0.045686025172472,
   -0.05736939236521721,
   -0.109817273914814,
   -0.19167572259902954,
   0.16075213253498077,
   0.12144536525011063,
   -0.01566886343061924,
   -0.10854502767324448,
   -0.18026331067085266,
   -0.2651243507862091,
   -0.009126106277108192,
   -0.5096121430397034,
   -0.049720004200935364,
   -0.4264870882034302,
   0.2519453465938568,
   -0.030129358172416687,
   0.04161727428436279,
   0.07289857417345047,
   -0.11881688237190247,
   -0.2963106036186218,
   -0.05878390744328499,
   -0.17022854089736938,
   0.3600552976131439,
   -0.1964406818151474,
   -0.1802477389574051,
   -0.3827347159385681,
   0.3135072588920593,
   -0.11187595129013062,
   0.03275452181696892,
   -0.0055224597454071045,
   0.09867344796657562,
   -0.08815953135490417,
   0.2704507112503052,
   -0.0415581651031971,
   0.21221265196800232,
   -0.023531733080744743,
   0.16795562207698822,
   0.20565159618854523,
   0.02761092595756054,
   -0.07730939239263535,
   0.5091796517372131,
   -0.15215256810188293,
   -0.05122719332575798,
   -0.04231914132833481,
   -0.03530510514974594,
   0.0840807780623436,
   0.014360304921865463,
   0.11074770987033844,
   -0.28155869245529175,
   -0.09148512780666351,
   0.11416888982057571,
   0.20027002692222595,
   0.15983814001083374,
   0.10818887501955032,
   0.13701358437538147,
   0.10016269236803055,
   -0.0013049696572124958,
   -0.06059829518198967,
   0.34492892026901245,
   -0.18167535960674286,
   0.031131932511925697,
   0.10055272281169891,
   0.2665448486804962,
   -0.36737048625946045,
   0.43965303897857666,
   -0.2034057229757309,
   -0.3261301517486572,
   0.12656426429748535,
   -0.057980142533779144,
   -0.0003158723993692547,
   0.11762558668851852,
   -0.03794008120894432,
   0.032762620598077774,
   -0.08102910965681076,
   -0.280317097902298,
   0.10829538106918335,
   -0.419932097196579,
   -0.12882183492183685,
   0.16266247630119324,
   0.0971486046910286,
   -0.042944859713315964,
   0.11959972977638245,
   -0.15163332223892212,
   0.1297806203365326,
   0.015424882993102074,
   0.1331978589296341,
   0.01622619293630123,
   0.08563846349716187,
   -0.09903958439826965,
   0.12804418802261353,
   0.14893606305122375,
   0.1436888873577118,
   -0.04322369396686554,
   0.07584841549396515,
   -0.251906156539917,
   0.39973753690719604,
   -0.04740745946764946,
   -0.37097814679145813,
   -0.3327541947364807,
   -0.14563913643360138,
   -0.16584327816963196,
   0.15307718515396118,
   -0.17861302196979523,
   0.02602010779082775,
   -0.06618465483188629,
   0.24729648232460022,
   -0.1597198098897934,
   0.4485660195350647,
   0.08724457025527954,
   -0.25628072023391724,
   -0.2000998854637146,
   0.27199721336364746,
   -0.32590606808662415,
   0.2783344089984894,
   -0.0489337183535099,
   0.20724530518054962,
   -0.0702253207564354,
   -0.029446860775351524,
   0.06937965750694275,
   0.07261890172958374,
   -0.062371060252189636,
   -0.15625086426734924,
   -0.06058048456907272,
   -0.05604006350040436,
   0.14000938832759857,
   0.276862233877182,
   -0.23172883689403534,
   0.15395841002464294,
   -0.10873951762914658,
   0.029793204739689827,
   -0.3099610507488251,
   0.16878774762153625,
   0.04967249929904938,
   -0.11036883294582367,
   -0.37851566076278687,
   0.20763938128948212,
   0.1271507441997528,
   0.008448873646557331,
   0.0405253991484642,
   0.04146847501397133,
   -0.0661516934633255,
   0.32532769441604614,
   0.17102712392807007,
   -0.33797645568847656,
   0.21156902611255646,
   -0.14068499207496643,
   -0.051406629383563995,
   -0.19068017601966858,
   0.07609482854604721,
   -0.33206725120544434,
   0.15746556222438812,
   -0.05187370628118515,
   0.11549189686775208,
   0.12348984181880951,
   -0.17041529715061188,
   0.4476706087589264,
   -0.02773555926978588,
   0.1461184173822403,
   -0.20942986011505127,
   -0.350335031747818,
   0.005889345426112413,
   -0.1584327071905136,
   0.22749683260917664,
   -0.3445497155189514,
   0.13223110139369965,
   -0.2135012298822403,
   0.18554386496543884,
   0.23687131702899933,
   0.033913951367139816,
   -0.24600860476493835,
   -0.08008770644664764,
   -0.060825515538454056,
   -0.06528408080339432,
   -0.13625860214233398,
   -0.059689491987228394,
   0.17592297494411469,
   0.26608532667160034,
   -0.11505868285894394,
   0.16452044248580933,
   -0.374236524105072,
   -0.16678446531295776,
   -0.12334278970956802,
   -0.030733199790120125,
   -0.1792410910129547,
   -0.02795463614165783,
   -0.18698203563690186,
   -0.1377468705177307,
   0.055420730262994766,
   -0.3629607558250427,
   0.16852673888206482,
   0.1307685226202011,
   0.1038782000541687,
   -0.106228306889534,
   -0.23522917926311493,
   0.11856376379728317,
   0.2568068206310272,
   0.018413184210658073,
   0.014529598876833916,
   0.01985369622707367,
   0.10484634339809418,
   0.12584637105464935,
   0.20765498280525208,
   0.22055795788764954,
   -0.11951294541358948,
   -0.2975403070449829,
   -0.257276326417923,
   -0.06723279505968094,
   0.1932564079761505,
   -0.01468498446047306,
   0.0032772128470242023,
   0.1824396252632141,
   0.05474292114377022,
   -0.2059192806482315,
   0.10475403070449829,
   0.12827537953853607,
   0.24430260062217712,
   -0.08191852271556854,
   0.3066619038581848,
   -0.2171093374490738,
   -0.15953662991523743,
   -0.3194897472858429,
   -0.3763757050037384,
   0.05583227798342705,
   -0.24936774373054504,
   -0.1543668955564499,
   0.18823543190956116,
   0.09437629580497742,
   0.0851776972413063,
   0.187114879488945,
   -0.05801507085561752,
   0.2922237813472748,
   -0.1038033589720726,
   -0.13448414206504822,
   0.031704407185316086,
   -0.050040051341056824,
   -0.164564311504364,
   -0.2788151800632477,
   0.19171179831027985,
   -0.13500858843326569,
   -0.015819355845451355,
   0.22879120707511902,
   0.17512838542461395,
   -0.05990215018391609,
   -0.2988598346710205,
   -0.3067958354949951,
   -0.24472086131572723,
   -0.04366074129939079,
   -0.019952600821852684,
   -0.19170065224170685,
   0.0035208233166486025,
   -0.19427938759326935,
   0.009472695179283619,
   0.09609612077474594,
   0.14822502434253693,
   -0.30505648255348206,
   0.022283077239990234,
   -0.08352382481098175,
   0.3108328580856323,
   0.23411063849925995,
   0.2982529103755951,
   -0.05076741799712181,
   -0.018611682578921318,
   0.33344969153404236,
   -0.13724486529827118,
   -0.058445654809474945,
   0.09686817973852158,
   0.11075761169195175,
   -0.03695812448859215,
   -0.13765838742256165,
   -0.015129256062209606,
   -0.3638685345649719,
   0.1779051274061203,
   0.05029917508363724,
   -0.09576914459466934,
   0.15881779789924622,
   0.09679263085126877,
   0.14957363903522491,
   -0.1752639263868332,
   -0.20073208212852478,
   -0.021819381043314934,
   -0.03589751943945885,
   -0.30565744638442993,
   0.14473170042037964,
   0.048521045595407486,
   0.061208032071590424,
   0.14783690869808197,
   -0.13735710084438324,
   0.3141656219959259,
   -0.3093617260456085,
   0.169610857963562,
   0.25349700450897217,
   0.019312750548124313,
   0.10946914553642273,
   0.18609113991260529,
   -0.0685250535607338,
   0.09514109045267105,
   -0.1100710928440094,
   0.1176896020770073,
   0.014252502471208572,
   0.17045894265174866,
   0.012622445821762085,
   -0.17719309031963348,
   0.012065398506820202,
   -0.15738791227340698,
   0.057272594422101974,
   -0.026884866878390312,
   0.09717393666505814,
   0.15428392589092255,
   0.016478976234793663,
   0.15210624039173126,
   -0.18809737265110016,
   0.04310259595513344,
   -0.053058914840221405,
   0.09178875386714935,
   -0.04588352143764496,
   0.049295175820589066,
   0.41193556785583496,
   -0.15725794434547424,
   -0.09594225138425827,
   -0.11480961740016937,
   -0.23408202826976776,
   0.1725059151649475,
   -0.10359171777963638,
   0.43393847346305847,
   0.10539907217025757,
   -0.20568254590034485,
   -0.18375557661056519,
   0.10784245282411575,
   0.1563078612089157,
   -0.08700785785913467,
   -0.41943100094795227,
   0.17806382477283478,
   -0.07148520648479462,
   0.14713889360427856,
   -0.17362481355667114,
   -0.07576011121273041,
   -0.12683771550655365,
   0.3968907594680786,
   0.12452440708875656,
   -0.32867783308029175,
   0.001631870400160551,
   -0.010830463841557503],
  [0.0904824361205101,
   0.1345222294330597,
   -0.10305275768041611,
   -0.2516885995864868,
   -0.13074859976768494,
   -0.012482289224863052,
   0.3628193438053131,
   0.3097284734249115,
   -0.08563688397407532,
   -0.09711681306362152,
   0.08015702664852142,
   -0.08681347221136093,
   0.05137164518237114,
   0.32270342111587524,
   0.049096643924713135,
   -0.03361731022596359,
   0.3636243939399719,
   0.1376350373029709,
   -0.05532160773873329,
   -0.009662005119025707,
   -0.1462794691324234,
   -0.05434807762503624,
   0.16568410396575928,
   0.13133558630943298,
   0.012398993596434593,
   -0.19740208983421326,
   -0.08147665113210678,
   0.0010568093275651336,
   -0.07660296559333801,
   -0.16873924434185028,
   -0.09034755080938339,
   -0.31513023376464844,
   0.03965149074792862,
   -0.1615838259458542,
   -0.16105909645557404,
   0.38390523195266724,
   0.02658202312886715,
   0.13537895679473877,
   0.2350025475025177,
   -0.11404236406087875,
   -0.16948755085468292,
   -0.2655356526374817,
   -0.1647520810365677,
   0.053783975541591644,
   -0.042777251452207565,
   -0.10843901336193085,
   0.02272646501660347,
   -0.11356036365032196,
   -0.0032988113816827536,
   0.13424131274223328,
   -0.024809397757053375,
   -0.21160349249839783,
   -0.09197068214416504,
   -0.12393516302108765,
   0.05970054492354393,
   -0.15832674503326416,
   0.10739224404096603,
   -0.03455814719200134,
   0.04884367436170578,
   -0.14298048615455627,
   -0.18294543027877808,
   -0.0015578403836116195,
   -0.14366263151168823,
   0.05254405736923218,
   -0.22116491198539734,
   -0.30907243490219116,
   0.019184904173016548,
   -0.0577629953622818,
   -0.29764196276664734,
   0.16550017893314362,
   0.2302170842885971,
   -0.08847443759441376,
   0.4496372640132904,
   0.007049038540571928,
   -0.01611446961760521,
   -0.2051764279603958,
   -0.19173654913902283,
   0.03522823750972748,
   0.10244951397180557,
   0.02336135134100914,
   0.19811677932739258,
   -0.3076517879962921,
   -0.26634225249290466,
   0.05712880566716194,
   0.13929809629917145,
   -0.08949825167655945,
   -0.010432058945298195,
   -0.23343127965927124,
   0.07121823728084564,
   0.26334095001220703,
   -0.10205995291471481,
   0.20983584225177765,
   0.5952377915382385,
   0.005067279562354088,
   0.06229511275887489,
   0.061153922230005264,
   0.12410107254981995,
   0.11854492127895355,
   -0.46804001927375793,
   0.22873537242412567,
   -0.10580785572528839,
   -0.04853490740060806,
   -0.1394256204366684,
   0.23533464968204498,
   0.1827874630689621,
   -0.010049303993582726,
   0.07484398037195206,
   -0.08496883511543274,
   -0.12651453912258148,
   -0.10883859544992447,
   0.027006328105926514,
   -0.01150219514966011,
   -0.06248386949300766,
   0.04783141613006592,
   -0.21976803243160248,
   0.13970859348773956,
   -0.20655551552772522,
   0.24889343976974487,
   0.03436972573399544,
   -0.24819114804267883,
   0.1561136096715927,
   -0.2503899931907654,
   -0.08497148752212524,
   0.08472069352865219,
   0.09812363237142563,
   -0.03553508594632149,
   0.06431533396244049,
   0.16552872955799103,
   -0.13571329414844513,
   0.16157576441764832,
   -0.11758818477392197,
   -0.10729005932807922,
   0.030218297615647316,
   -0.04050607979297638,
   -0.25143343210220337,
   -0.10682377219200134,
   0.1146506667137146,
   0.197125643491745,
   0.07084707915782928,
   -0.0237618088722229,
   -0.13228805363178253,
   0.4120185971260071,
   0.08172956109046936,
   0.06933541595935822,
   0.04682411625981331,
   -0.026053551584482193,
   0.12026794999837875,
   -0.03798811510205269,
   -0.08531524986028671,
   0.25345006585121155,
   -0.3010854125022888,
   -0.14105473458766937,
   0.1804080605506897,
   0.08907829225063324,
   0.11524084210395813,
   -0.021890247240662575,
   -0.07184337079524994,
   0.2491840422153473,
   -0.11816795915365219,
   -0.06395284086465836,
   -0.11762460321187973,
   0.2132922112941742,
   0.32801294326782227,
   -0.14422722160816193,
   -0.12802337110042572,
   -0.050632450729608536,
   0.06349503993988037,
   0.07494525611400604,
   0.10068655759096146,
   -0.11793125420808792,
   -0.07857111096382141,
   0.2093069702386856,
   -0.24110163748264313,
   -0.17206653952598572,
   0.17237503826618195,
   0.03489997982978821,
   -0.20114968717098236,
   0.19265107810497284,
   0.023991908878087997,
   0.14018727838993073,
   0.08487158268690109,
   -0.008975531905889511,
   -0.15121491253376007,
   0.13366425037384033,
   -0.15804196894168854,
   0.02468978799879551,
   -0.012354332022368908,
   0.059557899832725525,
   0.11560595780611038,
   -0.04018499329686165,
   0.15879444777965546,
   0.0332888588309288,
   -0.07633969187736511,
   0.09612815827131271,
   0.15599679946899414,
   0.14900048077106476,
   -0.20140144228935242,
   0.10727278888225555,
   0.12936890125274658,
   0.07153210788965225,
   -0.27242594957351685,
   -0.29223552346229553,
   0.18874099850654602,
   -0.15061376988887787,
   0.23048518598079681,
   -0.040385425090789795,
   -0.06466160714626312,
   0.03416553884744644,
   -0.22857126593589783,
   0.189309224486351,
   0.09550478309392929,
   -0.05924699455499649,
   -0.0042284713126719,
   -0.00022091814025770873,
   -0.00638709357008338,
   -0.0842990130186081,
   0.14871113002300262,
   0.2235533446073532,
   -0.008161045610904694,
   -0.07036084681749344,
   0.19945044815540314,
   0.08535361289978027,
   0.10798502713441849,
   -0.3536664545536041,
   0.05792723968625069,
   -0.1193997785449028,
   0.11419326812028885,
   -0.12400534749031067,
   -0.02446664869785309,
   -0.1507558375597,
   -0.26264941692352295,
   0.14297038316726685,
   -0.32796722650527954,
   0.058469515293836594,
   -0.4530147910118103,
   0.023910533636808395,
   -0.020992908626794815,
   0.00023579641128890216,
   0.12469293177127838,
   -0.28051701188087463,
   -0.10888400673866272,
   -0.0008585884934291244,
   -0.19835394620895386,
   0.32214006781578064,
   0.49397680163383484,
   0.006256685592234135,
   0.006238499190658331,
   0.3142656981945038,
   0.048903997987508774,
   0.4241488575935364,
   0.046938393265008926,
   0.15760524570941925,
   -0.1400976926088333,
   -0.05430392175912857,
   0.02167164906859398,
   0.13930022716522217,
   -0.22730934619903564,
   -0.0030397626105695963,
   0.042667556554079056,
   0.523905873298645,
   -0.05039213225245476,
   -0.006377038545906544,
   -0.25911426544189453,
   0.04632682725787163,
   0.2233477383852005,
   -0.21754813194274902,
   -0.4081060290336609,
   0.09518513083457947,
   -0.22122614085674286,
   -0.17263765633106232,
   -0.06137184426188469,
   -0.08890561014413834,
   -0.1537139117717743,
   0.05855264514684677,
   -0.27894163131713867,
   -0.14837084710597992,
   0.07209852337837219,
   -0.17487075924873352,
   0.0017488563898950815,
   0.16858476400375366,
   0.20723208785057068,
   -0.06439877301454544,
   0.2464669793844223,
   0.0003201218496542424,
   0.07336192578077316,
   -0.17219850420951843,
   -0.19479739665985107,
   0.08200240135192871,
   0.268462598323822,
   -0.10767998546361923,
   0.03726029768586159,
   0.27603814005851746,
   -0.2363719344139099,
   0.14189283549785614,
   -0.16161881387233734,
   -0.16811130940914154,
   -0.28497275710105896,
   0.21210408210754395,
   0.07510064542293549,
   0.220266193151474,
   0.3443617522716522,
   0.1426030546426773,
   0.09313715994358063,
   -0.24111291766166687,
   0.10095734894275665,
   0.15466593205928802,
   -0.10716919600963593,
   -0.25695133209228516,
   0.11326628178358078,
   0.227731853723526,
   -0.07314390689134598,
   0.03235172480344772,
   0.001921172603033483,
   0.09367655217647552,
   0.19690223038196564,
   0.1959661990404129,
   0.061301782727241516,
   -0.0022170767188072205,
   0.16738946735858917,
   -0.25838810205459595,
   0.038717035204172134,
   0.3427707850933075,
   -0.041843898594379425,
   -0.0713387057185173,
   -0.07847480475902557,
   0.09671320766210556,
   0.012110321782529354,
   -0.18893341720104218,
   -0.0006253840401768684,
   -0.10924399644136429,
   0.2033819854259491,
   -0.0693235993385315,
   -0.023468146100640297,
   -0.29098981618881226,
   0.016953442245721817,
   -0.012355717830359936,
   -0.3718518018722534,
   -0.020071636885404587,
   -0.10765133053064346,
   0.10581354051828384,
   0.013630297034978867,
   -0.13753370940685272,
   0.017231883481144905,
   -0.0776326060295105,
   -0.21320444345474243,
   -0.02126229926943779,
   -0.04857486113905907,
   -0.29788339138031006,
   0.08866412192583084,
   0.2817820608615875,
   -0.15545952320098877,
   0.08376245945692062,
   -0.19861812889575958,
   -0.14551767706871033,
   0.022888369858264923,
   -0.08928663283586502,
   -0.23871098458766937,
   -0.2945806384086609,
   0.15976355969905853,
   0.024854397401213646,
   0.10348436236381531,
   0.011079253628849983,
   0.2295474112033844,
   0.2428913414478302,
   -0.19197019934654236,
   0.17735004425048828,
   0.0428730733692646,
   0.08410386741161346,
   -0.03116457723081112,
   0.06446646898984909,
   0.08321034908294678,
   -0.05767104774713516,
   -0.16237425804138184,
   0.08501774072647095,
   0.049983855336904526,
   0.29655855894088745,
   -0.02992711216211319,
   -0.18325796723365784,
   -0.2792954742908478,
   0.20316261053085327,
   0.3037492632865906,
   -0.3436567187309265,
   -0.12429636716842651,
   0.37940824031829834]],
 &#39;orig_truelabel_probs&#39;: [0.8694749474525452, 0.9398784637451172],
 &#39;orig_vm_predclass&#39;: [0, 1],
 &#39;text&#39;: [&#34;the movie&#39;s biggest shocks come from seeing former nymphette juliette lewis playing a salt-of-the-earth mommy named minnie and watching slim travel incognito in a ridiculous wig no respectable halloween costume shop would ever try to sell .&#34;,
  &#39;&#34; on guard ! &#34; won\&#39;t be placed in the pantheon of the best of the swashbucklers but it is a whole lot of fun and you get to see the one of the world\&#39;s best actors , daniel auteuil , have a whale of a good time .&#39;]}</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Alternately you can look at some random elements of a dataset with the <code>ds.show_random_elements()</code> method.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">ds</span><span class="o">.</span><span class="n">show_random_elements</span><span class="p">(</span><span class="n">ds</span><span class="o">.</span><span class="n">dsd_raw</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">],</span> <span class="n">num_examples</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea "><table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>text</th>
      <th>label</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>a great ending doesn't make up for a weak movie , and crazy as hell doesn't even have a great ending .</td>
      <td>neg</td>
    </tr>
    <tr>
      <th>1</th>
      <td>while the isle is both preposterous and thoroughly misogynistic , its vistas are incredibly beautiful to look at .</td>
      <td>pos</td>
    </tr>
    <tr>
      <th>2</th>
      <td>not exactly the bees knees</td>
      <td>neg</td>
    </tr>
  </tbody>
</table></div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">ds</span><span class="o">.</span><span class="n">show_random_elements</span><span class="p">(</span><span class="n">ds</span><span class="o">.</span><span class="n">dsd_tkn</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">],</span> <span class="n">num_examples</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea "><table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>attention_mask</th>
      <th>idx</th>
      <th>input_ids</th>
      <th>label</th>
      <th>n_tokens</th>
      <th>orig_sts_embeddings</th>
      <th>orig_truelabel_probs</th>
      <th>orig_vm_predclass</th>
      <th>text</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>
      <td>2952</td>
      <td>[0, 3341, 63, 11676, 34510, 2156, 24, 39197, 1626, 84, 23810, 479, 2]</td>
      <td>pos</td>
      <td>13</td>
      <td>[0.07683645188808441, -0.43254953622817993, -0.2884201407432556, 0.26368406414985657, -0.15067246556282043, -0.29725706577301025, 0.44652673602104187, -0.09599904716014862, 0.4136199951171875, 0.22868911921977997, 0.16475704312324524, 0.2580578923225403, -0.009651213884353638, -0.15675018727779388, 0.028356363996863365, 0.026996750384569168, 0.3257802426815033, -0.09476791322231293, -0.1322847455739975, 0.40260812640190125, -0.06383713334798813, 0.23907266557216644, 0.16382071375846863, 0.22284190356731415, -0.07003384083509445, -0.2778371274471283, 0.06157108023762703, -0.14136412739753723, -0.14780288934707642, -0.2185499370098114, -0.19067807495594025, -0.05854059010744095, -0.1803152859210968, 0.24854472279548645, -0.1485261619091034, 0.38437846302986145, -0.09991002082824707, 0.07585038244724274, 0.11837996542453766, -0.4445829391479492, -0.026835225522518158, 0.19295825064182281, 0.009423277340829372, 0.24481302499771118, -0.06806370615959167, -0.03962473198771477, -0.05362413823604584, 0.2703951299190521, -0.019495781511068344, -0.2742648720741272, -0.1754714846611023, -0.047957465052604675, -0.09943359345197678, -0.18178799748420715, 0.000764952739700675, -0.1270955502986908, 0.30256763100624084, 0.017745088785886765, 0.1505133956670761, -0.09769076108932495, 0.1602364182472229, -0.016127118840813637, 0.10854503512382507, 0.11427223682403564, 0.08034198731184006, -0.4638966917991638, -0.051793172955513, -0.07844981551170349, -0.012365324422717094, -0.21001778542995453, 0.2400374412536621, 0.03593837469816208, 0.4045008718967438, 0.09282571822404861, 0.11244865506887436, 0.16519945859909058, 0.16836334764957428, -0.2736123502254486, 0.03752522170543671, 0.10063756257295609, -0.001285043079406023, 0.16157469153404236, 0.5426371097564697, 0.2488955408334732, -0.034798894077539444, 0.11979421228170395, 0.05712924897670746, -0.1519034504890442, 0.09678438305854797, 0.09584493190050125, -0.3669874370098114, 0.125444233417511, 0.40931230783462524, 0.3035696744918823, 0.18691092729568481, -0.2104356288909912, -0.15142661333084106, 0.016831260174512863, -0.10474022477865219, 0.1896384060382843, ...]</td>
      <td>0.931301</td>
      <td>1</td>
      <td>like its bizarre heroine , it irrigates our souls .</td>
    </tr>
    <tr>
      <th>1</th>
      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>
      <td>3573</td>
      <td>[0, 13138, 4376, 10, 182, 1375, 8, 20853, 5257, 41887, 7, 5, 18701, 43328, 479, 2]</td>
      <td>pos</td>
      <td>16</td>
      <td>[-0.20158840715885162, 0.3575786054134369, -0.38341793417930603, 0.18010327219963074, 0.15630246698856354, 0.38274314999580383, -0.09994902461767197, -0.2318796068429947, 0.31283318996429443, 0.11660215258598328, -0.11918359249830246, 0.02431304007768631, 0.149966299533844, 0.10298259556293488, -0.14447380602359772, -0.18221139907836914, 0.00669496413320303, 0.29211005568504333, 0.07370553910732269, 0.11665214598178864, -0.08646053075790405, 0.22458311915397644, 0.4172590970993042, 0.2418132871389389, 0.20363584160804749, -0.09745723754167557, -0.06742429733276367, -0.05254404991865158, -0.16569049656391144, -0.1287563592195511, 0.27005329728126526, 0.06663543730974197, -0.2167079597711563, 0.07535022497177124, -0.027371976524591446, 0.2469516545534134, 0.33272191882133484, 0.37361210584640503, 0.049456264823675156, -0.06388180702924728, -0.11500751972198486, 0.41049230098724365, 0.19662395119667053, 0.14603233337402344, 0.24917030334472656, 0.09485176205635071, -0.07280126214027405, 0.2429356575012207, -0.12741756439208984, 0.2231244444847107, -0.25517117977142334, -0.16563566029071808, -0.19966357946395874, 0.1950351595878601, 0.4458578824996948, 0.07378891110420227, -0.14559735357761383, -0.13437621295452118, 0.13913419842720032, -0.1785784363746643, 0.07854782044887543, -0.1836431622505188, 0.24719442427158356, 0.07032902538776398, 0.10869353264570236, -0.3437102735042572, -0.06741522997617722, 0.17490465939044952, -0.2120242714881897, 0.5022298097610474, -0.406875342130661, -0.1948540061712265, 0.49807024002075195, -0.20378531515598297, 0.1250046342611313, -0.4025477468967438, -0.0820605680346489, 0.01799776591360569, -0.3588275611400604, 0.2247607707977295, 0.15300235152244568, 0.22950297594070435, 0.30480924248695374, 0.14958475530147552, 0.06558987498283386, 0.0847502276301384, 0.11094487458467484, 0.038049597293138504, 0.2623656094074249, 0.17512740194797516, -0.23059511184692383, 0.1199222281575203, 0.3239966928958893, -0.082222118973732, 0.1591596156358719, -0.09350860118865967, -0.11698610335588455, -0.19592158496379852, 0.4761217534542084, 0.15343964099884033, ...]</td>
      <td>0.958571</td>
      <td>1</td>
      <td>provides a very moving and revelatory footnote to the holocaust .</td>
    </tr>
    <tr>
      <th>2</th>
      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>
      <td>5589</td>
      <td>[0, 1264, 95, 23120, 17081, 352, 13, 5, 220, 4817, 396, 2623, 203, 26350, 7, 5, 3768, 479, 2]</td>
      <td>neg</td>
      <td>19</td>
      <td>[-0.07974279671907425, -0.0712166577577591, -0.039970070123672485, 0.0007532645249739289, 0.19971798360347748, -0.06183060258626938, -0.05134312063455582, 0.32594773173332214, 0.3937385380268097, -0.022144082933664322, 0.21838627755641937, 0.27371323108673096, 0.26927459239959717, 0.06295505166053772, -0.19895893335342407, -0.20393683016300201, -0.11135062575340271, 0.11019532382488251, -0.2996702790260315, 0.0112022515386343, -0.40957605838775635, -0.12017344683408737, 0.18621665239334106, 0.016812538728117943, 0.23999541997909546, -0.1859787106513977, 0.11688186973333359, 0.05328073725104332, -0.23316197097301483, -0.3899984657764435, -0.1998777538537979, -0.43840503692626953, 0.1213247999548912, 0.10185296088457108, 0.08310198783874512, 0.3317270576953888, -0.08138290047645569, 0.1843833029270172, -0.10513550788164139, -0.2397989183664322, -0.24391785264015198, 0.2868635952472687, -0.14646278321743011, 0.15775363147258759, -0.021649273112416267, -0.12723657488822937, 0.09280068427324295, 0.0035478512290865183, -0.025228489190340042, 0.13578663766384125, -0.2502560615539551, -0.04018213227391243, -0.2480120062828064, -0.21175764501094818, 0.11948485672473907, 0.1399693340063095, -0.3697361946105957, 0.042635075747966766, 0.03373183682560921, -0.11777245253324509, 0.01075794454663992, -0.3459096848964691, 0.10292027145624161, 0.09431789070367813, 0.26532837748527527, -0.3107123076915741, 0.03377913311123848, -0.37663134932518005, 0.11032536625862122, 0.5276355147361755, 0.27742302417755127, -0.12793944776058197, 0.0142912482842803, 0.0338447131216526, 0.2502032220363617, 0.19924692809581757, -0.07416054606437683, -0.12118217349052429, 0.2643100917339325, 0.12474198639392853, -0.010701295919716358, 0.16725444793701172, 0.1870589703321457, -0.16427773237228394, -0.39120978116989136, -0.03582170605659485, 0.4065021574497223, -0.014093264006078243, -0.1936904788017273, 0.15390048921108246, 0.17351402342319489, -0.01267438754439354, 0.48825645446777344, 0.31152695417404175, -0.4173009693622589, 0.2794550359249115, -0.044307924807071686, 0.370815247297287, -0.21668657660484314, 0.040798477828502655, ...]</td>
      <td>0.795055</td>
      <td>0</td>
      <td>one just waits grimly for the next shock without developing much attachment to the characters .</td>
    </tr>
  </tbody>
</table></div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Accessing-DataLoaders">Accessing DataLoaders<a class="anchor-link" href="#Accessing-DataLoaders"> </a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We can access dataloaders for the raw text in <code>ds.dsd_raw</code> with <code>ds.dld_raw</code>, and for the tokenised text in <code>ds.dsd_tkn</code> with <code>ds_dld_tkn</code>. Both of these are dictionaries of dataloaders with keys <code>['train', 'valid', 'test', 'train_eval]</code>.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Dataloader dict has keys:&quot;</span><span class="p">,</span> <span class="n">ds</span><span class="o">.</span><span class="n">dld_raw</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
<span class="n">batch_raw</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">ds</span><span class="o">.</span><span class="n">dld_raw</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">]))</span>
<span class="n">batch_tkn</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">ds</span><span class="o">.</span><span class="n">dld_tkn</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">batch_raw</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="n">batch_tkn</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Tokenised input is of shape:&quot;</span><span class="p">,</span> <span class="n">batch_tkn</span><span class="p">[</span><span class="s1">&#39;input_ids&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Dataloader dict has keys: dict_keys([&#39;train&#39;, &#39;test&#39;, &#39;valid&#39;, &#39;train_eval&#39;])
dict_keys([&#39;text&#39;, &#39;idx&#39;])
dict_keys([&#39;idx&#39;, &#39;attention_mask&#39;, &#39;input_ids&#39;, &#39;label&#39;, &#39;orig_truelabel_probs&#39;, &#39;orig_sts_embeddings&#39;])
Tokenised input is of shape: torch.Size([32, 64])
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

</div>
 

