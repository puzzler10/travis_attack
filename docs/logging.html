---

title: Title


keywords: fastai
sidebar: home_sidebar



nb_path: "30_logging.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: 30_logging.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">plot_grad_flow</span><span class="p">(</span><span class="n">named_parameters</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;Plots the gradients flowing through different layers in the net during training.</span>
<span class="sd">    Can be used for checking for possible gradient vanishing / exploding problems.</span>
<span class="sd">    </span>
<span class="sd">    Usage: Plug this function in Trainer class after loss.backwards() as </span>
<span class="sd">    &quot;plot_grad_flow(self.model.named_parameters())&quot; to visualize the gradient flow&#39;&#39;&#39;</span>
    <span class="kn">from</span> <span class="nn">matplotlib.lines</span> <span class="kn">import</span> <span class="n">Line2D</span>
    <span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
    <span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span> 
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
    <span class="n">ave_grads</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">max_grads</span><span class="o">=</span> <span class="p">[]</span>
    <span class="n">layers</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">n</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">named_parameters</span><span class="p">:</span>
        <span class="k">if</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="s2">&quot;bias&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">n</span><span class="p">):</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
            <span class="n">ave_grads</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>
            <span class="n">max_grads</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span><span class="o">.</span><span class="n">max</span><span class="p">())</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">max_grads</span><span class="p">)),</span> <span class="n">max_grads</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;c&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">max_grads</span><span class="p">)),</span> <span class="n">ave_grads</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;b&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">hlines</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">ave_grads</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;k&quot;</span> <span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">ave_grads</span><span class="p">),</span> <span class="mi">1</span><span class="p">),</span> <span class="n">layers</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="s2">&quot;vertical&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">ave_grads</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="n">bottom</span> <span class="o">=</span> <span class="o">-</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">0.02</span><span class="p">)</span> <span class="c1"># zoom in on the lower gradient regions</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Layers&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Average Gradient&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Gradient Flow&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="n">Line2D</span><span class="p">([</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;c&quot;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">4</span><span class="p">),</span>
                <span class="n">Line2D</span><span class="p">([</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">4</span><span class="p">),</span>
                <span class="n">Line2D</span><span class="p">([</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;k&quot;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">4</span><span class="p">)],</span> <span class="p">[</span><span class="s1">&#39;max-gradient&#39;</span><span class="p">,</span> <span class="s1">&#39;mean-gradient&#39;</span><span class="p">,</span> <span class="s1">&#39;zero-gradient&#39;</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">plt</span>


<span class="k">def</span> <span class="nf">print_info_on_generated_text</span><span class="p">():</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Prints a bunch of statistics around the generated text. Useful for debugging purposes.</span>
<span class="sd">        So far only works for greedy search.</span>
<span class="sd">        OUTDATED OUTDATED</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">######################################################################</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Original text: </span><span class="si">{</span><span class="n">text</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">tgt_text</span> <span class="o">=</span> <span class="n">pp_tokenizer</span><span class="o">.</span><span class="n">batch_decode</span><span class="p">(</span><span class="n">translated</span><span class="o">.</span><span class="n">sequences</span><span class="p">,</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">tgt_text_with_tokens</span> <span class="o">=</span> <span class="n">pp_tokenizer</span><span class="o">.</span><span class="n">batch_decode</span><span class="p">(</span><span class="n">translated</span><span class="o">.</span><span class="n">sequences</span><span class="p">,</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Generated text: </span><span class="si">{</span><span class="n">tgt_text</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Generated text with special tokens: </span><span class="si">{</span><span class="n">tgt_text_with_tokens</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Shape of translated.sequences:</span><span class="si">{</span><span class="n">translated</span><span class="o">.</span><span class="n">sequences</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;translated.sequences:</span><span class="si">{</span><span class="n">translated</span><span class="o">.</span><span class="n">sequences</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Scores is a tuple of length </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">translated</span><span class="o">.</span><span class="n">scores</span><span class="p">)</span><span class="si">}</span><span class="s2"> </span><span class="se">\</span>
<span class="s2">    and each score is a tensor of shape </span><span class="si">{</span><span class="n">translated</span><span class="o">.</span><span class="n">scores</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">scores_stacked</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">translated</span><span class="o">.</span><span class="n">scores</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Stacking the scores into a tensor of shape </span><span class="si">{</span><span class="n">scores_stacked</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">scores_softmax</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">scores_stacked</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Now taking softmax. This shouldn&#39;t change the shape, but just to check,</span><span class="se">\</span>
<span class="s2">    its shape is </span><span class="si">{</span><span class="n">scores_softmax</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">probsums</span> <span class="o">=</span> <span class="n">scores_softmax</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;These are probabilities now and so they should all sum to 1 (or close to it) in the axis </span><span class="se">\</span>
<span class="s2">    corresponding to each time step. We can check the sums here: </span><span class="si">{</span><span class="n">probsums</span><span class="si">}</span><span class="s2">, but it&#39;s a long tensor </span><span class="se">\</span>
<span class="s2">    of shape </span><span class="si">{</span><span class="n">probsums</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2"> and hard to see, so summing over all these values and removing 1 </span><span class="se">\</span>
<span class="s2">    from each gives </span><span class="si">{</span><span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">probsums</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span><span class="si">}</span><span class="s2"> </span><span class="se">\</span>
<span class="s2">    which should be close to 0.&quot;</span><span class="p">)</span>
    <span class="n">seq_without_first_tkn</span> <span class="o">=</span> <span class="n">translated</span><span class="o">.</span><span class="n">sequences</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:]</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Now calculating sequence probabilities&quot;</span><span class="p">)</span>
    <span class="n">seq_token_probs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">scores_softmax</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="n">seq_without_first_tkn</span><span class="p">[:,:,</span><span class="kc">None</span><span class="p">])</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">seq_prob</span> <span class="o">=</span> <span class="n">seq_token_probs</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Sequence probability: </span><span class="si">{</span><span class="n">seq_prob</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># Get the 2nd and 3rd most likely tokens at each st</span>
    <span class="n">topk_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">topk</span><span class="p">(</span><span class="n">scores_softmax</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">indices</span><span class="p">[:,:,</span><span class="mi">1</span><span class="p">:]</span>
    <span class="n">topk_tokens_probs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">scores_softmax</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="n">topk_ids</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">toks2</span> <span class="o">=</span> <span class="n">pp_tokenizer</span><span class="o">.</span><span class="n">convert_ids_to_tokens</span><span class="p">(</span><span class="n">topk_ids</span><span class="p">[:,:,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">squeeze</span><span class="p">())</span>
    <span class="n">toks3</span> <span class="o">=</span> <span class="n">pp_tokenizer</span><span class="o">.</span><span class="n">convert_ids_to_tokens</span><span class="p">(</span><span class="n">topk_ids</span><span class="p">[:,:,</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">squeeze</span><span class="p">())</span>
    <span class="n">tok_probs2</span> <span class="o">=</span> <span class="n">topk_tokens_probs</span><span class="p">[:,:,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
    <span class="n">tok_probs3</span> <span class="o">=</span> <span class="n">topk_tokens_probs</span><span class="p">[:,:,</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>

    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Probabilities of getting the top 3 tokens at each step:&quot;</span><span class="p">)</span>
    <span class="n">tokens</span> <span class="o">=</span> <span class="n">pp_tokenizer</span><span class="o">.</span><span class="n">convert_ids_to_tokens</span><span class="p">(</span><span class="n">seq_without_first_tkn</span><span class="o">.</span><span class="n">squeeze</span><span class="p">())</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">p2</span><span class="p">,</span><span class="n">t2</span><span class="p">,</span><span class="n">p3</span><span class="p">,</span><span class="n">t3</span><span class="p">)</span>  <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">seq_token_probs</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(),</span> <span class="n">tokens</span><span class="p">,</span> <span class="n">tok_probs2</span><span class="p">,</span> <span class="n">toks2</span><span class="p">,</span> <span class="n">tok_probs3</span><span class="p">,</span> <span class="n">toks3</span><span class="p">):</span> 
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">t</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span><span class="mi">3</span><span class="p">)</span><span class="si">}</span><span class="s2">  </span><span class="si">{</span><span class="n">t2</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">p2</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span><span class="mi">3</span><span class="p">)</span><span class="si">}</span><span class="s2">  </span><span class="si">{</span><span class="n">t3</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">p3</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span><span class="mi">3</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>    
    
    
    
<span class="k">def</span> <span class="nf">check_parameters_update</span><span class="p">(</span><span class="n">dl</span><span class="p">):</span> 
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    This checks which parameters are being updated. </span>
<span class="sd">    We run one forward pass+backward pass (updating the parameters once) </span>
<span class="sd">    and look at which ones change. </span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Check which parameters should be updated</span>
    <span class="n">params_with_grad</span> <span class="o">=</span> <span class="p">[</span><span class="n">o</span> <span class="k">for</span> <span class="n">o</span> <span class="ow">in</span> <span class="n">pp_model</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">()</span> <span class="k">if</span> <span class="n">o</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">]</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;---- Parameters with &#39;requires_grad&#39; and their sizes ------&quot;</span><span class="p">)</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span> <span class="ow">in</span> <span class="n">params_with_grad</span><span class="p">:</span>  <span class="nb">print</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
        
    <span class="c1">## Take a step and see which weights update</span>
    <span class="n">params_all</span> <span class="o">=</span> <span class="p">[</span><span class="n">o</span> <span class="k">for</span> <span class="n">o</span> <span class="ow">in</span> <span class="n">pp_model</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">()]</span>  <span class="c1"># this is updated by a training step    </span>
    <span class="n">params_all_initial</span> <span class="o">=</span> <span class="p">[(</span><span class="n">name</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">clone</span><span class="p">())</span> <span class="k">for</span> <span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span> <span class="ow">in</span> <span class="n">params_all</span><span class="p">]</span>  <span class="c1"># Initial values</span>
        
    <span class="c1"># take a step    </span>
    <span class="n">loss</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">pp_logp</span> <span class="o">=</span> <span class="n">training_step</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">---- Matrix norm of parameter update for one step ------</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">_</span><span class="p">,</span><span class="n">old_p</span><span class="p">),</span> <span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">new_p</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">params_all_initial</span><span class="p">,</span> <span class="n">params_all</span><span class="p">):</span> 
        <span class="nb">print</span> <span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">new_p</span> <span class="o">-</span> <span class="n">old_p</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">())</span> 
    
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

</div>
 

