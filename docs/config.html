---

title: Config


keywords: fastai
sidebar: home_sidebar



nb_path: "03_config.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: 03_config.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Here we define a class <a href="/travis_attack/config.html#Config"><code>Config</code></a> to hold hyperparameters and global variables.</p>
<p>Design from <a href="https://github.com/cswinter/DeepCodeCraft/blob/master/hyper_params.py">https://github.com/cswinter/DeepCodeCraft/blob/master/hyper_params.py</a></p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="Config" class="doc_header"><code>class</code> <code>Config</code><a href="https://github.com/puzzler10/travis_attack/tree/main/travis_attack/config.py#L9" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>Config</code>()</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Usage">Usage<a class="anchor-link" href="#Usage"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Basics">Basics<a class="anchor-link" href="#Basics"> </a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The easiest way is to edit the variables in the config object as you please and then initialise the config object. This will first initialise a set of default values as specified in <code>__init__()</code>. Next it calls the methods <code>adjust_config_for_simple_dataset()</code> or <code>adjust_config_for_rotten_tomatoes_dataset()</code> to overwrite some of these defaults with dataset-specific variables.</p>
<p>Once ready, call <code>cfg = Config()</code> and access values as attributes of <code>cfg</code>. For example:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">cfg</span> <span class="o">=</span> <span class="n">Config</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Dataset name: &quot;</span><span class="p">,</span> <span class="n">cfg</span><span class="o">.</span><span class="n">dataset_name</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Number of train epochs: &quot;</span><span class="p">,</span> <span class="n">cfg</span><span class="o">.</span><span class="n">n_train_epochs</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Batch size for train?: &quot;</span><span class="p">,</span> <span class="n">cfg</span><span class="o">.</span><span class="n">batch_size_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Max paraphrase length?: &quot;</span><span class="p">,</span> <span class="n">cfg</span><span class="o">.</span><span class="n">pp</span><span class="p">[</span><span class="s1">&#39;max_length&#39;</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Dataset name:  rotten_tomatoes
Number of train epochs:  250
Batch size for train?:  32
Max paraphrase length?:  64
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>You can also manually specify which dataset to use by calling the <code>adjust_config_...</code> functions yourself. This is useful for writing test cases.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">cfg</span> <span class="o">=</span> <span class="n">Config</span><span class="p">()</span><span class="o">.</span><span class="n">adjust_config_for_simple_dataset</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Dataset name: &quot;</span><span class="p">,</span> <span class="n">cfg</span><span class="o">.</span><span class="n">dataset_name</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Number of train epochs: &quot;</span><span class="p">,</span> <span class="n">cfg</span><span class="o">.</span><span class="n">n_train_epochs</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Batch size for train?: &quot;</span><span class="p">,</span> <span class="n">cfg</span><span class="o">.</span><span class="n">batch_size_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Max paraphrase length?: &quot;</span><span class="p">,</span> <span class="n">cfg</span><span class="o">.</span><span class="n">pp</span><span class="p">[</span><span class="s1">&#39;max_length&#39;</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Dataset name:  simple
Number of train epochs:  60
Batch size for train?:  2
Max paraphrase length?:  20
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">cfg</span> <span class="o">=</span> <span class="n">Config</span><span class="p">()</span><span class="o">.</span><span class="n">adjust_config_for_rotten_tomatoes_dataset</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Dataset name: &quot;</span><span class="p">,</span> <span class="n">cfg</span><span class="o">.</span><span class="n">dataset_name</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Number of train epochs: &quot;</span><span class="p">,</span> <span class="n">cfg</span><span class="o">.</span><span class="n">n_train_epochs</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Batch size for train?: &quot;</span><span class="p">,</span> <span class="n">cfg</span><span class="o">.</span><span class="n">batch_size_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Max paraphrase length?: &quot;</span><span class="p">,</span> <span class="n">cfg</span><span class="o">.</span><span class="n">pp</span><span class="p">[</span><span class="s1">&#39;max_length&#39;</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Dataset name:  rotten_tomatoes
Number of train epochs:  250
Batch size for train?:  32
Max paraphrase length?:  64
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>You can use <code>vars(cfg)</code> to get all parameters as a dict:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">pprint</span> <span class="kn">import</span> <span class="n">pprint</span>
<span class="n">pprint</span><span class="p">(</span><span class="nb">vars</span><span class="p">(</span><span class="n">cfg</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>{&#39;accumulation_steps&#39;: 1,
 &#39;batch_size_eval&#39;: 128,
 &#39;batch_size_train&#39;: 32,
 &#39;bucket_by_length&#39;: True,
 &#39;dataset_name&#39;: &#39;rotten_tomatoes&#39;,
 &#39;device&#39;: device(type=&#39;cuda&#39;),
 &#39;devicenum&#39;: 0,
 &#39;embedding_padding_multiple&#39;: 8,
 &#39;eval_freq&#39;: 1,
 &#39;label_cname&#39;: &#39;label&#39;,
 &#39;lr&#39;: 1e-05,
 &#39;metrics&#39;: [&#39;loss&#39;,
             &#39;pp_logp&#39;,
             &#39;reward&#39;,
             &#39;vm_score&#39;,
             &#39;sts_score&#39;,
             &#39;label_flip&#39;],
 &#39;n_layers_frozen&#39;: &#39;2&#39;,
 &#39;n_shards&#39;: None,
 &#39;n_train_epochs&#39;: 250,
 &#39;n_wkrs&#39;: 0,
 &#39;normalise_rewards&#39;: False,
 &#39;orig_cname&#39;: &#39;text&#39;,
 &#39;orig_max_length&#39;: 64,
 &#39;orig_padding_multiple&#39;: 8,
 &#39;pad_token_embeddings&#39;: True,
 &#39;path_checkpoints&#39;: &#39;../model_checkpoints/travis_attack/&#39;,
 &#39;path_data&#39;: &#39;./data/&#39;,
 &#39;pin_memory&#39;: True,
 &#39;pp&#39;: {&#39;diversity_penalty&#39;: 0.0,
        &#39;length_penalty&#39;: 1,
        &#39;max_length&#39;: 64,
        &#39;min_length&#39;: 5,
        &#39;num_beam_groups&#39;: 1,
        &#39;num_beams&#39;: 1,
        &#39;num_return_sequences&#39;: 1,
        &#39;temperature&#39;: 1.5},
 &#39;pp_name&#39;: &#39;eugenesiow/bart-paraphrase&#39;,
 &#39;remove_misclassified_examples&#39;: True,
 &#39;reward_strategy&#39;: &#39;[-0.5 if sts &lt; 0.5 else 0.5+v*sts for v,sts in &#39;
                    &#39;zip(vm_scores, sts_scores)]&#39;,
 &#39;sampling_strategy&#39;: &#39;greedy&#39;,
 &#39;save_model_freq&#39;: 10,
 &#39;save_model_while_training&#39;: False,
 &#39;seed&#39;: 420,
 &#39;shard_contiguous&#39;: None,
 &#39;shuffle_train&#39;: False,
 &#39;splits&#39;: [&#39;train&#39;, &#39;valid&#39;, &#39;test&#39;],
 &#39;sts_name&#39;: &#39;sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2&#39;,
 &#39;use_fp16&#39;: True,
 &#39;use_small_ds&#39;: False,
 &#39;vm_name&#39;: &#39;textattack/distilbert-base-uncased-rotten-tomatoes&#39;,
 &#39;wandb&#39;: {&#39;log_grads&#39;: False,
           &#39;log_grads_freq&#39;: 1,
           &#39;log_token_entropy&#39;: True,
           &#39;log_token_probabilities&#39;: True,
           &#39;log_training_step_table&#39;: True,
           &#39;mode&#39;: &#39;online&#39;,
           &#39;n_examples_plot&#39;: 4,
           &#39;plot_examples&#39;: False},
 &#39;zero_grad_with_none&#39;: False}
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Using-a-small-dataset-for-testing">Using a small dataset for testing<a class="anchor-link" href="#Using-a-small-dataset-for-testing"> </a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>If you want to do testing on a small dataset you can chain on <code>use_small_ds()</code> to adjust the config accordingly.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">cfg</span> <span class="o">=</span> <span class="n">Config</span><span class="p">()</span><span class="o">.</span><span class="n">adjust_config_for_rotten_tomatoes_dataset</span><span class="p">()</span><span class="o">.</span><span class="n">small_ds</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Dataset name: &quot;</span><span class="p">,</span> <span class="n">cfg</span><span class="o">.</span><span class="n">dataset_name</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Number of train epochs: &quot;</span><span class="p">,</span> <span class="n">cfg</span><span class="o">.</span><span class="n">n_train_epochs</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Batch size for train?: &quot;</span><span class="p">,</span> <span class="n">cfg</span><span class="o">.</span><span class="n">batch_size_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Max paraphrase length?: &quot;</span><span class="p">,</span> <span class="n">cfg</span><span class="o">.</span><span class="n">pp</span><span class="p">[</span><span class="s1">&#39;max_length&#39;</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Using small dataset?&quot;</span><span class="p">,</span> <span class="n">cfg</span><span class="o">.</span><span class="n">use_small_ds</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;How many shards?&quot;</span><span class="p">,</span> <span class="n">cfg</span><span class="o">.</span><span class="n">n_shards</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Dataset name:  rotten_tomatoes
Number of train epochs:  250
Batch size for train?:  32
Max paraphrase length?:  64
Using small dataset? True
How many shards? 60
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This functionality is disabled for the simple dataset because we only have 4 data points for each split.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">test_fail</span><span class="p">(</span><span class="n">Config</span><span class="p">()</span><span class="o">.</span><span class="n">adjust_config_for_simple_dataset</span><span class="p">()</span><span class="o">.</span><span class="n">adjust_config_for_simple_dataset</span><span class="p">()</span><span class="o">.</span><span class="n">small_ds</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

</div>
 

