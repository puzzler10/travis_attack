{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import torch\n",
    "import datetime\n",
    "import warnings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from fastcore.test import test_fail\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define a class `Config` to hold hyperparameters and global variables.\n",
    "\n",
    "Design from https://github.com/cswinter/DeepCodeCraft/blob/master/hyper_params.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Config: \n",
    "    def __init__(self): \n",
    "        \"\"\"Set up default parameters\"\"\"\n",
    "          \n",
    "        ### Models and datasets\n",
    "        # options for the pp_model \n",
    "        # 1. tuner007/pegasus_paraphrase\n",
    "        # 2. tdopierre/ProtAugment-ParaphraseGenerator\n",
    "        # 3. eugenesiow/bart-paraphrase\n",
    "        self.pp_name = \"tuner007/pegasus_paraphrase\"\n",
    "        self.vm_name = \"textattack/distilbert-base-uncased-rotten-tomatoes\"\n",
    "        self.sts_name = \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\n",
    "        self.dataset_name = \"rotten_tomatoes\"\n",
    "        \n",
    "        ### Training hyperparameters\n",
    "        self.seed = 420\n",
    "        self.use_fp16 = False\n",
    "        self.lr = 1e-5   \n",
    "        self.normalise_rewards = False\n",
    "        self.pin_memory = True\n",
    "        self.zero_grad_with_none = False\n",
    "        self.pad_token_embeddings = False\n",
    "        self.embedding_padding_multiple = 8\n",
    "        self.orig_padding_multiple = 8   # pad input to multiple of this\n",
    "        self.bucket_by_length = True\n",
    "        self.shuffle_train = False\n",
    "        self.remove_misclassified_examples = True\n",
    "        self.unfreeze_last_n_layers = \"all\"  #counting from the back. set to \"all\" to do no layer freezing, else set to an int \n",
    "        self.reward_fn = \"reward_fn_1\"\n",
    "        # This makes the reward function easier to see in wandb\n",
    "        # copy-paste this from reward function\n",
    "        self.reward_strategy = \"[-0.3 if sts < 0.6   else max(0.2 + v*sts*4, 0) for v,sts in zip(vm_scores, sts_scores)]\" \n",
    "\n",
    "        ### Paraphrase parameters  \n",
    "        self.pp = {\n",
    "            \"num_beams\": 1, \n",
    "            \"num_return_sequences\": 1, \n",
    "            \"num_beam_groups\": 1, \n",
    "            \"diversity_penalty\": 0.,   # must be a float\n",
    "            \"temperature\": 1,\n",
    "            \"length_penalty\" : 1,\n",
    "            \"min_length\" : 5,\n",
    "        }\n",
    "        \n",
    "        ### Used for testing\n",
    "        self.use_small_ds = False\n",
    "        self.n_shards = None\n",
    "        self.shard_contiguous = None\n",
    "        \n",
    "        ### Logging parameters\n",
    "        self.save_model_while_training = False\n",
    "        self.save_model_freq = 10\n",
    "        \n",
    "        ### These parameters don't do anything yet\n",
    "        self.sampling_strategy = \"greedy\"  # doesn't do anything\n",
    "     \n",
    "        ### W&B parameters\n",
    "        self.wandb = dict(\n",
    "            project = \"travis_attack\",\n",
    "            entity = \"uts_nlp\",\n",
    "            mode = \"online\",  # set to \"disabled\" to turn off wandb, \"online\" to enable it\n",
    "            log_grads = False, \n",
    "            log_grads_freq = 1,  # no effect if wandb_log_grads is False\n",
    "            log_token_entropy = True,\n",
    "            log_token_probabilities = True, \n",
    "            run_notes = f\"Reward: {self.reward_strategy}\\nDataset: {self.dataset_name}\"\n",
    "        )\n",
    "        \n",
    "        ### Devices and GPU settings\n",
    "        #### TODO: do you need this with accelerator? does this handle the post-processing analytics too?\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \n",
    "        self.devicenum = torch.cuda.current_device() if self.device.type == 'cuda' else -1\n",
    "        # When not using Accelerator\n",
    "        #n_wkrs = 4 * torch.cuda.device_count()\n",
    "        # When using Accelerator \n",
    "        self.n_wkrs = 0 \n",
    "        \n",
    "        ## Globals \n",
    "        self.splits = ['train', 'valid', 'test']\n",
    "        self.metrics = ['loss', 'pp_logp', 'reward', 'vm_score', \"sts_score\", 'label_flip']\n",
    "        self.path_data = \"./data/\"\n",
    "        self.path_checkpoints = \"../model_checkpoints/travis_attack/\"\n",
    "        self.path_run = None  # keep as None; this is automatically filled out by Trainer class\n",
    "        self.path_data_cache = \"/data/tproth/.cache/huggingface/datasets/\"\n",
    "        self.path_logs = f\"./logs/\"\n",
    "        self.path_logfile = self.path_logs + f\"run_{datetime.datetime.now().strftime('%Y-%m-%d_%H:%M:%S')}.txt\"\n",
    "        \n",
    "        # Adjust config depending on dataset. \n",
    "        if self.dataset_name   == \"simple\":           self.adjust_config_for_simple_dataset()\n",
    "        elif self.dataset_name == \"rotten_tomatoes\":  self.adjust_config_for_rotten_tomatoes_dataset()  \n",
    "        \n",
    "        # Checks\n",
    "        self._validate_n_epochs()\n",
    "        \n",
    "    def adjust_config_for_simple_dataset(self): \n",
    "        \"\"\"Adjust config for the simple dataset.\"\"\"\n",
    "        self.dataset_name = \"simple\"\n",
    "        self.orig_cname = \"text\"\n",
    "        self.label_cname = 'label'\n",
    "        self.orig_max_length = 20\n",
    "        self.pp['max_length'] = 20 \n",
    "        self.batch_size_train = 4\n",
    "        self.batch_size_eval = 4\n",
    "        self.acc_steps = 2  \n",
    "        self.n_train_epochs = 300\n",
    "        self.eval_freq = 1\n",
    "        return self\n",
    "    \n",
    "    def adjust_config_for_rotten_tomatoes_dataset(self): \n",
    "        \"\"\"Adjust config for the rotten_tomatoes dataset.\"\"\"\n",
    "        self.dataset_name = \"rotten_tomatoes\"\n",
    "        self.orig_cname = \"text\"\n",
    "        self.label_cname = 'label'\n",
    "        self.orig_max_length = 60  # seems to be the longest that pegasus is trained on. \n",
    "        self.pp['max_length'] = 60 \n",
    "        self.batch_size_train = 16\n",
    "        self.batch_size_eval = 64\n",
    "        self.acc_steps = 4\n",
    "        self.n_train_epochs = 2\n",
    "        self.eval_freq = 1\n",
    "        return self    \n",
    "        \n",
    "    def small_ds(self):\n",
    "        \"\"\"Adjust the config to use a small dataset (for testing purposes).\n",
    "        Not possible when using the simple dataset. \"\"\"\n",
    "        if self.dataset_name == \"simple\": \n",
    "            raise Exception(\"Don't shard when using the simple dataset (no need)\")\n",
    "        self.use_small_ds = True  # for testing purposes \n",
    "        self.n_shards = 300\n",
    "        self.shard_contiguous = False\n",
    "        return self\n",
    "    \n",
    "    def _validate_n_epochs(self): \n",
    "        if self.n_train_epochs % self.eval_freq != 0: \n",
    "            raise Exception(\"Set n_train_epochs to a multiple of eval_freq so there are no leftover epochs.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_utils.ipynb.\n",
      "Converted 02_tests.ipynb.\n",
      "Converted 03_config.ipynb.\n",
      "Converted 07_models.ipynb.\n",
      "Converted 10_data.ipynb.\n",
      "Converted 20_trainer.ipynb.\n",
      "Converted 25_insights.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted run.ipynb.\n",
      "Converted show_examples.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basics "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The easiest way is to edit the variables in the config object as you please and then initialise the config object. This will first initialise a set of default values as specified in `__init__()`. Next it calls the methods `adjust_config_for_simple_dataset()` or `adjust_config_for_rotten_tomatoes_dataset()` to overwrite some of these defaults with dataset-specific variables. \n",
    "\n",
    "Once ready, call `cfg = Config()` and access values as attributes of `cfg`. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = Config()\n",
    "print(\"Dataset name: \", cfg.dataset_name)\n",
    "print(\"Number of train epochs: \", cfg.n_train_epochs)\n",
    "print(\"Batch size for train?: \", cfg.batch_size_train)\n",
    "print(\"Max paraphrase length?: \", cfg.pp['max_length'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also manually specify which dataset to use by calling the `adjust_config_...` functions yourself. This is useful for writing test cases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = Config().adjust_config_for_simple_dataset()\n",
    "print(\"Dataset name: \", cfg.dataset_name)\n",
    "print(\"Number of train epochs: \", cfg.n_train_epochs)\n",
    "print(\"Batch size for train?: \", cfg.batch_size_train)\n",
    "print(\"Max paraphrase length?: \", cfg.pp['max_length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = Config().adjust_config_for_rotten_tomatoes_dataset()\n",
    "print(\"Dataset name: \", cfg.dataset_name)\n",
    "print(\"Number of train epochs: \", cfg.n_train_epochs)\n",
    "print(\"Batch size for train?: \", cfg.batch_size_train)\n",
    "print(\"Max paraphrase length?: \", cfg.pp['max_length'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use `vars(cfg)` to get all parameters as a dict: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "pprint(vars(cfg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using a small dataset for testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to do testing on a small dataset you can chain on `use_small_ds()` to adjust the config accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = Config().adjust_config_for_rotten_tomatoes_dataset().small_ds()\n",
    "print(\"Dataset name: \", cfg.dataset_name)\n",
    "print(\"Number of train epochs: \", cfg.n_train_epochs)\n",
    "print(\"Batch size for train?: \", cfg.batch_size_train)\n",
    "print(\"Max paraphrase length?: \", cfg.pp['max_length'])\n",
    "print(\"Using small dataset?\", cfg.use_small_ds)\n",
    "print(\"How many shards?\", cfg.n_shards)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This functionality is disabled for the simple dataset because we only have 4 data points for each split. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fail(Config().adjust_config_for_simple_dataset().adjust_config_for_simple_dataset().small_ds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
