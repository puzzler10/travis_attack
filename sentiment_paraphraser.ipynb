{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GLUE sets: model will be trained on eval set, so you shouldn't also test on the eval set. The problem is that the labels are withheld for the test set. \n",
    "Start with SNLI. MultiNLI is a later option too. As is rotten_tomatoes. \n",
    "* Victim model performance on dataset train, valid, test set. (done, written code to measure it)\n",
    "* Create new paraphrased valid + test datasets (done a preliminary version on the valid set) \n",
    "* Measure victim model performance on paraphrased datasets (done. on vanilla valid set is about 87% accuracy. generating 16 paraphrases (i.e. not many) and evaluating performance on all of them, we get ~75% accuracy)\n",
    "* Get document embeddings of original and paraphrased and compare (done)\n",
    "  * https://github.com/UKPLab/sentence-transformers\n",
    "* Write a simple way to measure paraphrase quality (done) \n",
    "* Construct reward function \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch \n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import load_dataset, load_metric\n",
    "import datasets, transformers\n",
    "from transformers import pipeline, AutoModelForSeq2SeqLM, AutoModelForSequenceClassification, AutoTokenizer\n",
    "from pprint import pprint\n",
    "import numpy as np, pandas as pd\n",
    "from utils import *   # local script \n",
    "import pyarrow\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from IPython.core.debugger import set_trace\n",
    "from GPUtil import showUtilization\n",
    "import seaborn as sns\n",
    "from itertools import repeat\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "path_cache = './cache/'\n",
    "path_results = \"./results/\"\n",
    "\n",
    "seed = 420\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \n",
    "devicenum = torch.cuda.current_device() if device.type == 'cuda' else -1\n",
    "n_wkrs = 4 * torch.cuda.device_count()\n",
    "batch_size = 64\n",
    "pd.set_option(\"display.max_colwidth\", 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paraphrase model (para)\n",
    "para_name = \"tuner007/pegasus_paraphrase\"\n",
    "para_tokenizer = AutoTokenizer.from_pretrained(para_name)\n",
    "para_model = AutoModelForSeq2SeqLM.from_pretrained(para_name).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Victim Model (VM)\n",
    "vm_name = \"textattack/distilbert-base-cased-snli\"\n",
    "vm_tokenizer = AutoTokenizer.from_pretrained(vm_name)\n",
    "vm_model = AutoModelForSequenceClassification.from_pretrained(vm_name).to(device)\n",
    "vm_idx2lbl = vm_model.config.id2label\n",
    "vm_lbl2idx = vm_model.config.label2id\n",
    "vm_num_labels = vm_model.num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Semantic Similarity model \n",
    "embedding_model = SentenceTransformer('paraphrase-distilroberta-base-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset snli (/data/tproth/.cache/huggingface/datasets/snli/plain_text/1.0.0/1f60b67533b65ae0275561ff7828aad5ee4282d0e6f844fd148d05d3c6ea251b)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bf1efbe71974b58a7a780b00a4b16bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=551.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb575b92c8d242ddac865e6661de6dbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caf1ebde46d64884b143d84103261723",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"snli\")\n",
    "train,valid,test = dataset['train'],dataset['validation'],dataset['test']\n",
    "\n",
    "label_cname = 'label'\n",
    "remove_minus1_labels = lambda x: x[label_cname] != -1\n",
    "train = train.filter(remove_minus1_labels)\n",
    "valid = valid.filter(remove_minus1_labels)\n",
    "test = test.filter(remove_minus1_labels)\n",
    "\n",
    "# make sure that all datasets have the same number of labels as what the victim model predicts\n",
    "assert train.features[label_cname].num_classes == vm_num_labels\n",
    "assert valid.features[label_cname].num_classes == vm_num_labels\n",
    "assert test.features[ label_cname].num_classes == vm_num_labels\n",
    "\n",
    "train_dl = DataLoader(train, batch_size=batch_size, shuffle=True, num_workers=n_wkrs)\n",
    "valid_dl = DataLoader(valid, batch_size=batch_size, shuffle=True, num_workers=n_wkrs)\n",
    "test_dl = DataLoader( test,  batch_size=batch_size, shuffle=True, num_workers=n_wkrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def get_paraphrases(input_text,num_return_sequences,num_beams, num_beam_groups=1,diversity_penalty=0):\n",
    "    batch = para_tokenizer(input_text,truncation=True,padding='longest', return_tensors=\"pt\").to(device)\n",
    "    translated = para_model.generate(**batch,num_beams=num_beams, num_return_sequences=num_return_sequences, \n",
    "                                   temperature=1.5, num_beam_groups=num_beam_groups, diversity_penalty=diversity_penalty)\n",
    "    tgt_text = para_tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
    "    return tgt_text\n",
    "\n",
    "def gen_dataset_paraphrases(x, cname_input, cname_output, n_seed_seqs=32): \n",
    "    \"\"\" x: one row of a dataset. \n",
    "    cname_input: column to generate paraphrases for \n",
    "    cname_output: column name to give output of paraphrases \n",
    "    n_seed_seqs: rough indicator of how many paraphrases to return. \n",
    "            For now, keep at 4,8,16,32,64 etc\"\"\"\n",
    "    # TODO: figure out how to batch this. \n",
    "    if n_seed_seqs % 4 != 0: raise ValueError(\"keep n_seed_seqs divisible by 4 for now\")\n",
    "    n = n_seed_seqs/2\n",
    "    #low diversity (ld) paraphrases \n",
    "    ld_l = get_paraphrases(x[cname_input],num_return_sequences=int(n),\n",
    "                            num_beams=int(n))\n",
    "    #high diversity (hd) paraphrases. We can use num_beam_groups and diversity_penalty as hyperparameters. \n",
    "    hd_l =  get_paraphrases(x[cname_input],num_return_sequences=int(n),\n",
    "                            num_beams=int(n), num_beam_groups=int(n),diversity_penalty=50002.5)\n",
    "    l = ld_l + hd_l \n",
    "    x[cname_output] = l #TODO: change to list(set(l))             \n",
    "    return x \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate paraphrase dataset\n",
    "n_seed_seqs = 48\n",
    "fname = path_cache + 'valid_small_'+ str(n_seed_seqs)\n",
    "if os.path.exists(fname):  # simple caching\n",
    "    valid_small = datasets.load_from_disk(fname)\n",
    "else:\n",
    "    valid_small = valid.shard(20, 0, contiguous=True)\n",
    "    valid_small = valid_small.map(lambda x: gen_dataset_paraphrases(x, n_seed_seqs=n_seed_seqs,\n",
    "                        cname_input='hypothesis', cname_output='hypothesis_paraphrases'),\n",
    "                    batched=False)\n",
    "    valid_small.save_to_disk(fname)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Create a new version of paraphrase dataset by repeating all other fields to be same \n",
    "# length as number of paraphrases. \n",
    "def create_paraphrase_dataset(batch, l_cname): \n",
    "    \"\"\"Repeat the other fields to be the same length as the number of paraphrases.\n",
    "    l_cname: column name that contains the list of paraphrases\"\"\"    \n",
    "    return_d = defaultdict(list) \n",
    "    for o in zip(*batch.values()):\n",
    "        d = dict(zip(batch.keys(), o))\n",
    "        n_paraphrases = len(d[l_cname])\n",
    "        for k,v in d.items(): \n",
    "            return_d[k] += v if k == l_cname else [v for o in range(n_paraphrases)]\n",
    "    return return_d      \n",
    "\n",
    "\n",
    "fname = path_cache + 'valid_small_paraphrases_' + str(n_seed_seqs)\n",
    "if os.path.exists(fname):     \n",
    "    valid_small_paraphrases = datasets.load_from_disk(fname)\n",
    "else:\n",
    "    # Need to call this with batched=True to work. \n",
    "    valid_small_paraphrases = valid_small.map(lambda x: create_paraphrase_dataset(x,\n",
    "                                                             l_cname='hypothesis_paraphrases'), \n",
    "                                              batched=True)\n",
    "    valid_small_paraphrases.save_to_disk(fname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Generate results dataframe \n",
    "def get_vm_scores(): \n",
    "    \"\"\"very hacky procedure to generate victim model scores \"\"\"\n",
    "    # Get preds and accuracy on the paraphrase dataset\n",
    "    print(\"Getting victim model scores.\")\n",
    "    some_dl = DataLoader(valid_small_paraphrases, batch_size=batch_size, shuffle=False, \n",
    "                         num_workers=n_wkrs, pin_memory=True)\n",
    "    dl = some_dl\n",
    "    metric = load_metric('accuracy')\n",
    "    para_probs_l,orig_probs_l = [], []\n",
    "    assert vm_model.training == False  # checks that model is in eval mode \n",
    "    #monitor = Monitor(2)  # track GPU usage and memory\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(dl): \n",
    "            if i % 50 == 0 : print(i, \"out of\", len(dl))\n",
    "            labels,premise = data['label'].to(device),data[\"premise\"]\n",
    "            paraphrases,orig = data[\"hypothesis_paraphrases\"],data[\"hypothesis\"]\n",
    "\n",
    "            # predictions for original\n",
    "            inputs = vm_tokenizer(premise,orig,padding=True,truncation=True, return_tensors=\"pt\")\n",
    "            inputs.to(device)\n",
    "            outputs = vm_model(**inputs, labels=labels)\n",
    "            probs = outputs.logits.softmax(1)\n",
    "            preds = probs.argmax(1)\n",
    "            orig_probs_l.append(probs.cpu())  \n",
    "\n",
    "            # predictions for paraphrases\n",
    "            inputs = vm_tokenizer(premise,paraphrases, padding=True,truncation=True, return_tensors=\"pt\")\n",
    "            inputs.to(device)\n",
    "            outputs = vm_model(**inputs, labels=labels)\n",
    "            probs = outputs.logits.softmax(1)\n",
    "            preds = probs.argmax(1)\n",
    "            para_probs_l.append(probs.cpu())\n",
    "            metric.add_batch(predictions=preds, references=labels)\n",
    "\n",
    "    orig_probs_t, para_probs_t = torch.cat(orig_probs_l),torch.cat(para_probs_l)\n",
    "    #monitor.stop()\n",
    "\n",
    "    # bit of a hack, i'm sure there's a native pytorch function for this but I couldn't find it\n",
    "    vm_para_scores = torch.tensor([r[idx] for idx,r in zip(valid_small_paraphrases['label'],para_probs_t)])\n",
    "    vm_orig_scores = torch.tensor([r[idx] for idx,r in zip(valid_small_paraphrases['label'],orig_probs_t)])\n",
    "    return para_probs_t, orig_probs_t\n",
    "\n",
    "def generate_sim_scores(): \n",
    "    \"\"\"Function to just loop and generate sim scores for each input\"\"\"\n",
    "    print(\"Getting similarity scores\")\n",
    "    sim_score_l = []\n",
    "    for i, data in enumerate(valid_small): \n",
    "        if i % 50 == 0 : print(i, \"out of\", len(valid_small))\n",
    "        orig, para = data['hypothesis'], data['hypothesis_paraphrases']\n",
    "        orig_emb,para_emb  = embedding_model.encode(orig),embedding_model.encode(para)\n",
    "        cos_sim = util.cos_sim(orig_emb,para_emb)[0]\n",
    "        sim_score_l.append(cos_sim)\n",
    "    sim_score_t = torch.cat(sim_score_l)\n",
    "    return sim_score_t\n",
    "\n",
    "fname = path_cache + 'results_df' + str(n_seed_seqs) + \"_1.csv\"\n",
    "if os.path.exists(fname):\n",
    "    results_df = pd.read_csv(fname)\n",
    "else: \n",
    "    sim_score_t = generate_sim_scores()\n",
    "    para_probs_t, orig_probs_t = get_vm_scores()\n",
    "    vm_para_scores = torch.tensor([r[idx] for idx,r in zip(valid_small_paraphrases['label'],para_probs_t)])\n",
    "    vm_orig_scores = torch.tensor([r[idx] for idx,r in zip(valid_small_paraphrases['label'],orig_probs_t)])\n",
    "    \n",
    "    results_df = pd.DataFrame({'premise': valid_small_paraphrases['premise'],\n",
    "                  'orig': valid_small_paraphrases['hypothesis'],\n",
    "                  'para': valid_small_paraphrases['hypothesis_paraphrases'],\n",
    "                  'sim_score': sim_score_t,\n",
    "                  'label_true': valid_small_paraphrases['label'], \n",
    "                  'label_vm_orig': orig_probs_t.argmax(1),\n",
    "                  'label_vm_para': para_probs_t.argmax(1),\n",
    "                  'vm_orig_truelabel': vm_orig_scores,             \n",
    "                  'vm_para_truelabel': vm_para_scores,\n",
    "                  'vm_truelabel_change': vm_orig_scores - vm_para_scores,\n",
    "                  'vm_orig_class0': orig_probs_t[:,0], \n",
    "                  'vm_orig_class1': orig_probs_t[:,1], \n",
    "                  'vm_orig_class2': orig_probs_t[:,2],  \n",
    "                  'vm_para_class0': para_probs_t[:,0], \n",
    "                  'vm_para_class1': para_probs_t[:,1], \n",
    "                  'vm_para_class2': para_probs_t[:,2]     \n",
    "                  })\n",
    "    results_df['vm_truelabel_change_X_sim_score'] = results_df['vm_truelabel_change'] * results_df['sim_score']\n",
    "    results_df.to_csv(fname, index_label = 'idx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Permutation method to detect label flips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take each example $Ex$ in the filtered set and generate paraphrases (e.g. 16) of it (or it might work better with a simple token-replacement strategy). Run each through the victim model (might be better with a different model, but still trained on dataset) and record predictions. Then tally up the label predictions (or maybe take average of the probabilities). Each prediction is a vote for the true label. Idea is that if $Ex$ changes ground truth label to class 4, then most of the paraphrases of $Ex$ will be of class 4 too. If $Ex$ is truly adversarial, then most of the paraphrases of $Ex$ are likely to be of the original class. \n",
    "\n",
    "Variations \n",
    "\n",
    "* Instead of generating further paraphrases for all label flippers, try the checklist tests on the input. e.g. replace number/proper noun\n",
    "* Try systematic perturbations\n",
    "* Record probability of the true class or the predicted class and put it into a distribution. Calculate entropy of it (STRIP style). The idea is that there is some reliable difference in these probabilities between ground-truth flips and otherwise and that entropy can be used as a rough measurement to distinguish between it. \n",
    "* Can try the above while keeping track of sentence embeddings + attention layers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-ebc62bd8d2fb84e0\n",
      "Reusing dataset csv (/data/tproth/.cache/huggingface/datasets/csv/default-ebc62bd8d2fb84e0/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0)\n"
     ]
    }
   ],
   "source": [
    "# Read in manually labelled data. This is to track results. \n",
    "fname = path_cache + 'results_df_48_20210514_labelled_subset.csv'\n",
    "dset_advlbl = load_dataset('csv', data_files=fname)['train'].train_test_split(test_size=0.25)\n",
    "train_advlbl,test_advlbl = dset_advlbl['train'],dset_advlbl['test']\n",
    "\n",
    "\n",
    "# # as pandas df\n",
    "# df_advlbl = pd.read_csv(fname)\n",
    "# train_advlbl,_,test_advlbl = create_train_valid_test(df_advlbl, frac_train=0.75, frac_valid = 0.001)\n",
    "# # To join with the original. (might be some issues with the idx/row-number col)\n",
    "# # x = pd.merge(results_df, df_advlbl, on =['idx', 'premise','orig', 'para'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_advlbl_df,test_advlbl_df = pd.DataFrame(dset_advlbl['train']),pd.DataFrame(dset_advlbl['test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paraphrases of paraphrases "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nlp dataset -> gen_paraphrases (returns dataset) -> create_paraphrase_dataset -> get vm labels -> save in data frame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e21655706b9745b697d0cca58d6ee950",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=198.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n = 16 \n",
    "cols_to_drop = ['is_adversarial','label_true','label_vm_orig','label_vm_para','orig','sim_score']\n",
    "def paraphrase_and_return_dict(x, n_seed_seqs=16): \n",
    "    x['perms'] = get_paraphrases(x['para'], num_return_sequences=n, num_beams=n)\n",
    "    return x \n",
    "train_advlbl_perms = train_advlbl.map(lambda x: paraphrase_and_return_dict(x, n_seed_seqs=n),\n",
    "                  batched=False, remove_columns = cols_to_drop)\n",
    "train_advlbl_expanded = train_advlbl_perms.map(lambda x: create_paraphrase_dataset(x, l_cname='perms'),\n",
    "                           batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Get victim model predictions for each prediction  \n",
    "advlbl_expanded_dl = DataLoader(train_advlbl_expanded, batch_size=batch_size, shuffle=False, \n",
    "                                num_workers=n_wkrs, pin_memory=True)\n",
    "dl = advlbl_expanded_dl\n",
    "probs_l = []\n",
    "assert vm_model.training == False  # checks that model is in eval mode \n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(dl): \n",
    "        if i % 50 == 0 : print(i, \"out of\", len(dl))\n",
    "        premise,perms = data[\"premise\"],data[\"perms\"]\n",
    "        # predictions for original\n",
    "        inputs = vm_tokenizer(premise,perms,padding=True,truncation=True, return_tensors=\"pt\")\n",
    "        inputs.to(device)\n",
    "        outputs = vm_model(**inputs)\n",
    "        probs = outputs.logits.softmax(1)\n",
    "        # preds = probs.argmax(1)\n",
    "        probs_l.append(probs.cpu()) \n",
    "\n",
    "probs_t = torch.cat(probs_l)\n",
    "preds_t = torch.argmax(probs_t,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bring back to original\n",
    "train_advlbl_expanded = train_advlbl_expanded.add_column('vm_label', preds_t.tolist())\n",
    "train_advlbl_expanded = train_advlbl_expanded.add_column('vm_prob0', probs_t[:,0].tolist())\n",
    "train_advlbl_expanded = train_advlbl_expanded.add_column('vm_prob1', probs_t[:,1].tolist())\n",
    "train_advlbl_expanded = train_advlbl_expanded.add_column('vm_prob2', probs_t[:,2].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make into pandas_df \n",
    "advlbl_df = pd.DataFrame(train_advlbl_expanded) \n",
    "advlbl_df.vm_label = advlbl_df.vm_label.astype('category')\n",
    "\n",
    "# Count \"votes\" of each set of permutations \n",
    "votes_df = advlbl_df.groupby(['idx'])['vm_label'].describe()\n",
    "votes_df = votes_df.rename(columns={'count':'votes','unique': \"n_cats_with_votes\",\n",
    "                                     \"top\": 'top_cat', 'freq': 'top_cat_votes'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_advlbl_df = pd.merge(train_advlbl_df, votes_df, left_on='idx', right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = advlbl_df[['vm_prob0','vm_prob1','vm_prob2']][0:16].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(x):\n",
    "    \"\"\"\n",
    "    x is assumed to be an (nsignals, nsamples) array containing integers between\n",
    "    0 and n_unique_vals\n",
    "    \"\"\"\n",
    "    x = np.atleast_2d(x)\n",
    "    nrows, ncols = x.shape\n",
    "    nbins = x.max() + 1\n",
    "\n",
    "    # count the number of occurrences for each unique integer between 0 and x.max()\n",
    "    # in each row of x\n",
    "    counts = np.vstack((np.bincount(row, minlength=nbins) for row in x))\n",
    "\n",
    "    # divide by number of columns to get the probability of each unique value\n",
    "    p = counts / float(ncols)\n",
    "\n",
    "    # compute Shannon entropy in bits\n",
    "    return -np.sum(p * np.log2(p), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot cast array data from dtype('float64') to dtype('int64') according to the rule 'safe'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-317-1ff4acbdb752>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbincount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mbincount\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot cast array data from dtype('float64') to dtype('int64') according to the rule 'safe'"
     ]
    }
   ],
   "source": [
    "np.bincount(x[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vm_prob0</th>\n",
       "      <th>vm_prob1</th>\n",
       "      <th>vm_prob2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.078689</td>\n",
       "      <td>0.010921</td>\n",
       "      <td>0.001433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.078541</td>\n",
       "      <td>0.012596</td>\n",
       "      <td>0.001009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.072975</td>\n",
       "      <td>0.042969</td>\n",
       "      <td>0.011727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.029920</td>\n",
       "      <td>0.132521</td>\n",
       "      <td>0.212876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.072770</td>\n",
       "      <td>0.044026</td>\n",
       "      <td>0.012171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.023403</td>\n",
       "      <td>0.152397</td>\n",
       "      <td>0.238178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.057459</td>\n",
       "      <td>0.082056</td>\n",
       "      <td>0.078675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.074377</td>\n",
       "      <td>0.016331</td>\n",
       "      <td>0.024472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.064317</td>\n",
       "      <td>0.083978</td>\n",
       "      <td>0.033467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.073438</td>\n",
       "      <td>0.039123</td>\n",
       "      <td>0.011907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.047608</td>\n",
       "      <td>0.103280</td>\n",
       "      <td>0.124096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.062893</td>\n",
       "      <td>0.089360</td>\n",
       "      <td>0.038153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.076665</td>\n",
       "      <td>0.024391</td>\n",
       "      <td>0.003356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.078673</td>\n",
       "      <td>0.009969</td>\n",
       "      <td>0.002306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.078863</td>\n",
       "      <td>0.009913</td>\n",
       "      <td>0.001140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.029408</td>\n",
       "      <td>0.146169</td>\n",
       "      <td>0.205035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    vm_prob0  vm_prob1  vm_prob2\n",
       "0   0.078689  0.010921  0.001433\n",
       "1   0.078541  0.012596  0.001009\n",
       "2   0.072975  0.042969  0.011727\n",
       "3   0.029920  0.132521  0.212876\n",
       "4   0.072770  0.044026  0.012171\n",
       "5   0.023403  0.152397  0.238178\n",
       "6   0.057459  0.082056  0.078675\n",
       "7   0.074377  0.016331  0.024472\n",
       "8   0.064317  0.083978  0.033467\n",
       "9   0.073438  0.039123  0.011907\n",
       "10  0.047608  0.103280  0.124096\n",
       "11  0.062893  0.089360  0.038153\n",
       "12  0.076665  0.024391  0.003356\n",
       "13  0.078673  0.009969  0.002306\n",
       "14  0.078863  0.009913  0.001140\n",
       "15  0.029408  0.146169  0.205035"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.bincount(x[:0], minlength=nbins) for row in x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axis.YAxis at 0x2b81b2d6f8e0>"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.yaxis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2       0\n",
       "3       2\n",
       "4       0\n",
       "       ..\n",
       "3163    1\n",
       "3164    1\n",
       "3165    1\n",
       "3166    1\n",
       "3167    0\n",
       "Name: vm_label, Length: 3168, dtype: category\n",
       "Categories (3, int64): [0, 1, 2]"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "advlbl_df.vm_label.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "idx    vm_label\n",
       "7718   0           16\n",
       "12487  1           16\n",
       "687    0           16\n",
       "1526   1           16\n",
       "18937  0           16\n",
       "                   ..\n",
       "1103   1            1\n",
       "       0            1\n",
       "9422   2            1\n",
       "1054   2            1\n",
       "374    1            1\n",
       "Length: 359, dtype: int64"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "advlbl_df.value_counts(['idx', 'vm_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'n' is not a valid function for 'DataFrameGroupBy' object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-243-8e003b475f79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0madvlbl_grp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Programs/miniconda/envs/nlp_env/lib/python3.8/site-packages/pandas/core/groupby/generic.py\u001b[0m in \u001b[0;36maggregate\u001b[0;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    943\u001b[0m             )\n\u001b[1;32m    944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 945\u001b[0;31m         \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_aggregate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    946\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhow\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Programs/miniconda/envs/nlp_env/lib/python3.8/site-packages/pandas/core/base.py\u001b[0m in \u001b[0;36m_aggregate\u001b[0;34m(self, arg, *args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_aggregate_string_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Programs/miniconda/envs/nlp_env/lib/python3.8/site-packages/pandas/core/base.py\u001b[0m in \u001b[0;36m_try_aggregate_string_function\u001b[0;34m(self, arg, *args, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m         raise AttributeError(\n\u001b[0m\u001b[1;32m    278\u001b[0m             \u001b[0;34mf\"'{arg}' is not a valid function for '{type(self).__name__}' object\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m         )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'n' is not a valid function for 'DataFrameGroupBy' object"
     ]
    }
   ],
   "source": [
    "advlbl_grp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>para</th>\n",
       "      <th>perms</th>\n",
       "      <th>premise</th>\n",
       "      <th>vm_label</th>\n",
       "      <th>vm_prob0</th>\n",
       "      <th>vm_prob1</th>\n",
       "      <th>vm_prob2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13505</td>\n",
       "      <td>A man and woman stand near the beach.</td>\n",
       "      <td>Two people stand near the beach.</td>\n",
       "      <td>A carefully balanced male stands on one foot near a clean ocean beach area.</td>\n",
       "      <td>0</td>\n",
       "      <td>0.979817</td>\n",
       "      <td>0.017380</td>\n",
       "      <td>0.002803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13505</td>\n",
       "      <td>A man and woman stand near the beach.</td>\n",
       "      <td>Two people are near the beach.</td>\n",
       "      <td>A carefully balanced male stands on one foot near a clean ocean beach area.</td>\n",
       "      <td>0</td>\n",
       "      <td>0.977980</td>\n",
       "      <td>0.020046</td>\n",
       "      <td>0.001974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13505</td>\n",
       "      <td>A man and woman stand near the beach.</td>\n",
       "      <td>A man and woman are outside.</td>\n",
       "      <td>A carefully balanced male stands on one foot near a clean ocean beach area.</td>\n",
       "      <td>0</td>\n",
       "      <td>0.908671</td>\n",
       "      <td>0.068383</td>\n",
       "      <td>0.022946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13505</td>\n",
       "      <td>A man and woman stand near the beach.</td>\n",
       "      <td>A man and woman are standing.</td>\n",
       "      <td>A carefully balanced male stands on one foot near a clean ocean beach area.</td>\n",
       "      <td>2</td>\n",
       "      <td>0.372555</td>\n",
       "      <td>0.210900</td>\n",
       "      <td>0.416545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13505</td>\n",
       "      <td>A man and woman stand near the beach.</td>\n",
       "      <td>A man and a woman are outside.</td>\n",
       "      <td>A carefully balanced male stands on one foot near a clean ocean beach area.</td>\n",
       "      <td>0</td>\n",
       "      <td>0.906121</td>\n",
       "      <td>0.070064</td>\n",
       "      <td>0.023815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3163</th>\n",
       "      <td>23223</td>\n",
       "      <td>The child plays in the mud...</td>\n",
       "      <td>The child is outside.</td>\n",
       "      <td>A little baby with dirty fingers and smudges on her face points to her blue eye.</td>\n",
       "      <td>1</td>\n",
       "      <td>0.202849</td>\n",
       "      <td>0.778191</td>\n",
       "      <td>0.018960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3164</th>\n",
       "      <td>23223</td>\n",
       "      <td>The child plays in the mud...</td>\n",
       "      <td>A kid plays in the mud.</td>\n",
       "      <td>A little baby with dirty fingers and smudges on her face points to her blue eye.</td>\n",
       "      <td>1</td>\n",
       "      <td>0.173756</td>\n",
       "      <td>0.514919</td>\n",
       "      <td>0.311325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3165</th>\n",
       "      <td>23223</td>\n",
       "      <td>The child plays in the mud...</td>\n",
       "      <td>The child plays in the mud.</td>\n",
       "      <td>A little baby with dirty fingers and smudges on her face points to her blue eye.</td>\n",
       "      <td>1</td>\n",
       "      <td>0.077979</td>\n",
       "      <td>0.496839</td>\n",
       "      <td>0.425181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3166</th>\n",
       "      <td>23223</td>\n",
       "      <td>The child plays in the mud...</td>\n",
       "      <td>A child is playing in mud.</td>\n",
       "      <td>A little baby with dirty fingers and smudges on her face points to her blue eye.</td>\n",
       "      <td>1</td>\n",
       "      <td>0.134194</td>\n",
       "      <td>0.532714</td>\n",
       "      <td>0.333092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3167</th>\n",
       "      <td>23223</td>\n",
       "      <td>The child plays in the mud...</td>\n",
       "      <td>The child is wet.</td>\n",
       "      <td>A little baby with dirty fingers and smudges on her face points to her blue eye.</td>\n",
       "      <td>0</td>\n",
       "      <td>0.811961</td>\n",
       "      <td>0.181487</td>\n",
       "      <td>0.006552</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3168 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        idx                                   para  \\\n",
       "0     13505  A man and woman stand near the beach.   \n",
       "1     13505  A man and woman stand near the beach.   \n",
       "2     13505  A man and woman stand near the beach.   \n",
       "3     13505  A man and woman stand near the beach.   \n",
       "4     13505  A man and woman stand near the beach.   \n",
       "...     ...                                    ...   \n",
       "3163  23223          The child plays in the mud...   \n",
       "3164  23223          The child plays in the mud...   \n",
       "3165  23223          The child plays in the mud...   \n",
       "3166  23223          The child plays in the mud...   \n",
       "3167  23223          The child plays in the mud...   \n",
       "\n",
       "                                 perms  \\\n",
       "0     Two people stand near the beach.   \n",
       "1       Two people are near the beach.   \n",
       "2         A man and woman are outside.   \n",
       "3        A man and woman are standing.   \n",
       "4       A man and a woman are outside.   \n",
       "...                                ...   \n",
       "3163             The child is outside.   \n",
       "3164           A kid plays in the mud.   \n",
       "3165       The child plays in the mud.   \n",
       "3166        A child is playing in mud.   \n",
       "3167                 The child is wet.   \n",
       "\n",
       "                                                                               premise  \\\n",
       "0          A carefully balanced male stands on one foot near a clean ocean beach area.   \n",
       "1          A carefully balanced male stands on one foot near a clean ocean beach area.   \n",
       "2          A carefully balanced male stands on one foot near a clean ocean beach area.   \n",
       "3          A carefully balanced male stands on one foot near a clean ocean beach area.   \n",
       "4          A carefully balanced male stands on one foot near a clean ocean beach area.   \n",
       "...                                                                                ...   \n",
       "3163  A little baby with dirty fingers and smudges on her face points to her blue eye.   \n",
       "3164  A little baby with dirty fingers and smudges on her face points to her blue eye.   \n",
       "3165  A little baby with dirty fingers and smudges on her face points to her blue eye.   \n",
       "3166  A little baby with dirty fingers and smudges on her face points to her blue eye.   \n",
       "3167  A little baby with dirty fingers and smudges on her face points to her blue eye.   \n",
       "\n",
       "      vm_label  vm_prob0  vm_prob1  vm_prob2  \n",
       "0            0  0.979817  0.017380  0.002803  \n",
       "1            0  0.977980  0.020046  0.001974  \n",
       "2            0  0.908671  0.068383  0.022946  \n",
       "3            2  0.372555  0.210900  0.416545  \n",
       "4            0  0.906121  0.070064  0.023815  \n",
       "...        ...       ...       ...       ...  \n",
       "3163         1  0.202849  0.778191  0.018960  \n",
       "3164         1  0.173756  0.514919  0.311325  \n",
       "3165         1  0.077979  0.496839  0.425181  \n",
       "3166         1  0.134194  0.532714  0.333092  \n",
       "3167         0  0.811961  0.181487  0.006552  \n",
       "\n",
       "[3168 rows x 8 columns]"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "advlbl_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Archive "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # calculates performance of victim model on a dataloader\n",
    "\n",
    "# dl = valid_dl\n",
    "# metric = load_metric('accuracy')\n",
    "# for i, data in enumerate(dl): \n",
    "#     if i % 10 == 0 : print(i, \"out of\", len(dl)) \n",
    "#     labels,premise,hypothesis = data['label'].to(device),data[\"premise\"],data[\"hypothesis\"]\n",
    "#     inputs = vm_tokenizer(premise,hypothesis, padding=True,truncation=True, return_tensors=\"pt\")\n",
    "#     inputs.to(device)\n",
    "#     outputs = vm_model(**inputs, labels=labels)\n",
    "#     probs = outputs.logits.softmax(1)\n",
    "#     preds = probs.argmax(1)\n",
    "#     metric.add_batch(predictions=preds, references=labels)\n",
    "\n",
    "# metric.compute()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Score semantic similarity with cross encoders\n",
    "\n",
    "# from sentence_transformers.cross_encoder import CrossEncoder\n",
    "# cross_encoder= CrossEncoder('cross-encoder/quora-distilroberta-base')\n",
    "# i =11\n",
    "# data = valid_small[i]\n",
    "# orig, para = data['hypothesis'], data['hypothesis_paraphrases']\n",
    "# orig_rep = [orig for i in range(len(para))]\n",
    "# pairs = list(zip(orig_rep,para))\n",
    "# scores = cross_encoder.predict(pairs)\n",
    "# results_df = pd.DataFrame({'pairs':pairs, 'para': para,'score': cos_sim})\n",
    "# print(orig)\n",
    "# results_df.sort_values('score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # with sentence transformers\n",
    "\n",
    "# valid_small_dl = DataLoader(valid_small, batch_size=4, shuffle=False, \n",
    "#                      num_workers=n_wkrs, pin_memory=True)\n",
    "# sim_score_l = []\n",
    "# for i, data in enumerate(valid_small_dl): \n",
    "#     pass\n",
    "#     orig, para = data['hypothesis'], data['hypothesis_paraphrases']\n",
    "#     orig_emb,para_emb  = embedding_model.encode(orig),embedding_model.encode(para)\n",
    "# #     cos_sim = util.cos_sim(orig_emb,para_emb)[0]\n",
    "# #     results_df = pd.DataFrame({'para': para,'score': cos_sim})\n",
    "# #     print(orig)\n",
    "# #     results_df.sort_values('score', ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
