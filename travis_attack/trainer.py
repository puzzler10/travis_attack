# AUTOGENERATED! DO NOT EDIT! File to edit: 20_trainer.ipynb (unless otherwise specified).

__all__ = ['get_vm_probs', 'get_optimizer']

# Cell
import torch, wandb, gc
from tqdm.auto import tqdm
from .utils import timecode, show_gpu
from .models import save_model
from .charts import plot_grad_flow, plot_wandb_charts

# Cell
def get_vm_probs(text, cfg, vm_tokenizer, vm_model, return_predclass=False):
    """Used in data cleaning and by the reward_fn to get vm_score"""
    if vm_model.training: vm_model.eval()
    with torch.no_grad():
        tkns = vm_tokenizer(text, truncation=True, padding=True, pad_to_multiple_of=cfg.orig_padding_multiple,
                            return_tensors="pt").to(cfg.device)
        logits = vm_model(**tkns).logits
        probs = torch.softmax(logits,1)
        if return_predclass:    return probs, torch.argmax(probs,1)
        else:                   return probs

# Cell
def get_optimizer(cfg, pp_model):  return torch.optim.AdamW(pp_model.parameters(), lr=cfg.lr)