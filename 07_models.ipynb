{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext line_profiler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import numpy as np\n",
    "from transformers import (AutoModelForSeq2SeqLM, AutoModelForSequenceClassification, AutoTokenizer)\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from types import MethodType\n",
    "from undecorated import undecorated\n",
    "from travis_attack.config import Config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide \n",
    "from IPython.core.debugger import set_trace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _prepare_pp_tokenizer_and_model(cfg): \n",
    "    \"\"\"As well as preparing the pp model and tokenizer this function also adds a new method `generate_with_grad` to \n",
    "    the pp model so that we can backprop when generating.\"\"\"\n",
    "    pp_tokenizer = AutoTokenizer.from_pretrained(cfg.pp_name)\n",
    "    # takes about 3GB memory space up on the GPU\n",
    "    # change the `local_files_only` argument if changing the model name \n",
    "    pp_model = AutoModelForSeq2SeqLM.from_pretrained(cfg.pp_name, local_files_only=True)\n",
    "    pp_model.train()\n",
    "    pp_model_freeze_layers(cfg, pp_model)  # dictated by cfg.unfreeze_last_n_layers; set to \"all\" to do no freezing\n",
    "    generate_with_grad = undecorated(pp_model.generate)      # remove the @no_grad decorator from generate\n",
    "    pp_model.generate_with_grad = MethodType(generate_with_grad, pp_model) \n",
    "    return pp_tokenizer, pp_model \n",
    "    \n",
    "def _prepare_vm_tokenizer_and_model(cfg): \n",
    "    vm_tokenizer = AutoTokenizer.from_pretrained(cfg.vm_name)\n",
    "    #TODO: do I need the .to(device) for the vm model when using accelerate?\n",
    "    # change the `local_files_only` argument if changing the model name \n",
    "    vm_model = AutoModelForSequenceClassification.from_pretrained(cfg.vm_name, local_files_only=True).to(cfg.device)\n",
    "    vm_model.eval()\n",
    "    return vm_tokenizer, vm_model \n",
    "    \n",
    "def _pad_model_token_embeddings(cfg, pp_model, vm_model, sts_model): \n",
    "    \"\"\"Resize first/embedding layer of all models to be a multiple of cfg.embedding_padding_multiple. \n",
    "    Good for tensor core efficiency when using fp16.\n",
    "    Makes changes to models in-place.\"\"\"\n",
    "    def pad_token_embeddings_to_multiple_of_n(model, n):\n",
    "        def get_new_vocab_size(model): return int((np.floor(model.config.vocab_size / n) + 1) * n)\n",
    "        model.resize_token_embeddings(get_new_vocab_size(model))\n",
    "    pad_token_embeddings_to_multiple_of_n(pp_model, cfg.embedding_padding_multiple)\n",
    "    pad_token_embeddings_to_multiple_of_n(vm_model, cfg.embedding_padding_multiple)\n",
    "    # sts_model is from SentenceTransformers so needs a bit of unwrapping to access the base huggingface model \n",
    "    pad_token_embeddings_to_multiple_of_n(sts_model._first_module().auto_model, cfg.embedding_padding_multiple) \n",
    "\n",
    "def _update_config(cfg, vm_model, pp_model): \n",
    "    cfg.vm_num_labels = vm_model.num_labels\n",
    "    cfg.vocab_size = pp_model.get_input_embeddings().num_embeddings   # unlike pp_tokenizer.vocab_size this includes the padding \n",
    "    return cfg\n",
    "\n",
    "def prepare_models(cfg): \n",
    "    \"\"\"Load tokenizers and models for vm, pp, sts. \n",
    "    Pad the first embedding layer if specified in the config.  \n",
    "    Do layer freezing if specified (TODO). \n",
    "    Update config with some model-specific variables. \n",
    "    \"\"\"\n",
    "    vm_tokenizer, vm_model = _prepare_vm_tokenizer_and_model(cfg)\n",
    "    pp_tokenizer, pp_model = _prepare_pp_tokenizer_and_model(cfg)\n",
    "    sts_model = SentenceTransformer(cfg.sts_name)\n",
    "    if cfg.pad_token_embeddings:  _pad_model_token_embeddings(cfg, pp_model, vm_model, sts_model)\n",
    "    cfg = _update_config(cfg, vm_model, pp_model)\n",
    "    return vm_tokenizer, vm_model, pp_tokenizer, pp_model, sts_model, cfg\n",
    "\n",
    "def _get_layers_to_unfreeze(cfg): \n",
    "    \"\"\"Return a list that determines which layers should be kept unfrozen\"\"\"\n",
    "    if cfg.pp_name   == \"tuner007/pegasus_paraphrase\":               \n",
    "        unfreeze_layer_list,last_layer_num = ['decoder.layer_norm'],          15\n",
    "    elif cfg.pp_name == \"tdopierre/ProtAugment-ParaphraseGenerator\": \n",
    "        unfreeze_layer_list,last_layer_num = ['decoder.layernorm_embedding'],  5\n",
    "    elif cfg.pp_name == \"eugenesiow/bart-paraphrase\":                \n",
    "        unfreeze_layer_list,last_layer_num = ['decoder.layernorm_embedding'], 11\n",
    "    for i in range(last_layer_num, last_layer_num-cfg.unfreeze_last_n_layers, -1): \n",
    "        unfreeze_layer_list.append(f'decoder.layers.{i}')\n",
    "    # self.lm_head is tied (the same parameter as) to self.encoder.embed_tokens and self.decoder.embed_tokens.\n",
    "    # and this is given by shared.weight\n",
    "    # From here: https://github.com/huggingface/transformers/issues/10479#issuecomment-788964822\n",
    "    unfreeze_layer_list.append('shared.weight')\n",
    "    return unfreeze_layer_list\n",
    "\n",
    "def pp_model_freeze_layers(cfg, pp_model): \n",
    "    \"\"\"Freeze all layers of pp_model except the last few decoder layers (determined by cfg.unfreeze_last_n_layers), \n",
    "    the final layer_norm layer, and the linear head (which is tied to the input embeddings). \"\"\"\n",
    "    if cfg.unfreeze_last_n_layers == \"all\":\n",
    "        for i, (name, param) in enumerate(pp_model.base_model.named_parameters()): param.requires_grad = True\n",
    "    else: \n",
    "        unfreeze_layer_list = _get_layers_to_unfreeze(cfg)\n",
    "        for i, (name, param) in enumerate(pp_model.base_model.named_parameters()): \n",
    "            if np.any([o in name for o in unfreeze_layer_list]):   param.requires_grad = True\n",
    "            else:                                                  param.requires_grad = False\n",
    "    return pp_model\n",
    "\n",
    "\n",
    "def save_pp_model(pp_model, optimizer, path_run, epoch): \n",
    "    \"\"\"Save training state (for both pp_model and optimiser) as a checkpoint at a given epoch. \"\"\"\n",
    "    path = f\"{path_run}model_{epoch}\"\n",
    "    torch.save({\n",
    "                'epoch': epoch,\n",
    "                'pp_model_state_dict': pp_model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                }, path)\n",
    "    \n",
    "def resume_pp_model(pp_model, optimizer, path): \n",
    "    \"\"\"Replace the training state with a saved checkpoint.. Reinitialises both pp_model and optimiser state. \"\"\"\n",
    "    state = torch.load(path)\n",
    "    pp_model.load_state_dict(state['pp_model_state_dict'])\n",
    "    optimizer.load_state_dict(state['optimizer_state_dict'])\n",
    "    return pp_model, optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main function is `prepare_models(cfg)`. This gives all the models and tokenizers needed for the other sections and also updates + returns the config. It takes care of embedding layer resizing and layer freezing too. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = Config()\n",
    "vm_tokenizer, vm_model, pp_tokenizer, pp_model, sts_model, cfg = prepare_models(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and saving model checkpoints  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If needed you can save and reload models from a checkpoint with `save_pp_model()` and `resume_pp_model()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer freezing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do layer freezing on the pp model use the `pp_model_freeze_layers()` function. This will freeze all layers except:  \n",
    "\n",
    "* the last `cfg.unfreeze_last_n_layers` layers of the decoder.\n",
    "* the final layernorm layer \n",
    "* the LM head (which is tied to the input embeddings) which is given by `shared.weight`. \n",
    "\n",
    "At the moment I'm not certain on if I should be unfreezing the linear head and the layernorm layers or leaving them frozen. I am erring on the side of unfreezing and making them trainable).  \n",
    "\n",
    "To freeze all layers except the last few, set the number of layers to unfreeze by assigning cfg.unfreeze_last_n_layers to an int. To unfreeze the whole model, set `cfg.unfreeze_last_n_layers = \"all\"` \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test it out. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of decoder layers to unfreeze: 3\n"
     ]
    }
   ],
   "source": [
    "cfg = Config()\n",
    "cfg.pp_name  = \"tuner007/pegasus_paraphrase\"\n",
    "cfg.unfreeze_last_n_layers = 3\n",
    "_, pp_model = _prepare_pp_tokenizer_and_model(cfg)\n",
    "pp_model = pp_model_freeze_layers(cfg, pp_model)\n",
    "print(\"Number of decoder layers to unfreeze:\", cfg.unfreeze_last_n_layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check which layers are frozen and unfrozen: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 shared.weight True\n",
      "1 encoder.embed_positions.weight False\n",
      "2 encoder.layers.0.self_attn.k_proj.weight False\n",
      "3 encoder.layers.0.self_attn.k_proj.bias False\n",
      "4 encoder.layers.0.self_attn.v_proj.weight False\n",
      "5 encoder.layers.0.self_attn.v_proj.bias False\n",
      "6 encoder.layers.0.self_attn.q_proj.weight False\n",
      "7 encoder.layers.0.self_attn.q_proj.bias False\n",
      "8 encoder.layers.0.self_attn.out_proj.weight False\n",
      "9 encoder.layers.0.self_attn.out_proj.bias False\n",
      "10 encoder.layers.0.self_attn_layer_norm.weight False\n",
      "11 encoder.layers.0.self_attn_layer_norm.bias False\n",
      "12 encoder.layers.0.fc1.weight False\n",
      "13 encoder.layers.0.fc1.bias False\n",
      "14 encoder.layers.0.fc2.weight False\n",
      "15 encoder.layers.0.fc2.bias False\n",
      "16 encoder.layers.0.final_layer_norm.weight False\n",
      "17 encoder.layers.0.final_layer_norm.bias False\n",
      "18 encoder.layers.1.self_attn.k_proj.weight False\n",
      "19 encoder.layers.1.self_attn.k_proj.bias False\n",
      "20 encoder.layers.1.self_attn.v_proj.weight False\n",
      "21 encoder.layers.1.self_attn.v_proj.bias False\n",
      "22 encoder.layers.1.self_attn.q_proj.weight False\n",
      "23 encoder.layers.1.self_attn.q_proj.bias False\n",
      "24 encoder.layers.1.self_attn.out_proj.weight False\n",
      "25 encoder.layers.1.self_attn.out_proj.bias False\n",
      "26 encoder.layers.1.self_attn_layer_norm.weight False\n",
      "27 encoder.layers.1.self_attn_layer_norm.bias False\n",
      "28 encoder.layers.1.fc1.weight False\n",
      "29 encoder.layers.1.fc1.bias False\n",
      "30 encoder.layers.1.fc2.weight False\n",
      "31 encoder.layers.1.fc2.bias False\n",
      "32 encoder.layers.1.final_layer_norm.weight False\n",
      "33 encoder.layers.1.final_layer_norm.bias False\n",
      "34 encoder.layers.2.self_attn.k_proj.weight False\n",
      "35 encoder.layers.2.self_attn.k_proj.bias False\n",
      "36 encoder.layers.2.self_attn.v_proj.weight False\n",
      "37 encoder.layers.2.self_attn.v_proj.bias False\n",
      "38 encoder.layers.2.self_attn.q_proj.weight False\n",
      "39 encoder.layers.2.self_attn.q_proj.bias False\n",
      "40 encoder.layers.2.self_attn.out_proj.weight False\n",
      "41 encoder.layers.2.self_attn.out_proj.bias False\n",
      "42 encoder.layers.2.self_attn_layer_norm.weight False\n",
      "43 encoder.layers.2.self_attn_layer_norm.bias False\n",
      "44 encoder.layers.2.fc1.weight False\n",
      "45 encoder.layers.2.fc1.bias False\n",
      "46 encoder.layers.2.fc2.weight False\n",
      "47 encoder.layers.2.fc2.bias False\n",
      "48 encoder.layers.2.final_layer_norm.weight False\n",
      "49 encoder.layers.2.final_layer_norm.bias False\n",
      "50 encoder.layers.3.self_attn.k_proj.weight False\n",
      "51 encoder.layers.3.self_attn.k_proj.bias False\n",
      "52 encoder.layers.3.self_attn.v_proj.weight False\n",
      "53 encoder.layers.3.self_attn.v_proj.bias False\n",
      "54 encoder.layers.3.self_attn.q_proj.weight False\n",
      "55 encoder.layers.3.self_attn.q_proj.bias False\n",
      "56 encoder.layers.3.self_attn.out_proj.weight False\n",
      "57 encoder.layers.3.self_attn.out_proj.bias False\n",
      "58 encoder.layers.3.self_attn_layer_norm.weight False\n",
      "59 encoder.layers.3.self_attn_layer_norm.bias False\n",
      "60 encoder.layers.3.fc1.weight False\n",
      "61 encoder.layers.3.fc1.bias False\n",
      "62 encoder.layers.3.fc2.weight False\n",
      "63 encoder.layers.3.fc2.bias False\n",
      "64 encoder.layers.3.final_layer_norm.weight False\n",
      "65 encoder.layers.3.final_layer_norm.bias False\n",
      "66 encoder.layers.4.self_attn.k_proj.weight False\n",
      "67 encoder.layers.4.self_attn.k_proj.bias False\n",
      "68 encoder.layers.4.self_attn.v_proj.weight False\n",
      "69 encoder.layers.4.self_attn.v_proj.bias False\n",
      "70 encoder.layers.4.self_attn.q_proj.weight False\n",
      "71 encoder.layers.4.self_attn.q_proj.bias False\n",
      "72 encoder.layers.4.self_attn.out_proj.weight False\n",
      "73 encoder.layers.4.self_attn.out_proj.bias False\n",
      "74 encoder.layers.4.self_attn_layer_norm.weight False\n",
      "75 encoder.layers.4.self_attn_layer_norm.bias False\n",
      "76 encoder.layers.4.fc1.weight False\n",
      "77 encoder.layers.4.fc1.bias False\n",
      "78 encoder.layers.4.fc2.weight False\n",
      "79 encoder.layers.4.fc2.bias False\n",
      "80 encoder.layers.4.final_layer_norm.weight False\n",
      "81 encoder.layers.4.final_layer_norm.bias False\n",
      "82 encoder.layers.5.self_attn.k_proj.weight False\n",
      "83 encoder.layers.5.self_attn.k_proj.bias False\n",
      "84 encoder.layers.5.self_attn.v_proj.weight False\n",
      "85 encoder.layers.5.self_attn.v_proj.bias False\n",
      "86 encoder.layers.5.self_attn.q_proj.weight False\n",
      "87 encoder.layers.5.self_attn.q_proj.bias False\n",
      "88 encoder.layers.5.self_attn.out_proj.weight False\n",
      "89 encoder.layers.5.self_attn.out_proj.bias False\n",
      "90 encoder.layers.5.self_attn_layer_norm.weight False\n",
      "91 encoder.layers.5.self_attn_layer_norm.bias False\n",
      "92 encoder.layers.5.fc1.weight False\n",
      "93 encoder.layers.5.fc1.bias False\n",
      "94 encoder.layers.5.fc2.weight False\n",
      "95 encoder.layers.5.fc2.bias False\n",
      "96 encoder.layers.5.final_layer_norm.weight False\n",
      "97 encoder.layers.5.final_layer_norm.bias False\n",
      "98 encoder.layers.6.self_attn.k_proj.weight False\n",
      "99 encoder.layers.6.self_attn.k_proj.bias False\n",
      "100 encoder.layers.6.self_attn.v_proj.weight False\n",
      "101 encoder.layers.6.self_attn.v_proj.bias False\n",
      "102 encoder.layers.6.self_attn.q_proj.weight False\n",
      "103 encoder.layers.6.self_attn.q_proj.bias False\n",
      "104 encoder.layers.6.self_attn.out_proj.weight False\n",
      "105 encoder.layers.6.self_attn.out_proj.bias False\n",
      "106 encoder.layers.6.self_attn_layer_norm.weight False\n",
      "107 encoder.layers.6.self_attn_layer_norm.bias False\n",
      "108 encoder.layers.6.fc1.weight False\n",
      "109 encoder.layers.6.fc1.bias False\n",
      "110 encoder.layers.6.fc2.weight False\n",
      "111 encoder.layers.6.fc2.bias False\n",
      "112 encoder.layers.6.final_layer_norm.weight False\n",
      "113 encoder.layers.6.final_layer_norm.bias False\n",
      "114 encoder.layers.7.self_attn.k_proj.weight False\n",
      "115 encoder.layers.7.self_attn.k_proj.bias False\n",
      "116 encoder.layers.7.self_attn.v_proj.weight False\n",
      "117 encoder.layers.7.self_attn.v_proj.bias False\n",
      "118 encoder.layers.7.self_attn.q_proj.weight False\n",
      "119 encoder.layers.7.self_attn.q_proj.bias False\n",
      "120 encoder.layers.7.self_attn.out_proj.weight False\n",
      "121 encoder.layers.7.self_attn.out_proj.bias False\n",
      "122 encoder.layers.7.self_attn_layer_norm.weight False\n",
      "123 encoder.layers.7.self_attn_layer_norm.bias False\n",
      "124 encoder.layers.7.fc1.weight False\n",
      "125 encoder.layers.7.fc1.bias False\n",
      "126 encoder.layers.7.fc2.weight False\n",
      "127 encoder.layers.7.fc2.bias False\n",
      "128 encoder.layers.7.final_layer_norm.weight False\n",
      "129 encoder.layers.7.final_layer_norm.bias False\n",
      "130 encoder.layers.8.self_attn.k_proj.weight False\n",
      "131 encoder.layers.8.self_attn.k_proj.bias False\n",
      "132 encoder.layers.8.self_attn.v_proj.weight False\n",
      "133 encoder.layers.8.self_attn.v_proj.bias False\n",
      "134 encoder.layers.8.self_attn.q_proj.weight False\n",
      "135 encoder.layers.8.self_attn.q_proj.bias False\n",
      "136 encoder.layers.8.self_attn.out_proj.weight False\n",
      "137 encoder.layers.8.self_attn.out_proj.bias False\n",
      "138 encoder.layers.8.self_attn_layer_norm.weight False\n",
      "139 encoder.layers.8.self_attn_layer_norm.bias False\n",
      "140 encoder.layers.8.fc1.weight False\n",
      "141 encoder.layers.8.fc1.bias False\n",
      "142 encoder.layers.8.fc2.weight False\n",
      "143 encoder.layers.8.fc2.bias False\n",
      "144 encoder.layers.8.final_layer_norm.weight False\n",
      "145 encoder.layers.8.final_layer_norm.bias False\n",
      "146 encoder.layers.9.self_attn.k_proj.weight False\n",
      "147 encoder.layers.9.self_attn.k_proj.bias False\n",
      "148 encoder.layers.9.self_attn.v_proj.weight False\n",
      "149 encoder.layers.9.self_attn.v_proj.bias False\n",
      "150 encoder.layers.9.self_attn.q_proj.weight False\n",
      "151 encoder.layers.9.self_attn.q_proj.bias False\n",
      "152 encoder.layers.9.self_attn.out_proj.weight False\n",
      "153 encoder.layers.9.self_attn.out_proj.bias False\n",
      "154 encoder.layers.9.self_attn_layer_norm.weight False\n",
      "155 encoder.layers.9.self_attn_layer_norm.bias False\n",
      "156 encoder.layers.9.fc1.weight False\n",
      "157 encoder.layers.9.fc1.bias False\n",
      "158 encoder.layers.9.fc2.weight False\n",
      "159 encoder.layers.9.fc2.bias False\n",
      "160 encoder.layers.9.final_layer_norm.weight False\n",
      "161 encoder.layers.9.final_layer_norm.bias False\n",
      "162 encoder.layers.10.self_attn.k_proj.weight False\n",
      "163 encoder.layers.10.self_attn.k_proj.bias False\n",
      "164 encoder.layers.10.self_attn.v_proj.weight False\n",
      "165 encoder.layers.10.self_attn.v_proj.bias False\n",
      "166 encoder.layers.10.self_attn.q_proj.weight False\n",
      "167 encoder.layers.10.self_attn.q_proj.bias False\n",
      "168 encoder.layers.10.self_attn.out_proj.weight False\n",
      "169 encoder.layers.10.self_attn.out_proj.bias False\n",
      "170 encoder.layers.10.self_attn_layer_norm.weight False\n",
      "171 encoder.layers.10.self_attn_layer_norm.bias False\n",
      "172 encoder.layers.10.fc1.weight False\n",
      "173 encoder.layers.10.fc1.bias False\n",
      "174 encoder.layers.10.fc2.weight False\n",
      "175 encoder.layers.10.fc2.bias False\n",
      "176 encoder.layers.10.final_layer_norm.weight False\n",
      "177 encoder.layers.10.final_layer_norm.bias False\n",
      "178 encoder.layers.11.self_attn.k_proj.weight False\n",
      "179 encoder.layers.11.self_attn.k_proj.bias False\n",
      "180 encoder.layers.11.self_attn.v_proj.weight False\n",
      "181 encoder.layers.11.self_attn.v_proj.bias False\n",
      "182 encoder.layers.11.self_attn.q_proj.weight False\n",
      "183 encoder.layers.11.self_attn.q_proj.bias False\n",
      "184 encoder.layers.11.self_attn.out_proj.weight False\n",
      "185 encoder.layers.11.self_attn.out_proj.bias False\n",
      "186 encoder.layers.11.self_attn_layer_norm.weight False\n",
      "187 encoder.layers.11.self_attn_layer_norm.bias False\n",
      "188 encoder.layers.11.fc1.weight False\n",
      "189 encoder.layers.11.fc1.bias False\n",
      "190 encoder.layers.11.fc2.weight False\n",
      "191 encoder.layers.11.fc2.bias False\n",
      "192 encoder.layers.11.final_layer_norm.weight False\n",
      "193 encoder.layers.11.final_layer_norm.bias False\n",
      "194 encoder.layers.12.self_attn.k_proj.weight False\n",
      "195 encoder.layers.12.self_attn.k_proj.bias False\n",
      "196 encoder.layers.12.self_attn.v_proj.weight False\n",
      "197 encoder.layers.12.self_attn.v_proj.bias False\n",
      "198 encoder.layers.12.self_attn.q_proj.weight False\n",
      "199 encoder.layers.12.self_attn.q_proj.bias False\n",
      "200 encoder.layers.12.self_attn.out_proj.weight False\n",
      "201 encoder.layers.12.self_attn.out_proj.bias False\n",
      "202 encoder.layers.12.self_attn_layer_norm.weight False\n",
      "203 encoder.layers.12.self_attn_layer_norm.bias False\n",
      "204 encoder.layers.12.fc1.weight False\n",
      "205 encoder.layers.12.fc1.bias False\n",
      "206 encoder.layers.12.fc2.weight False\n",
      "207 encoder.layers.12.fc2.bias False\n",
      "208 encoder.layers.12.final_layer_norm.weight False\n",
      "209 encoder.layers.12.final_layer_norm.bias False\n",
      "210 encoder.layers.13.self_attn.k_proj.weight False\n",
      "211 encoder.layers.13.self_attn.k_proj.bias False\n",
      "212 encoder.layers.13.self_attn.v_proj.weight False\n",
      "213 encoder.layers.13.self_attn.v_proj.bias False\n",
      "214 encoder.layers.13.self_attn.q_proj.weight False\n",
      "215 encoder.layers.13.self_attn.q_proj.bias False\n",
      "216 encoder.layers.13.self_attn.out_proj.weight False\n",
      "217 encoder.layers.13.self_attn.out_proj.bias False\n",
      "218 encoder.layers.13.self_attn_layer_norm.weight False\n",
      "219 encoder.layers.13.self_attn_layer_norm.bias False\n",
      "220 encoder.layers.13.fc1.weight False\n",
      "221 encoder.layers.13.fc1.bias False\n",
      "222 encoder.layers.13.fc2.weight False\n",
      "223 encoder.layers.13.fc2.bias False\n",
      "224 encoder.layers.13.final_layer_norm.weight False\n",
      "225 encoder.layers.13.final_layer_norm.bias False\n",
      "226 encoder.layers.14.self_attn.k_proj.weight False\n",
      "227 encoder.layers.14.self_attn.k_proj.bias False\n",
      "228 encoder.layers.14.self_attn.v_proj.weight False\n",
      "229 encoder.layers.14.self_attn.v_proj.bias False\n",
      "230 encoder.layers.14.self_attn.q_proj.weight False\n",
      "231 encoder.layers.14.self_attn.q_proj.bias False\n",
      "232 encoder.layers.14.self_attn.out_proj.weight False\n",
      "233 encoder.layers.14.self_attn.out_proj.bias False\n",
      "234 encoder.layers.14.self_attn_layer_norm.weight False\n",
      "235 encoder.layers.14.self_attn_layer_norm.bias False\n",
      "236 encoder.layers.14.fc1.weight False\n",
      "237 encoder.layers.14.fc1.bias False\n",
      "238 encoder.layers.14.fc2.weight False\n",
      "239 encoder.layers.14.fc2.bias False\n",
      "240 encoder.layers.14.final_layer_norm.weight False\n",
      "241 encoder.layers.14.final_layer_norm.bias False\n",
      "242 encoder.layers.15.self_attn.k_proj.weight False\n",
      "243 encoder.layers.15.self_attn.k_proj.bias False\n",
      "244 encoder.layers.15.self_attn.v_proj.weight False\n",
      "245 encoder.layers.15.self_attn.v_proj.bias False\n",
      "246 encoder.layers.15.self_attn.q_proj.weight False\n",
      "247 encoder.layers.15.self_attn.q_proj.bias False\n",
      "248 encoder.layers.15.self_attn.out_proj.weight False\n",
      "249 encoder.layers.15.self_attn.out_proj.bias False\n",
      "250 encoder.layers.15.self_attn_layer_norm.weight False\n",
      "251 encoder.layers.15.self_attn_layer_norm.bias False\n",
      "252 encoder.layers.15.fc1.weight False\n",
      "253 encoder.layers.15.fc1.bias False\n",
      "254 encoder.layers.15.fc2.weight False\n",
      "255 encoder.layers.15.fc2.bias False\n",
      "256 encoder.layers.15.final_layer_norm.weight False\n",
      "257 encoder.layers.15.final_layer_norm.bias False\n",
      "258 encoder.layer_norm.weight False\n",
      "259 encoder.layer_norm.bias False\n",
      "260 decoder.embed_positions.weight False\n",
      "261 decoder.layers.0.self_attn.k_proj.weight False\n",
      "262 decoder.layers.0.self_attn.k_proj.bias False\n",
      "263 decoder.layers.0.self_attn.v_proj.weight False\n",
      "264 decoder.layers.0.self_attn.v_proj.bias False\n",
      "265 decoder.layers.0.self_attn.q_proj.weight False\n",
      "266 decoder.layers.0.self_attn.q_proj.bias False\n",
      "267 decoder.layers.0.self_attn.out_proj.weight False\n",
      "268 decoder.layers.0.self_attn.out_proj.bias False\n",
      "269 decoder.layers.0.self_attn_layer_norm.weight False\n",
      "270 decoder.layers.0.self_attn_layer_norm.bias False\n",
      "271 decoder.layers.0.encoder_attn.k_proj.weight False\n",
      "272 decoder.layers.0.encoder_attn.k_proj.bias False\n",
      "273 decoder.layers.0.encoder_attn.v_proj.weight False\n",
      "274 decoder.layers.0.encoder_attn.v_proj.bias False\n",
      "275 decoder.layers.0.encoder_attn.q_proj.weight False\n",
      "276 decoder.layers.0.encoder_attn.q_proj.bias False\n",
      "277 decoder.layers.0.encoder_attn.out_proj.weight False\n",
      "278 decoder.layers.0.encoder_attn.out_proj.bias False\n",
      "279 decoder.layers.0.encoder_attn_layer_norm.weight False\n",
      "280 decoder.layers.0.encoder_attn_layer_norm.bias False\n",
      "281 decoder.layers.0.fc1.weight False\n",
      "282 decoder.layers.0.fc1.bias False\n",
      "283 decoder.layers.0.fc2.weight False\n",
      "284 decoder.layers.0.fc2.bias False\n",
      "285 decoder.layers.0.final_layer_norm.weight False\n",
      "286 decoder.layers.0.final_layer_norm.bias False\n",
      "287 decoder.layers.1.self_attn.k_proj.weight False\n",
      "288 decoder.layers.1.self_attn.k_proj.bias False\n",
      "289 decoder.layers.1.self_attn.v_proj.weight False\n",
      "290 decoder.layers.1.self_attn.v_proj.bias False\n",
      "291 decoder.layers.1.self_attn.q_proj.weight False\n",
      "292 decoder.layers.1.self_attn.q_proj.bias False\n",
      "293 decoder.layers.1.self_attn.out_proj.weight False\n",
      "294 decoder.layers.1.self_attn.out_proj.bias False\n",
      "295 decoder.layers.1.self_attn_layer_norm.weight False\n",
      "296 decoder.layers.1.self_attn_layer_norm.bias False\n",
      "297 decoder.layers.1.encoder_attn.k_proj.weight False\n",
      "298 decoder.layers.1.encoder_attn.k_proj.bias False\n",
      "299 decoder.layers.1.encoder_attn.v_proj.weight False\n",
      "300 decoder.layers.1.encoder_attn.v_proj.bias False\n",
      "301 decoder.layers.1.encoder_attn.q_proj.weight False\n",
      "302 decoder.layers.1.encoder_attn.q_proj.bias False\n",
      "303 decoder.layers.1.encoder_attn.out_proj.weight False\n",
      "304 decoder.layers.1.encoder_attn.out_proj.bias False\n",
      "305 decoder.layers.1.encoder_attn_layer_norm.weight False\n",
      "306 decoder.layers.1.encoder_attn_layer_norm.bias False\n",
      "307 decoder.layers.1.fc1.weight False\n",
      "308 decoder.layers.1.fc1.bias False\n",
      "309 decoder.layers.1.fc2.weight False\n",
      "310 decoder.layers.1.fc2.bias False\n",
      "311 decoder.layers.1.final_layer_norm.weight False\n",
      "312 decoder.layers.1.final_layer_norm.bias False\n",
      "313 decoder.layers.2.self_attn.k_proj.weight False\n",
      "314 decoder.layers.2.self_attn.k_proj.bias False\n",
      "315 decoder.layers.2.self_attn.v_proj.weight False\n",
      "316 decoder.layers.2.self_attn.v_proj.bias False\n",
      "317 decoder.layers.2.self_attn.q_proj.weight False\n",
      "318 decoder.layers.2.self_attn.q_proj.bias False\n",
      "319 decoder.layers.2.self_attn.out_proj.weight False\n",
      "320 decoder.layers.2.self_attn.out_proj.bias False\n",
      "321 decoder.layers.2.self_attn_layer_norm.weight False\n",
      "322 decoder.layers.2.self_attn_layer_norm.bias False\n",
      "323 decoder.layers.2.encoder_attn.k_proj.weight False\n",
      "324 decoder.layers.2.encoder_attn.k_proj.bias False\n",
      "325 decoder.layers.2.encoder_attn.v_proj.weight False\n",
      "326 decoder.layers.2.encoder_attn.v_proj.bias False\n",
      "327 decoder.layers.2.encoder_attn.q_proj.weight False\n",
      "328 decoder.layers.2.encoder_attn.q_proj.bias False\n",
      "329 decoder.layers.2.encoder_attn.out_proj.weight False\n",
      "330 decoder.layers.2.encoder_attn.out_proj.bias False\n",
      "331 decoder.layers.2.encoder_attn_layer_norm.weight False\n",
      "332 decoder.layers.2.encoder_attn_layer_norm.bias False\n",
      "333 decoder.layers.2.fc1.weight False\n",
      "334 decoder.layers.2.fc1.bias False\n",
      "335 decoder.layers.2.fc2.weight False\n",
      "336 decoder.layers.2.fc2.bias False\n",
      "337 decoder.layers.2.final_layer_norm.weight False\n",
      "338 decoder.layers.2.final_layer_norm.bias False\n",
      "339 decoder.layers.3.self_attn.k_proj.weight False\n",
      "340 decoder.layers.3.self_attn.k_proj.bias False\n",
      "341 decoder.layers.3.self_attn.v_proj.weight False\n",
      "342 decoder.layers.3.self_attn.v_proj.bias False\n",
      "343 decoder.layers.3.self_attn.q_proj.weight False\n",
      "344 decoder.layers.3.self_attn.q_proj.bias False\n",
      "345 decoder.layers.3.self_attn.out_proj.weight False\n",
      "346 decoder.layers.3.self_attn.out_proj.bias False\n",
      "347 decoder.layers.3.self_attn_layer_norm.weight False\n",
      "348 decoder.layers.3.self_attn_layer_norm.bias False\n",
      "349 decoder.layers.3.encoder_attn.k_proj.weight False\n",
      "350 decoder.layers.3.encoder_attn.k_proj.bias False\n",
      "351 decoder.layers.3.encoder_attn.v_proj.weight False\n",
      "352 decoder.layers.3.encoder_attn.v_proj.bias False\n",
      "353 decoder.layers.3.encoder_attn.q_proj.weight False\n",
      "354 decoder.layers.3.encoder_attn.q_proj.bias False\n",
      "355 decoder.layers.3.encoder_attn.out_proj.weight False\n",
      "356 decoder.layers.3.encoder_attn.out_proj.bias False\n",
      "357 decoder.layers.3.encoder_attn_layer_norm.weight False\n",
      "358 decoder.layers.3.encoder_attn_layer_norm.bias False\n",
      "359 decoder.layers.3.fc1.weight False\n",
      "360 decoder.layers.3.fc1.bias False\n",
      "361 decoder.layers.3.fc2.weight False\n",
      "362 decoder.layers.3.fc2.bias False\n",
      "363 decoder.layers.3.final_layer_norm.weight False\n",
      "364 decoder.layers.3.final_layer_norm.bias False\n",
      "365 decoder.layers.4.self_attn.k_proj.weight False\n",
      "366 decoder.layers.4.self_attn.k_proj.bias False\n",
      "367 decoder.layers.4.self_attn.v_proj.weight False\n",
      "368 decoder.layers.4.self_attn.v_proj.bias False\n",
      "369 decoder.layers.4.self_attn.q_proj.weight False\n",
      "370 decoder.layers.4.self_attn.q_proj.bias False\n",
      "371 decoder.layers.4.self_attn.out_proj.weight False\n",
      "372 decoder.layers.4.self_attn.out_proj.bias False\n",
      "373 decoder.layers.4.self_attn_layer_norm.weight False\n",
      "374 decoder.layers.4.self_attn_layer_norm.bias False\n",
      "375 decoder.layers.4.encoder_attn.k_proj.weight False\n",
      "376 decoder.layers.4.encoder_attn.k_proj.bias False\n",
      "377 decoder.layers.4.encoder_attn.v_proj.weight False\n",
      "378 decoder.layers.4.encoder_attn.v_proj.bias False\n",
      "379 decoder.layers.4.encoder_attn.q_proj.weight False\n",
      "380 decoder.layers.4.encoder_attn.q_proj.bias False\n",
      "381 decoder.layers.4.encoder_attn.out_proj.weight False\n",
      "382 decoder.layers.4.encoder_attn.out_proj.bias False\n",
      "383 decoder.layers.4.encoder_attn_layer_norm.weight False\n",
      "384 decoder.layers.4.encoder_attn_layer_norm.bias False\n",
      "385 decoder.layers.4.fc1.weight False\n",
      "386 decoder.layers.4.fc1.bias False\n",
      "387 decoder.layers.4.fc2.weight False\n",
      "388 decoder.layers.4.fc2.bias False\n",
      "389 decoder.layers.4.final_layer_norm.weight False\n",
      "390 decoder.layers.4.final_layer_norm.bias False\n",
      "391 decoder.layers.5.self_attn.k_proj.weight False\n",
      "392 decoder.layers.5.self_attn.k_proj.bias False\n",
      "393 decoder.layers.5.self_attn.v_proj.weight False\n",
      "394 decoder.layers.5.self_attn.v_proj.bias False\n",
      "395 decoder.layers.5.self_attn.q_proj.weight False\n",
      "396 decoder.layers.5.self_attn.q_proj.bias False\n",
      "397 decoder.layers.5.self_attn.out_proj.weight False\n",
      "398 decoder.layers.5.self_attn.out_proj.bias False\n",
      "399 decoder.layers.5.self_attn_layer_norm.weight False\n",
      "400 decoder.layers.5.self_attn_layer_norm.bias False\n",
      "401 decoder.layers.5.encoder_attn.k_proj.weight False\n",
      "402 decoder.layers.5.encoder_attn.k_proj.bias False\n",
      "403 decoder.layers.5.encoder_attn.v_proj.weight False\n",
      "404 decoder.layers.5.encoder_attn.v_proj.bias False\n",
      "405 decoder.layers.5.encoder_attn.q_proj.weight False\n",
      "406 decoder.layers.5.encoder_attn.q_proj.bias False\n",
      "407 decoder.layers.5.encoder_attn.out_proj.weight False\n",
      "408 decoder.layers.5.encoder_attn.out_proj.bias False\n",
      "409 decoder.layers.5.encoder_attn_layer_norm.weight False\n",
      "410 decoder.layers.5.encoder_attn_layer_norm.bias False\n",
      "411 decoder.layers.5.fc1.weight False\n",
      "412 decoder.layers.5.fc1.bias False\n",
      "413 decoder.layers.5.fc2.weight False\n",
      "414 decoder.layers.5.fc2.bias False\n",
      "415 decoder.layers.5.final_layer_norm.weight False\n",
      "416 decoder.layers.5.final_layer_norm.bias False\n",
      "417 decoder.layers.6.self_attn.k_proj.weight False\n",
      "418 decoder.layers.6.self_attn.k_proj.bias False\n",
      "419 decoder.layers.6.self_attn.v_proj.weight False\n",
      "420 decoder.layers.6.self_attn.v_proj.bias False\n",
      "421 decoder.layers.6.self_attn.q_proj.weight False\n",
      "422 decoder.layers.6.self_attn.q_proj.bias False\n",
      "423 decoder.layers.6.self_attn.out_proj.weight False\n",
      "424 decoder.layers.6.self_attn.out_proj.bias False\n",
      "425 decoder.layers.6.self_attn_layer_norm.weight False\n",
      "426 decoder.layers.6.self_attn_layer_norm.bias False\n",
      "427 decoder.layers.6.encoder_attn.k_proj.weight False\n",
      "428 decoder.layers.6.encoder_attn.k_proj.bias False\n",
      "429 decoder.layers.6.encoder_attn.v_proj.weight False\n",
      "430 decoder.layers.6.encoder_attn.v_proj.bias False\n",
      "431 decoder.layers.6.encoder_attn.q_proj.weight False\n",
      "432 decoder.layers.6.encoder_attn.q_proj.bias False\n",
      "433 decoder.layers.6.encoder_attn.out_proj.weight False\n",
      "434 decoder.layers.6.encoder_attn.out_proj.bias False\n",
      "435 decoder.layers.6.encoder_attn_layer_norm.weight False\n",
      "436 decoder.layers.6.encoder_attn_layer_norm.bias False\n",
      "437 decoder.layers.6.fc1.weight False\n",
      "438 decoder.layers.6.fc1.bias False\n",
      "439 decoder.layers.6.fc2.weight False\n",
      "440 decoder.layers.6.fc2.bias False\n",
      "441 decoder.layers.6.final_layer_norm.weight False\n",
      "442 decoder.layers.6.final_layer_norm.bias False\n",
      "443 decoder.layers.7.self_attn.k_proj.weight False\n",
      "444 decoder.layers.7.self_attn.k_proj.bias False\n",
      "445 decoder.layers.7.self_attn.v_proj.weight False\n",
      "446 decoder.layers.7.self_attn.v_proj.bias False\n",
      "447 decoder.layers.7.self_attn.q_proj.weight False\n",
      "448 decoder.layers.7.self_attn.q_proj.bias False\n",
      "449 decoder.layers.7.self_attn.out_proj.weight False\n",
      "450 decoder.layers.7.self_attn.out_proj.bias False\n",
      "451 decoder.layers.7.self_attn_layer_norm.weight False\n",
      "452 decoder.layers.7.self_attn_layer_norm.bias False\n",
      "453 decoder.layers.7.encoder_attn.k_proj.weight False\n",
      "454 decoder.layers.7.encoder_attn.k_proj.bias False\n",
      "455 decoder.layers.7.encoder_attn.v_proj.weight False\n",
      "456 decoder.layers.7.encoder_attn.v_proj.bias False\n",
      "457 decoder.layers.7.encoder_attn.q_proj.weight False\n",
      "458 decoder.layers.7.encoder_attn.q_proj.bias False\n",
      "459 decoder.layers.7.encoder_attn.out_proj.weight False\n",
      "460 decoder.layers.7.encoder_attn.out_proj.bias False\n",
      "461 decoder.layers.7.encoder_attn_layer_norm.weight False\n",
      "462 decoder.layers.7.encoder_attn_layer_norm.bias False\n",
      "463 decoder.layers.7.fc1.weight False\n",
      "464 decoder.layers.7.fc1.bias False\n",
      "465 decoder.layers.7.fc2.weight False\n",
      "466 decoder.layers.7.fc2.bias False\n",
      "467 decoder.layers.7.final_layer_norm.weight False\n",
      "468 decoder.layers.7.final_layer_norm.bias False\n",
      "469 decoder.layers.8.self_attn.k_proj.weight False\n",
      "470 decoder.layers.8.self_attn.k_proj.bias False\n",
      "471 decoder.layers.8.self_attn.v_proj.weight False\n",
      "472 decoder.layers.8.self_attn.v_proj.bias False\n",
      "473 decoder.layers.8.self_attn.q_proj.weight False\n",
      "474 decoder.layers.8.self_attn.q_proj.bias False\n",
      "475 decoder.layers.8.self_attn.out_proj.weight False\n",
      "476 decoder.layers.8.self_attn.out_proj.bias False\n",
      "477 decoder.layers.8.self_attn_layer_norm.weight False\n",
      "478 decoder.layers.8.self_attn_layer_norm.bias False\n",
      "479 decoder.layers.8.encoder_attn.k_proj.weight False\n",
      "480 decoder.layers.8.encoder_attn.k_proj.bias False\n",
      "481 decoder.layers.8.encoder_attn.v_proj.weight False\n",
      "482 decoder.layers.8.encoder_attn.v_proj.bias False\n",
      "483 decoder.layers.8.encoder_attn.q_proj.weight False\n",
      "484 decoder.layers.8.encoder_attn.q_proj.bias False\n",
      "485 decoder.layers.8.encoder_attn.out_proj.weight False\n",
      "486 decoder.layers.8.encoder_attn.out_proj.bias False\n",
      "487 decoder.layers.8.encoder_attn_layer_norm.weight False\n",
      "488 decoder.layers.8.encoder_attn_layer_norm.bias False\n",
      "489 decoder.layers.8.fc1.weight False\n",
      "490 decoder.layers.8.fc1.bias False\n",
      "491 decoder.layers.8.fc2.weight False\n",
      "492 decoder.layers.8.fc2.bias False\n",
      "493 decoder.layers.8.final_layer_norm.weight False\n",
      "494 decoder.layers.8.final_layer_norm.bias False\n",
      "495 decoder.layers.9.self_attn.k_proj.weight False\n",
      "496 decoder.layers.9.self_attn.k_proj.bias False\n",
      "497 decoder.layers.9.self_attn.v_proj.weight False\n",
      "498 decoder.layers.9.self_attn.v_proj.bias False\n",
      "499 decoder.layers.9.self_attn.q_proj.weight False\n",
      "500 decoder.layers.9.self_attn.q_proj.bias False\n",
      "501 decoder.layers.9.self_attn.out_proj.weight False\n",
      "502 decoder.layers.9.self_attn.out_proj.bias False\n",
      "503 decoder.layers.9.self_attn_layer_norm.weight False\n",
      "504 decoder.layers.9.self_attn_layer_norm.bias False\n",
      "505 decoder.layers.9.encoder_attn.k_proj.weight False\n",
      "506 decoder.layers.9.encoder_attn.k_proj.bias False\n",
      "507 decoder.layers.9.encoder_attn.v_proj.weight False\n",
      "508 decoder.layers.9.encoder_attn.v_proj.bias False\n",
      "509 decoder.layers.9.encoder_attn.q_proj.weight False\n",
      "510 decoder.layers.9.encoder_attn.q_proj.bias False\n",
      "511 decoder.layers.9.encoder_attn.out_proj.weight False\n",
      "512 decoder.layers.9.encoder_attn.out_proj.bias False\n",
      "513 decoder.layers.9.encoder_attn_layer_norm.weight False\n",
      "514 decoder.layers.9.encoder_attn_layer_norm.bias False\n",
      "515 decoder.layers.9.fc1.weight False\n",
      "516 decoder.layers.9.fc1.bias False\n",
      "517 decoder.layers.9.fc2.weight False\n",
      "518 decoder.layers.9.fc2.bias False\n",
      "519 decoder.layers.9.final_layer_norm.weight False\n",
      "520 decoder.layers.9.final_layer_norm.bias False\n",
      "521 decoder.layers.10.self_attn.k_proj.weight False\n",
      "522 decoder.layers.10.self_attn.k_proj.bias False\n",
      "523 decoder.layers.10.self_attn.v_proj.weight False\n",
      "524 decoder.layers.10.self_attn.v_proj.bias False\n",
      "525 decoder.layers.10.self_attn.q_proj.weight False\n",
      "526 decoder.layers.10.self_attn.q_proj.bias False\n",
      "527 decoder.layers.10.self_attn.out_proj.weight False\n",
      "528 decoder.layers.10.self_attn.out_proj.bias False\n",
      "529 decoder.layers.10.self_attn_layer_norm.weight False\n",
      "530 decoder.layers.10.self_attn_layer_norm.bias False\n",
      "531 decoder.layers.10.encoder_attn.k_proj.weight False\n",
      "532 decoder.layers.10.encoder_attn.k_proj.bias False\n",
      "533 decoder.layers.10.encoder_attn.v_proj.weight False\n",
      "534 decoder.layers.10.encoder_attn.v_proj.bias False\n",
      "535 decoder.layers.10.encoder_attn.q_proj.weight False\n",
      "536 decoder.layers.10.encoder_attn.q_proj.bias False\n",
      "537 decoder.layers.10.encoder_attn.out_proj.weight False\n",
      "538 decoder.layers.10.encoder_attn.out_proj.bias False\n",
      "539 decoder.layers.10.encoder_attn_layer_norm.weight False\n",
      "540 decoder.layers.10.encoder_attn_layer_norm.bias False\n",
      "541 decoder.layers.10.fc1.weight False\n",
      "542 decoder.layers.10.fc1.bias False\n",
      "543 decoder.layers.10.fc2.weight False\n",
      "544 decoder.layers.10.fc2.bias False\n",
      "545 decoder.layers.10.final_layer_norm.weight False\n",
      "546 decoder.layers.10.final_layer_norm.bias False\n",
      "547 decoder.layers.11.self_attn.k_proj.weight False\n",
      "548 decoder.layers.11.self_attn.k_proj.bias False\n",
      "549 decoder.layers.11.self_attn.v_proj.weight False\n",
      "550 decoder.layers.11.self_attn.v_proj.bias False\n",
      "551 decoder.layers.11.self_attn.q_proj.weight False\n",
      "552 decoder.layers.11.self_attn.q_proj.bias False\n",
      "553 decoder.layers.11.self_attn.out_proj.weight False\n",
      "554 decoder.layers.11.self_attn.out_proj.bias False\n",
      "555 decoder.layers.11.self_attn_layer_norm.weight False\n",
      "556 decoder.layers.11.self_attn_layer_norm.bias False\n",
      "557 decoder.layers.11.encoder_attn.k_proj.weight False\n",
      "558 decoder.layers.11.encoder_attn.k_proj.bias False\n",
      "559 decoder.layers.11.encoder_attn.v_proj.weight False\n",
      "560 decoder.layers.11.encoder_attn.v_proj.bias False\n",
      "561 decoder.layers.11.encoder_attn.q_proj.weight False\n",
      "562 decoder.layers.11.encoder_attn.q_proj.bias False\n",
      "563 decoder.layers.11.encoder_attn.out_proj.weight False\n",
      "564 decoder.layers.11.encoder_attn.out_proj.bias False\n",
      "565 decoder.layers.11.encoder_attn_layer_norm.weight False\n",
      "566 decoder.layers.11.encoder_attn_layer_norm.bias False\n",
      "567 decoder.layers.11.fc1.weight False\n",
      "568 decoder.layers.11.fc1.bias False\n",
      "569 decoder.layers.11.fc2.weight False\n",
      "570 decoder.layers.11.fc2.bias False\n",
      "571 decoder.layers.11.final_layer_norm.weight False\n",
      "572 decoder.layers.11.final_layer_norm.bias False\n",
      "573 decoder.layers.12.self_attn.k_proj.weight False\n",
      "574 decoder.layers.12.self_attn.k_proj.bias False\n",
      "575 decoder.layers.12.self_attn.v_proj.weight False\n",
      "576 decoder.layers.12.self_attn.v_proj.bias False\n",
      "577 decoder.layers.12.self_attn.q_proj.weight False\n",
      "578 decoder.layers.12.self_attn.q_proj.bias False\n",
      "579 decoder.layers.12.self_attn.out_proj.weight False\n",
      "580 decoder.layers.12.self_attn.out_proj.bias False\n",
      "581 decoder.layers.12.self_attn_layer_norm.weight False\n",
      "582 decoder.layers.12.self_attn_layer_norm.bias False\n",
      "583 decoder.layers.12.encoder_attn.k_proj.weight False\n",
      "584 decoder.layers.12.encoder_attn.k_proj.bias False\n",
      "585 decoder.layers.12.encoder_attn.v_proj.weight False\n",
      "586 decoder.layers.12.encoder_attn.v_proj.bias False\n",
      "587 decoder.layers.12.encoder_attn.q_proj.weight False\n",
      "588 decoder.layers.12.encoder_attn.q_proj.bias False\n",
      "589 decoder.layers.12.encoder_attn.out_proj.weight False\n",
      "590 decoder.layers.12.encoder_attn.out_proj.bias False\n",
      "591 decoder.layers.12.encoder_attn_layer_norm.weight False\n",
      "592 decoder.layers.12.encoder_attn_layer_norm.bias False\n",
      "593 decoder.layers.12.fc1.weight False\n",
      "594 decoder.layers.12.fc1.bias False\n",
      "595 decoder.layers.12.fc2.weight False\n",
      "596 decoder.layers.12.fc2.bias False\n",
      "597 decoder.layers.12.final_layer_norm.weight False\n",
      "598 decoder.layers.12.final_layer_norm.bias False\n",
      "599 decoder.layers.13.self_attn.k_proj.weight True\n",
      "600 decoder.layers.13.self_attn.k_proj.bias True\n",
      "601 decoder.layers.13.self_attn.v_proj.weight True\n",
      "602 decoder.layers.13.self_attn.v_proj.bias True\n",
      "603 decoder.layers.13.self_attn.q_proj.weight True\n",
      "604 decoder.layers.13.self_attn.q_proj.bias True\n",
      "605 decoder.layers.13.self_attn.out_proj.weight True\n",
      "606 decoder.layers.13.self_attn.out_proj.bias True\n",
      "607 decoder.layers.13.self_attn_layer_norm.weight True\n",
      "608 decoder.layers.13.self_attn_layer_norm.bias True\n",
      "609 decoder.layers.13.encoder_attn.k_proj.weight True\n",
      "610 decoder.layers.13.encoder_attn.k_proj.bias True\n",
      "611 decoder.layers.13.encoder_attn.v_proj.weight True\n",
      "612 decoder.layers.13.encoder_attn.v_proj.bias True\n",
      "613 decoder.layers.13.encoder_attn.q_proj.weight True\n",
      "614 decoder.layers.13.encoder_attn.q_proj.bias True\n",
      "615 decoder.layers.13.encoder_attn.out_proj.weight True\n",
      "616 decoder.layers.13.encoder_attn.out_proj.bias True\n",
      "617 decoder.layers.13.encoder_attn_layer_norm.weight True\n",
      "618 decoder.layers.13.encoder_attn_layer_norm.bias True\n",
      "619 decoder.layers.13.fc1.weight True\n",
      "620 decoder.layers.13.fc1.bias True\n",
      "621 decoder.layers.13.fc2.weight True\n",
      "622 decoder.layers.13.fc2.bias True\n",
      "623 decoder.layers.13.final_layer_norm.weight True\n",
      "624 decoder.layers.13.final_layer_norm.bias True\n",
      "625 decoder.layers.14.self_attn.k_proj.weight True\n",
      "626 decoder.layers.14.self_attn.k_proj.bias True\n",
      "627 decoder.layers.14.self_attn.v_proj.weight True\n",
      "628 decoder.layers.14.self_attn.v_proj.bias True\n",
      "629 decoder.layers.14.self_attn.q_proj.weight True\n",
      "630 decoder.layers.14.self_attn.q_proj.bias True\n",
      "631 decoder.layers.14.self_attn.out_proj.weight True\n",
      "632 decoder.layers.14.self_attn.out_proj.bias True\n",
      "633 decoder.layers.14.self_attn_layer_norm.weight True\n",
      "634 decoder.layers.14.self_attn_layer_norm.bias True\n",
      "635 decoder.layers.14.encoder_attn.k_proj.weight True\n",
      "636 decoder.layers.14.encoder_attn.k_proj.bias True\n",
      "637 decoder.layers.14.encoder_attn.v_proj.weight True\n",
      "638 decoder.layers.14.encoder_attn.v_proj.bias True\n",
      "639 decoder.layers.14.encoder_attn.q_proj.weight True\n",
      "640 decoder.layers.14.encoder_attn.q_proj.bias True\n",
      "641 decoder.layers.14.encoder_attn.out_proj.weight True\n",
      "642 decoder.layers.14.encoder_attn.out_proj.bias True\n",
      "643 decoder.layers.14.encoder_attn_layer_norm.weight True\n",
      "644 decoder.layers.14.encoder_attn_layer_norm.bias True\n",
      "645 decoder.layers.14.fc1.weight True\n",
      "646 decoder.layers.14.fc1.bias True\n",
      "647 decoder.layers.14.fc2.weight True\n",
      "648 decoder.layers.14.fc2.bias True\n",
      "649 decoder.layers.14.final_layer_norm.weight True\n",
      "650 decoder.layers.14.final_layer_norm.bias True\n",
      "651 decoder.layers.15.self_attn.k_proj.weight True\n",
      "652 decoder.layers.15.self_attn.k_proj.bias True\n",
      "653 decoder.layers.15.self_attn.v_proj.weight True\n",
      "654 decoder.layers.15.self_attn.v_proj.bias True\n",
      "655 decoder.layers.15.self_attn.q_proj.weight True\n",
      "656 decoder.layers.15.self_attn.q_proj.bias True\n",
      "657 decoder.layers.15.self_attn.out_proj.weight True\n",
      "658 decoder.layers.15.self_attn.out_proj.bias True\n",
      "659 decoder.layers.15.self_attn_layer_norm.weight True\n",
      "660 decoder.layers.15.self_attn_layer_norm.bias True\n",
      "661 decoder.layers.15.encoder_attn.k_proj.weight True\n",
      "662 decoder.layers.15.encoder_attn.k_proj.bias True\n",
      "663 decoder.layers.15.encoder_attn.v_proj.weight True\n",
      "664 decoder.layers.15.encoder_attn.v_proj.bias True\n",
      "665 decoder.layers.15.encoder_attn.q_proj.weight True\n",
      "666 decoder.layers.15.encoder_attn.q_proj.bias True\n",
      "667 decoder.layers.15.encoder_attn.out_proj.weight True\n",
      "668 decoder.layers.15.encoder_attn.out_proj.bias True\n",
      "669 decoder.layers.15.encoder_attn_layer_norm.weight True\n",
      "670 decoder.layers.15.encoder_attn_layer_norm.bias True\n",
      "671 decoder.layers.15.fc1.weight True\n",
      "672 decoder.layers.15.fc1.bias True\n",
      "673 decoder.layers.15.fc2.weight True\n",
      "674 decoder.layers.15.fc2.bias True\n",
      "675 decoder.layers.15.final_layer_norm.weight True\n",
      "676 decoder.layers.15.final_layer_norm.bias True\n",
      "677 decoder.layer_norm.weight True\n",
      "678 decoder.layer_norm.bias True\n"
     ]
    }
   ],
   "source": [
    "for i, (name, param) in enumerate(pp_model.base_model.named_parameters()): print(i, name, param.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can test too that we leave the LM head unfrozen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (name, param) in enumerate(pp_model.lm_head.named_parameters()):     assert param.requires_grad "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try with no layer freezing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.unfreeze_last_n_layers = \"all\"\n",
    "pp_model = pp_model_freeze_layers(cfg, pp_model)\n",
    "for i, (name, param) in enumerate(pp_model.base_model.named_parameters()): assert param.requires_grad\n",
    "for i, (name, param) in enumerate(pp_model.lm_head.named_parameters()):    assert param.requires_grad "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also test this works with the other models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of decoder layers to unfreeze: 2\n",
      "0 shared.weight True\n",
      "1 encoder.embed_positions.weight False\n",
      "2 encoder.layers.0.self_attn.k_proj.weight False\n",
      "3 encoder.layers.0.self_attn.k_proj.bias False\n",
      "4 encoder.layers.0.self_attn.v_proj.weight False\n",
      "5 encoder.layers.0.self_attn.v_proj.bias False\n",
      "6 encoder.layers.0.self_attn.q_proj.weight False\n",
      "7 encoder.layers.0.self_attn.q_proj.bias False\n",
      "8 encoder.layers.0.self_attn.out_proj.weight False\n",
      "9 encoder.layers.0.self_attn.out_proj.bias False\n",
      "10 encoder.layers.0.self_attn_layer_norm.weight False\n",
      "11 encoder.layers.0.self_attn_layer_norm.bias False\n",
      "12 encoder.layers.0.fc1.weight False\n",
      "13 encoder.layers.0.fc1.bias False\n",
      "14 encoder.layers.0.fc2.weight False\n",
      "15 encoder.layers.0.fc2.bias False\n",
      "16 encoder.layers.0.final_layer_norm.weight False\n",
      "17 encoder.layers.0.final_layer_norm.bias False\n",
      "18 encoder.layers.1.self_attn.k_proj.weight False\n",
      "19 encoder.layers.1.self_attn.k_proj.bias False\n",
      "20 encoder.layers.1.self_attn.v_proj.weight False\n",
      "21 encoder.layers.1.self_attn.v_proj.bias False\n",
      "22 encoder.layers.1.self_attn.q_proj.weight False\n",
      "23 encoder.layers.1.self_attn.q_proj.bias False\n",
      "24 encoder.layers.1.self_attn.out_proj.weight False\n",
      "25 encoder.layers.1.self_attn.out_proj.bias False\n",
      "26 encoder.layers.1.self_attn_layer_norm.weight False\n",
      "27 encoder.layers.1.self_attn_layer_norm.bias False\n",
      "28 encoder.layers.1.fc1.weight False\n",
      "29 encoder.layers.1.fc1.bias False\n",
      "30 encoder.layers.1.fc2.weight False\n",
      "31 encoder.layers.1.fc2.bias False\n",
      "32 encoder.layers.1.final_layer_norm.weight False\n",
      "33 encoder.layers.1.final_layer_norm.bias False\n",
      "34 encoder.layers.2.self_attn.k_proj.weight False\n",
      "35 encoder.layers.2.self_attn.k_proj.bias False\n",
      "36 encoder.layers.2.self_attn.v_proj.weight False\n",
      "37 encoder.layers.2.self_attn.v_proj.bias False\n",
      "38 encoder.layers.2.self_attn.q_proj.weight False\n",
      "39 encoder.layers.2.self_attn.q_proj.bias False\n",
      "40 encoder.layers.2.self_attn.out_proj.weight False\n",
      "41 encoder.layers.2.self_attn.out_proj.bias False\n",
      "42 encoder.layers.2.self_attn_layer_norm.weight False\n",
      "43 encoder.layers.2.self_attn_layer_norm.bias False\n",
      "44 encoder.layers.2.fc1.weight False\n",
      "45 encoder.layers.2.fc1.bias False\n",
      "46 encoder.layers.2.fc2.weight False\n",
      "47 encoder.layers.2.fc2.bias False\n",
      "48 encoder.layers.2.final_layer_norm.weight False\n",
      "49 encoder.layers.2.final_layer_norm.bias False\n",
      "50 encoder.layers.3.self_attn.k_proj.weight False\n",
      "51 encoder.layers.3.self_attn.k_proj.bias False\n",
      "52 encoder.layers.3.self_attn.v_proj.weight False\n",
      "53 encoder.layers.3.self_attn.v_proj.bias False\n",
      "54 encoder.layers.3.self_attn.q_proj.weight False\n",
      "55 encoder.layers.3.self_attn.q_proj.bias False\n",
      "56 encoder.layers.3.self_attn.out_proj.weight False\n",
      "57 encoder.layers.3.self_attn.out_proj.bias False\n",
      "58 encoder.layers.3.self_attn_layer_norm.weight False\n",
      "59 encoder.layers.3.self_attn_layer_norm.bias False\n",
      "60 encoder.layers.3.fc1.weight False\n",
      "61 encoder.layers.3.fc1.bias False\n",
      "62 encoder.layers.3.fc2.weight False\n",
      "63 encoder.layers.3.fc2.bias False\n",
      "64 encoder.layers.3.final_layer_norm.weight False\n",
      "65 encoder.layers.3.final_layer_norm.bias False\n",
      "66 encoder.layers.4.self_attn.k_proj.weight False\n",
      "67 encoder.layers.4.self_attn.k_proj.bias False\n",
      "68 encoder.layers.4.self_attn.v_proj.weight False\n",
      "69 encoder.layers.4.self_attn.v_proj.bias False\n",
      "70 encoder.layers.4.self_attn.q_proj.weight False\n",
      "71 encoder.layers.4.self_attn.q_proj.bias False\n",
      "72 encoder.layers.4.self_attn.out_proj.weight False\n",
      "73 encoder.layers.4.self_attn.out_proj.bias False\n",
      "74 encoder.layers.4.self_attn_layer_norm.weight False\n",
      "75 encoder.layers.4.self_attn_layer_norm.bias False\n",
      "76 encoder.layers.4.fc1.weight False\n",
      "77 encoder.layers.4.fc1.bias False\n",
      "78 encoder.layers.4.fc2.weight False\n",
      "79 encoder.layers.4.fc2.bias False\n",
      "80 encoder.layers.4.final_layer_norm.weight False\n",
      "81 encoder.layers.4.final_layer_norm.bias False\n",
      "82 encoder.layers.5.self_attn.k_proj.weight False\n",
      "83 encoder.layers.5.self_attn.k_proj.bias False\n",
      "84 encoder.layers.5.self_attn.v_proj.weight False\n",
      "85 encoder.layers.5.self_attn.v_proj.bias False\n",
      "86 encoder.layers.5.self_attn.q_proj.weight False\n",
      "87 encoder.layers.5.self_attn.q_proj.bias False\n",
      "88 encoder.layers.5.self_attn.out_proj.weight False\n",
      "89 encoder.layers.5.self_attn.out_proj.bias False\n",
      "90 encoder.layers.5.self_attn_layer_norm.weight False\n",
      "91 encoder.layers.5.self_attn_layer_norm.bias False\n",
      "92 encoder.layers.5.fc1.weight False\n",
      "93 encoder.layers.5.fc1.bias False\n",
      "94 encoder.layers.5.fc2.weight False\n",
      "95 encoder.layers.5.fc2.bias False\n",
      "96 encoder.layers.5.final_layer_norm.weight False\n",
      "97 encoder.layers.5.final_layer_norm.bias False\n",
      "98 encoder.layernorm_embedding.weight False\n",
      "99 encoder.layernorm_embedding.bias False\n",
      "100 decoder.embed_positions.weight False\n",
      "101 decoder.layers.0.self_attn.k_proj.weight False\n",
      "102 decoder.layers.0.self_attn.k_proj.bias False\n",
      "103 decoder.layers.0.self_attn.v_proj.weight False\n",
      "104 decoder.layers.0.self_attn.v_proj.bias False\n",
      "105 decoder.layers.0.self_attn.q_proj.weight False\n",
      "106 decoder.layers.0.self_attn.q_proj.bias False\n",
      "107 decoder.layers.0.self_attn.out_proj.weight False\n",
      "108 decoder.layers.0.self_attn.out_proj.bias False\n",
      "109 decoder.layers.0.self_attn_layer_norm.weight False\n",
      "110 decoder.layers.0.self_attn_layer_norm.bias False\n",
      "111 decoder.layers.0.encoder_attn.k_proj.weight False\n",
      "112 decoder.layers.0.encoder_attn.k_proj.bias False\n",
      "113 decoder.layers.0.encoder_attn.v_proj.weight False\n",
      "114 decoder.layers.0.encoder_attn.v_proj.bias False\n",
      "115 decoder.layers.0.encoder_attn.q_proj.weight False\n",
      "116 decoder.layers.0.encoder_attn.q_proj.bias False\n",
      "117 decoder.layers.0.encoder_attn.out_proj.weight False\n",
      "118 decoder.layers.0.encoder_attn.out_proj.bias False\n",
      "119 decoder.layers.0.encoder_attn_layer_norm.weight False\n",
      "120 decoder.layers.0.encoder_attn_layer_norm.bias False\n",
      "121 decoder.layers.0.fc1.weight False\n",
      "122 decoder.layers.0.fc1.bias False\n",
      "123 decoder.layers.0.fc2.weight False\n",
      "124 decoder.layers.0.fc2.bias False\n",
      "125 decoder.layers.0.final_layer_norm.weight False\n",
      "126 decoder.layers.0.final_layer_norm.bias False\n",
      "127 decoder.layers.1.self_attn.k_proj.weight False\n",
      "128 decoder.layers.1.self_attn.k_proj.bias False\n",
      "129 decoder.layers.1.self_attn.v_proj.weight False\n",
      "130 decoder.layers.1.self_attn.v_proj.bias False\n",
      "131 decoder.layers.1.self_attn.q_proj.weight False\n",
      "132 decoder.layers.1.self_attn.q_proj.bias False\n",
      "133 decoder.layers.1.self_attn.out_proj.weight False\n",
      "134 decoder.layers.1.self_attn.out_proj.bias False\n",
      "135 decoder.layers.1.self_attn_layer_norm.weight False\n",
      "136 decoder.layers.1.self_attn_layer_norm.bias False\n",
      "137 decoder.layers.1.encoder_attn.k_proj.weight False\n",
      "138 decoder.layers.1.encoder_attn.k_proj.bias False\n",
      "139 decoder.layers.1.encoder_attn.v_proj.weight False\n",
      "140 decoder.layers.1.encoder_attn.v_proj.bias False\n",
      "141 decoder.layers.1.encoder_attn.q_proj.weight False\n",
      "142 decoder.layers.1.encoder_attn.q_proj.bias False\n",
      "143 decoder.layers.1.encoder_attn.out_proj.weight False\n",
      "144 decoder.layers.1.encoder_attn.out_proj.bias False\n",
      "145 decoder.layers.1.encoder_attn_layer_norm.weight False\n",
      "146 decoder.layers.1.encoder_attn_layer_norm.bias False\n",
      "147 decoder.layers.1.fc1.weight False\n",
      "148 decoder.layers.1.fc1.bias False\n",
      "149 decoder.layers.1.fc2.weight False\n",
      "150 decoder.layers.1.fc2.bias False\n",
      "151 decoder.layers.1.final_layer_norm.weight False\n",
      "152 decoder.layers.1.final_layer_norm.bias False\n",
      "153 decoder.layers.2.self_attn.k_proj.weight False\n",
      "154 decoder.layers.2.self_attn.k_proj.bias False\n",
      "155 decoder.layers.2.self_attn.v_proj.weight False\n",
      "156 decoder.layers.2.self_attn.v_proj.bias False\n",
      "157 decoder.layers.2.self_attn.q_proj.weight False\n",
      "158 decoder.layers.2.self_attn.q_proj.bias False\n",
      "159 decoder.layers.2.self_attn.out_proj.weight False\n",
      "160 decoder.layers.2.self_attn.out_proj.bias False\n",
      "161 decoder.layers.2.self_attn_layer_norm.weight False\n",
      "162 decoder.layers.2.self_attn_layer_norm.bias False\n",
      "163 decoder.layers.2.encoder_attn.k_proj.weight False\n",
      "164 decoder.layers.2.encoder_attn.k_proj.bias False\n",
      "165 decoder.layers.2.encoder_attn.v_proj.weight False\n",
      "166 decoder.layers.2.encoder_attn.v_proj.bias False\n",
      "167 decoder.layers.2.encoder_attn.q_proj.weight False\n",
      "168 decoder.layers.2.encoder_attn.q_proj.bias False\n",
      "169 decoder.layers.2.encoder_attn.out_proj.weight False\n",
      "170 decoder.layers.2.encoder_attn.out_proj.bias False\n",
      "171 decoder.layers.2.encoder_attn_layer_norm.weight False\n",
      "172 decoder.layers.2.encoder_attn_layer_norm.bias False\n",
      "173 decoder.layers.2.fc1.weight False\n",
      "174 decoder.layers.2.fc1.bias False\n",
      "175 decoder.layers.2.fc2.weight False\n",
      "176 decoder.layers.2.fc2.bias False\n",
      "177 decoder.layers.2.final_layer_norm.weight False\n",
      "178 decoder.layers.2.final_layer_norm.bias False\n",
      "179 decoder.layers.3.self_attn.k_proj.weight False\n",
      "180 decoder.layers.3.self_attn.k_proj.bias False\n",
      "181 decoder.layers.3.self_attn.v_proj.weight False\n",
      "182 decoder.layers.3.self_attn.v_proj.bias False\n",
      "183 decoder.layers.3.self_attn.q_proj.weight False\n",
      "184 decoder.layers.3.self_attn.q_proj.bias False\n",
      "185 decoder.layers.3.self_attn.out_proj.weight False\n",
      "186 decoder.layers.3.self_attn.out_proj.bias False\n",
      "187 decoder.layers.3.self_attn_layer_norm.weight False\n",
      "188 decoder.layers.3.self_attn_layer_norm.bias False\n",
      "189 decoder.layers.3.encoder_attn.k_proj.weight False\n",
      "190 decoder.layers.3.encoder_attn.k_proj.bias False\n",
      "191 decoder.layers.3.encoder_attn.v_proj.weight False\n",
      "192 decoder.layers.3.encoder_attn.v_proj.bias False\n",
      "193 decoder.layers.3.encoder_attn.q_proj.weight False\n",
      "194 decoder.layers.3.encoder_attn.q_proj.bias False\n",
      "195 decoder.layers.3.encoder_attn.out_proj.weight False\n",
      "196 decoder.layers.3.encoder_attn.out_proj.bias False\n",
      "197 decoder.layers.3.encoder_attn_layer_norm.weight False\n",
      "198 decoder.layers.3.encoder_attn_layer_norm.bias False\n",
      "199 decoder.layers.3.fc1.weight False\n",
      "200 decoder.layers.3.fc1.bias False\n",
      "201 decoder.layers.3.fc2.weight False\n",
      "202 decoder.layers.3.fc2.bias False\n",
      "203 decoder.layers.3.final_layer_norm.weight False\n",
      "204 decoder.layers.3.final_layer_norm.bias False\n",
      "205 decoder.layers.4.self_attn.k_proj.weight True\n",
      "206 decoder.layers.4.self_attn.k_proj.bias True\n",
      "207 decoder.layers.4.self_attn.v_proj.weight True\n",
      "208 decoder.layers.4.self_attn.v_proj.bias True\n",
      "209 decoder.layers.4.self_attn.q_proj.weight True\n",
      "210 decoder.layers.4.self_attn.q_proj.bias True\n",
      "211 decoder.layers.4.self_attn.out_proj.weight True\n",
      "212 decoder.layers.4.self_attn.out_proj.bias True\n",
      "213 decoder.layers.4.self_attn_layer_norm.weight True\n",
      "214 decoder.layers.4.self_attn_layer_norm.bias True\n",
      "215 decoder.layers.4.encoder_attn.k_proj.weight True\n",
      "216 decoder.layers.4.encoder_attn.k_proj.bias True\n",
      "217 decoder.layers.4.encoder_attn.v_proj.weight True\n",
      "218 decoder.layers.4.encoder_attn.v_proj.bias True\n",
      "219 decoder.layers.4.encoder_attn.q_proj.weight True\n",
      "220 decoder.layers.4.encoder_attn.q_proj.bias True\n",
      "221 decoder.layers.4.encoder_attn.out_proj.weight True\n",
      "222 decoder.layers.4.encoder_attn.out_proj.bias True\n",
      "223 decoder.layers.4.encoder_attn_layer_norm.weight True\n",
      "224 decoder.layers.4.encoder_attn_layer_norm.bias True\n",
      "225 decoder.layers.4.fc1.weight True\n",
      "226 decoder.layers.4.fc1.bias True\n",
      "227 decoder.layers.4.fc2.weight True\n",
      "228 decoder.layers.4.fc2.bias True\n",
      "229 decoder.layers.4.final_layer_norm.weight True\n",
      "230 decoder.layers.4.final_layer_norm.bias True\n",
      "231 decoder.layers.5.self_attn.k_proj.weight True\n",
      "232 decoder.layers.5.self_attn.k_proj.bias True\n",
      "233 decoder.layers.5.self_attn.v_proj.weight True\n",
      "234 decoder.layers.5.self_attn.v_proj.bias True\n",
      "235 decoder.layers.5.self_attn.q_proj.weight True\n",
      "236 decoder.layers.5.self_attn.q_proj.bias True\n",
      "237 decoder.layers.5.self_attn.out_proj.weight True\n",
      "238 decoder.layers.5.self_attn.out_proj.bias True\n",
      "239 decoder.layers.5.self_attn_layer_norm.weight True\n",
      "240 decoder.layers.5.self_attn_layer_norm.bias True\n",
      "241 decoder.layers.5.encoder_attn.k_proj.weight True\n",
      "242 decoder.layers.5.encoder_attn.k_proj.bias True\n",
      "243 decoder.layers.5.encoder_attn.v_proj.weight True\n",
      "244 decoder.layers.5.encoder_attn.v_proj.bias True\n",
      "245 decoder.layers.5.encoder_attn.q_proj.weight True\n",
      "246 decoder.layers.5.encoder_attn.q_proj.bias True\n",
      "247 decoder.layers.5.encoder_attn.out_proj.weight True\n",
      "248 decoder.layers.5.encoder_attn.out_proj.bias True\n",
      "249 decoder.layers.5.encoder_attn_layer_norm.weight True\n",
      "250 decoder.layers.5.encoder_attn_layer_norm.bias True\n",
      "251 decoder.layers.5.fc1.weight True\n",
      "252 decoder.layers.5.fc1.bias True\n",
      "253 decoder.layers.5.fc2.weight True\n",
      "254 decoder.layers.5.fc2.bias True\n",
      "255 decoder.layers.5.final_layer_norm.weight True\n",
      "256 decoder.layers.5.final_layer_norm.bias True\n",
      "257 decoder.layernorm_embedding.weight True\n",
      "258 decoder.layernorm_embedding.bias True\n",
      "\n",
      "#################################################\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of decoder layers to unfreeze: 2\n",
      "0 shared.weight True\n",
      "1 encoder.embed_positions.weight False\n",
      "2 encoder.layers.0.self_attn.k_proj.weight False\n",
      "3 encoder.layers.0.self_attn.k_proj.bias False\n",
      "4 encoder.layers.0.self_attn.v_proj.weight False\n",
      "5 encoder.layers.0.self_attn.v_proj.bias False\n",
      "6 encoder.layers.0.self_attn.q_proj.weight False\n",
      "7 encoder.layers.0.self_attn.q_proj.bias False\n",
      "8 encoder.layers.0.self_attn.out_proj.weight False\n",
      "9 encoder.layers.0.self_attn.out_proj.bias False\n",
      "10 encoder.layers.0.self_attn_layer_norm.weight False\n",
      "11 encoder.layers.0.self_attn_layer_norm.bias False\n",
      "12 encoder.layers.0.fc1.weight False\n",
      "13 encoder.layers.0.fc1.bias False\n",
      "14 encoder.layers.0.fc2.weight False\n",
      "15 encoder.layers.0.fc2.bias False\n",
      "16 encoder.layers.0.final_layer_norm.weight False\n",
      "17 encoder.layers.0.final_layer_norm.bias False\n",
      "18 encoder.layers.1.self_attn.k_proj.weight False\n",
      "19 encoder.layers.1.self_attn.k_proj.bias False\n",
      "20 encoder.layers.1.self_attn.v_proj.weight False\n",
      "21 encoder.layers.1.self_attn.v_proj.bias False\n",
      "22 encoder.layers.1.self_attn.q_proj.weight False\n",
      "23 encoder.layers.1.self_attn.q_proj.bias False\n",
      "24 encoder.layers.1.self_attn.out_proj.weight False\n",
      "25 encoder.layers.1.self_attn.out_proj.bias False\n",
      "26 encoder.layers.1.self_attn_layer_norm.weight False\n",
      "27 encoder.layers.1.self_attn_layer_norm.bias False\n",
      "28 encoder.layers.1.fc1.weight False\n",
      "29 encoder.layers.1.fc1.bias False\n",
      "30 encoder.layers.1.fc2.weight False\n",
      "31 encoder.layers.1.fc2.bias False\n",
      "32 encoder.layers.1.final_layer_norm.weight False\n",
      "33 encoder.layers.1.final_layer_norm.bias False\n",
      "34 encoder.layers.2.self_attn.k_proj.weight False\n",
      "35 encoder.layers.2.self_attn.k_proj.bias False\n",
      "36 encoder.layers.2.self_attn.v_proj.weight False\n",
      "37 encoder.layers.2.self_attn.v_proj.bias False\n",
      "38 encoder.layers.2.self_attn.q_proj.weight False\n",
      "39 encoder.layers.2.self_attn.q_proj.bias False\n",
      "40 encoder.layers.2.self_attn.out_proj.weight False\n",
      "41 encoder.layers.2.self_attn.out_proj.bias False\n",
      "42 encoder.layers.2.self_attn_layer_norm.weight False\n",
      "43 encoder.layers.2.self_attn_layer_norm.bias False\n",
      "44 encoder.layers.2.fc1.weight False\n",
      "45 encoder.layers.2.fc1.bias False\n",
      "46 encoder.layers.2.fc2.weight False\n",
      "47 encoder.layers.2.fc2.bias False\n",
      "48 encoder.layers.2.final_layer_norm.weight False\n",
      "49 encoder.layers.2.final_layer_norm.bias False\n",
      "50 encoder.layers.3.self_attn.k_proj.weight False\n",
      "51 encoder.layers.3.self_attn.k_proj.bias False\n",
      "52 encoder.layers.3.self_attn.v_proj.weight False\n",
      "53 encoder.layers.3.self_attn.v_proj.bias False\n",
      "54 encoder.layers.3.self_attn.q_proj.weight False\n",
      "55 encoder.layers.3.self_attn.q_proj.bias False\n",
      "56 encoder.layers.3.self_attn.out_proj.weight False\n",
      "57 encoder.layers.3.self_attn.out_proj.bias False\n",
      "58 encoder.layers.3.self_attn_layer_norm.weight False\n",
      "59 encoder.layers.3.self_attn_layer_norm.bias False\n",
      "60 encoder.layers.3.fc1.weight False\n",
      "61 encoder.layers.3.fc1.bias False\n",
      "62 encoder.layers.3.fc2.weight False\n",
      "63 encoder.layers.3.fc2.bias False\n",
      "64 encoder.layers.3.final_layer_norm.weight False\n",
      "65 encoder.layers.3.final_layer_norm.bias False\n",
      "66 encoder.layers.4.self_attn.k_proj.weight False\n",
      "67 encoder.layers.4.self_attn.k_proj.bias False\n",
      "68 encoder.layers.4.self_attn.v_proj.weight False\n",
      "69 encoder.layers.4.self_attn.v_proj.bias False\n",
      "70 encoder.layers.4.self_attn.q_proj.weight False\n",
      "71 encoder.layers.4.self_attn.q_proj.bias False\n",
      "72 encoder.layers.4.self_attn.out_proj.weight False\n",
      "73 encoder.layers.4.self_attn.out_proj.bias False\n",
      "74 encoder.layers.4.self_attn_layer_norm.weight False\n",
      "75 encoder.layers.4.self_attn_layer_norm.bias False\n",
      "76 encoder.layers.4.fc1.weight False\n",
      "77 encoder.layers.4.fc1.bias False\n",
      "78 encoder.layers.4.fc2.weight False\n",
      "79 encoder.layers.4.fc2.bias False\n",
      "80 encoder.layers.4.final_layer_norm.weight False\n",
      "81 encoder.layers.4.final_layer_norm.bias False\n",
      "82 encoder.layers.5.self_attn.k_proj.weight False\n",
      "83 encoder.layers.5.self_attn.k_proj.bias False\n",
      "84 encoder.layers.5.self_attn.v_proj.weight False\n",
      "85 encoder.layers.5.self_attn.v_proj.bias False\n",
      "86 encoder.layers.5.self_attn.q_proj.weight False\n",
      "87 encoder.layers.5.self_attn.q_proj.bias False\n",
      "88 encoder.layers.5.self_attn.out_proj.weight False\n",
      "89 encoder.layers.5.self_attn.out_proj.bias False\n",
      "90 encoder.layers.5.self_attn_layer_norm.weight False\n",
      "91 encoder.layers.5.self_attn_layer_norm.bias False\n",
      "92 encoder.layers.5.fc1.weight False\n",
      "93 encoder.layers.5.fc1.bias False\n",
      "94 encoder.layers.5.fc2.weight False\n",
      "95 encoder.layers.5.fc2.bias False\n",
      "96 encoder.layers.5.final_layer_norm.weight False\n",
      "97 encoder.layers.5.final_layer_norm.bias False\n",
      "98 encoder.layers.6.self_attn.k_proj.weight False\n",
      "99 encoder.layers.6.self_attn.k_proj.bias False\n",
      "100 encoder.layers.6.self_attn.v_proj.weight False\n",
      "101 encoder.layers.6.self_attn.v_proj.bias False\n",
      "102 encoder.layers.6.self_attn.q_proj.weight False\n",
      "103 encoder.layers.6.self_attn.q_proj.bias False\n",
      "104 encoder.layers.6.self_attn.out_proj.weight False\n",
      "105 encoder.layers.6.self_attn.out_proj.bias False\n",
      "106 encoder.layers.6.self_attn_layer_norm.weight False\n",
      "107 encoder.layers.6.self_attn_layer_norm.bias False\n",
      "108 encoder.layers.6.fc1.weight False\n",
      "109 encoder.layers.6.fc1.bias False\n",
      "110 encoder.layers.6.fc2.weight False\n",
      "111 encoder.layers.6.fc2.bias False\n",
      "112 encoder.layers.6.final_layer_norm.weight False\n",
      "113 encoder.layers.6.final_layer_norm.bias False\n",
      "114 encoder.layers.7.self_attn.k_proj.weight False\n",
      "115 encoder.layers.7.self_attn.k_proj.bias False\n",
      "116 encoder.layers.7.self_attn.v_proj.weight False\n",
      "117 encoder.layers.7.self_attn.v_proj.bias False\n",
      "118 encoder.layers.7.self_attn.q_proj.weight False\n",
      "119 encoder.layers.7.self_attn.q_proj.bias False\n",
      "120 encoder.layers.7.self_attn.out_proj.weight False\n",
      "121 encoder.layers.7.self_attn.out_proj.bias False\n",
      "122 encoder.layers.7.self_attn_layer_norm.weight False\n",
      "123 encoder.layers.7.self_attn_layer_norm.bias False\n",
      "124 encoder.layers.7.fc1.weight False\n",
      "125 encoder.layers.7.fc1.bias False\n",
      "126 encoder.layers.7.fc2.weight False\n",
      "127 encoder.layers.7.fc2.bias False\n",
      "128 encoder.layers.7.final_layer_norm.weight False\n",
      "129 encoder.layers.7.final_layer_norm.bias False\n",
      "130 encoder.layers.8.self_attn.k_proj.weight False\n",
      "131 encoder.layers.8.self_attn.k_proj.bias False\n",
      "132 encoder.layers.8.self_attn.v_proj.weight False\n",
      "133 encoder.layers.8.self_attn.v_proj.bias False\n",
      "134 encoder.layers.8.self_attn.q_proj.weight False\n",
      "135 encoder.layers.8.self_attn.q_proj.bias False\n",
      "136 encoder.layers.8.self_attn.out_proj.weight False\n",
      "137 encoder.layers.8.self_attn.out_proj.bias False\n",
      "138 encoder.layers.8.self_attn_layer_norm.weight False\n",
      "139 encoder.layers.8.self_attn_layer_norm.bias False\n",
      "140 encoder.layers.8.fc1.weight False\n",
      "141 encoder.layers.8.fc1.bias False\n",
      "142 encoder.layers.8.fc2.weight False\n",
      "143 encoder.layers.8.fc2.bias False\n",
      "144 encoder.layers.8.final_layer_norm.weight False\n",
      "145 encoder.layers.8.final_layer_norm.bias False\n",
      "146 encoder.layers.9.self_attn.k_proj.weight False\n",
      "147 encoder.layers.9.self_attn.k_proj.bias False\n",
      "148 encoder.layers.9.self_attn.v_proj.weight False\n",
      "149 encoder.layers.9.self_attn.v_proj.bias False\n",
      "150 encoder.layers.9.self_attn.q_proj.weight False\n",
      "151 encoder.layers.9.self_attn.q_proj.bias False\n",
      "152 encoder.layers.9.self_attn.out_proj.weight False\n",
      "153 encoder.layers.9.self_attn.out_proj.bias False\n",
      "154 encoder.layers.9.self_attn_layer_norm.weight False\n",
      "155 encoder.layers.9.self_attn_layer_norm.bias False\n",
      "156 encoder.layers.9.fc1.weight False\n",
      "157 encoder.layers.9.fc1.bias False\n",
      "158 encoder.layers.9.fc2.weight False\n",
      "159 encoder.layers.9.fc2.bias False\n",
      "160 encoder.layers.9.final_layer_norm.weight False\n",
      "161 encoder.layers.9.final_layer_norm.bias False\n",
      "162 encoder.layers.10.self_attn.k_proj.weight False\n",
      "163 encoder.layers.10.self_attn.k_proj.bias False\n",
      "164 encoder.layers.10.self_attn.v_proj.weight False\n",
      "165 encoder.layers.10.self_attn.v_proj.bias False\n",
      "166 encoder.layers.10.self_attn.q_proj.weight False\n",
      "167 encoder.layers.10.self_attn.q_proj.bias False\n",
      "168 encoder.layers.10.self_attn.out_proj.weight False\n",
      "169 encoder.layers.10.self_attn.out_proj.bias False\n",
      "170 encoder.layers.10.self_attn_layer_norm.weight False\n",
      "171 encoder.layers.10.self_attn_layer_norm.bias False\n",
      "172 encoder.layers.10.fc1.weight False\n",
      "173 encoder.layers.10.fc1.bias False\n",
      "174 encoder.layers.10.fc2.weight False\n",
      "175 encoder.layers.10.fc2.bias False\n",
      "176 encoder.layers.10.final_layer_norm.weight False\n",
      "177 encoder.layers.10.final_layer_norm.bias False\n",
      "178 encoder.layers.11.self_attn.k_proj.weight False\n",
      "179 encoder.layers.11.self_attn.k_proj.bias False\n",
      "180 encoder.layers.11.self_attn.v_proj.weight False\n",
      "181 encoder.layers.11.self_attn.v_proj.bias False\n",
      "182 encoder.layers.11.self_attn.q_proj.weight False\n",
      "183 encoder.layers.11.self_attn.q_proj.bias False\n",
      "184 encoder.layers.11.self_attn.out_proj.weight False\n",
      "185 encoder.layers.11.self_attn.out_proj.bias False\n",
      "186 encoder.layers.11.self_attn_layer_norm.weight False\n",
      "187 encoder.layers.11.self_attn_layer_norm.bias False\n",
      "188 encoder.layers.11.fc1.weight False\n",
      "189 encoder.layers.11.fc1.bias False\n",
      "190 encoder.layers.11.fc2.weight False\n",
      "191 encoder.layers.11.fc2.bias False\n",
      "192 encoder.layers.11.final_layer_norm.weight False\n",
      "193 encoder.layers.11.final_layer_norm.bias False\n",
      "194 encoder.layernorm_embedding.weight False\n",
      "195 encoder.layernorm_embedding.bias False\n",
      "196 decoder.embed_positions.weight False\n",
      "197 decoder.layers.0.self_attn.k_proj.weight False\n",
      "198 decoder.layers.0.self_attn.k_proj.bias False\n",
      "199 decoder.layers.0.self_attn.v_proj.weight False\n",
      "200 decoder.layers.0.self_attn.v_proj.bias False\n",
      "201 decoder.layers.0.self_attn.q_proj.weight False\n",
      "202 decoder.layers.0.self_attn.q_proj.bias False\n",
      "203 decoder.layers.0.self_attn.out_proj.weight False\n",
      "204 decoder.layers.0.self_attn.out_proj.bias False\n",
      "205 decoder.layers.0.self_attn_layer_norm.weight False\n",
      "206 decoder.layers.0.self_attn_layer_norm.bias False\n",
      "207 decoder.layers.0.encoder_attn.k_proj.weight False\n",
      "208 decoder.layers.0.encoder_attn.k_proj.bias False\n",
      "209 decoder.layers.0.encoder_attn.v_proj.weight False\n",
      "210 decoder.layers.0.encoder_attn.v_proj.bias False\n",
      "211 decoder.layers.0.encoder_attn.q_proj.weight False\n",
      "212 decoder.layers.0.encoder_attn.q_proj.bias False\n",
      "213 decoder.layers.0.encoder_attn.out_proj.weight False\n",
      "214 decoder.layers.0.encoder_attn.out_proj.bias False\n",
      "215 decoder.layers.0.encoder_attn_layer_norm.weight False\n",
      "216 decoder.layers.0.encoder_attn_layer_norm.bias False\n",
      "217 decoder.layers.0.fc1.weight False\n",
      "218 decoder.layers.0.fc1.bias False\n",
      "219 decoder.layers.0.fc2.weight False\n",
      "220 decoder.layers.0.fc2.bias False\n",
      "221 decoder.layers.0.final_layer_norm.weight False\n",
      "222 decoder.layers.0.final_layer_norm.bias False\n",
      "223 decoder.layers.1.self_attn.k_proj.weight False\n",
      "224 decoder.layers.1.self_attn.k_proj.bias False\n",
      "225 decoder.layers.1.self_attn.v_proj.weight False\n",
      "226 decoder.layers.1.self_attn.v_proj.bias False\n",
      "227 decoder.layers.1.self_attn.q_proj.weight False\n",
      "228 decoder.layers.1.self_attn.q_proj.bias False\n",
      "229 decoder.layers.1.self_attn.out_proj.weight False\n",
      "230 decoder.layers.1.self_attn.out_proj.bias False\n",
      "231 decoder.layers.1.self_attn_layer_norm.weight False\n",
      "232 decoder.layers.1.self_attn_layer_norm.bias False\n",
      "233 decoder.layers.1.encoder_attn.k_proj.weight False\n",
      "234 decoder.layers.1.encoder_attn.k_proj.bias False\n",
      "235 decoder.layers.1.encoder_attn.v_proj.weight False\n",
      "236 decoder.layers.1.encoder_attn.v_proj.bias False\n",
      "237 decoder.layers.1.encoder_attn.q_proj.weight False\n",
      "238 decoder.layers.1.encoder_attn.q_proj.bias False\n",
      "239 decoder.layers.1.encoder_attn.out_proj.weight False\n",
      "240 decoder.layers.1.encoder_attn.out_proj.bias False\n",
      "241 decoder.layers.1.encoder_attn_layer_norm.weight False\n",
      "242 decoder.layers.1.encoder_attn_layer_norm.bias False\n",
      "243 decoder.layers.1.fc1.weight False\n",
      "244 decoder.layers.1.fc1.bias False\n",
      "245 decoder.layers.1.fc2.weight False\n",
      "246 decoder.layers.1.fc2.bias False\n",
      "247 decoder.layers.1.final_layer_norm.weight False\n",
      "248 decoder.layers.1.final_layer_norm.bias False\n",
      "249 decoder.layers.2.self_attn.k_proj.weight False\n",
      "250 decoder.layers.2.self_attn.k_proj.bias False\n",
      "251 decoder.layers.2.self_attn.v_proj.weight False\n",
      "252 decoder.layers.2.self_attn.v_proj.bias False\n",
      "253 decoder.layers.2.self_attn.q_proj.weight False\n",
      "254 decoder.layers.2.self_attn.q_proj.bias False\n",
      "255 decoder.layers.2.self_attn.out_proj.weight False\n",
      "256 decoder.layers.2.self_attn.out_proj.bias False\n",
      "257 decoder.layers.2.self_attn_layer_norm.weight False\n",
      "258 decoder.layers.2.self_attn_layer_norm.bias False\n",
      "259 decoder.layers.2.encoder_attn.k_proj.weight False\n",
      "260 decoder.layers.2.encoder_attn.k_proj.bias False\n",
      "261 decoder.layers.2.encoder_attn.v_proj.weight False\n",
      "262 decoder.layers.2.encoder_attn.v_proj.bias False\n",
      "263 decoder.layers.2.encoder_attn.q_proj.weight False\n",
      "264 decoder.layers.2.encoder_attn.q_proj.bias False\n",
      "265 decoder.layers.2.encoder_attn.out_proj.weight False\n",
      "266 decoder.layers.2.encoder_attn.out_proj.bias False\n",
      "267 decoder.layers.2.encoder_attn_layer_norm.weight False\n",
      "268 decoder.layers.2.encoder_attn_layer_norm.bias False\n",
      "269 decoder.layers.2.fc1.weight False\n",
      "270 decoder.layers.2.fc1.bias False\n",
      "271 decoder.layers.2.fc2.weight False\n",
      "272 decoder.layers.2.fc2.bias False\n",
      "273 decoder.layers.2.final_layer_norm.weight False\n",
      "274 decoder.layers.2.final_layer_norm.bias False\n",
      "275 decoder.layers.3.self_attn.k_proj.weight False\n",
      "276 decoder.layers.3.self_attn.k_proj.bias False\n",
      "277 decoder.layers.3.self_attn.v_proj.weight False\n",
      "278 decoder.layers.3.self_attn.v_proj.bias False\n",
      "279 decoder.layers.3.self_attn.q_proj.weight False\n",
      "280 decoder.layers.3.self_attn.q_proj.bias False\n",
      "281 decoder.layers.3.self_attn.out_proj.weight False\n",
      "282 decoder.layers.3.self_attn.out_proj.bias False\n",
      "283 decoder.layers.3.self_attn_layer_norm.weight False\n",
      "284 decoder.layers.3.self_attn_layer_norm.bias False\n",
      "285 decoder.layers.3.encoder_attn.k_proj.weight False\n",
      "286 decoder.layers.3.encoder_attn.k_proj.bias False\n",
      "287 decoder.layers.3.encoder_attn.v_proj.weight False\n",
      "288 decoder.layers.3.encoder_attn.v_proj.bias False\n",
      "289 decoder.layers.3.encoder_attn.q_proj.weight False\n",
      "290 decoder.layers.3.encoder_attn.q_proj.bias False\n",
      "291 decoder.layers.3.encoder_attn.out_proj.weight False\n",
      "292 decoder.layers.3.encoder_attn.out_proj.bias False\n",
      "293 decoder.layers.3.encoder_attn_layer_norm.weight False\n",
      "294 decoder.layers.3.encoder_attn_layer_norm.bias False\n",
      "295 decoder.layers.3.fc1.weight False\n",
      "296 decoder.layers.3.fc1.bias False\n",
      "297 decoder.layers.3.fc2.weight False\n",
      "298 decoder.layers.3.fc2.bias False\n",
      "299 decoder.layers.3.final_layer_norm.weight False\n",
      "300 decoder.layers.3.final_layer_norm.bias False\n",
      "301 decoder.layers.4.self_attn.k_proj.weight False\n",
      "302 decoder.layers.4.self_attn.k_proj.bias False\n",
      "303 decoder.layers.4.self_attn.v_proj.weight False\n",
      "304 decoder.layers.4.self_attn.v_proj.bias False\n",
      "305 decoder.layers.4.self_attn.q_proj.weight False\n",
      "306 decoder.layers.4.self_attn.q_proj.bias False\n",
      "307 decoder.layers.4.self_attn.out_proj.weight False\n",
      "308 decoder.layers.4.self_attn.out_proj.bias False\n",
      "309 decoder.layers.4.self_attn_layer_norm.weight False\n",
      "310 decoder.layers.4.self_attn_layer_norm.bias False\n",
      "311 decoder.layers.4.encoder_attn.k_proj.weight False\n",
      "312 decoder.layers.4.encoder_attn.k_proj.bias False\n",
      "313 decoder.layers.4.encoder_attn.v_proj.weight False\n",
      "314 decoder.layers.4.encoder_attn.v_proj.bias False\n",
      "315 decoder.layers.4.encoder_attn.q_proj.weight False\n",
      "316 decoder.layers.4.encoder_attn.q_proj.bias False\n",
      "317 decoder.layers.4.encoder_attn.out_proj.weight False\n",
      "318 decoder.layers.4.encoder_attn.out_proj.bias False\n",
      "319 decoder.layers.4.encoder_attn_layer_norm.weight False\n",
      "320 decoder.layers.4.encoder_attn_layer_norm.bias False\n",
      "321 decoder.layers.4.fc1.weight False\n",
      "322 decoder.layers.4.fc1.bias False\n",
      "323 decoder.layers.4.fc2.weight False\n",
      "324 decoder.layers.4.fc2.bias False\n",
      "325 decoder.layers.4.final_layer_norm.weight False\n",
      "326 decoder.layers.4.final_layer_norm.bias False\n",
      "327 decoder.layers.5.self_attn.k_proj.weight False\n",
      "328 decoder.layers.5.self_attn.k_proj.bias False\n",
      "329 decoder.layers.5.self_attn.v_proj.weight False\n",
      "330 decoder.layers.5.self_attn.v_proj.bias False\n",
      "331 decoder.layers.5.self_attn.q_proj.weight False\n",
      "332 decoder.layers.5.self_attn.q_proj.bias False\n",
      "333 decoder.layers.5.self_attn.out_proj.weight False\n",
      "334 decoder.layers.5.self_attn.out_proj.bias False\n",
      "335 decoder.layers.5.self_attn_layer_norm.weight False\n",
      "336 decoder.layers.5.self_attn_layer_norm.bias False\n",
      "337 decoder.layers.5.encoder_attn.k_proj.weight False\n",
      "338 decoder.layers.5.encoder_attn.k_proj.bias False\n",
      "339 decoder.layers.5.encoder_attn.v_proj.weight False\n",
      "340 decoder.layers.5.encoder_attn.v_proj.bias False\n",
      "341 decoder.layers.5.encoder_attn.q_proj.weight False\n",
      "342 decoder.layers.5.encoder_attn.q_proj.bias False\n",
      "343 decoder.layers.5.encoder_attn.out_proj.weight False\n",
      "344 decoder.layers.5.encoder_attn.out_proj.bias False\n",
      "345 decoder.layers.5.encoder_attn_layer_norm.weight False\n",
      "346 decoder.layers.5.encoder_attn_layer_norm.bias False\n",
      "347 decoder.layers.5.fc1.weight False\n",
      "348 decoder.layers.5.fc1.bias False\n",
      "349 decoder.layers.5.fc2.weight False\n",
      "350 decoder.layers.5.fc2.bias False\n",
      "351 decoder.layers.5.final_layer_norm.weight False\n",
      "352 decoder.layers.5.final_layer_norm.bias False\n",
      "353 decoder.layers.6.self_attn.k_proj.weight False\n",
      "354 decoder.layers.6.self_attn.k_proj.bias False\n",
      "355 decoder.layers.6.self_attn.v_proj.weight False\n",
      "356 decoder.layers.6.self_attn.v_proj.bias False\n",
      "357 decoder.layers.6.self_attn.q_proj.weight False\n",
      "358 decoder.layers.6.self_attn.q_proj.bias False\n",
      "359 decoder.layers.6.self_attn.out_proj.weight False\n",
      "360 decoder.layers.6.self_attn.out_proj.bias False\n",
      "361 decoder.layers.6.self_attn_layer_norm.weight False\n",
      "362 decoder.layers.6.self_attn_layer_norm.bias False\n",
      "363 decoder.layers.6.encoder_attn.k_proj.weight False\n",
      "364 decoder.layers.6.encoder_attn.k_proj.bias False\n",
      "365 decoder.layers.6.encoder_attn.v_proj.weight False\n",
      "366 decoder.layers.6.encoder_attn.v_proj.bias False\n",
      "367 decoder.layers.6.encoder_attn.q_proj.weight False\n",
      "368 decoder.layers.6.encoder_attn.q_proj.bias False\n",
      "369 decoder.layers.6.encoder_attn.out_proj.weight False\n",
      "370 decoder.layers.6.encoder_attn.out_proj.bias False\n",
      "371 decoder.layers.6.encoder_attn_layer_norm.weight False\n",
      "372 decoder.layers.6.encoder_attn_layer_norm.bias False\n",
      "373 decoder.layers.6.fc1.weight False\n",
      "374 decoder.layers.6.fc1.bias False\n",
      "375 decoder.layers.6.fc2.weight False\n",
      "376 decoder.layers.6.fc2.bias False\n",
      "377 decoder.layers.6.final_layer_norm.weight False\n",
      "378 decoder.layers.6.final_layer_norm.bias False\n",
      "379 decoder.layers.7.self_attn.k_proj.weight False\n",
      "380 decoder.layers.7.self_attn.k_proj.bias False\n",
      "381 decoder.layers.7.self_attn.v_proj.weight False\n",
      "382 decoder.layers.7.self_attn.v_proj.bias False\n",
      "383 decoder.layers.7.self_attn.q_proj.weight False\n",
      "384 decoder.layers.7.self_attn.q_proj.bias False\n",
      "385 decoder.layers.7.self_attn.out_proj.weight False\n",
      "386 decoder.layers.7.self_attn.out_proj.bias False\n",
      "387 decoder.layers.7.self_attn_layer_norm.weight False\n",
      "388 decoder.layers.7.self_attn_layer_norm.bias False\n",
      "389 decoder.layers.7.encoder_attn.k_proj.weight False\n",
      "390 decoder.layers.7.encoder_attn.k_proj.bias False\n",
      "391 decoder.layers.7.encoder_attn.v_proj.weight False\n",
      "392 decoder.layers.7.encoder_attn.v_proj.bias False\n",
      "393 decoder.layers.7.encoder_attn.q_proj.weight False\n",
      "394 decoder.layers.7.encoder_attn.q_proj.bias False\n",
      "395 decoder.layers.7.encoder_attn.out_proj.weight False\n",
      "396 decoder.layers.7.encoder_attn.out_proj.bias False\n",
      "397 decoder.layers.7.encoder_attn_layer_norm.weight False\n",
      "398 decoder.layers.7.encoder_attn_layer_norm.bias False\n",
      "399 decoder.layers.7.fc1.weight False\n",
      "400 decoder.layers.7.fc1.bias False\n",
      "401 decoder.layers.7.fc2.weight False\n",
      "402 decoder.layers.7.fc2.bias False\n",
      "403 decoder.layers.7.final_layer_norm.weight False\n",
      "404 decoder.layers.7.final_layer_norm.bias False\n",
      "405 decoder.layers.8.self_attn.k_proj.weight False\n",
      "406 decoder.layers.8.self_attn.k_proj.bias False\n",
      "407 decoder.layers.8.self_attn.v_proj.weight False\n",
      "408 decoder.layers.8.self_attn.v_proj.bias False\n",
      "409 decoder.layers.8.self_attn.q_proj.weight False\n",
      "410 decoder.layers.8.self_attn.q_proj.bias False\n",
      "411 decoder.layers.8.self_attn.out_proj.weight False\n",
      "412 decoder.layers.8.self_attn.out_proj.bias False\n",
      "413 decoder.layers.8.self_attn_layer_norm.weight False\n",
      "414 decoder.layers.8.self_attn_layer_norm.bias False\n",
      "415 decoder.layers.8.encoder_attn.k_proj.weight False\n",
      "416 decoder.layers.8.encoder_attn.k_proj.bias False\n",
      "417 decoder.layers.8.encoder_attn.v_proj.weight False\n",
      "418 decoder.layers.8.encoder_attn.v_proj.bias False\n",
      "419 decoder.layers.8.encoder_attn.q_proj.weight False\n",
      "420 decoder.layers.8.encoder_attn.q_proj.bias False\n",
      "421 decoder.layers.8.encoder_attn.out_proj.weight False\n",
      "422 decoder.layers.8.encoder_attn.out_proj.bias False\n",
      "423 decoder.layers.8.encoder_attn_layer_norm.weight False\n",
      "424 decoder.layers.8.encoder_attn_layer_norm.bias False\n",
      "425 decoder.layers.8.fc1.weight False\n",
      "426 decoder.layers.8.fc1.bias False\n",
      "427 decoder.layers.8.fc2.weight False\n",
      "428 decoder.layers.8.fc2.bias False\n",
      "429 decoder.layers.8.final_layer_norm.weight False\n",
      "430 decoder.layers.8.final_layer_norm.bias False\n",
      "431 decoder.layers.9.self_attn.k_proj.weight False\n",
      "432 decoder.layers.9.self_attn.k_proj.bias False\n",
      "433 decoder.layers.9.self_attn.v_proj.weight False\n",
      "434 decoder.layers.9.self_attn.v_proj.bias False\n",
      "435 decoder.layers.9.self_attn.q_proj.weight False\n",
      "436 decoder.layers.9.self_attn.q_proj.bias False\n",
      "437 decoder.layers.9.self_attn.out_proj.weight False\n",
      "438 decoder.layers.9.self_attn.out_proj.bias False\n",
      "439 decoder.layers.9.self_attn_layer_norm.weight False\n",
      "440 decoder.layers.9.self_attn_layer_norm.bias False\n",
      "441 decoder.layers.9.encoder_attn.k_proj.weight False\n",
      "442 decoder.layers.9.encoder_attn.k_proj.bias False\n",
      "443 decoder.layers.9.encoder_attn.v_proj.weight False\n",
      "444 decoder.layers.9.encoder_attn.v_proj.bias False\n",
      "445 decoder.layers.9.encoder_attn.q_proj.weight False\n",
      "446 decoder.layers.9.encoder_attn.q_proj.bias False\n",
      "447 decoder.layers.9.encoder_attn.out_proj.weight False\n",
      "448 decoder.layers.9.encoder_attn.out_proj.bias False\n",
      "449 decoder.layers.9.encoder_attn_layer_norm.weight False\n",
      "450 decoder.layers.9.encoder_attn_layer_norm.bias False\n",
      "451 decoder.layers.9.fc1.weight False\n",
      "452 decoder.layers.9.fc1.bias False\n",
      "453 decoder.layers.9.fc2.weight False\n",
      "454 decoder.layers.9.fc2.bias False\n",
      "455 decoder.layers.9.final_layer_norm.weight False\n",
      "456 decoder.layers.9.final_layer_norm.bias False\n",
      "457 decoder.layers.10.self_attn.k_proj.weight True\n",
      "458 decoder.layers.10.self_attn.k_proj.bias True\n",
      "459 decoder.layers.10.self_attn.v_proj.weight True\n",
      "460 decoder.layers.10.self_attn.v_proj.bias True\n",
      "461 decoder.layers.10.self_attn.q_proj.weight True\n",
      "462 decoder.layers.10.self_attn.q_proj.bias True\n",
      "463 decoder.layers.10.self_attn.out_proj.weight True\n",
      "464 decoder.layers.10.self_attn.out_proj.bias True\n",
      "465 decoder.layers.10.self_attn_layer_norm.weight True\n",
      "466 decoder.layers.10.self_attn_layer_norm.bias True\n",
      "467 decoder.layers.10.encoder_attn.k_proj.weight True\n",
      "468 decoder.layers.10.encoder_attn.k_proj.bias True\n",
      "469 decoder.layers.10.encoder_attn.v_proj.weight True\n",
      "470 decoder.layers.10.encoder_attn.v_proj.bias True\n",
      "471 decoder.layers.10.encoder_attn.q_proj.weight True\n",
      "472 decoder.layers.10.encoder_attn.q_proj.bias True\n",
      "473 decoder.layers.10.encoder_attn.out_proj.weight True\n",
      "474 decoder.layers.10.encoder_attn.out_proj.bias True\n",
      "475 decoder.layers.10.encoder_attn_layer_norm.weight True\n",
      "476 decoder.layers.10.encoder_attn_layer_norm.bias True\n",
      "477 decoder.layers.10.fc1.weight True\n",
      "478 decoder.layers.10.fc1.bias True\n",
      "479 decoder.layers.10.fc2.weight True\n",
      "480 decoder.layers.10.fc2.bias True\n",
      "481 decoder.layers.10.final_layer_norm.weight True\n",
      "482 decoder.layers.10.final_layer_norm.bias True\n",
      "483 decoder.layers.11.self_attn.k_proj.weight True\n",
      "484 decoder.layers.11.self_attn.k_proj.bias True\n",
      "485 decoder.layers.11.self_attn.v_proj.weight True\n",
      "486 decoder.layers.11.self_attn.v_proj.bias True\n",
      "487 decoder.layers.11.self_attn.q_proj.weight True\n",
      "488 decoder.layers.11.self_attn.q_proj.bias True\n",
      "489 decoder.layers.11.self_attn.out_proj.weight True\n",
      "490 decoder.layers.11.self_attn.out_proj.bias True\n",
      "491 decoder.layers.11.self_attn_layer_norm.weight True\n",
      "492 decoder.layers.11.self_attn_layer_norm.bias True\n",
      "493 decoder.layers.11.encoder_attn.k_proj.weight True\n",
      "494 decoder.layers.11.encoder_attn.k_proj.bias True\n",
      "495 decoder.layers.11.encoder_attn.v_proj.weight True\n",
      "496 decoder.layers.11.encoder_attn.v_proj.bias True\n",
      "497 decoder.layers.11.encoder_attn.q_proj.weight True\n",
      "498 decoder.layers.11.encoder_attn.q_proj.bias True\n",
      "499 decoder.layers.11.encoder_attn.out_proj.weight True\n",
      "500 decoder.layers.11.encoder_attn.out_proj.bias True\n",
      "501 decoder.layers.11.encoder_attn_layer_norm.weight True\n",
      "502 decoder.layers.11.encoder_attn_layer_norm.bias True\n",
      "503 decoder.layers.11.fc1.weight True\n",
      "504 decoder.layers.11.fc1.bias True\n",
      "505 decoder.layers.11.fc2.weight True\n",
      "506 decoder.layers.11.fc2.bias True\n",
      "507 decoder.layers.11.final_layer_norm.weight True\n",
      "508 decoder.layers.11.final_layer_norm.bias True\n",
      "509 decoder.layernorm_embedding.weight True\n",
      "510 decoder.layernorm_embedding.bias True\n",
      "\n",
      "#################################################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cfg.unfreeze_last_n_layers = 2\n",
    "for name in [\"tdopierre/ProtAugment-ParaphraseGenerator\", \"eugenesiow/bart-paraphrase\"]: \n",
    "    cfg = Config()\n",
    "    cfg.pp_name  = name\n",
    "    _, pp_model = _prepare_pp_tokenizer_and_model(cfg)\n",
    "    pp_model = pp_model_freeze_layers(cfg, pp_model)\n",
    "    print(\"Number of decoder layers to unfreeze:\", cfg.unfreeze_last_n_layers)\n",
    "    for i, (name, param) in enumerate(pp_model.base_model.named_parameters()): print(i, name, param.requires_grad)\n",
    "    for i, (name, param) in enumerate(pp_model.lm_head.named_parameters()):     assert param.requires_grad \n",
    "    print(\"\\n#################################################\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#hide\n",
    "## Export "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_utils.ipynb.\n",
      "Converted 03_config.ipynb.\n",
      "Converted 07_models.ipynb.\n",
      "Converted 10_data.ipynb.\n",
      "Converted 20_trainer.ipynb.\n",
      "Converted 30_logging.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted run.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
