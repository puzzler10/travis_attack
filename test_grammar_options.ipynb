{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from travis_attack.utils import round_t\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"textattack/albert-base-v2-CoLA\")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"textattack/albert-base-v2-CoLA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "text =['however however tempered elements are the direct antithesis of what is right. ',\n",
    " \"though mild amusing I can't recommend it\",\n",
    " 'this is a film about film living in its own head',\n",
    " 'although small movie impact ',\n",
    " 'even tunney misfire though',\n",
    " 'although somewhat inane cross between xxx and vertical limits',\n",
    " 'Thoughthoughhill may not enough to salvage this boxing movie',\n",
    " 'though though stunning film tour de force.',\n",
    " 'although however Diaz wears her welcome in her performance',\n",
    " 'though though just collection of this and that fills time without unified whole',\n",
    " 'depths of despair believable',\n",
    " 'though who needs love',\n",
    " 'although however the repread of material already plumbed by martin scorsese',\n",
    " 'I thought the watch stopped keeping time as I logged clockstoppers',\n",
    " 'Epps neither charisma nor the natural affability that made tucker star',\n",
    " \"sometimes but because simone is not real she can't provide conflict.\",\n",
    " 'the sweet home stereotype',\n",
    " 'though though plodding teen remake mechanical grease on the plot twists',\n",
    " 'however sadness though not without fun',\n",
    " 'though though delightful coming-of-age story',\n",
    " 'half baked',\n",
    " \"movies to you misty even when you don't want\",\n",
    " 'though though stiff and schmaltzy directed',\n",
    " 'however objects could go long',\n",
    " 'but provoke sexual romp has something',\n",
    " 'maryam now timely',\n",
    " 'however although Ponski found perfect material to address his own World War iI experience in his Signature Style addressed',\n",
    " 'though though many shallower movies these days are shorter',\n",
    " 'it expose the hustler life of male hustlers exploitive without insightful',\n",
    " \"other than that the cast list eye see you junk isn't fooled\",\n",
    " 'although however you must-see list ecks',\n",
    " 'though though the fast runner transports the viewer into space',\n",
    " 'sometimes the movie idiomatic lackluster',\n",
    " 'comedy bonehead summer.',\n",
    " 'even though poor editing bad ultracheesy dialogue about radical action',\n",
    " 'this version justice stevenson both sci-fi genre',\n",
    " 'when i see madonna.',\n",
    " 'she is stylishly directed with verve.',\n",
    " 'singles culture one of the best',\n",
    " 'even if 88 minute highlight reel is longer',\n",
    " 'victim domestic abuse victims pity and terror.',\n",
    " 'although however magical the film not in mysterious spring performances',\n",
    " 'character portrait romantic comedy beat-the-clock thriller',\n",
    " \"eventhough Kusk's brillant here\",\n",
    " 'though though fine movie go see it ',\n",
    " 'however it claims simple diversion for kids',\n",
    " 'cinema movies movies movies',\n",
    " 'though though superior genre storytelling gets under our skin simply crossing the nuclear line',\n",
    " 'although however corpuse count ultimately overrides what little we learn about vicarious redemption',\n",
    " 'though though interesting unfaithfully']\n",
    "#text = [\"hello my name is tom\", \"I liked this movie\", \"I really did enjoy this\"]\n",
    "\n",
    "#mylabels = [1,1,1,1,1,1,1,1,1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import language_tool_python\n",
    "from nlprule import Tokenizer, Rules\n",
    "\n",
    "tokenizer = Tokenizer.load(\"en\")\n",
    "rules = Rules.load(\"en\", tokenizer)\n",
    "#grammar_error_threshold = 0\n",
    "\n",
    "lang_tool = language_tool_python.LanguageTool(\"en-US\", config={ 'cacheSize': 1000, 'pipelineCaching': True})\n",
    "# grammar_error_threshold = grammar_error_threshold\n",
    "# grammar_error_cache = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "??language_tool_python.LanguageTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To ignore: 'category': 'CASING', 'category': 'TYPOS'\n",
    "\n",
    "# to find grammar errors in original sentence\n",
    "#         original_num_errors = self.get_errors(reference_text, use_cache=True)\n",
    "#        errors_added = self.get_errors(transformed_text) - original_num_errors\n",
    "#        return errors_added <= self.grammar_error_threshold\n",
    "\n",
    "# to close tool at the end \n",
    "# tool.close() \n",
    "\n",
    "# 'disabledRuleIds' - a comma-separated list of rule ids that are turned off for this server (optional)\n",
    "'cacheTTLSeconds' - how many seconds sentences are kept in cache (optional, default: 300 if 'cacheSize' is set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lang_tool.disable_spellchecking()\n",
    "lang_tool.disabled_categories.update({'CASING'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "however however tempered elements are the direct antithesis of what is right. \n",
      "[]\n",
      "[Match({'ruleId': 'RB_RB_COMMA', 'message': 'Consider adding a comma between these intensifiers.', 'replacements': ['however, however', 'however'], 'offsetInContext': 0, 'context': 'however however tempered elements are the direct antith...', 'offset': 0, 'errorLength': 15, 'category': 'PUNCTUATION', 'ruleIssueType': 'typographical', 'sentence': 'however however tempered elements are the direct antithesis of what is right.'})]\n",
      "\n",
      "\n",
      "though mild amusing I can't recommend it\n",
      "[]\n",
      "[]\n",
      "\n",
      "\n",
      "this is a film about film living in its own head\n",
      "[]\n",
      "[]\n",
      "\n",
      "\n",
      "although small movie impact \n",
      "[]\n",
      "[]\n",
      "\n",
      "\n",
      "even tunney misfire though\n",
      "[]\n",
      "[Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'message': 'Possible spelling mistake found.', 'replacements': ['Tunney', 'tunnel', 'tunny', 'Tenney', 'Tunja', 'turned', 'Sunday', 'runner', 'runway', 'tune', 'Turkey', 'Turner', 'tunes', 'tunnels', 'funny', 'junta', 'stunned', 'tuned', 'wanna', 'Donna', 'Hanna', 'Tulsa', 'funnel', 'gonna', 'gunned', 'gunner', 'gunnery', 'sunny', 'turkey', 'Tanner', 'Tanya', 'Tonga', 'Yunnan', 'bunny', 'nunnery', 'tannery', 'tuner', 'Jenna', 'Kinney', 'Penney', 'Tania', 'manna', 'tanned', 'tanner', 'tourney', 'Taney', 'Trina', 'henna', 'runny', 'stunner', 'tinned', 'turner', 'turnkey', 'Janna', 'Penna', 'Tonya', 'gurney', 'tinny', 'Tawney', 'gunny', 'senna', 'Tonia', 'punned', 'tenner', 'punnet', 'runnel', 'sunned', 'dunned', 'dunner', 'Dunne', 'Juana', 'funner', 'gunnel', 'tonne', 'tonnes', 'tunnies', 'Buena', 'Finney', 'Gunnar', 'Kenney', 'Sunnah', 'Tacna', 'Tanja', 'Ñuñoa'], 'offsetInContext': 5, 'context': 'even tunney misfire though', 'offset': 5, 'errorLength': 6, 'category': 'TYPOS', 'ruleIssueType': 'misspelling', 'sentence': 'even tunney misfire though'})]\n",
      "\n",
      "\n",
      "although somewhat inane cross between xxx and vertical limits\n",
      "[]\n",
      "[]\n",
      "\n",
      "\n",
      "Thoughthoughhill may not enough to salvage this boxing movie\n",
      "[]\n",
      "[Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'message': 'Possible spelling mistake found.', 'replacements': [], 'offsetInContext': 0, 'context': 'Thoughthoughhill may not enough to salvage this boxing m...', 'offset': 0, 'errorLength': 16, 'category': 'TYPOS', 'ruleIssueType': 'misspelling', 'sentence': 'Thoughthoughhill may not enough to salvage this boxing movie'})]\n",
      "\n",
      "\n",
      "though though stunning film tour de force.\n",
      "[]\n",
      "[Match({'ruleId': 'RB_RB_COMMA', 'message': 'Consider adding a comma between these intensifiers.', 'replacements': ['though, though', 'though'], 'offsetInContext': 0, 'context': 'though though stunning film tour de force.', 'offset': 0, 'errorLength': 13, 'category': 'PUNCTUATION', 'ruleIssueType': 'typographical', 'sentence': 'though though stunning film tour de force.'})]\n",
      "\n",
      "\n",
      "although however Diaz wears her welcome in her performance\n",
      "[]\n",
      "[]\n",
      "\n",
      "\n",
      "though though just collection of this and that fills time without unified whole\n",
      "[]\n",
      "[Match({'ruleId': 'RB_RB_COMMA', 'message': 'Consider adding a comma between these intensifiers.', 'replacements': ['though, though', 'though'], 'offsetInContext': 0, 'context': 'though though just collection of this and that fills ...', 'offset': 0, 'errorLength': 13, 'category': 'PUNCTUATION', 'ruleIssueType': 'typographical', 'sentence': 'though though just collection of this and that fills time without unified whole'})]\n",
      "\n",
      "\n",
      "depths of despair believable\n",
      "[]\n",
      "[]\n",
      "\n",
      "\n",
      "though who needs love\n",
      "[]\n",
      "[]\n",
      "\n",
      "\n",
      "although however the repread of material already plumbed by martin scorsese\n",
      "[]\n",
      "[Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'message': 'Possible spelling mistake found.', 'replacements': ['reread', 'retread', 'rep read'], 'offsetInContext': 21, 'context': 'although however the repread of material already plumbed by martin s...', 'offset': 21, 'errorLength': 7, 'category': 'TYPOS', 'ruleIssueType': 'misspelling', 'sentence': 'although however the repread of material already plumbed by martin scorsese'}), Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'message': 'Possible spelling mistake found.', 'replacements': ['Scorsese', 'scores'], 'offsetInContext': 43, 'context': '...d of material already plumbed by martin scorsese', 'offset': 67, 'errorLength': 8, 'category': 'TYPOS', 'ruleIssueType': 'misspelling', 'sentence': 'although however the repread of material already plumbed by martin scorsese'})]\n",
      "\n",
      "\n",
      "I thought the watch stopped keeping time as I logged clockstoppers\n",
      "[]\n",
      "[Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'message': 'Possible spelling mistake found.', 'replacements': ['clock stoppers', 'clocks toppers'], 'offsetInContext': 43, 'context': '... watch stopped keeping time as I logged clockstoppers', 'offset': 53, 'errorLength': 13, 'category': 'TYPOS', 'ruleIssueType': 'misspelling', 'sentence': 'I thought the watch stopped keeping time as I logged clockstoppers'})]\n",
      "\n",
      "\n",
      "Epps neither charisma nor the natural affability that made tucker star\n",
      "[]\n",
      "[Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'message': 'Possible spelling mistake found.', 'replacements': ['EPP', 'Apps', 'CPPS', 'EOPS', 'EPOS', 'EPS', 'PPS', 'EPs', 'ERPs'], 'offsetInContext': 0, 'context': 'Epps neither charisma nor the natural affabi...', 'offset': 0, 'errorLength': 4, 'category': 'TYPOS', 'ruleIssueType': 'misspelling', 'sentence': 'Epps neither charisma nor the natural affability that made tucker star'})]\n",
      "\n",
      "\n",
      "sometimes but because simone is not real she can't provide conflict.\n",
      "[]\n",
      "[Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'message': 'Possible spelling mistake found.', 'replacements': ['Simone', 'Simon', 'simony', 'sim one', 'Simona', 'Simón', 'someone', 'simple', 'stone', 'Stone', 'smoke', 'Simmons', 'sine', 'kimono', 'shone', 'simile', 'scone', 'smote', 'Timon', 'simonize', 'Limón', 'Simeon', 'Sion'], 'offsetInContext': 22, 'context': \"sometimes but because simone is not real she can't provide conflict....\", 'offset': 22, 'errorLength': 6, 'category': 'TYPOS', 'ruleIssueType': 'misspelling', 'sentence': \"sometimes but because simone is not real she can't provide conflict.\"})]\n",
      "\n",
      "\n",
      "the sweet home stereotype\n",
      "[]\n",
      "[]\n",
      "\n",
      "\n",
      "though though plodding teen remake mechanical grease on the plot twists\n",
      "[]\n",
      "[Match({'ruleId': 'ENGLISH_WORD_REPEAT_RULE', 'message': 'Possible typo: you repeated a word', 'replacements': ['though'], 'offsetInContext': 0, 'context': 'though though plodding teen remake mechanical grease ...', 'offset': 0, 'errorLength': 13, 'category': 'MISC', 'ruleIssueType': 'duplication', 'sentence': 'though though plodding teen remake mechanical grease on the plot twists'})]\n",
      "\n",
      "\n",
      "however sadness though not without fun\n",
      "[]\n",
      "[]\n",
      "\n",
      "\n",
      "though though delightful coming-of-age story\n",
      "[]\n",
      "[Match({'ruleId': 'RB_RB_COMMA', 'message': 'Consider adding a comma between these intensifiers.', 'replacements': ['though, though', 'though'], 'offsetInContext': 0, 'context': 'though though delightful coming-of-age story', 'offset': 0, 'errorLength': 13, 'category': 'PUNCTUATION', 'ruleIssueType': 'typographical', 'sentence': 'though though delightful coming-of-age story'})]\n",
      "\n",
      "\n",
      "half baked\n",
      "[]\n",
      "[Match({'ruleId': 'EN_COMPOUNDS', 'message': 'This word is normally spelled with a hyphen.', 'replacements': ['half-baked'], 'offsetInContext': 0, 'context': 'half baked', 'offset': 0, 'errorLength': 10, 'category': 'MISC', 'ruleIssueType': 'misspelling', 'sentence': 'half baked'})]\n",
      "\n",
      "\n",
      "movies to you misty even when you don't want\n",
      "[]\n",
      "[]\n",
      "\n",
      "\n",
      "though though stiff and schmaltzy directed\n",
      "[]\n",
      "[Match({'ruleId': 'RB_RB_COMMA', 'message': 'Consider adding a comma between these intensifiers.', 'replacements': ['though, though', 'though'], 'offsetInContext': 0, 'context': 'though though stiff and schmaltzy directed', 'offset': 0, 'errorLength': 13, 'category': 'PUNCTUATION', 'ruleIssueType': 'typographical', 'sentence': 'though though stiff and schmaltzy directed'})]\n",
      "\n",
      "\n",
      "however objects could go long\n",
      "[]\n",
      "[]\n",
      "\n",
      "\n",
      "but provoke sexual romp has something\n",
      "[]\n",
      "[]\n",
      "\n",
      "\n",
      "maryam now timely\n",
      "[]\n",
      "[Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'message': 'Possible spelling mistake found.', 'replacements': ['Maryam', 'mar yam', 'Mariam', 'Mary', 'Maria', 'Maya', 'Aryan', 'Marian', 'Mara', 'Markham', 'Marley', 'Marta', 'Mayan', 'Miriam', 'Magyar', 'madam', 'Marat', 'Marla', 'maria', 'Marva', 'Maryann', 'Mayas', 'Mayra', 'ARYM', 'Madam', 'Markab', 'Mauryan', 'Mirzam', 'Aaryan', 'Arya', 'Darya', 'Mariah', 'Mariyah', 'María', 'Maurya', 'Myriam', \"ma'am\"], 'offsetInContext': 0, 'context': 'maryam now timely', 'offset': 0, 'errorLength': 6, 'category': 'TYPOS', 'ruleIssueType': 'misspelling', 'sentence': 'maryam now timely'})]\n",
      "\n",
      "\n",
      "however although Ponski found perfect material to address his own World War iI experience in his Signature Style addressed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'message': 'Possible spelling mistake found.', 'replacements': ['Bonsai', 'Polanski', 'Nonskid', 'Polska', 'Ponzi', 'Pons'], 'offsetInContext': 17, 'context': 'however although Ponski found perfect material to address his o...', 'offset': 17, 'errorLength': 6, 'category': 'TYPOS', 'ruleIssueType': 'misspelling', 'sentence': 'however although Ponski found perfect material to address his own World War iI experience in his Signature Style addressed'}), Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'message': 'Possible spelling mistake found.', 'replacements': ['ii', 'in', 'is', 'I', 'it', 'if', 'ID', 'IQ', 'id', 'GI', 'IIT', 'Wii', 'hi', 'pi', 'IH', 'IPI', 'IP', 'AI', 'AII', 'BII', 'Bi', 'CI', 'CII', 'Ci', 'DI', 'Di', 'EI', 'FI', 'FII', 'HI', 'IA', 'IAI', 'ICI', 'IE', 'IF', 'IFI', 'IGI', 'IIA', 'IIC', 'IIF', 'IIM', 'IIN', 'IIS', 'IJ', 'IL', 'IN', 'IOI', 'IR', 'IRI', 'IS', 'ISI', 'IT', 'IV', 'IVI', 'IZ', 'Ia', 'In', 'Io', 'Ir', 'It', 'LI', 'Li', 'MI', 'NI', 'Ni', 'QI', 'RI', 'SI', 'SII', 'Si', 'TI', 'Ti', 'UI', 'VI', 'WI', 'Xi', 'ZI', 'bi', 'i', 'iii', 'iv', 'ix', 'lii', 'mi', 'oi', 'ti', 'vi', 'vii', 'xi', 'xii', 'i I', 'IB', 'IC', 'IG', 'IM', 'INI', 'IU', 'Yi', 'ai'], 'offsetInContext': 43, 'context': '...t material to address his own World War iI experience in his Signature Style addre...', 'offset': 76, 'errorLength': 2, 'category': 'TYPOS', 'ruleIssueType': 'misspelling', 'sentence': 'however although Ponski found perfect material to address his own World War iI experience in his Signature Style addressed'}), Match({'ruleId': 'HE_VERB_AGR', 'message': 'The singular proper name ‘iI’ must be used with a third-person or a past tense verb.', 'replacements': ['experiences', 'experienced'], 'offsetInContext': 43, 'context': '...aterial to address his own World War iI experience in his Signature Style addressed', 'offset': 79, 'errorLength': 10, 'category': 'GRAMMAR', 'ruleIssueType': 'grammar', 'sentence': 'however although Ponski found perfect material to address his own World War iI experience in his Signature Style addressed'})]\n",
      "\n",
      "\n",
      "though though many shallower movies these days are shorter\n",
      "[]\n",
      "[Match({'ruleId': 'ENGLISH_WORD_REPEAT_RULE', 'message': 'Possible typo: you repeated a word', 'replacements': ['though'], 'offsetInContext': 0, 'context': 'though though many shallower movies these days are sh...', 'offset': 0, 'errorLength': 13, 'category': 'MISC', 'ruleIssueType': 'duplication', 'sentence': 'though though many shallower movies these days are shorter'})]\n",
      "\n",
      "\n",
      "it expose the hustler life of male hustlers exploitive without insightful\n",
      "[]\n",
      "[Match({'ruleId': 'IT_VBZ', 'message': 'After ‘it’, use the third-person verb form “exposes”.', 'replacements': ['exposes'], 'offsetInContext': 3, 'context': 'it expose the hustler life of male hustlers explo...', 'offset': 3, 'errorLength': 6, 'category': 'GRAMMAR', 'ruleIssueType': 'grammar', 'sentence': 'it expose the hustler life of male hustlers exploitive without insightful'})]\n",
      "\n",
      "\n",
      "other than that the cast list eye see you junk isn't fooled\n",
      "[]\n",
      "[]\n",
      "\n",
      "\n",
      "although however you must-see list ecks\n",
      "[]\n",
      "[Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'message': 'Possible spelling mistake found.', 'replacements': ['decks', 'necks', 'pecks', 'becks', 'elks', 'ecus', 'CKS', 'ECS', 'ECTS', 'CKs', 'ECDs', 'ECTs', 'écus'], 'offsetInContext': 35, 'context': 'although however you must-see list ecks', 'offset': 35, 'errorLength': 4, 'category': 'TYPOS', 'ruleIssueType': 'misspelling', 'sentence': 'although however you must-see list ecks'})]\n",
      "\n",
      "\n",
      "though though the fast runner transports the viewer into space\n",
      "[]\n",
      "[Match({'ruleId': 'ENGLISH_WORD_REPEAT_RULE', 'message': 'Possible typo: you repeated a word', 'replacements': ['though'], 'offsetInContext': 0, 'context': 'though though the fast runner transports the viewer i...', 'offset': 0, 'errorLength': 13, 'category': 'MISC', 'ruleIssueType': 'duplication', 'sentence': 'though though the fast runner transports the viewer into space'})]\n",
      "\n",
      "\n",
      "sometimes the movie idiomatic lackluster\n",
      "[]\n",
      "[]\n",
      "\n",
      "\n",
      "comedy bonehead summer.\n",
      "[]\n",
      "[]\n",
      "\n",
      "\n",
      "even though poor editing bad ultracheesy dialogue about radical action\n",
      "[]\n",
      "[Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'message': 'Possible spelling mistake found.', 'replacements': [], 'offsetInContext': 29, 'context': 'even though poor editing bad ultracheesy dialogue about radical action', 'offset': 29, 'errorLength': 11, 'category': 'TYPOS', 'ruleIssueType': 'misspelling', 'sentence': 'even though poor editing bad ultracheesy dialogue about radical action'})]\n",
      "\n",
      "\n",
      "this version justice stevenson both sci-fi genre\n",
      "[]\n",
      "[Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'message': 'Possible spelling mistake found.', 'replacements': ['Stevenson', 'Stevens', 'Stephenson'], 'offsetInContext': 21, 'context': 'this version justice stevenson both sci-fi genre', 'offset': 21, 'errorLength': 9, 'category': 'TYPOS', 'ruleIssueType': 'misspelling', 'sentence': 'this version justice stevenson both sci-fi genre'})]\n",
      "\n",
      "\n",
      "when i see madonna.\n",
      "[<nlprule.Suggestion object at 0x2b1ca7213d30>]\n",
      "[Match({'ruleId': 'I_LOWERCASE', 'message': 'The personal pronoun “I” should be uppercase.', 'replacements': ['I'], 'offsetInContext': 5, 'context': 'when i see madonna.', 'offset': 5, 'errorLength': 1, 'category': 'TYPOS', 'ruleIssueType': 'misspelling', 'sentence': 'when i see madonna.'}), Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'message': 'Possible spelling mistake found.', 'replacements': ['Madonna', 'Madonnas', 'Ladonna', 'Donna', 'manna'], 'offsetInContext': 11, 'context': 'when i see madonna.', 'offset': 11, 'errorLength': 7, 'category': 'TYPOS', 'ruleIssueType': 'misspelling', 'sentence': 'when i see madonna.'})]\n",
      "\n",
      "\n",
      "she is stylishly directed with verve.\n",
      "[]\n",
      "[]\n",
      "\n",
      "\n",
      "singles culture one of the best\n",
      "[]\n",
      "[]\n",
      "\n",
      "\n",
      "even if 88 minute highlight reel is longer\n",
      "[]\n",
      "[]\n",
      "\n",
      "\n",
      "victim domestic abuse victims pity and terror.\n",
      "[]\n",
      "[]\n",
      "\n",
      "\n",
      "although however magical the film not in mysterious spring performances\n",
      "[]\n",
      "[]\n",
      "\n",
      "\n",
      "character portrait romantic comedy beat-the-clock thriller\n",
      "[]\n",
      "[]\n",
      "\n",
      "\n",
      "eventhough Kusk's brillant here\n",
      "[]\n",
      "[Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'message': 'Possible spelling mistake found.', 'replacements': ['even though'], 'offsetInContext': 0, 'context': \"eventhough Kusk's brillant here\", 'offset': 0, 'errorLength': 10, 'category': 'TYPOS', 'ruleIssueType': 'misspelling', 'sentence': \"eventhough Kusk's brillant here\"}), Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'message': 'Possible spelling mistake found.', 'replacements': ['Dusk', 'Musk', 'Husk', 'Tusk', 'Rusk', 'Busk', 'KUSC', 'Kursk', 'Kush'], 'offsetInContext': 11, 'context': \"eventhough Kusk's brillant here\", 'offset': 11, 'errorLength': 4, 'category': 'TYPOS', 'ruleIssueType': 'misspelling', 'sentence': \"eventhough Kusk's brillant here\"}), Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'message': 'Possible spelling mistake found.', 'replacements': ['brilliant', 'brill ant'], 'offsetInContext': 18, 'context': \"eventhough Kusk's brillant here\", 'offset': 18, 'errorLength': 8, 'category': 'TYPOS', 'ruleIssueType': 'misspelling', 'sentence': \"eventhough Kusk's brillant here\"})]\n",
      "\n",
      "\n",
      "though though fine movie go see it \n",
      "[]\n",
      "[Match({'ruleId': 'RB_RB_COMMA', 'message': 'Consider adding a comma between these intensifiers.', 'replacements': ['though, though', 'though'], 'offsetInContext': 0, 'context': 'though though fine movie go see it ', 'offset': 0, 'errorLength': 13, 'category': 'PUNCTUATION', 'ruleIssueType': 'typographical', 'sentence': 'though though fine movie go see it'})]\n",
      "\n",
      "\n",
      "however it claims simple diversion for kids\n",
      "[]\n",
      "[]\n",
      "\n",
      "\n",
      "cinema movies movies movies\n",
      "[]\n",
      "[]\n",
      "\n",
      "\n",
      "though though superior genre storytelling gets under our skin simply crossing the nuclear line\n",
      "[]\n",
      "[Match({'ruleId': 'RB_RB_COMMA', 'message': 'Consider adding a comma between these intensifiers.', 'replacements': ['though, though', 'though'], 'offsetInContext': 0, 'context': 'though though superior genre storytelling gets under ...', 'offset': 0, 'errorLength': 13, 'category': 'PUNCTUATION', 'ruleIssueType': 'typographical', 'sentence': 'though though superior genre storytelling gets under our skin simply crossing the nuclear line'})]\n",
      "\n",
      "\n",
      "although however corpuse count ultimately overrides what little we learn about vicarious redemption\n",
      "[]\n",
      "[Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'message': 'Possible spelling mistake found.', 'replacements': ['corpse', 'corpus', 'corp use', 'corpuses'], 'offsetInContext': 17, 'context': 'although however corpuse count ultimately overrides what little ...', 'offset': 17, 'errorLength': 7, 'category': 'TYPOS', 'ruleIssueType': 'misspelling', 'sentence': 'although however corpuse count ultimately overrides what little we learn about vicarious redemption'})]\n",
      "\n",
      "\n",
      "though though interesting unfaithfully\n",
      "[]\n",
      "[Match({'ruleId': 'RB_RB_COMMA', 'message': 'Consider adding a comma between these intensifiers.', 'replacements': ['though, though', 'though'], 'offsetInContext': 0, 'context': 'though though interesting unfaithfully', 'offset': 0, 'errorLength': 13, 'category': 'PUNCTUATION', 'ruleIssueType': 'typographical', 'sentence': 'though though interesting unfaithfully'})]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for x in text: \n",
    "    print(x)\n",
    "    match = lang_tool.check(x)\n",
    "    print(rules.suggest(x))\n",
    "    print(match)\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                self.grammar_error_cache[text] = len(self.lang_tool.check(text))\n",
    "            return self.grammar_error_cache[text]\n",
    "        else:\n",
    "            return len(self.lang_tool.check(text))\n",
    "\n",
    "\n",
    "    def _check_constraint(self, transformed_text, reference_text):\n",
    "        original_num_errors = self.get_errors(reference_text, use_cache=True)\n",
    "        errors_added = self.get_errors(transformed_text) - original_num_errors\n",
    "        return errors_added <= self.grammar_error_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'language_tool_python' from '/home/tproth/Programs/miniconda/envs/nlp_env/lib/python3.8/site-packages/language_tool_python/__init__.py'>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "language_tool_python.LanguageTool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = tokenizer(text, padding=True, return_tensors=\"pt\").to('cuda')\n",
    "#input_ids, attention_mask = encoding[\"input_ids\"].to(device), encoding[\"attention_mask\"].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cola_model = model \n",
    "cola_tokenizer = tokenizer\n",
    "def get_cola_probs(pp_l, cfg, cola_tokenizer, cola_model): \n",
    "    inputs = cola_tokenizer(pp_l, return_tensors=\"pt\", padding=True, truncation=True).to(cfg.device)\n",
    "    with torch.no_grad():\n",
    "        logits = cola_model(**inputs).logits\n",
    "        probs = logits.softmax(1)\n",
    "    return probs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.83 0.17] however however tempered elements are the direct antithesis of what is right. \n",
      "[0.34 0.66] though mild amusing I can't recommend it\n",
      "[0.03 0.97] this is a film about film living in its own head\n",
      "[0.95 0.05] although small movie impact \n",
      "[0.35 0.65] even tunney misfire though\n",
      "[0.71 0.29] although somewhat inane cross between xxx and vertical limits\n",
      "[0.97 0.03] Thoughthoughhill may not enough to salvage this boxing movie\n",
      "[0.97 0.03] though though stunning film tour de force.\n",
      "[0.93 0.07] although however Diaz wears her welcome in her performance\n",
      "[0.78 0.22] though though just collection of this and that fills time without unified whole\n",
      "[0.31 0.69] depths of despair believable\n",
      "[0.64 0.36] though who needs love\n",
      "[0.94 0.06] although however the repread of material already plumbed by martin scorsese\n",
      "[0.56 0.44] I thought the watch stopped keeping time as I logged clockstoppers\n",
      "[0.85 0.15] Epps neither charisma nor the natural affability that made tucker star\n",
      "[0.57 0.43] sometimes but because simone is not real she can't provide conflict.\n",
      "[0.5 0.5] the sweet home stereotype\n",
      "[0.98 0.02] though though plodding teen remake mechanical grease on the plot twists\n",
      "[0.93 0.07] however sadness though not without fun\n",
      "[0.95 0.05] though though delightful coming-of-age story\n",
      "[0.19 0.81] half baked\n",
      "[0.98 0.02] movies to you misty even when you don't want\n",
      "[0.89 0.11] though though stiff and schmaltzy directed\n",
      "[0.05 0.95] however objects could go long\n",
      "[0.31 0.69] but provoke sexual romp has something\n",
      "[0.85 0.15] maryam now timely\n",
      "[0.73 0.27] however although Ponski found perfect material to address his own World War iI experience in his Signature Style addressed\n",
      "[0.62 0.38] though though many shallower movies these days are shorter\n",
      "[0.97 0.03] it expose the hustler life of male hustlers exploitive without insightful\n",
      "[0.93 0.07] other than that the cast list eye see you junk isn't fooled\n",
      "[0.97 0.03] although however you must-see list ecks\n",
      "[0.48 0.52] though though the fast runner transports the viewer into space\n",
      "[0.94 0.06] sometimes the movie idiomatic lackluster\n",
      "[0.63 0.37] comedy bonehead summer.\n",
      "[0.71 0.29] even though poor editing bad ultracheesy dialogue about radical action\n",
      "[0.77 0.23] this version justice stevenson both sci-fi genre\n",
      "[0.95 0.05] when i see madonna.\n",
      "[0.06 0.94] she is stylishly directed with verve.\n",
      "[0.69 0.31] singles culture one of the best\n",
      "[0.88 0.12] even if 88 minute highlight reel is longer\n",
      "[0.94 0.06] victim domestic abuse victims pity and terror.\n",
      "[0.92 0.08] although however magical the film not in mysterious spring performances\n",
      "[0.44 0.56] character portrait romantic comedy beat-the-clock thriller\n",
      "[0.19 0.81] eventhough Kusk's brillant here\n",
      "[0.97 0.03] though though fine movie go see it \n",
      "[0.82 0.18] however it claims simple diversion for kids\n",
      "[0.53 0.47] cinema movies movies movies\n",
      "[0.9 0.1] though though superior genre storytelling gets under our skin simply crossing the nuclear line\n",
      "[0.95 0.05] although however corpuse count ultimately overrides what little we learn about vicarious redemption\n",
      "[0.95 0.05] though though interesting unfaithfully\n"
     ]
    }
   ],
   "source": [
    "model_output = model(**encoding)\n",
    "probs = torch.softmax(model_output.logits,1)\n",
    "\n",
    "for p,t in zip(probs,text): \n",
    "    print(round_t(p), t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Impressions: \n",
    "    * first random batch of 10, me and the model agreed with 9.\n",
    "    * second random batch of 10, me and the model agreed on all (though they were mostly all bad)\n",
    "    * third batch, agreed with 9/10\n",
    "    * fourth batch from simple dataset, we agreed on all. I'm fine with random punctuation and the model seems to be okay with it for the most part. \n",
    "    * fifth batch, we agreed on 8/10. \n",
    "    * sixth batch, i put in a bunch of original examples. it agreed with 9/10, then 10/10\n",
    "    * finally I made a bunch of paraphrases myself. It liked 9/10. \n",
    "    \n",
    "The best thing about it is that it gets rid of the absolute trash. Sometimes it seems to put a valid sentence as invalid but overall it does pretty well. \n",
    "   \n",
    "I think we can go with this and set the cutoff maybe to a class 0 rating ( acceptable) of 0.5 - so if we get higher than this probability for \"crap\" then we ditch it. keep this the same way round as sts score. \n",
    "cola_acceptable_threshold = 0.5\n",
    "   \n",
    "   \n",
    "maybe this is hard for shorter sentences? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Connection error, and we cannot find the requested files in the cached path. Please try again or make sure your Internet connection is on.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-1f270cefd41f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mgf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGramformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_gpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 1=corrector, 2=detector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m influent_sentences = [\n",
      "\u001b[0;32m~/Programs/miniconda/envs/nlp_env/lib/python3.8/site-packages/gramformer/gramformer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, models, use_gpu)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmodels\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorrection_tokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorrection_model_tag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorrection_model\u001b[0m     \u001b[0;34m=\u001b[0m \u001b[0mAutoModelForSeq2SeqLM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorrection_model_tag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorrection_model\u001b[0m     \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorrection_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Programs/miniconda/envs/nlp_env/lib/python3.8/site-packages/transformers/models/auto/tokenization_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    496\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0;31m# Next, let's try to use the tokenizer_config file to get the tokenizer class.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m         \u001b[0mtokenizer_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_tokenizer_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m         \u001b[0mconfig_tokenizer_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tokenizer_class\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[0mtokenizer_auto_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Programs/miniconda/envs/nlp_env/lib/python3.8/site-packages/transformers/models/auto/tokenization_auto.py\u001b[0m in \u001b[0;36mget_tokenizer_config\u001b[0;34m(pretrained_model_name_or_path, cache_dir, force_download, resume_download, proxies, use_auth_token, revision, local_files_only, **kwargs)\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0mtokenizer_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_tokenizer_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tokenizer-test\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m     ```\"\"\"\n\u001b[0;32m--> 359\u001b[0;31m     resolved_config_file = get_file_from_repo(\n\u001b[0m\u001b[1;32m    360\u001b[0m         \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0mTOKENIZER_CONFIG_FILE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Programs/miniconda/envs/nlp_env/lib/python3.8/site-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mget_file_from_repo\u001b[0;34m(path_or_repo, filename, cache_dir, force_download, resume_download, proxies, use_auth_token, revision, local_files_only)\u001b[0m\n\u001b[1;32m    676\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m         \u001b[0;31m# Load from URL or cache if already cached\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         resolved_file = cached_path(\n\u001b[0m\u001b[1;32m    679\u001b[0m             \u001b[0mresolved_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m             \u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Programs/miniconda/envs/nlp_env/lib/python3.8/site-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_path\u001b[0;34m(url_or_filename, cache_dir, force_download, proxies, resume_download, user_agent, extract_compressed_file, force_extract, use_auth_token, local_files_only)\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_remote_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_or_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0;31m# URL, so get it from the cache (downloading if necessary)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m         output_path = get_from_cache(\n\u001b[0m\u001b[1;32m    283\u001b[0m             \u001b[0murl_or_filename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m             \u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Programs/miniconda/envs/nlp_env/lib/python3.8/site-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mget_from_cache\u001b[0;34m(url, cache_dir, force_download, proxies, etag_timeout, resume_download, user_agent, use_auth_token, local_files_only)\u001b[0m\n\u001b[1;32m    543\u001b[0m                     )\n\u001b[1;32m    544\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m                     raise ValueError(\n\u001b[0m\u001b[1;32m    546\u001b[0m                         \u001b[0;34m\"Connection error, and we cannot find the requested files in the cached path.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m                         \u001b[0;34m\" Please try again or make sure your Internet connection is on.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Connection error, and we cannot find the requested files in the cached path. Please try again or make sure your Internet connection is on."
     ]
    }
   ],
   "source": [
    "from gramformer import Gramformer\n",
    "\n",
    "\n",
    "gf = Gramformer(models = 1, use_gpu=False) # 1=corrector, 2=detector\n",
    "\n",
    "influent_sentences = [\n",
    "    \"He are moving here.\",\n",
    "    \"the collection of letters was original used by the ancient Romans\",\n",
    "    \"We enjoys horror movies\",\n",
    "    \"Anna and Mike is going skiing\",\n",
    "    \"I will eat fish for dinner and drank milk\",\n",
    "    \"what be the reason for everyone leave the comapny\"\n",
    "]   \n",
    "\n",
    "for influent_sentence in influent_sentences:\n",
    "    corrected_sentences = gf.correct(influent_sentence, max_candidates=1)\n",
    "    print(\"[Input] \", influent_sentence)\n",
    "    for corrected_sentence in corrected_sentences:\n",
    "      print(\"[Edits] \", gf.get_edits(influent_sentence, corrected_sentence))\n",
    "    print(\"-\" *100)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
